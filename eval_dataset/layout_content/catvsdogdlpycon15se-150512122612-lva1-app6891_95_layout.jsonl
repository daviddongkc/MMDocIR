{"layout": 0, "type": "text", "text": "Deep Learning: ", "text_level": 1, "page_idx": 0, "bbox": [170, 79, 598, 134], "page_size": [768.0, 576.0]}
{"layout": 1, "type": "text", "text": "and Deep Data-Science ", "text_level": 1, "page_idx": 0, "bbox": [107, 152, 660, 198], "page_size": [768.0, 576.0]}
{"layout": 2, "type": "image", "page_idx": 0, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_0.jpg", "bbox": [237, 201, 506, 376], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a cat and a dog facing each other against a green checkered background. The text \"CAT vs DOG\" is displayed below them."}
{"layout": 3, "type": "image", "page_idx": 0, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_1.jpg", "bbox": [82, 327, 167, 412], "page_size": [768.0, 576.0], "ocr_text": "ah\n\na rae zs\n", "vlm_text": "The image shows a logo with a blue background. In the center, there is a crown at the top of a wreath. Inside the wreath, the text reads \"KTH VETENSKAP OCH KONST.\" This is the emblem of the KTH Royal Institute of Technology in Sweden."}
{"layout": 4, "type": "text", "text": "12May2015 ", "page_idx": 0, "bbox": [312, 394, 433, 412], "page_size": [768.0, 576.0]}
{"layout": 5, "type": "text", "text": "ROYAL INSTITUTE OF TECHNOLOGY ", "page_idx": 0, "bbox": [86, 420, 163, 434], "page_size": [768.0, 576.0]}
{"layout": 6, "type": "text", "text": "Graph Technologies R&D roelof@graph-technologies.com ", "page_idx": 0, "bbox": [425, 435, 746, 492], "page_size": [768.0, 576.0]}
{"layout": 7, "type": "text", "text": "roelof@kth.se www.csc.kth.se/-roelof/ ", "page_idx": 0, "bbox": [18, 446, 254, 492], "page_size": [768.0, 576.0]}
{"layout": 8, "type": "text", "text": "slides online at: ", "page_idx": 0, "bbox": [321, 514, 472, 530], "page_size": [768.0, 576.0]}
{"layout": 9, "type": "text", "text": "BUT FIRST ", "text_level": 1, "page_idx": 1, "bbox": [212, 38, 516, 90], "page_size": [768.0, 576.0]}
{"layout": 10, "type": "text", "text": "are you a CATPERSON? ", "page_idx": 1, "bbox": [298, 112, 413, 130], "page_size": [768.0, 576.0]}
{"layout": 11, "type": "text", "text": "", "page_idx": 1, "bbox": [102, 151, 268, 171], "page_size": [768.0, 576.0]}
{"layout": 12, "type": "image", "page_idx": 1, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_2.jpg", "bbox": [30, 195, 328, 555], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "This image is a humorous or edited photo showing a person sitting and holding a cat. The person's head has been replaced with the head of a cat, making it look like a human with a cat head holding a regular cat."}
{"layout": 13, "type": "text", "text": "DOG PERSON? ", "page_idx": 1, "bbox": [488, 150, 661, 172], "page_size": [768.0, 576.0]}
{"layout": 14, "type": "image", "page_idx": 1, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_3.jpg", "bbox": [404, 202, 743, 552], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a digitally manipulated creature that has the body of a dog but with human facial features, like eyes and lips."}
{"layout": 15, "type": "text", "text": "in the next few minutes we'llbe making a ", "page_idx": 2, "bbox": [180, 12, 553, 83], "page_size": [768.0, 576.0]}
{"layout": 16, "type": "image", "page_idx": 2, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_4.jpg", "bbox": [67, 95, 699, 487], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a cat and a dog facing each other with the words \"CAT vs DOG\" below them. The background is a green pattern with squares and circles."}
{"layout": 17, "type": "text", "text": "DETECTOR ", "page_idx": 2, "bbox": [232, 504, 535, 547], "page_size": [768.0, 576.0]}
{"layout": 18, "type": "text", "text": "main Libraries ", "text_level": 1, "page_idx": 3, "bbox": [189, 33, 583, 95], "page_size": [768.0, 576.0]}
{"layout": 19, "type": "text", "text": "sckikit-learn(machine learning) http://scikit-learn.org caffe(deep learning)-for training deep neural nets （for today:loading a pre-trained one)http://caffe.berkeley vision.org ", "page_idx": 3, "bbox": [63, 139, 701, 334], "page_size": [768.0, 576.0]}
{"layout": 20, "type": "text", "text": "theano(efficient gpu-powered math) http://www.deep learning.net/software/theano/ ", "page_idx": 3, "bbox": [63, 369, 652, 430], "page_size": [768.0, 576.0]}
{"layout": 21, "type": "text", "text": "oi python notebook http://ipython.org/notebook.html ", "page_idx": 3, "bbox": [63, 467, 486, 525], "page_size": [768.0, 576.0]}
{"layout": 22, "type": "text", "text": "scikit-learn ", "text_level": 1, "page_idx": 4, "bbox": [394, 78, 646, 113], "page_size": [768.0, 576.0]}
{"layout": 23, "type": "image", "page_idx": 4, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_5.jpg", "bbox": [90, 79, 385, 233], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image depicts several subplots showing decision boundaries of different machine learning models applied to a classification problem. Each subplot likely uses a different algorithm, such as k-Nearest Neighbors, Linear SVM, RBF SVM, Decision Trees, Random Forests, and AdaBoost. The regions are colored to indicate the areas classified for each class, with scatter plots of data points marked as well."}
{"layout": 24, "type": "text", "text": "Machine Leaming in Python ", "page_idx": 4, "bbox": [394, 115, 557, 127], "page_size": [768.0, 576.0]}
{"layout": 25, "type": "text", "text": "Simple and efficient toolsfor data mining and data analysis Accessible to everybody,and reusable in various contexts Builton NumPy,SciPy.and matplotlib Open source,commercially usable-BSD license ", "page_idx": 4, "bbox": [412, 143, 732, 219], "page_size": [768.0, 576.0]}
{"layout": 26, "type": "text", "text": "Classification ", "text_level": 1, "page_idx": 4, "bbox": [38, 273, 149, 290], "page_size": [768.0, 576.0]}
{"layout": 27, "type": "text", "text": "Clustering ", "text_level": 1, "page_idx": 4, "bbox": [511, 273, 595, 291], "page_size": [768.0, 576.0]}
{"layout": 28, "type": "text", "text": "Regression ", "text_level": 1, "page_idx": 4, "bbox": [274, 274, 367, 290], "page_size": [768.0, 576.0]}
{"layout": 29, "type": "text", "text": "Predicting a continuous-valued attribute associated with an object Applications:Drug response,Stock prices. Algorithms:SVR,ridge regression Lasso,.. -Examples ", "page_idx": 4, "bbox": [290, 307, 493, 399], "page_size": [768.0, 576.0]}
{"layout": 30, "type": "text", "text": "Automatic grouping of similar objects intosets. Applications:Customer segmentation, Grouping experiment outcomes Algorithms:k-Means,spectral clustering,mean-shift,... -Examples ", "page_idx": 4, "bbox": [526, 307, 732, 398], "page_size": [768.0, 576.0]}
{"layout": 31, "type": "text", "text": "l dent if ying to which category anobject belongsto. Applications:Spam detection,lmage recognition. Algorithms:SVM,nearest neighbors random forest,... -Examples ", "page_idx": 4, "bbox": [53, 307, 257, 398], "page_size": [768.0, 576.0]}
{"layout": 32, "type": "text", "text": "Dimensionality reduction ", "text_level": 1, "page_idx": 4, "bbox": [38, 434, 241, 451], "page_size": [768.0, 576.0]}
{"layout": 33, "type": "text", "text": "Model selection ", "text_level": 1, "page_idx": 4, "bbox": [274, 434, 403, 451], "page_size": [768.0, 576.0]}
{"layout": 34, "type": "text", "text": "Preprocessing ", "text_level": 1, "page_idx": 4, "bbox": [511, 435, 629, 452], "page_size": [768.0, 576.0]}
{"layout": 35, "type": "text", "text": "Reducing the number of random variables to consider. ", "page_idx": 4, "bbox": [53, 467, 217, 493], "page_size": [768.0, 576.0]}
{"layout": 36, "type": "text", "text": "Feature extraction and normalization ", "page_idx": 4, "bbox": [526, 468, 710, 477], "page_size": [768.0, 576.0]}
{"layout": 37, "type": "text", "text": "Comparing,validating and choosing parameters and models. Goal:lm proved accuracy via parameter tuning Modules:grid search,cross validation metrics. ", "page_idx": 4, "bbox": [290, 467, 487, 559], "page_size": [768.0, 576.0]}
{"layout": 38, "type": "text", "text": "Application:Transforming input data suchas text for use with machine learning algorithms. Modules:preprocessing,feature extraction. ", "page_idx": 4, "bbox": [526, 489, 710, 556], "page_size": [768.0, 576.0]}
{"layout": 39, "type": "text", "text": "Applications:Visualization.Increased efficiency Algorithms:PCA,feature selection, non-negative matrix factorization ", "page_idx": 4, "bbox": [53, 505, 245, 559], "page_size": [768.0, 576.0]}
{"layout": 40, "type": "text", "text": "Caffe ", "text_level": 1, "page_idx": 5, "bbox": [22, 30, 79, 53], "page_size": [768.0, 576.0]}
{"layout": 41, "type": "text", "text": "Deep learning framework bytheBVLC ", "page_idx": 5, "bbox": [23, 73, 153, 103], "page_size": [768.0, 576.0]}
{"layout": 42, "type": "text", "text": "Createdby Yang qing Jia Lead Developer Evan Shelhamer ", "page_idx": 5, "bbox": [23, 126, 105, 195], "page_size": [768.0, 576.0]}
{"layout": 43, "type": "text", "text": "JMiew On GitHub ", "page_idx": 5, "bbox": [39, 223, 126, 231], "page_size": [768.0, 576.0]}
{"layout": 44, "type": "text", "text": "Caffe ", "text_level": 1, "page_idx": 5, "bbox": [225, 30, 282, 53], "page_size": [768.0, 576.0]}
{"layout": 45, "type": "text", "text": "Caffeisa deep learning framework made with expression,speed,and modular it yin mind.ltis developed by the Berkeley Vision and Learning Center(BVLC)andby community contributors. Yang qing Jia created theproject during his PhD at UCBerkeley.Caff e is released under theBSD 2- Clause license. ", "page_idx": 5, "bbox": [225, 73, 723, 142], "page_size": [768.0, 576.0]}
{"layout": 46, "type": "text", "text": "Checkout our web image classification demo! ", "page_idx": 5, "bbox": [225, 165, 458, 176], "page_size": [768.0, 576.0]}
{"layout": 47, "type": "text", "text": "WhyCaffe? ", "text_level": 1, "page_idx": 5, "bbox": [226, 209, 323, 231], "page_size": [768.0, 576.0]}
{"layout": 48, "type": "text", "text": "Expressive architecture encourages application and innovation.Models and optimization are defined by configuration without hard-coding.Switch between CPU and GPUby setting a single flag to train on a GPumachine then deploy to commodity clusters or mobile devices ", "page_idx": 5, "bbox": [226, 249, 729, 298], "page_size": [768.0, 576.0]}
{"layout": 49, "type": "text", "text": "Extensible code fosters active development.InCaffe'sfirstyear,it has been forked by over 1,oo0 developers andhad many significant changes contributed back.Thanksto these contributors the framework tracks the state-of-the-art in both code and models ", "page_idx": 5, "bbox": [226, 322, 721, 371], "page_size": [768.0, 576.0]}
{"layout": 50, "type": "text", "text": "Speedmakes Caff e perfect for research experiments and industry deployment.Caff e can process over 6 oM images per day with as in gleN viD lAK 40 GPU\\*.That's1ms/image for inference and 4 ms/image for learning.We believe that Caff e is the fastest con v net implementation available. ", "page_idx": 5, "bbox": [226, 397, 721, 447], "page_size": [768.0, 576.0]}
{"layout": 51, "type": "text", "text": "Community:Caffe already powers academic research projects,startup prototypes,and even large scale industrial applications in vision,speech,and multimedia.Join our community of brewers on thecaffe-users group and G it hub ", "page_idx": 5, "bbox": [226, 469, 729, 519], "page_size": [768.0, 576.0]}
{"layout": 52, "type": "text", "text": "Welcome ", "text_level": 1, "page_idx": 6, "bbox": [14, 49, 100, 69], "page_size": [768.0, 576.0]}
{"layout": 53, "type": "text", "text": "The a no is a Python library that allows you to define,optimize,and evaluate mathematical expressions involving multi-dimensional arrays efficiently.Theano features: ", "page_idx": 6, "bbox": [15, 88, 494, 139], "page_size": [768.0, 576.0]}
{"layout": 54, "type": "text", "text": "tight integration with Num Py-Usenumpy.nd array in The a no-compiled ", "page_idx": 6, "bbox": [37, 156, 483, 171], "page_size": [768.0, 576.0]}
{"layout": 55, "type": "text", "text": "functions.  ${\\bf140x}$  faster than with CPU.(float 32 only) efficient symbolic differentiation-The a no does your derivatives for function with one or many inputs. speed and stability optimization s-Get the right answer for  $\\log(1+x)$  even when x is really tiny. dynamic C code generation-Evaluate expressions faster. extensive unit-testing andself-verification-Detect and diagnose many types ofmistake. ", "page_idx": 6, "bbox": [37, 176, 532, 362], "page_size": [768.0, 576.0]}
{"layout": 56, "type": "text", "text": "The a no has been powering large-scale computationally intensive scientific investigations since 2 oo 7.But it is also approachable enough to be used in the classroom(IF T 6266 at the University of Montreal) ", "page_idx": 6, "bbox": [15, 380, 483, 431], "page_size": [768.0, 576.0]}
{"layout": 57, "type": "text", "text": "News ", "text_level": 1, "page_idx": 6, "bbox": [15, 454, 67, 471], "page_size": [768.0, 576.0]}
{"layout": 58, "type": "image", "page_idx": 6, "bbox": [567, 46, 748, 89], "page_size": [768.0, 576.0]}
{"layout": 59, "type": "text", "text": "Table Of Contents ", "page_idx": 6, "bbox": [575, 106, 692, 117], "page_size": [768.0, 576.0]}
{"layout": 60, "type": "text", "text": "Welcome News Download Status Citing Theano Documentation Community ", "page_idx": 6, "bbox": [568, 132, 658, 241], "page_size": [768.0, 576.0]}
{"layout": 61, "type": "text", "text": "Next topic ", "page_idx": 6, "bbox": [575, 261, 643, 272], "page_size": [768.0, 576.0]}
{"layout": 62, "type": "text", "text": "Release Notes ", "page_idx": 6, "bbox": [568, 291, 651, 304], "page_size": [768.0, 576.0]}
{"layout": 63, "type": "text", "text": "This Page ", "page_idx": 6, "bbox": [575, 324, 643, 338], "page_size": [768.0, 576.0]}
{"layout": 64, "type": "text", "text": "Show Source ", "page_idx": 6, "bbox": [568, 351, 643, 362], "page_size": [768.0, 576.0]}
{"layout": 65, "type": "text", "text": "Quick search ", "page_idx": 6, "bbox": [575, 383, 658, 394], "page_size": [768.0, 576.0]}
{"layout": 66, "type": "image", "page_idx": 6, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_6.jpg", "bbox": [728, 410, 754, 428], "page_size": [768.0, 576.0], "ocr_text": "Go\n", "vlm_text": "The image shows a button or similar graphic with the word \"Go\" written on it."}
{"layout": 67, "type": "text", "text": "Enter search terms or a module class or function name. ", "page_idx": 6, "bbox": [568, 442, 738, 471], "page_size": [768.0, 576.0]}
{"layout": 68, "type": "text", "text": "We support cuD NN if it is installed by the user. Open Machine Learning Workshop 2 o 14 presentation Colin Raff el tutorial on The a no. lan Goodfellow did a 12 h class with exercises on The a no ", "page_idx": 6, "bbox": [38, 494, 390, 561], "page_size": [768.0, 576.0]}
{"layout": 69, "type": "text", "text": "IP[y]: IPython Interactive Computing ", "text_level": 1, "page_idx": 7, "bbox": [9, 7, 438, 69], "page_size": [768.0, 576.0]}
{"layout": 70, "type": "text", "text": "Install·Docs·Videos·News·Cite·Sponsors  $^{\\ast}$  Donate ", "page_idx": 7, "bbox": [21, 86, 449, 98], "page_size": [768.0, 576.0]}
{"layout": 71, "type": "text", "text": "The I Python Notebook ", "text_level": 1, "page_idx": 7, "bbox": [9, 118, 304, 146], "page_size": [768.0, 576.0]}
{"layout": 72, "type": "text", "text": "TheIPython Notebook is an interactive computational environment,inwhichyou can combine code execution,rich text,mathematics,plotsand rich media,asshownin this example session: ", "page_idx": 7, "bbox": [7, 168, 571, 219], "page_size": [768.0, 576.0]}
{"layout": 73, "type": "image", "page_idx": 7, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_7.jpg", "bbox": [146, 225, 435, 491.75], "page_size": [768.0, 576.0], "ocr_text": "IPiyi: Notebook speciogre Lemsenn mw Gr ture\n\nee ee ee ee eee\n\nSimple acest candi\n\nVing meaner. sree Te eneey SOME of 8 RR SE\nte te by kag 2 daca wm Ty mabe Ke Ke\n\nds fuje free stigyaie ipert eretile\nrate, K+ sald rend teot_sees ee)\n\nAE CP A aS AGATE AG PRN, eg\n\nIn 10}: Wg, (ark, and) = pitmcbplete(s, 2, Haynie (12, 49)\namt plet(s)) ek set_T0tiet ew satis vigeal-}\nsab apecgren(a); andere 2itbe( Lpeccmagren jj\n\nnas os nape\n\n", "vlm_text": "This image shows an IPython Notebook (now known as Jupyter Notebook) interface titled \"Simple spectral analysis\". It illustrates the Discrete Fourier Transform (DFT) with a mathematical equation and Python code snippets. The notebook imports a WAV file using the `scipy.io` module and visualizes its waveform and spectrogram using Matplotlib.\n\nThe interface displays:\n- Some description and mathematical equation for DFT.\n- Python code for importing and analyzing an audio file.\n- A plot of the audio signal waveform and a spectrogram.\n\nThe left plot shows the raw audio signal, and the right plot shows its spectrogram, representing frequency content over time."}
{"layout": 74, "type": "text", "text": "It aims to bean agile tool for both exploratory computation and data analysis,and provides a platform to support reproducible research,since all inputs and outputs maybe stored in a one-to-one way in notebook documents. ", "page_idx": 7, "bbox": [7, 496, 571, 545], "page_size": [768.0, 576.0]}
{"layout": 75, "type": "image", "page_idx": 7, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_8.jpg", "bbox": [585, 116, 747, 135], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a search box with the text \"Google™ Custom Search\" and a \"Search\" button next to it."}
{"layout": 76, "type": "text", "text": "VERSIONS ", "text_level": 1, "page_idx": 7, "bbox": [584, 153, 682, 170], "page_size": [768.0, 576.0]}
{"layout": 77, "type": "text", "text": "Stable 3.1-April2015 Install ", "page_idx": 7, "bbox": [590, 187, 689, 236], "page_size": [768.0, 576.0]}
{"layout": 78, "type": "text", "text": "Development 4.0.dev GitHub ", "page_idx": 7, "bbox": [590, 257, 685, 304], "page_size": [768.0, 576.0]}
{"layout": 79, "type": "text", "text": "Offline Docs All Versions GitHub ", "page_idx": 7, "bbox": [590, 324, 673, 371], "page_size": [768.0, 576.0]}
{"layout": 80, "type": "text", "text": "NOTEBOOK VIEWER ", "page_idx": 7, "bbox": [585, 406, 685, 437], "page_size": [768.0, 576.0]}
{"layout": 81, "type": "text", "text": "Share your notebooks ", "page_idx": 7, "bbox": [585, 450, 718, 462], "page_size": [768.0, 576.0]}
{"layout": 82, "type": "image", "page_idx": 7, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_9.jpg", "bbox": [589, 470, 751, 568], "page_size": [768.0, 576.0], "ocr_text": "ee ee ee ee ae\na es ee es\npay er inenre siemens eh\n\ner\n\n", "vlm_text": "The image appears to be a blurry bar chart with two sets of bars, likely representing data from the years 1950 and 2000, indicated by the color legend. Below the chart, there is some text about confidence sets and a mathematical expression, but it's too blurry to read clearly."}
{"layout": 83, "type": "text", "text": "Code is ahead,soon... ", "page_idx": 8, "bbox": [252, 44, 553, 66], "page_size": [768.0, 576.0]}
{"layout": 84, "type": "image", "page_idx": 8, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_10.jpg", "bbox": [175, 98.25, 653, 517], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image features a cute cartoon bear sitting with a speech bubble above it. The text next to the bear reads \"BEAR WITH ME.\" The speech bubble contains the text \"I promise :)\" which is partially visible. The image is a playful pun using the bear to emphasize the phrase."}
{"layout": 85, "type": "text", "text": "DataScience？", "text_level": 1, "page_idx": 9, "bbox": [183, 27, 583, 89], "page_size": [768.0, 576.0]}
{"layout": 86, "type": "text", "text": "\"Data science is clearly a blend of the hackers'art,statistics and machine learning ", "page_idx": 9, "bbox": [54, 187, 631, 313], "page_size": [768.0, 576.0]}
{"layout": 87, "type": "text", "text": "—Hilary Mason & Chris Wiggins, 2010 ", "page_idx": 9, "bbox": [213, 359, 708, 386], "page_size": [768.0, 576.0]}
{"layout": 88, "type": "image", "page_idx": 10, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_11.jpg", "bbox": [208, 103, 572, 465], "page_size": [768.0, 576.0], "ocr_text": "Machine\nLearning\n\n", "vlm_text": "The image is a Venn diagram illustrating the intersection of three skill sets: \"Hacking Skills,\" \"Math & Statistics Knowledge,\" and \"Substantive Expertise.\" \n\n- The area where all three circles overlap is labeled \"Data Science.\"\n- The overlap between \"Hacking Skills\" and \"Math & Statistics Knowledge\" is labeled \"Machine Learning.\"\n- The overlap between \"Math & Statistics Knowledge\" and \"Substantive Expertise\" is labeled \"Traditional Research.\"\n- The overlap between \"Hacking Skills\" and \"Substantive Expertise\" is labeled \"Danger Zone!\""}
{"layout": 89, "type": "text", "text": "Features=Awesome ness ", "text_level": 1, "page_idx": 11, "bbox": [79, 35, 688, 82], "page_size": [768.0, 576.0]}
{"layout": 90, "type": "text", "text": "I feature ", "page_idx": 11, "bbox": [130, 195, 226, 219], "page_size": [768.0, 576.0]}
{"layout": 91, "type": "text", "text": ">Features=Awesome ness ", "text_level": 1, "page_idx": 12, "bbox": [81, 33, 689, 82], "page_size": [768.0, 576.0]}
{"layout": 92, "type": "image", "page_idx": 12, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_12.jpg", "bbox": [40, 96, 361, 177], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows an illustration of cute, stylized dog and cat heads. The dogs have brown and beige features, while the cats are grey with stripes. They are arranged in a playful pattern."}
{"layout": 93, "type": "text", "text": "I feature ", "page_idx": 12, "bbox": [129, 195, 226, 219], "page_size": [768.0, 576.0]}
{"layout": 94, "type": "image", "page_idx": 12, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_13.jpg", "img_caption": "Feature1 ", "bbox": [18, 254, 339, 475], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image appears to be a 2D plot with two features labeled as \"Feature 1\" and \"Feature 2.\" The plot contains illustrations of cats and dogs scattered across the grid. Each point on the plot is represented by either a cat face or a dog face, indicating their position based on the two features."}
{"layout": 95, "type": "text", "text": "2features ", "page_idx": 12, "bbox": [98, 495, 206, 516], "page_size": [768.0, 576.0]}
{"layout": 96, "type": "image", "page_idx": 13, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_14.jpg", "bbox": [38, 0, 363, 180], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image features a cute row of cartoon-style animal faces, specifically dogs and cats, lined up in a pattern. The animals have round faces with simple, playful features."}
{"layout": 97, "type": "text", "text": "1 feature ", "page_idx": 13, "bbox": [130, 196, 225, 218], "page_size": [768.0, 576.0]}
{"layout": 98, "type": "image", "page_idx": 13, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_15.jpg", "bbox": [21, 255, 333, 470], "page_size": [768.0, 576.0], "ocr_text": "Feature 1\n", "vlm_text": "The image is a two-dimensional plot with feature axes labeled \"Feature 1\" and \"Feature 2.\" It displays cartoon faces of cats and dogs scattered on a grid. The green shaded areas seem to separate groups of cats and dogs, likely representing different classifications or clusters in a feature space."}
{"layout": 99, "type": "text", "text": "2features ", "page_idx": 13, "bbox": [98, 494, 207, 517], "page_size": [768.0, 576.0]}
{"layout": 100, "type": "text", "text": "too few features/dimensions=over fitting ", "page_idx": 13, "bbox": [28, 529, 490, 553], "page_size": [768.0, 576.0]}
{"layout": 101, "type": "text", "text": ">Features = Awesome ness ", "text_level": 1, "page_idx": 14, "bbox": [79, 32, 688, 82], "page_size": [768.0, 576.0]}
{"layout": 102, "type": "image", "page_idx": 14, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_16.jpg", "img_caption": "Ifeature ", "bbox": [39, 108, 362, 219], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image features a pattern with illustrated faces of dogs and cats arranged in a sequence. They are cartoon-like with simple features and are placed above a line that resembles a ruler."}
{"layout": 103, "type": "image", "page_idx": 14, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_17.jpg", "img_caption": "Feature1 ", "bbox": [19, 255, 333, 470], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image depicts a 3D grid or plot with illustrations of cats and dogs. The plot is labeled with \"Feature 1\" and \"Feature 2\" on the axes. The animals are positioned in different regions, possibly to represent clusters or categories based on these features. There are shaded green areas highlighting certain regions on the plot."}
{"layout": 104, "type": "text", "text": "2features ", "page_idx": 14, "bbox": [98, 494, 206, 517], "page_size": [768.0, 576.0]}
{"layout": 105, "type": "image", "page_idx": 14, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_18.jpg", "img_caption": "Feature 1 ", "bbox": [435, 120, 711, 481], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image depicts a three-dimensional graph with a grid and axes labeled \"Feature 1,\" \"Feature 2,\" and \"Feature 3.\" Within the graph are illustrated faces of cats and dogs placed at various points, likely representing data points based on the three features."}
{"layout": 106, "type": "text", "text": "3features too few features/dimensions=over fitting ", "page_idx": 14, "bbox": [498, 495, 607, 518], "page_size": [768.0, 576.0]}
{"layout": 107, "type": "text", "text": "", "page_idx": 14, "bbox": [28, 528, 490, 554], "page_size": [768.0, 576.0]}
{"layout": 108, "type": "text", "text": "More Features=Awesome ness! ", "text_level": 1, "page_idx": 15, "bbox": [186, 29, 581, 55], "page_size": [768.0, 576.0]}
{"layout": 109, "type": "image", "page_idx": 15, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_19.jpg", "bbox": [40, 109, 360, 178], "page_size": [768.0, 576.0], "ocr_text": "Pid e Wants J wes\nSees Sees See\n\n", "vlm_text": "The image features a row of stylized, cartoon-like dog and cat faces arranged along what looks like a measurement scale or ruler. The dog faces have brown and white colors, while the cat faces have gray markings. They all have friendly expressions."}
{"layout": 110, "type": "text", "text": "Ifeature ", "page_idx": 15, "bbox": [130, 195, 225, 218], "page_size": [768.0, 576.0]}
{"layout": 111, "type": "image", "page_idx": 15, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_20.jpg", "img_caption": "2features ", "bbox": [19, 256, 334, 519], "page_size": [768.0, 576.0], "ocr_text": "Feature 1\n", "vlm_text": "The image is a 3D plot with two axes labeled \"Feature 1\" and \"Feature 2.\" It depicts a scatter plot with cartoon images of cats and dogs. Cats and dogs are placed in different areas, suggesting classification based on the two features. Some areas are highlighted to indicate clusters or decision boundaries within the plot."}
{"layout": 112, "type": "image", "page_idx": 15, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_21.jpg", "img_caption": "3features ", "bbox": [424, 123, 726, 521], "page_size": [768.0, 576.0], "ocr_text": "meet Mm\n\n2 aa\n\n<i)\n\nMy\n\neo\n\nha\n\n|\n(\nfh\n\n", "vlm_text": "The image is a three-dimensional graph with three labeled axes: Feature 1, Feature 2, and Feature 3. It depicts illustrations of cats and dogs positioned within the 3D space. A green plane is shown, separating cats from the dog, suggesting a decision boundary commonly used in classifications like those in machine learning."}
{"layout": 113, "type": "text", "text": "+十 Data Needs also grow! ", "text_level": 1, "page_idx": 16, "bbox": [106, 33, 665, 81], "page_size": [768.0, 576.0]}
{"layout": 114, "type": "image", "page_idx": 16, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_22.jpg", "bbox": [45, 91, 719, 317], "page_size": [768.0, 576.0], "ocr_text": "F\n\n", "vlm_text": "The image contains three plots, each illustrating a different visual representation of data using icons of dogs and cats:\n\n1. **Left Plot**: A 1D plot with a linear gradient from red to green. Cat and dog icons are aligned along a horizontal axis, possibly denoting a range or category.\n\n2. **Middle Plot**: A 2D plot with a gradient background spanning from red to green, featuring cats and dogs scattered across a square grid. The numbering suggests value ranges on the axes.\n\n3. **Right Plot**: A 3D cube with a similar gradient effect and animal icons within the cube, depicting a volumetric space with labeled axes providing additional dimensions.\n\nThis visualization likely represents data in increasing complexity from 1D to 3D, combining both quantifiable values and categorical representations using the animal icons."}
{"layout": 115, "type": "image", "page_idx": 17, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_23.jpg", "bbox": [181, 41, 570, 509], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image is a simple diagram of a classifier system. It shows an icon of a dog being input into a box labeled \"Simple Classifier.\" There are two output funnels labeled \"DOGS\" and \"CATS.\" The image of the dog exits through the \"DOGS\" funnel. This represents a basic classification task where an item (a dog) is correctly categorized."}
{"layout": 116, "type": "image", "page_idx": 18, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_24.jpg", "bbox": [118, 40, 567, 508], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a simple diagram of an animal classifier system with labels for \"CATS\" and \"DOGS\" on the outputs. There is a red prohibition symbol overlaying the diagram, indicating a restriction or negation."}
{"layout": 117, "type": "text", "text": "Deep Learning? ", "text_level": 1, "page_idx": 19, "bbox": [173, 27, 595, 90], "page_size": [768.0, 576.0]}
{"layout": 118, "type": "text", "text": "·A host of statistical machine learning techniques ", "page_idx": 19, "bbox": [63, 161, 642, 240], "page_size": [768.0, 576.0]}
{"layout": 119, "type": "text", "text": "Enables the automatic learning offeature hierarchies ", "page_idx": 19, "bbox": [63, 280, 705, 352], "page_size": [768.0, 576.0]}
{"layout": 120, "type": "text", "text": "Generally based on artificial neural networks ", "page_idx": 19, "bbox": [72, 396, 605, 466], "page_size": [768.0, 576.0]}
{"layout": 121, "type": "text", "text": "Deep Learning ", "text_level": 1, "page_idx": 20, "bbox": [189, 9, 581, 66], "page_size": [768.0, 576.0]}
{"layout": 122, "type": "image", "page_idx": 20, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_25.jpg", "bbox": [102, 73, 567, 533], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "This image is an illustration of a \"Deep Learning Classifier.\" It shows various icons representing different objects like an anchor, dog, bicycle, hammer, glasses, apple, tree, mug, sailboat, and cat being fed into a funnel. The funnel is connected to a machine labeled \"Deep Learning Classifier,\" which categorizes items into groups such as animals, plants, food, tools, and insects. There's also a calendar in the background with pages for the 12th and 13th torn off, indicating the current date as the 14th."}
{"layout": 123, "type": "text", "text": "Deep Learning? ", "text_level": 1, "page_idx": 21, "bbox": [174, 21, 593, 84], "page_size": [768.0, 576.0]}
{"layout": 124, "type": "text", "text": "Manually designed features areoften over-specified, incomplete and take along time to design and validate Learned Features are easy to adapt,fastto learn ", "page_idx": 21, "bbox": [34, 109, 724, 222], "page_size": [768.0, 576.0]}
{"layout": 125, "type": "text", "text": "Deep learning provides a very flexible,(almost?) universal,learn able framework for representing world,visual and T ingui stic information. ", "page_idx": 21, "bbox": [34, 281, 659, 380], "page_size": [768.0, 576.0]}
{"layout": 126, "type": "text", "text": "Deep learning can learn unsupervised(fromraw text/audio/images/whatever content)and supervised(with specific labels like positive/ negative) ", "page_idx": 21, "bbox": [34, 409, 670, 546], "page_size": [768.0, 576.0]}
{"layout": 127, "type": "text", "text": "2006+:The Deep Learning Conspirators ", "text_level": 1, "page_idx": 22, "bbox": [9, 2, 748, 45.75], "page_size": [768.0, 576.0]}
{"layout": 128, "type": "image", "page_idx": 22, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_26.jpg", "bbox": [100, 46.25, 766, 573], "page_size": [768.0, 576.0], "ocr_text": "Stacked\nAutoencoders\n\nUniversité\nde Montréal\n\npie Bengio\n\nKingston\n\nCon puter Science (\n\nUNIVERSITY OF TORON’ TO »\n\niT = Utica\nSchenectacy\n\nHinton 300% glek a hban™\n\n‘Binghamton\n\nRestricted Boltzmann\nMachine\n\nSparse\nRepresentations\n\n", "vlm_text": "The image appears to be a collage featuring three individuals associated with deep learning and artificial intelligence. It shows a map in the background with the following elements:\n\n1. **Hinton** (pictured)\n   - Associated logos: Google and University of Toronto\n   - Text: \"Restricted Boltzmann Machine\"\n\n2. **Bengio** (pictured)\n   - Associated logo: Université de Montréal\n   - Text: \"Stacked Autoencoders\"\n\n3. **LeCun** (pictured)\n   - Associated logos: Facebook and New York University\n   - Text: \"Sparse Representations\"\n\nThese names are likely linked to their contributions to AI and machine learning research."}
{"layout": 129, "type": "text", "text": "Audio Recognition ", "text_level": 1, "page_idx": 23, "bbox": [209, 34, 556, 84], "page_size": [768.0, 576.0]}
{"layout": 130, "type": "text", "text": "Traditional Deep Learning ", "page_idx": 23, "bbox": [292, 106, 514, 122], "page_size": [768.0, 576.0]}
{"layout": 131, "type": "image", "page_idx": 23, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_27.jpg", "bbox": [30, 124.25, 760, 503], "page_size": [768.0, 576.0], "ocr_text": "Error Rate\n\n1998\n\n2000\n\n2006\n\n2008\n\n2010\n\n2012\n\n2014\n", "vlm_text": "The image is a scatter plot showing error rates from 1998 to 2014. The y-axis represents the error rate, ranging from 15 to 31, and the x-axis represents years from 1998 to 2014. The data points are represented by blue and orange dots. The blue dots are mostly clustered between 23 and 31 error rates from 1998 to 2010. Starting around 2010, orange dots appear, showing a decreasing trend in error rates, reaching below 19 by 2014."}
{"layout": 132, "type": "text", "text": "Image Recognition ", "text_level": 1, "page_idx": 24, "bbox": [203, 25, 563, 77], "page_size": [768.0, 576.0]}
{"layout": 133, "type": "image", "page_idx": 24, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_28.jpg", "bbox": [32, 98, 749, 473], "page_size": [768.0, 576.0], "ocr_text": "OTraditionalCV @ Deep Learning\n\noe\n\nef\n\n2014\n\n2013\n\n2012\n\n2011\n", "vlm_text": "The image is a chart comparing error rates for traditional computer vision (CV) methods and deep learning from 2010 to 2014. \n\n- **Y-axis**: Error Rate (ranging from 7% to 79%)\n- **X-axis**: Years (2010 to 2014)\n- **Blue dots**: Represent traditional CV\n- **Orange dots**: Represent deep learning\n\nThe chart shows that error rates for traditional CV were high in 2010 and decreased over time. Deep learning began appearing around 2012 with lower error rates compared to traditional CV, continuing to improve through 2014."}
{"layout": 134, "type": "text", "text": "Natural Langauge Processing ", "text_level": 1, "page_idx": 25, "bbox": [107, 28, 661, 72], "page_size": [768.0, 576.0]}
{"layout": 135, "type": "text", "text": "", "page_idx": 25, "bbox": [324, 289, 360, 303], "page_size": [768.0, 576.0]}
{"layout": 136, "type": "text", "text": "Natural Langauge Processing ", "text_level": 1, "page_idx": 26, "bbox": [107, 25, 663, 73], "page_size": [768.0, 576.0]}
{"layout": 137, "type": "text", "text": "cloudy days don'+ last forever. ", "page_idx": 26, "bbox": [211, 183, 607, 210], "page_size": [768.0, 576.0]}
{"layout": 138, "type": "image", "page_idx": 26, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_29.jpg", "bbox": [178, 218.25, 636, 517], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image is a simple illustration of a bright yellow sun with rays shining against a light blue sky, surrounded by dark clouds. "}
{"layout": 139, "type": "text", "text": "DL? How 2. ", "text_level": 1, "page_idx": 27, "bbox": [228, 15, 516, 72.75], "page_size": [768.0, 576.0]}
{"layout": 140, "type": "image", "page_idx": 27, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_30.jpg", "bbox": [39, 100, 459, 523], "page_size": [768.0, 576.0], "ocr_text": "A\npHD oReD sae\nPra® Deh er\n\n", "vlm_text": "The image shows a collage of multiple faces arranged in a grid pattern. Each square in the grid contains a different face, displaying a variety of expressions and features."}
{"layout": 141, "type": "image", "page_idx": 27, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_31.jpg", "bbox": [466, 73.25, 758, 531], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows an illustrated bear with a speech bubble. The bubble contains the text \"almost at the code...\" The bear appears to be sitting and has a friendly expression."}
{"layout": 142, "type": "image", "page_idx": 28, "bbox": [26, 259, 152.75, 473], "page_size": [768.0, 576.0]}
{"layout": 143, "type": "image", "page_idx": 28, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_32.jpg", "bbox": [153.25, 262, 700, 476], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a collage of human faces on the left side and a diagram of a neural network on the right side. The faces represent input data fed into the neural network, which has multiple layers, including an input layer, several hidden layers, and an output layer. This setup typically illustrates how neural networks are used in machine learning for tasks like image recognition or facial recognition."}
{"layout": 144, "type": "image", "page_idx": 29, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_33.jpg", "bbox": [230, 104, 742, 227], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image appears to show visualizations related to a neural network or deep learning model, likely showcasing different layers of a convolutional neural network (CNN). \n\n- The first section seems to represent convolutional filters from an early layer, capturing simple features like edges. \n- The middle section may be from a deeper layer, showing combinations of features like parts of faces. \n- The last section looks like even deeper layers, where the model captures more complex representations resembling full faces.\n\nThese types of visualizations are often used to understand how CNNs process and learn different features from input data."}
{"layout": 145, "type": "text", "text": "Deepneural networks learn hierarchical feature represent at lons ", "page_idx": 29, "bbox": [31, 152, 211, 238], "page_size": [768.0, 576.0]}
{"layout": 146, "type": "image", "page_idx": 29, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_34.jpg", "bbox": [25, 260, 238, 472], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image contains a grid of multiple faces in various expressions and appearances."}
{"layout": 147, "type": "image", "page_idx": 29, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_35.jpg", "bbox": [243, 261, 703, 474], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "This image depicts a diagram of a neural network. It shows multiple layers, including an input layer, several hidden layers, and an output layer. Each circle represents a neuron, and the lines represent connections (weights) between the neurons across layers. This structure illustrates how data flows through a neural network from input to output."}
{"layout": 148, "type": "image", "page_idx": 30, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_36.jpg", "bbox": [433, 21, 635, 156], "page_size": [768.0, 576.0], "ocr_text": "rm om ry ay dle\nam G “ou\nUAGer %\n\noe ens\n\n", "vlm_text": "The image appears to be a grid of abstract or blurred faces. This type of image is often used in studies related to facial recognition or image processing, where the emphasis is on training algorithms to recognize patterns or features in facial structures. Each face seems deliberately blurred, possibly to test recognition capabilities or to anonymize individual identities."}
{"layout": 149, "type": "image", "page_idx": 30, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_37.jpg", "bbox": [421, 198, 647, 340], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image appears to be a grid of abstract, distorted facial features. This could be a visual representation used in image processing or a neural network for recognizing or generating facial features."}
{"layout": 150, "type": "image", "page_idx": 30, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_38.jpg", "bbox": [437, 375, 635, 539], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image appears to be a grid containing multiple small, abstract patterns. These patterns likely resemble Gabor filters or similar visual stimuli used in image processing or neural networks to detect edges or textures. Each square contains a unique pattern that may vary in orientation and intensity."}
{"layout": 151, "type": "text", "text": "input layer ", "page_idx": 31, "bbox": [44, 519, 106.75, 532], "page_size": [768.0, 576.0]}
{"layout": 152, "type": "image", "page_idx": 31, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_39.jpg", "bbox": [107.25, 16, 647, 545], "page_size": [768.0, 576.0], "ocr_text": "yer\n\ncage SLE\nBe hs Set ed\n=\n\nAhi\ne\n“py\n\n‘\nWK\n\nayy\n\neK\n\nete\nail\nEi]\noe\n\nwal\n\nBigger\n\nRY\n\n", "vlm_text": "This image shows a visualization of a neural network architecture. It features multiple layers of neurons connected with lines, illustrating the connections between layers. On the right, there are grids of images representing visual features that the network might learn at different layers. From bottom to top, the image depicts:\n\n1. Basic features like edges or gradients.\n2. More complex features like parts of faces.\n3. Full face reconstructions.\n\nThese representations illustrate how a neural network processes and identifies hierarchical features in images."}
{"layout": 153, "type": "image", "page_idx": 32, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_40.jpg", "bbox": [142, 51, 620, 448.75], "page_size": [768.0, 576.0], "ocr_text": "Coding\n\nients\n\n¢\n", "vlm_text": "The image is a cartoon illustration of two classification processes. On the left, there's a \"Deep Learning Classifier\" box that takes input from an image of a dog and categorizes it into broad categories like \"Animals,\" \"Plants,\" \"Food,\" \"Tools,\" and \"Insects.\" The output then goes to a \"Simple Classifier\" box that categorizes the image into more specific categories like \"Cats\" or \"Dogs,\" with the dog image resulting in the \"Dogs\" category."}
{"layout": 154, "type": "text", "text": "our ", "text_level": 1, "page_idx": 32, "bbox": [89, 449.25, 425, 477], "page_size": [768.0, 576.0]}
{"layout": 155, "type": "text", "text": "Dog ", "page_idx": 33, "bbox": [672, 20, 749, 67], "page_size": [768.0, 576.0]}
{"layout": 156, "type": "image", "page_idx": 33, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_41.jpg", "bbox": [117, 95.25, 679, 503], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image is a humorous illustration of a two-step classification process. It includes a \"Deep Learning Classifier\" machine and a \"Simple Classifier\" machine, suggesting a system that first categorizes an image using deep learning into broad categories like \"animals, plants, food, tools, insects,\" and then further refines it into specific categories such as \"cats\" or \"dogs.\" The image specifically mentions Kaggle's Cat vs Dog dataset. The initial image input shows a dog silhouette, and the output label is \"DOG.\""}
{"layout": 157, "type": "text", "text": "Wed 25 Sep 2013-S at 1 Feb 2014(15 months ago) ", "page_idx": 34, "bbox": [187, 50, 363, 59], "page_size": [768.0, 576.0]}
{"layout": 158, "type": "text", "text": "Dashboard ", "page_idx": 34, "bbox": [55, 95, 106, 106], "page_size": [768.0, 576.0]}
{"layout": 159, "type": "text", "text": "Home ", "page_idx": 34, "bbox": [55, 120, 84, 129], "page_size": [768.0, 576.0]}
{"layout": 160, "type": "text", "text": "Data ", "page_idx": 34, "bbox": [55, 135, 84, 144], "page_size": [768.0, 576.0]}
{"layout": 161, "type": "text", "text": "Make a submission ", "page_idx": 34, "bbox": [55, 149, 137, 156], "page_size": [768.0, 576.0]}
{"layout": 162, "type": "text", "text": "Information Description Evaluation Rules Prizes Winners ", "page_idx": 34, "bbox": [55, 168, 106, 232], "page_size": [768.0, 576.0]}
{"layout": 163, "type": "text", "text": "Forum ", "page_idx": 34, "bbox": [55, 243, 84, 253], "page_size": [768.0, 576.0]}
{"layout": 164, "type": "text", "text": "Visual lz ation ", "page_idx": 34, "bbox": [55, 308, 106, 317], "page_size": [768.0, 576.0]}
{"layout": 165, "type": "text", "text": "My Submissions ", "page_idx": 34, "bbox": [55, 364, 119, 372], "page_size": [768.0, 576.0]}
{"layout": 166, "type": "text", "text": "Leader board ", "text_level": 1, "page_idx": 34, "bbox": [57, 398, 115, 408], "page_size": [768.0, 576.0]}
{"layout": 167, "type": "text", "text": "1.Pierre Sermanet 2orchld\n\n 3.Owen\n\n 4.Paul Covington ", "page_idx": 34, "bbox": [55, 427, 123, 474], "page_size": [768.0, 576.0]}
{"layout": 168, "type": "text", "text": "Competition Details Getthe Data \\*Makea submission ", "page_idx": 34, "bbox": [201, 97, 461, 107], "page_size": [768.0, 576.0]}
{"layout": 169, "type": "text", "text": "Create an algorithm to distinguish dogs fromcats ", "text_level": 1, "page_idx": 34, "bbox": [199, 131, 544, 173], "page_size": [768.0, 576.0]}
{"layout": 170, "type": "text", "text": "In this competition,you'll write an algorithm to classify whether images contain eithera dog or a cat. This is easy for humans, dogs,and cats. Your computer will find it a bit more difficult. ", "page_idx": 34, "bbox": [201, 194, 577, 232], "page_size": [768.0, 576.0]}
{"layout": 171, "type": "image", "page_idx": 34, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_42.jpg", "bbox": [261, 250, 522, 405.75], "page_size": [768.0, 576.0], "ocr_text": "Data Files\n\n", "vlm_text": "The image shows a bulldog and a cat facing each other in front of a wooden background."}
{"layout": 172, "type": "table", "page_idx": 34, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_43.jpg", "bbox": [371, 406.25, 737, 499], "page_size": [768.0, 576.0], "ocr_text": "File Name Available Formats\nsampleSubmission wcsw (86.82 kb)\ntesti tip (271,15 mb)\ntrain Zip (543.16 mb)\n", "vlm_text": "The table lists files with their names and available formats:\n\n1. **File Name:** sampleSubmission\n   - **Available Formats:** .csv (86.82 kb)\n\n2. **File Name:** test1\n   - **Available Formats:** .zip (271.15 mb)\n\n3. **File Name:** train\n   - **Available Formats:** .zip (543.16 mb)"}
{"layout": 173, "type": "text", "text": "Deep Bluebeat Watson beat the bright e Canyou tell Fi ", "page_idx": 34, "bbox": [264, 432, 366, 470], "page_size": [768.0, 576.0]}
{"layout": 174, "type": "image", "page_idx": 35, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_44.jpg", "bbox": [143, 51, 383.75, 361], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a diagram of a \"Deep Learning Classifier\" machine. There is a funnel on the left, with an image of a dog being input into it. The machine has various labeled categories on the side, such as \"Animals,\" \"Plants,\" \"Food,\" \"Tools,\" and \"Insects.\" This illustration represents a simplified concept of a classifier sorting inputs into different categories."}
{"layout": 175, "type": "text", "text": "Pretrained Convolutional Neural Net (CNN) ", "text_level": 1, "page_idx": 35, "bbox": [420, 139, 756, 272], "page_size": [768.0, 576.0]}
{"layout": 176, "type": "image", "page_idx": 35, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_45.jpg", "bbox": [384.25, 296, 624, 503], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a diagram labeled \"Simple Classifier.\" It appears to have two output channels marked \"DOGS\" and \"CATS.\" A card labeled \"DOG\" with a silhouette of a dog is coming out of the \"DOGS\" channel. This suggests a simplistic visual representation of a system that classifies inputs into categories of dogs or cats."}
{"layout": 177, "type": "text", "text": "accuracy in < 1h ", "text_level": 1, "page_idx": 36, "bbox": [418, 73, 729, 112], "page_size": [768.0, 576.0]}
{"layout": 178, "type": "text", "text": "", "page_idx": 36, "bbox": [75, 391, 275, 482], "page_size": [768.0, 576.0]}
{"layout": 179, "type": "text", "text": "1 Load Pre trained Net ", "page_idx": 37, "bbox": [20, 53, 272, 74], "page_size": [768.0, 576.0]}
{"layout": 180, "type": "image", "page_idx": 37, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_46.jpg", "bbox": [4, 72.25, 749, 266], "page_size": [768.0, 576.0], "ocr_text": "RN EN a as\n\nconv1 conv2 conv3 conv4\n\n2 Extract features for all training images\n\nconv5\n\nComecton\n\nSeeeocece 5\n\na\n~\no\noo\n\ns@eeoeceeeooe\n", "vlm_text": "The image represents a diagram of a convolutional neural network (CNN) architecture. It starts with an image of a cartoon cat and shows the process of feature extraction through various convolutional and pooling layers, labeled as conv1 through conv5. The diagram includes fully connected layers, labeled as fc6, fc7, and fc8, which finalize the feature extraction for classification. The network details such as convolution and max-pooling operations are indicated, with neuron counts shown in the fully connected layers. The text \"1 Load Pretrained Net\" and \"2 Extract features for all training images\" suggests that the network is used for feature extraction in a pretrained model workflow."}
{"layout": 181, "type": "image", "page_idx": 37, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_47.jpg", "bbox": [2, 268, 732, 538], "page_size": [768.0, 576.0], "ocr_text": "d ad d eee\n1] 12 13 :\n3. train MLP on those features\nGy, Gy Ay °\n\nG3, Gy Gy, *\"\n\n", "vlm_text": "The image illustrates a process involving image feature extraction and classification using a neural network. \n\n1. **Image Features**: On the left, a matrix labeled \\(a_{ij}\\) represents features extracted from an image. The rows (\\(i\\)) correspond to different images, and the columns (\\(j\\)) correspond to different features.\n\n2. **Feature Selection**: A specific set of features (\\([a_{21}, a_{22}, a_{23}, \\ldots]\\)) is highlighted in blue, indicating the features that are being selected for further processing.\n\n3. **Training an MLP**: On the right, the text \"train MLP on those features\" appears, where MLP stands for Multi-Layer Perceptron, a type of neural network. The network diagram has nodes (neurons) with connections representing the flow of information.\n\n4. **Output Labels**: Two output nodes with pictures of a cat and a dog indicate that the MLP is used for classifying images into categories like 'cat' or 'dog'."}
{"layout": 182, "type": "text", "text": "1 Load Pre trained Net ", "text_level": 1, "page_idx": 38, "bbox": [11, 46, 300, 71], "page_size": [768.0, 576.0]}
{"layout": 183, "type": "image", "page_idx": 38, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_48.jpg", "bbox": [6, 82, 750, 274], "page_size": [768.0, 576.0], "ocr_text": "oat\neoccece\n\njee\n\na\n[oy]\ne¢\no\neo\n\nseeeoeeoeo\njeeee\n", "vlm_text": "This image depicts the architecture of a convolutional neural network (CNN), similar to AlexNet. It shows the various layers and operations applied to an input image of a cat:\n\n1. **Input Image**: The process starts with an image of a cat.\n2. **Convolutional Layers (conv1 to conv5)**: Various convolutional layers with different filter sizes and characteristics. Each layer progressively captures more abstract features. Max-pooling and response normalization are applied in some layers.\n3. **Fully Connected Layers (fc6, fc7, fc8)**: These layers follow the convolutional layers:\n   - **fc6 and fc7**: Each has 4096 neurons.\n   - **fc8**: The final layer, which has 1000 neurons, typically used for classification.\n\nThe structure is visualized with different colors for each layer, outlining the number of neurons and types of connections."}
{"layout": 184, "type": "text", "text": "No Free Lunch... But Free Models! ", "text_level": 1, "page_idx": 39, "bbox": [64, 18, 673, 64], "page_size": [768.0, 576.0]}
{"layout": 185, "type": "image", "page_idx": 39, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_49.jpg", "bbox": [460, 92, 721, 110], "page_size": [768.0, 576.0], "ocr_text": "@Watch- 625 WUnstar 3451 York 2,037\n", "vlm_text": "The image contains icons and text typically seen on a GitHub repository page:\n\n- An eye icon with the text \"Watch\" followed by the number 625.\n- A star icon with the text \"Unstar\" followed by the number 3,481.\n- A fork icon with the text \"Fork\" and the number 2,057.\n\nThese elements represent the number of users watching, starring, and forking the repository."}
{"layout": 186, "type": "text", "text": "BVLC/caffe ", "page_idx": 39, "bbox": [66, 96, 147, 108], "page_size": [768.0, 576.0]}
{"layout": 187, "type": "image", "page_idx": 39, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_50.jpg", "bbox": [592, 141, 679, 160], "page_size": [768.0, 576.0], "ocr_text": "CTE New Page\n", "vlm_text": "The image shows two buttons. One says \"Edit\" and the other says \"New Page.\" The \"Edit\" button is white, and the \"New Page\" button is green."}
{"layout": 188, "type": "text", "text": "ModelZoo ", "text_level": 1, "page_idx": 39, "bbox": [44, 141, 146, 162], "page_size": [768.0, 576.0]}
{"layout": 189, "type": "text", "text": "Liwei Wang edited this page 3 days ago·18 revisions ", "page_idx": 39, "bbox": [44, 168, 274, 180], "page_size": [768.0, 576.0]}
{"layout": 190, "type": "image", "page_idx": 39, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_51.jpg", "bbox": [517, 178, 720, 485], "page_size": [768.0, 576.0], "ocr_text": "y Pages (7) rl\nHome\n\n122]\nCaffe on EC2 Ubuntu 14.04 Cuda\nfs\n\ndn\nDevelopment\nInstallation\n\nInstallation (OSX)\nModel Zoo\n\nModels accuracy on imageNet\n2012 val\n\nPublications\n\nRelated Projects.\n\nUbuntu 14.04 ec2 instance\nUbuntu 14.04 VirtualBox VM\n", "vlm_text": "The image shows a navigation menu titled \"Pages\" with 11 items listed. The items are:\n\n1. Home\n2. Caffe on EC2 Ubuntu 14.04 Cuda 7\n3. Development\n4. Installation\n5. Installation (OSX)\n6. Model Zoo\n7. Models accuracy on ImageNet 2012 val\n8. Publications\n9. Related Projects\n10. Ubuntu 14.04 ec2 instance\n11. Ubuntu 14.04 VirtualBox VM"}
{"layout": 191, "type": "text", "text": "Trained models are posted here as links to Github Gists.Checkout the modelzoo documentation for details. ", "page_idx": 39, "bbox": [44, 208, 451, 235], "page_size": [768.0, 576.0]}
{"layout": 192, "type": "text", "text": "To acquire a model: ", "page_idx": 39, "bbox": [44, 252, 142, 263], "page_size": [768.0, 576.0]}
{"layout": 193, "type": "text", "text": "1.download the model gist by./scripts/download model from gist.sh<gist_id> xdirname> to load the model metadata,architecture,solver configuration,and so on (<dirname> is optional and defaults to caff e/models) ", "page_idx": 39, "bbox": [51, 280, 481, 328], "page_size": [768.0, 576.0]}
{"layout": 194, "type": "text", "text": "2.download themodel weightsby./scripts/download model binary.py <model_dir> where<model_dir>is the gist directory from the firststep ", "page_idx": 39, "bbox": [51, 333, 467, 365], "page_size": [768.0, 576.0]}
{"layout": 195, "type": "text", "text": "Berkeley-trained models ", "text_level": 1, "page_idx": 39, "bbox": [44, 385, 241, 403], "page_size": [768.0, 576.0]}
{"layout": 196, "type": "text", "text": "Finetuning on Flickr Style:same asprovided in models/,but listed hereasa Gist for anexample. ·B VLC Google Net ", "page_idx": 39, "bbox": [51, 420, 481, 467], "page_size": [768.0, 576.0]}
{"layout": 197, "type": "text", "text": "Network in Network model ", "text_level": 1, "page_idx": 39, "bbox": [43, 487, 258, 505], "page_size": [768.0, 576.0]}
{"layout": 198, "type": "text", "text": "Clone this wiki locally ", "page_idx": 39, "bbox": [520, 502, 606, 512], "page_size": [768.0, 576.0]}
{"layout": 199, "type": "text", "text": "jupyter ", "text_level": 1, "page_idx": 40, "bbox": [69, 58, 152, 81], "page_size": [768.0, 576.0]}
{"layout": 200, "type": "text", "text": "Running Clusters ", "page_idx": 40, "bbox": [107, 105, 210, 119], "page_size": [768.0, 576.0]}
{"layout": 201, "type": "text", "text": "Toimport anotebook,drag thefile onto the listing below or click ", "page_idx": 40, "bbox": [50, 134, 344, 145], "page_size": [768.0, 576.0]}
{"layout": 202, "type": "text", "text": "b vlc reference caff e net.caffemodel ", "page_idx": 40, "bbox": [89, 210, 261, 225], "page_size": [768.0, 576.0]}
{"layout": 203, "type": "text", "text": "deploy.prototxt ", "page_idx": 40, "bbox": [98, 237, 169, 249], "page_size": [768.0, 576.0]}
{"layout": 204, "type": "text", "text": "readme.md ", "page_idx": 40, "bbox": [98, 263, 152, 272], "page_size": [768.0, 576.0]}
{"layout": 205, "type": "text", "text": "solvor nrntotyt ", "page_idx": 40, "bbox": [98, 288, 169, 295], "page_size": [768.0, 576.0]}
{"layout": 206, "type": "text", "text": "J up y ter solver.prototxto3/17/2015 ", "page_idx": 40, "bbox": [69, 300, 284, 313], "page_size": [768.0, 576.0]}
{"layout": 207, "type": "text", "text": "Menu ", "page_idx": 40, "bbox": [50, 323, 86, 335], "page_size": [768.0, 576.0]}
{"layout": 208, "type": "text", "text": "current mode ", "page_idx": 40, "bbox": [279, 326, 332, 334], "page_size": [768.0, 576.0]}
{"layout": 209, "type": "text", "text": "Inet: \"models/b vlc reference caff e net/train_val.prototx 七\"testitor:1o00 test interval:looo bane1r:0.01 5 lr policy:\"step 6 qamma:0.1 7 stepsize: 100000 8 display: 20 9 maxiter:450000 10 momentum:0.9 11 v eight decay:0.0o05 12 snapshot:looo0 13 snapshot prefix: \"models/b vlc reference caffenet/caffenet train 14 solver mode: GPU ", "page_idx": 40, "bbox": [50, 358, 332, 536], "page_size": [768.0, 576.0]}
{"layout": 210, "type": "text", "text": "jupyter deploy.prototxt03/17/2015 ", "text_level": 1, "page_idx": 40, "bbox": [417, 58, 690, 81], "page_size": [768.0, 576.0]}
{"layout": 211, "type": "text", "text": "File Edit View Language ", "page_idx": 40, "bbox": [410, 90, 583, 104], "page_size": [768.0, 576.0]}
{"layout": 212, "type": "text", "text": "name:\"CaffeNet\" input:\"data\" input dim:10input dim:3input dim:227input dim:227layer{ name: \"conv1\" type: \"Convolution\" bottom:\"data\" top:\"conv1\" convolution param num output:96 kernel size:11 stride:4 layer{ name: \"relul\" type: \"ReLU\" bottom:\"convl\" top:\"conv1\" layer{ \"pool1\" type: \"Pooling\" bottom:\"conv1\" top:\"pool1\" pooling param pool:MAX kernel size:3 stride:2 ", "page_idx": 40, "bbox": [432, 131, 569, 551], "page_size": [768.0, 576.0]}
{"layout": 213, "type": "text", "text": "工%matplotlib·inlineimport logging from·glob·import.glob 4 from random import shuffle 5 import·pickle 6 7 # Make sure that caffe is on the python path: 8 caffe_root·=.. 9 import sys sys.path.insert(o, caffe_root + 'python') import.caffe 2 import·numpy.as.np 4 import·matplotlib.pyplot·as plt 5 import.matplotlib.image·as mpimg ", "page_idx": 41, "bbox": [22, 71, 487, 381], "page_size": [768.0, 576.0]}
{"layout": 214, "type": "text", "text": "MoDEL_FILE·='../models/b vlc reference caff e net/deploy.prototxt PRETRAINED =.'../models/b vlc reference caff e net/b vlc reference caff e net caffemodel' ", "page_idx": 42, "bbox": [36, 69, 744, 126], "page_size": [768.0, 576.0]}
{"layout": 215, "type": "text", "text": "def png_to_np(basedir,fetch target=False): logging.getLogger().setLevel(logging.INFo) 6 caffe.set mode gpu() 广 net =-caffe.ClaSsifier(MODEL_FILE, PRETRAINED 8 mean=np.load(caffe_root +.python/caffe/imagenet/ il sv rc 2012 mean.npy').mean(1).mean(1), 9 channel swap=(2,1,0), 10 raw_scale=255 11 image_dims=（256,-256)) ", "page_idx": 42, "bbox": [16, 150, 744, 334], "page_size": [768.0, 576.0]}
{"layout": 216, "type": "image", "page_idx": 42, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_52.jpg", "bbox": [83, 345, 685, 535], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "This image depicts a diagram of a convolutional neural network (CNN) architecture. The structure includes layers such as convolutional layers with specifications (like filter sizes and depths), max pooling layers, and dense (fully connected) layers. The network probably ends with an output layer with 1000 units, which is typical for image classification tasks like those using the ImageNet dataset. Numbers on the diagram refer to dimensions of feature maps at each stage."}
{"layout": 217, "type": "text", "text": "(convnet from Krizhevsky et al's NIPS 2o12 ImageNet classification paper) ", "page_idx": 42, "bbox": [36, 545, 729, 572], "page_size": [768.0, 576.0]}
{"layout": 218, "type": "text", "text": "1 Load Pre trained Net ", "page_idx": 43, "bbox": [14, 52, 265, 74], "page_size": [768.0, 576.0]}
{"layout": 219, "type": "image", "page_idx": 43, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_53.jpg", "bbox": [1, 70.25, 750, 472], "page_size": [768.0, 576.0], "ocr_text": "41 LMG PICA ICC IWeel\n\nconv1 conv2 conv3 conv4 conv5 fc6 fc7 fc8\nee\nBEF comotston ee Dense e @\n13 13 13 cy e @\n>>.” Se. ° ae Ln.\n. . . 1000\n2 Extract features for all training images : Pine\n\n4, Gy G3 *\n\n", "vlm_text": "The image is an illustration of a convolutional neural network (CNN) process.\n\n1. **Load Pretrained Net:** This refers to using a pre-trained CNN model. There's an icon of a cat, suggesting it's an example input image. \n   \n2. **Extract Features for All Training Images:** This shows a matrix representing features extracted from the image through different layers of the CNN. \n\n- The top part shows layers and operations like convolution and max-pooling.\n- The bottom part has a diagram showing how features are extracted from an image and stored in matrix form. \n\nThe visual suggests the steps involved in processing an image through a CNN to extract features."}
{"layout": 220, "type": "text", "text": "#feed image into the net re or k andreturn internal feature representation of layer fc 6 ", "text_level": 1, "page_idx": 44, "bbox": [16, 23, 711, 97], "page_size": [768.0, 576.0]}
{"layout": 221, "type": "text", "text": "def·activate(net,.im): 2 input image =.caffe.io.load_image（im) 3 #Resize the image to the standard (256,256） and oversample net input sized crops. 4 input over sampled = caffe.io.oversample([caffe.io.resize image(input image ,net.image_dims)], net.crop_dims) 5 #'data' is the input blob name in the model definition, so we preprocess for that input. 6 caff e input·=·np.asarray([net.transformer.preprocess('data', in_) for in_ in input over sampled]) # forward() takes keyword args for the input blobs with pre processed input arrays. 8 predicted = net.forward(data=caff e input) 9 # Activation of all convolutional layers and first fully connected 10 feat = net.blobs['fc6'].data[0] 11 return feat ", "page_idx": 44, "bbox": [24, 114, 739, 410], "page_size": [768.0, 576.0]}
{"layout": 222, "type": "text", "text": "#extract features from images ", "text_level": 1, "page_idx": 45, "bbox": [16, 27, 373, 61], "page_size": [768.0, 576.0]}
{"layout": 223, "type": "text", "text": "15 feature info-=·activate（net, files[o]) 16 feature count = feature info.shape[o] 17 feature d type = feature info.dtype 18data·= np.zeros((len(files), feature count), dtype=feature d type）192 for·n,im in enumerate（files): data[n,:]·=·activate（net,·im) 21 if·n %·1000==·0: 22 print 'Reading in image',n 23 24 return data, target, files ", "page_idx": 45, "bbox": [15, 72, 739, 282], "page_size": [768.0, 576.0]}
{"layout": 224, "type": "text", "text": "#dump features as pickle file ", "text_level": 1, "page_idx": 46, "bbox": [17, 26, 358, 62], "page_size": [768.0, 576.0]}
{"layout": 225, "type": "text", "text": "In[\\*]: x,Yfilenames  $=$  png_to_np( '/mnt/pet/train/',fetch target  $\\equiv$  True) pickle.dump(x,open('saved_x_v2.pkl','wb')) pickle.dump(y,open('saved_y_v2.pkl','wb')) pickle.dump（filenames,open('saved filenames v 2.pkl','wb')) ", "page_idx": 46, "bbox": [18, 91, 588, 173], "page_size": [768.0, 576.0]}
{"layout": 226, "type": "text", "text": "Reading in image 0 Reading in image 1000 Reading in image 2000 Reading in image 3000 Reading in image 4000 Reading in image 5000 Reading in image6000 Reading in image 7000 Reading in image 8000 ", "page_idx": 46, "bbox": [87, 187, 263, 333], "page_size": [768.0, 576.0]}
{"layout": 227, "type": "text", "text": ".. ", "page_idx": 46, "bbox": [93, 346, 111, 362], "page_size": [768.0, 576.0]}
{"layout": 228, "type": "text", "text": "1 Load Pretrained Net ", "page_idx": 47, "bbox": [20, 53, 272, 74], "page_size": [768.0, 576.0]}
{"layout": 229, "type": "image", "page_idx": 47, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_54.jpg", "bbox": [3, 71.25, 751, 274.75], "page_size": [768.0, 576.0], "ocr_text": "id..\n\nSASS EER LEI 1 Oe\n\nconv1 conv2 conv3 conv4\n\n2 Extract features for all training images\ni- _\n\nconv5\n\nConmecton\n\nMau-P cong\nResponse “ormaiz.\n\n[ecccccce a\n\nseeeeoeoeoe\njeoee\n\na\n~\n\nfc8\n", "vlm_text": "The image appears to be a diagram illustrating the process of using a pre-trained neural network (possibly a convolutional neural network, or CNN) for feature extraction. \n\n1. **Load Pretrained Net**: Shows an image of a cat being input into the network.\n2. **Convolutional Layers (conv1 to conv5)**: Demonstrates various layers with operations like convolution, max-pooling, and response normalization, reducing the size of the feature maps.\n3. **Fully Connected Layers (fc6, fc7, fc8)**: Represents dense connections with neuron counts mentioned (4096 and 1000 neurons).\n\nThis is likely part of a workflow for image recognition or classification tasks."}
{"layout": 230, "type": "image", "page_idx": 47, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_55.jpg", "bbox": [1, 275.25, 748, 537], "page_size": [768.0, 576.0], "ocr_text": "d d ad ees =\nHe 3. train MLP on those features\n44, 4x 43 °° a\n\nG,, Gy Gy, *\"\"\n\n", "vlm_text": "The image appears to illustrate a machine learning process involving images, features, and a neural network. \n\n1. An image is being processed to extract features, represented as a matrix with notation \\(a_{ij}\\).\n2. These features are used to train a multilayer perceptron (MLP), a type of neural network.\n3. The diagram includes nodes and layers connected in a network, with icons of a cat and a dog indicating possible classification outcomes."}
{"layout": 231, "type": "text", "text": "Pylearn2: ", "text_level": 1, "page_idx": 48, "bbox": [305, 28, 463, 64], "page_size": [768.0, 576.0]}
{"layout": 232, "type": "text", "text": "Multilayer Perce ptr on(MLP)on topof extracted features ", "text_level": 1, "page_idx": 48, "bbox": [70, 70, 698, 150], "page_size": [768.0, 576.0]}
{"layout": 233, "type": "text", "text": "#imports ", "page_idx": 48, "bbox": [16, 173, 125, 205], "page_size": [768.0, 576.0]}
{"layout": 234, "type": "text", "text": "1 from·pylearn2.models·import mlp 2from pylearn2.costs.mlp.dropout import·Dropout 3 from·pylearn2.training algorithms·import·sgd,.learning rule 4 from pylearn2.termination criteria·import Epoch Counter 5 from·pylearn2.datasets·import·Dense Design Matrix 6 from pylearn2.train import Train 7 from pylearn2.train extensions import best params 8 from pylearn2.space import Vector Space 9 10 import.pickle import·numpy·as-np ", "page_idx": 48, "bbox": [16, 227, 629, 456], "page_size": [768.0, 576.0]}
{"layout": 235, "type": "text", "text": "#load earlier extracted features and labels\n\n #convert to input that py learn understands ", "page_idx": 49, "bbox": [12, 21, 528, 89], "page_size": [768.0, 576.0]}
{"layout": 236, "type": "text", "text": "x·=·pickle.load（open（'saved_x_v2.pkl','rb'))y=·pickle.load(open('saved_y_v2.pkl','rb')) 3 filenames =·pickle.load(open('saved filenames v 2.pkl',rb')) 一y·=·to_one_hot(y)5 in_space·=·Vector Space(dim=x.shape[1]) 6 full =·Dense Design Matrix（X=x, y=y) ", "page_idx": 49, "bbox": [30, 107, 737, 248], "page_size": [768.0, 576.0]}
{"layout": 237, "type": "text", "text": "#create ", "page_idx": 50, "bbox": [16, 20, 122, 49], "page_size": [768.0, 576.0]}
{"layout": 238, "type": "text", "text": "layers of MLP ", "page_idx": 50, "bbox": [16, 57, 122, 120], "page_size": [768.0, 576.0]}
{"layout": 239, "type": "text", "text": "#with ", "page_idx": 50, "bbox": [16, 143, 105, 169], "page_size": [768.0, 576.0]}
{"layout": 240, "type": "text", "text": "softmax as final layer ", "page_idx": 50, "bbox": [16, 183, 171, 249], "page_size": [768.0, 576.0]}
{"layout": 241, "type": "text", "text": "#trainer initialized withSGD momentum, dropout ", "page_idx": 50, "bbox": [24, 381, 161, 565], "page_size": [768.0, 576.0]}
{"layout": 242, "type": "image", "page_idx": 50, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_56.jpg", "bbox": [197, 8, 735, 576], "page_size": [768.0, 576.0], "ocr_text": "ll = mlp.RectifiedLinear( layer_name= (1,\n\nsparse_init=12, dem\n\ndim=5000,\nmax_col_norm=1. )\n\n12 = mlp.RectifiedLinear(layer_name='12\",\nsSparse_init=12,\ndim=5000,\nmax_col_norm=1.)\n\n13 = mlp.RectifiedLinear( layer_name='13',\nSparse_init=12,\ndim=5000,\nmax_col_norm=1. )\n\noutput = mlp.Softmax(layer_name='y',\nn_classes=2,\nirange=.0@5)\n\nlayers [l1, 12, 13, output]\nmdl = mlp.MLP( layers,\ninput_space=in_space)\n\nlr = .0001\n\nepochs = 100\n\ntrainer = sgd.SGD(learning_rate=lr,\nbatch_size=128,\nlearning_rule=learning_rule.Momentum(.5),\n# Remember, default dropout is .5\ncost=Dropout(input_include_probs={'11': .8},\n\ninput_scales={'l1': 1.}),\n\ntermination_criterion=EpochCounter(epochs),\nmonitoring_dataset={'train': full})\n", "vlm_text": "The image contains a code snippet written in Python. It appears to be configuring a multi-layer perceptron (MLP) neural network:\n\n1. **Layers**: \n   - `l1`, `l2`, and `l3` are Rectified Linear (ReLU) layers with a sparse initialization, each having a dimension of 5000 and a `max_col_norm` of 1.0.\n   - `output` is a Softmax layer for two classes.\n\n2. **Model Layers**:\n   - The layers are combined into a list: `[l1, l2, l3, output]`.\n\n3. **Model Initialization**:\n   - The model `mdl` is created from the layers using `mlp.MLP`.\n\n4. **Training Configuration**:\n   - Learning rate `lr` is set to 0.0001.\n   - Number of epochs is 100.\n   - Trainer is set up using stochastic gradient descent (SGD) with a learning rule and batch size of 128.\n\n5. **Dropout and Regularization**:\n   - Dropout is used with specified input inclusion probabilities.\n   - An epoch counter termination criterion is set, monitoring the training dataset.\n\nThis code is likely part of a machine learning training script."}
{"layout": 243, "type": "text", "text": "1 # no sklearn.cross validation > train test split 2 # own test/train split so we can also link filenames 3 splitter= round（len(x)\\*0.8) 4X train,X test·=·x[:splitter],x[splitter:] 5 y_train,y_test =y[:splitter],y[splitter:] 6 filenames train, filenames test = filenames[:splitter],filenames[splitter:] 7 8pickle.dump(x_train,open('saved feat x train v 2.pkl',-wb')) 9 pickle.dump(x_test,open('saved feat x test v 2.pkl',.'wb')) 10 pickle.dump(y_train,open('saved feat y train v 2.pkl','wb')) 1 pickle.dump(y_test,open('saved feat y test v 2.pkl','wb')) 12 pickle.dump（filenames train, open('saved feat filenames train v 2.pkl','wb')）3 pickle.dump(filenames test,open('saved feat filenames test v 2.pkl','wb'))", "page_idx": 51, "bbox": [15, 91, 740, 341], "page_size": [768.0, 576.0]}
{"layout": 244, "type": "text", "text": "#start our MLP (pylearn experiment metbod) ", "text_level": 1, "page_idx": 52, "bbox": [12, 38, 564, 73], "page_size": [768.0, 576.0]}
{"layout": 245, "type": "text", "text": "#liftoff! trn =·Dense Design Matrix（X=X_train, y=y_train) 3 tst =·Dense Design Matrix(X=X_test,y=y_test) trainer.monitoring data set='valid': tst, 'train':-trn} experiment.main_loop() ", "page_idx": 52, "bbox": [25, 96, 486, 216], "page_size": [768.0, 576.0]}
{"layout": 246, "type": "text", "text": "In [\\*]:trn  $=$   $\\tt X{=}{\\tt X}$  tst  $=$  Dense Design Matrix(  $\\tt X{=}{\\tt X}$  test,y-y_test) trainer.monitoring data set={'valid':tst, 'train':trn} experiment.main_loop() Parameter and initial learning rate summary: 11W:9.99999974738e-05 11_b:9.99999974738e-05 12_W:9.99999974738e-05 12_b:9.99999974738e-05 13_W:9.99999974738e-05 13 b:9.99999974738e-05 softmax b:9.99999974738e-05 softmax_W:9.99999974738e-05 Compiling sgd_update... Compiling sgd updated one.Time elapsed:1.686666 seconds compiling begin record entry... compiling begin record entry done.Time elapsed:0.548132 seconds Monitored channels: learning rate momentum total seconds last epoch ", "page_idx": 52, "bbox": [25, 240, 450, 499], "page_size": [768.0, 576.0]}
{"layout": 247, "type": "text", "text": "In[319]：", "page_idx": 53, "bbox": [45, 69, 143, 86], "page_size": [768.0, 576.0]}
{"layout": 248, "type": "text", "text": "plt.plot(score train[2:])plt.plot(score_test[2:]) ", "page_idx": 53, "bbox": [163, 68, 444, 109], "page_size": [768.0, 576.0]}
{"layout": 249, "type": "text", "text": "Out[319]:[<matplotlib.lines.Line 2 Dat 0 x 7 f 517 c 694450>] ", "page_idx": 53, "bbox": [45, 131, 671, 148], "page_size": [768.0, 576.0]}
{"layout": 250, "type": "image", "page_idx": 53, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_57.jpg", "bbox": [98, 171, 675, 514], "page_size": [768.0, 576.0], "ocr_text": "50%\n\n90%\n\n0 20 40 60 80 100\n", "vlm_text": "The image shows a line graph. The x-axis ranges from 0 to 100, and the y-axis has values between 0.0 and 0.5. Several lines are plotted, showing a trend that starts high and decreases rapidly, then levels out. There are also labels in a stylized font indicating \"50%\" at the top left and \"90%\" at the bottom left, and the title \"accuracy\" at the top center."}
{"layout": 251, "type": "text", "text": "In [319]: ", "page_idx": 54, "bbox": [45, 68, 143, 86], "page_size": [768.0, 576.0]}
{"layout": 252, "type": "text", "text": "plt.plot(score train[2:])plt.plot(score_test[2:]) ", "page_idx": 54, "bbox": [163, 67, 444, 109], "page_size": [768.0, 576.0]}
{"layout": 253, "type": "text", "text": "Out[319]:[<matplotlib.lines.Line 2 Dat 0 x 7 f 517 c 694450>] ", "page_idx": 54, "bbox": [45, 131, 671, 148], "page_size": [768.0, 576.0]}
{"layout": 254, "type": "image", "page_idx": 54, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_58.jpg", "bbox": [60, 162, 733, 503], "page_size": [768.0, 576.0], "ocr_text": "0.065\n94% 0.060\n0.055\n0.050\n0.045\n0.040\n0.035\n97% 0.030 } (...)\n\n0.025\n0 20 40 60 80 100\n", "vlm_text": "The image is a graph showing some form of data over the range from 0 to 100 on the x-axis. The y-axis ranges from 0.025 to 0.065. Two lines are plotted, one in green and one in blue, both generally decreasing over the x-axis range. There are two percentages, 94% and 97%, located on the left side, but their context is not clear. The word \"accuracy\" is located at the top, suggesting the graph might relate to model performance accuracy over iterations or epochs."}
{"layout": 255, "type": "text", "text": "start at iteration#2 ", "page_idx": 54, "bbox": [121, 510, 359, 528], "page_size": [768.0, 576.0]}
{"layout": 256, "type": "text", "text": "In[380]: input image  $=$  caffe.io.load_image('google-glasses-cat-2.jpg') plt.imshow(input image) ", "page_idx": 55, "bbox": [26, 32, 614, 65], "page_size": [768.0, 576.0]}
{"layout": 257, "type": "text", "text": "Out[380]:<matplotlib.image.Axes Image at 0 x 7 f 51 a 017 d 410> ", "page_idx": 55, "bbox": [26, 78, 490, 93], "page_size": [768.0, 576.0]}
{"layout": 258, "type": "image", "page_idx": 55, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_59.jpg", "bbox": [117, 108, 397, 349], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a cat wearing round, oversized sunglasses. The photo is black and white, with a focus on the cat's face. The image also has a grid overlay with axes typically seen in graphical plots, indicating pixel dimensions."}
{"layout": 259, "type": "text", "text": "In[381]: feat  $=$  get feat single image('google-glasses-cat-2.jpg')#run image through cnn  ${\\bf x}=$  feat  $\\textbf{y}=\\textbf{f}(~[\\mathbf{x}])$  #runfeature throughDBN  $>$  out: prediction ify: print \"WOOF!\" else: print \"MEOW!\" MEOW! ", "page_idx": 55, "bbox": [26, 377, 764, 520], "page_size": [768.0, 576.0]}
{"layout": 260, "type": "text", "text": "So are You more like a Dogor Cat? ", "text_level": 1, "page_idx": 56, "bbox": [86, 11, 654, 46], "page_size": [768.0, 576.0]}
{"layout": 261, "type": "image", "page_idx": 56, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_60.jpg", "bbox": [67, 97, 697, 486], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "This image shows a cat and a dog facing each other. The background is a green and yellow checkerboard pattern. The text under the cat and dog reads \"CAT vs DOG.\""}
{"layout": 262, "type": "text", "text": "DETECTOR ", "page_idx": 56, "bbox": [235, 505, 534, 547], "page_size": [768.0, 576.0]}
{"layout": 263, "type": "text", "text": "What about me? ", "text_level": 1, "page_idx": 57, "bbox": [42, 25, 125, 122], "page_size": [768.0, 576.0]}
{"layout": 264, "type": "text", "text": "CAT or DoG,that's the question... ", "page_idx": 57, "bbox": [186, 58, 557, 79], "page_size": [768.0, 576.0]}
{"layout": 265, "type": "image", "page_idx": 57, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_61.jpg", "bbox": [169, 85, 633, 499], "page_size": [768.0, 576.0], "ocr_text": "preade adapted from quizduell\n", "vlm_text": "The image shows a person with glasses wearing a hoodie, surrounded by other people in what appears to be an indoor setting. There is a computer screen or digital element at the bottom showing text related to WebRTC and a prompt to \"Share Snapshot.\" It seems to be a screenshot of a webcam capture during an event or meeting."}
{"layout": 266, "type": "text", "text": "I might put it up as a Flask site online,if people are interested?) ", "page_idx": 57, "bbox": [53, 519, 716, 572], "page_size": [768.0, 576.0]}
{"layout": 267, "type": "text", "text": "share ", "text_level": 1, "page_idx": 58, "bbox": [60, 119, 95, 382], "page_size": [768.0, 576.0]}
{"layout": 268, "type": "image", "page_idx": 58, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_62.jpg", "bbox": [119, 60, 703, 555], "page_size": [768.0, 576.0], "ocr_text": "2 seconds ago - 0 views -\n\n", "vlm_text": "The image shows a person with glasses and long hair, wearing a hoodie. They appear to be in a seated area, possibly at an indoor event or meeting, with several other people visible in the background. The setting looks like it could be a conference or lecture hall."}
{"layout": 269, "type": "text", "text": "--2015-05-1212:12:00--http://i.imgur.com/oMJyD00.jpg Resolving i.imgur.com（i.imgur.com)...199.27.76.193 Connecting to i.imgur.com（i.imgur.com)|199.27.76.193|:80...connected. HTTP request sent,awaiting response...2oo oK Length:58456(57K)[image/jpeg] Savingto:'oMJyDoo.jpg ", "page_idx": 59, "bbox": [182, 37, 616, 111], "page_size": [768.0, 576.0]}
{"layout": 270, "type": "text", "text": "1008 ===>]58,456 ==.-K/s in0.02s 2015-05-1212:12:00（2.97MB/s)-oMJyD00.jPg'SaVed[58456/58456] ", "page_idx": 59, "bbox": [182, 123, 649, 135], "page_size": [768.0, 576.0]}
{"layout": 271, "type": "text", "text": "", "page_idx": 59, "bbox": [182, 150, 592, 161], "page_size": [768.0, 576.0]}
{"layout": 272, "type": "text", "text": "In[393]:input image  $=$  caffe.io.load_image('oMJyDo0.jpg') plt.imshow(input image) ", "page_idx": 59, "bbox": [66, 194, 635, 230], "page_size": [768.0, 576.0]}
{"layout": 273, "type": "image", "page_idx": 59, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_63.jpg", "img_caption": "Out[393]:<matplotlib.image.Axes Image at 0 x 7 f 51 a e fe 5 e 50> ", "bbox": [62, 246, 621, 571], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a person with long hair and glasses in the foreground, looking at the camera. There is another person with glasses in the background. The setting appears to be indoors, possibly a conference or lecture hall, given the seated arrangement and ceiling lights. There are axis labels along the sides, suggesting the image might be part of a plot or graph from a data visualization tool like Matplotlib."}
{"layout": 274, "type": "text", "text": "In[395]：", "page_idx": 60, "bbox": [23, 44, 119, 61], "page_size": [768.0, 576.0]}
{"layout": 275, "type": "text", "text": "feat  $\\equiv$  get feat single image('rQ4bKra.jpg') #run image  ${\\textbf{x}}=$  feat Y=±([x]) #run feature through DBN > out: prediction if y: print \"wooFI'maDog! else: print\"MEOwI'maCat!\" ", "page_idx": 60, "bbox": [137, 41, 750, 196], "page_size": [768.0, 576.0]}
{"layout": 276, "type": "text", "text": "WOOFI'maDog! ", "page_idx": 60, "bbox": [138, 219, 305, 237], "page_size": [768.0, 576.0]}
{"layout": 277, "type": "text", "text": "feat  $\\equiv$  get feat single image('rQ4bKra.jpg')#run image  ${\\textbf{x}}=$  feat ", "page_idx": 61, "bbox": [137, 43, 750, 83], "page_size": [768.0, 576.0]}
{"layout": 278, "type": "text", "text": "Y= f([x]) #run feature through DBN > out: prediction ify：print\"wooF I'maDog!\" else: print\"MEOWI'maCat!\" ", "page_idx": 61, "bbox": [137, 86, 740, 196], "page_size": [768.0, 576.0]}
{"layout": 279, "type": "text", "text": "WOOFI'maDog! ", "page_idx": 61, "bbox": [137, 219, 305, 237], "page_size": [768.0, 576.0]}
{"layout": 280, "type": "image", "page_idx": 61, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_64.jpg", "bbox": [153, 247, 704, 568], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image features a comparison between a cat and a dog. The left side has an image of a cat's profile with a large red \"X\" over it, and the word \"CAT\" below. The right side shows a dog's profile with a green checkmark on it, accompanied by the word \"DOG.\" The background is a green and yellow geometric pattern. The text \"CAT vs DOG\" is centrally positioned."}
{"layout": 281, "type": "image", "page_idx": 62, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_65.jpg", "bbox": [2, 3, 768, 519.75], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows a painting of a cat and a dog lying close together, partially covered by fabric. At the top, blue text reads \"THATS ALL!\""}
{"layout": 282, "type": "text", "text": "In Touch! ", "text_level": 1, "page_idx": 63, "bbox": [259, 19, 459, 69], "page_size": [768.0, 576.0]}
{"layout": 283, "type": "text", "text": "Academic/Research ", "text_level": 1, "page_idx": 63, "bbox": [40, 93, 332, 130], "page_size": [768.0, 576.0]}
{"layout": 284, "type": "text", "text": "Data Science Consultancy ", "page_idx": 63, "bbox": [423, 101, 735, 127], "page_size": [768.0, 576.0]}
{"layout": 285, "type": "text", "text": "GveSystems Graph Technologies ", "page_idx": 63, "bbox": [497, 148, 735, 204], "page_size": [768.0, 576.0]}
{"layout": 286, "type": "text", "text": "as PhD candidate KTH/CSC: Always interested in discussing Machine Learning,Deep Architectures,Graphs,and Language Technology\" ", "page_idx": 63, "bbox": [44, 160, 358, 289], "page_size": [768.0, 576.0]}
{"layout": 287, "type": "image", "page_idx": 63, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_66.jpg", "bbox": [503, 223, 694, 471], "page_size": [768.0, 576.0], "ocr_text": "MACHINE\nLEARNING\n\nPOWER TO THE UATA\n\n", "vlm_text": "The image features a stylized design of three raised fists, each surrounded by stars. Below the fists, the text reads \"MACHINE LEARNING\" and \"POWER TO THE DATA.\" The overall color scheme is red and white, giving it a bold, poster-like appearance."}
{"layout": 288, "type": "image", "page_idx": 63, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_67.jpg", "bbox": [315, 317, 451, 452], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image appears to be an artistic, stylized portrait of a person with glasses. The image uses a sepia or monochromatic color scheme and has a textured, possibly halftone effect."}
{"layout": 289, "type": "image", "page_idx": 63, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_68.jpg", "img_caption": "ROYAL INSTITUTE OF TECHNOLOGY ", "bbox": [134, 319, 254, 471], "page_size": [768.0, 576.0], "ocr_text": "", "vlm_text": "The image shows the logo of the Royal Institute of Technology, also known as KTH. The logo features a crown above the letters \"KTH,\" with a wreath encircling the text \"VETENSKAP OCH KONST,\" which translates to \"Science and Art\" in English. The background is blue."}
{"layout": 290, "type": "text", "text": "roelof@kth.se www.csc.kth.se/\\~roelof/ ", "page_idx": 63, "bbox": [66, 492, 322, 543], "page_size": [768.0, 576.0]}
{"layout": 291, "type": "text", "text": "roelof@graph-systems.com www.graph-technologies.com ", "page_idx": 63, "bbox": [423, 493, 735, 545], "page_size": [768.0, 576.0]}
{"layout": 292, "type": "text", "text": "Wanna Know More? ", "text_level": 1, "page_idx": 64, "bbox": [140, 13, 576, 62], "page_size": [768.0, 576.0]}
{"layout": 293, "type": "text", "text": "bit.ly/SthlmDL ", "page_idx": 64, "bbox": [489, 69, 653, 86], "page_size": [768.0, 576.0]}
{"layout": 294, "type": "image", "page_idx": 64, "img_path": "layout_images/catvsdogdlpycon15se-150512122612-lva1-app6891_95_69.jpg", "img_caption": "Stockholm Deep Learning Meet up ", "bbox": [109, 124, 660, 568], "page_size": [768.0, 576.0], "ocr_text": "jup tools A My protie\n\nBa “embers sponsors P\n\nStockholm, Welcome! What's new\nSweden\nFounded Feb 21, 2015 * SCHEDULE A NEW MEETUP\nAbout us... Upcoming Past Calender\nApril 20 - 6:00 PM\nDatamaniacs 295\n\nDeep Learning for Bioinformatics\n\nGroup reviews 6 1\nAnm@GehM>c 28\n\nPast Meetups 2\n\n103 Datamaniacs | tint’ | 40 Photos\nOur calendar Bi\n\nAgenda: - 18:00 - 18:15 Grab a coffee/beer and get ready to\nOrganizer: rumble... * 18:15 - 18:30 Welcome «18:30 - 19:00 Roelof Pieters:\nRoelof Deep Learning, a birds eye view « 19:00 -... LEARN MORE\nPieters.\n\nMarch 10 - 6:00 PM\n\nKickoff! Deep Learning: Revolution or Hype in Data-\n\ni ?\n\nWe're about: Science ? MORE\n\nsrosecore A\nba) * @ NEW MEMBER\n\nArtificial Intelligence - . ; : Stefan Avesand\n\nOpen Source - Software 144 Datamaniacs | ‘rie | 35 Photos joined ma\nDevelopment - New\nTechnology : Big Data\n\nNatural Language\n\nDeep Learning is kicking off everywhere (see this front page\n\narticle in the New York Times for example)! There is good reason a NEW MEMBER\n\nto be excited about deep learning, as it's... LEARN MORE Mans Magnusson Ec\njoined\n\nProcessing « Machine\nLearning - Data\n\n", "vlm_text": "The image shows a webpage for the Stockholm Deep Learning Meetup. It includes details like:\n\n- **Location**: Stockholm, Sweden (founded February 21, 2015)\n- **Organizer**: Roelof Pieters\n- **Member Count**: 295 Datamaniacs\n- **Past Event**: \"Deep Learning for Bioinformatics\" on April 20 at 6:00 PM\n- **Agenda**: Starts with grabbing a coffee/beer, followed by a welcome speech and a talk by Roelof Pieters\n- **Another Past Event**: \"Kickoff! Deep Learning: Revolution or Hype in Data-Science?\" on March 10 at 6:00 PM\n- **Side Panel**: Features new members and images from presentations\n\nThe page also highlights topics of interest such as Big Data Analytics, Artificial Intelligence, and Machine Learning."}
{"layout": 295, "type": "text", "text": "WannaPlay?General Deep Learning ", "text_level": 1, "page_idx": 65, "bbox": [35, 23, 683, 66], "page_size": [768.0, 576.0]}
{"layout": 296, "type": "text", "text": "Theano - CPU/GPU symbolic expression compiler in python (from LISA lab at University of Montreal). http://deep learning.net/software/theano/ ", "page_idx": 65, "bbox": [64, 96, 692, 184], "page_size": [768.0, 576.0]}
{"layout": 297, "type": "text", "text": "Pylearn2 - library designed to make machine learning research easy.http://deep learning.net/software/ pylearn2/ ", "page_idx": 65, "bbox": [83, 199, 688, 288], "page_size": [768.0, 576.0]}
{"layout": 298, "type": "text", "text": ":Torch-Matlab-like environment for state-of-the-art machine learning algorithms in lua (fromRonan Collobert, Clement Farabet and Koray Ka vuk cuo g lu http://torch.ch/ ", "page_idx": 65, "bbox": [58, 302, 684, 422], "page_size": [768.0, 576.0]}
{"layout": 299, "type": "text", "text": "moreinfo:http://deep learning.net/software links/ ", "page_idx": 65, "bbox": [83, 439, 647, 460], "page_size": [768.0, 576.0]}
{"layout": 300, "type": "text", "text": "Wanna Play ?NLP ", "text_level": 1, "page_idx": 66, "bbox": [161, 10, 556, 59], "page_size": [768.0, 576.0]}
{"layout": 301, "type": "text", "text": "RNNLM (Mikolov) http://rnnlm.org ", "page_idx": 66, "bbox": [79, 70, 270, 117], "page_size": [768.0, 576.0]}
{"layout": 302, "type": "text", "text": "NB-SVM https://github.com/mesnilgr/nbsvm ", "page_idx": 66, "bbox": [79, 142, 414, 186], "page_size": [768.0, 576.0]}
{"layout": 303, "type": "text", "text": "Word2Vec(skipgrams/cbow) https://code.google.com/p/word2vec/(original) http://radi mre hur ek.com/gensim/models/word2vec.html(python) ", "page_idx": 66, "bbox": [79, 212, 700, 289], "page_size": [768.0, 576.0]}
{"layout": 304, "type": "text", "text": "GloVe http://nlp.stanford.edu/projects/glove/(original) https://github.com/maciejkula/glove-python(python) ", "page_idx": 66, "bbox": [79, 308, 586, 387], "page_size": [768.0, 576.0]}
{"layout": 305, "type": "text", "text": "Socheretal/Stanford RN N Sentiment code: http://nlp.stanford.edu/sentiment/code.html ", "page_idx": 66, "bbox": [79, 408, 516, 453], "page_size": [768.0, 576.0]}
{"layout": 306, "type": "text", "text": "Deep Learning without Magic Tutorial: http://nlp.stanford.edu/courses/NAACL2o13/ ", "page_idx": 66, "bbox": [79, 480, 511, 525], "page_size": [768.0, 576.0]}
{"layout": 307, "type": "text", "text": "Wanna Play ? Computer Uision ", "text_level": 1, "page_idx": 67, "bbox": [35, 17, 681, 69], "page_size": [768.0, 576.0]}
{"layout": 308, "type": "text", "text": "cuda-convnet2 (Alex Krizhevsky, Toronto) (c++/ CUDA,optimized for GTX58o) https://code.google.com/p/cuda-convnet2/ ", "page_idx": 67, "bbox": [85, 96, 624, 184], "page_size": [768.0, 576.0]}
{"layout": 309, "type": "text", "text": "Caffe (Berkeley) (Cuda/OpenCL, Theano, Python) http://caffe.berkeley vision.org/ ", "page_idx": 67, "bbox": [85, 213, 652, 273], "page_size": [768.0, 576.0]}
{"layout": 310, "type": "text", "text": "OverFeat(NYU)http://cilvr.nyu.edu/doku.php?id=code:start ", "page_idx": 67, "bbox": [85, 298, 574, 353], "page_size": [768.0, 576.0]}
