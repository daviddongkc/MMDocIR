{"layout": 0, "type": "text", "text": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning ", "text_level": 1, "page_idx": 0, "bbox": [140, 67, 455, 102], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 1, "type": "text", "text": "Kashyap Popat 1 , Subhabrata Mukherjee 2 , Andrew Yates 1 , Gerhard Weikum 1 1 Max Planck Institute for Informatics, Saarbr¨ ucken, Germany ", "page_idx": 0, "bbox": [102.06100463867188, 123.88201904296875, 497.9710998535156, 152.66641235351562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 2, "type": "text", "text": "Amazon Inc., Seattle, USA { kpopat,ayates,weikum } @mpi-inf.mpg.de, subhomj@amazon.com ", "page_idx": 0, "bbox": [97.02801513671875, 152.20742797851562, 503.5044250488281, 188.67901611328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 3, "type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0, "bbox": [159, 224, 204, 235], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 4, "type": "text", "text": "Misinformation such as fake news is one of the big challenges of our society. Research on automated fact-checking has proposed meth- ods based on supervised learning, but these approaches do not consider external evidence apart from labeled training instances. Recent approaches counter this deﬁcit by considering external sources related to a claim. However, these methods require substantial feature mod- eling and rich lexicons. This paper overcomes these limitations of prior work with an end-to- end model for evidence-aware credibility as- sessment of arbitrary textual claims, without any human intervention. It presents a neural network model that judiciously aggregates sig- nals from external evidence articles, the lan- guage of these articles and the trustworthiness of their sources. It also derives informative features for generating user-comprehensible explanations that makes the neural network predictions transparent to the end-user. Exper- iments with four datasets and ablation studies show the strength of our method. ", "page_idx": 0, "bbox": [89, 250.14154052734375, 273, 525.1603393554688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 5, "type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0, "bbox": [71, 538, 155, 553], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 6, "type": "text", "text": "Motivation:  Modern media (e.g., news feeds, mi- croblogs, etc.) exhibit an increasing fraction of misleading and manipulative content, from ques- tionable claims and “alternative facts” to com- pletely faked news. The media landscape is be- coming a twilight zone and battleground. This so- cietal challenge has led to the rise of fact-checking and debunking websites, such as  Snopes.com and  PolitiFact.com , where people research claims, manually assess their credibility, and present their verdict along with evidence (e.g., background ar- ticles, quotations, etc.). However, this manual ver- iﬁcation is time-consuming. To keep up with the scale and speed at which misinformation spreads, we need tools to automate this debunking process. ", "page_idx": 0, "bbox": [72, 562.8041381835938, 290, 766.03125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 7, "type": "text", "text": "State of the Art and Limitations:  Prior work on “truth discovery” (see  Li et al.  ( 2016 ) for survey) 1 largely focused on structured facts, typically in the form of subject-predicate-object triples, or on social media platforms like Twitter, Sina Weibo, etc. Recently, methods have been proposed to as- sess the credibility of claims in natural language form ( Popat et al. ,  2017 ;  Rashkin et al. ,  2017 ; Wang ,  2017 ), such as news headlines, quotes from speeches, blog posts, etc. ", "page_idx": 0, "bbox": [307, 223.0270233154297, 525, 358.5072937011719], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 8, "type": "text", "text": "The methods geared for general text input ad- dress the problem in different ways. On the one hand, methods like  Rashkin et al.  ( 2017 );  Wang ( 2017 ) train neural networks on labeled claims from sites like  PolitiFact.com , providing credibil- ity assessments without any explicit feature mod- eling. However, they use only the text of ques- tionable claims and no external evidence or inter- actions that provide limited context for credibil- ity analysis. These approaches also do not offer any explanation of their verdicts. On the other hand,  Popat et al.  ( 2017 ) considers external evi- dence in the form of other articles (retrieved from the Web) that conﬁrm or refute a claim, and jointly assesses the language style (using subjectivity lex- icons), the trustworthiness of the sources, and the credibility of the claim. This is achieved via a pipeline of supervised classiﬁers. On the upside, this method generates user-interpretable explana- tions by pointing to informative snippets of evi- dence articles. On the downside, it requires sub- stantial feature modeling and rich lexicons to de- tect bias and subjectivity in the language style. ", "page_idx": 0, "bbox": [307, 359.1858215332031, 525, 670.413330078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 9, "type": "text", "text": "Approach and Contribution:  To overcome the limitations of the prior works, we present  De-  $C l a r E^{2}$  , an end-to-end neural network model for assessing and explaining the credibility of arbi- trary claims in natural-language text form. Our approach combines the best of both families of prior methods. Similar to  Popat et al.  ( 2017 ), De- ClarE incorporates external evidence or counter- evidence from the Web as well as signals from the language style and the trustworthiness of the un- derlying sources. However, our method does not require any feature engineering, lexicons, or other manual intervention.  Rashkin et al.  ( 2017 );  Wang ( 2017 ) also develop an end-to-end model, but De- ClarE goes far beyond in terms of considering ex- ternal evidence and joint interactions between sev- eral factors, and also in its ability to generate user- interpretable explanations in addition to highly accurate assessments. For example, given the natural-language input claim  “the gun epidemic is the leading cause of death of young African- American men, more than the next nine causes put together”  by Hillary Clinton, DeClarE draws on evidence from the Web to arrive at its verdict  cred- ible , and returns annotated snippets like the one in Table  6  as explanation. These snippets, which contain evidence in the form of statistics and as- sertions, are automatically extracted from web ar- ticles from sources of varying credibility. ", "page_idx": 0, "bbox": [307, 670.6981811523438, 525, 724.8843383789062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 10, "type": "text", "text": "", "page_idx": 1, "bbox": [72, 63.68701934814453, 290, 402.0136413574219], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 11, "type": "text", "text": "Given an input claim, DeClarE searches for web articles related to the claim. It considers the  con- text  of the claim via word embeddings and the (language of) web articles captured via a bidirec- tional LSTM (biLSTM), while using an  attention mechanism to focus on parts of the articles accord- ing to their relevance to the claim. DeClarE then aggregates all the information about claim source, web article contexts, attention weights, and trust- worthiness of the underlying sources to assess the claim. It also derives informative features for in- terpretability, like source embeddings that capture trustworthiness and salient words captured via at- tention. Key contributions of this paper are:\n\n ", "page_idx": 1, "bbox": [72, 403.74114990234375, 290, 593.0256958007812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 12, "type": "text", "text": "•  Model:  An end-to-end neural network model which automatically assesses the credibility of natural-language claims, without any hand- ", "page_idx": 1, "bbox": [77, 597.3495483398438, 290, 637.9856567382812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 13, "type": "text", "text": "crafted features or lexicons.\n\n •  Interpret ability:  An  attention  mechanism in our model that generates user-comprehensible explanations, making credibility verdicts transparent and interpretable.\n\n •  Experiments:  Extensive experiments on four datasets and ablation studies, demonstrating effectiveness of our method over state-of-the- art baselines. ", "page_idx": 1, "bbox": [77, 638.3892211914062, 290, 765.9056396484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 14, "type": "text", "text": "2 End-to-end Framework for Credibility Analysis ", "text_level": 1, "page_idx": 1, "bbox": [306, 63, 523, 91], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 15, "type": "text", "text": "Consider a set of    $N$   claims    $\\left\\langle C_{n}\\right\\rangle$  from the respec- tive origins/sources    $\\left\\langle C S_{n}\\right\\rangle$  , where    $n~\\in~[1,N]$  . Each claim    $C_{n}$   is reported by a set of  M  arti- cles    $\\left<A_{m,n}\\right>$  along with their respective sources  $\\langle A S_{m,n}\\rangle$  , where    $m\\in[1,M]$  . Each corresponding tuple of claim and its origin, reporting articles and article sources –    $\\langle C_{n},C S_{n},A_{m,n},A S_{m,n}\\rangle$  forms a training instance in our setting, along with the credibility label of the claim used as ground-truth during network training. Figure  1  gives a pictorial overview of our model. In the following sections, we provide a detailed description of our approach. ", "page_idx": 1, "bbox": [306, 99, 525, 261.6907653808594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 16, "type": "text", "text": "2.1 Input Representations ", "text_level": 1, "page_idx": 1, "bbox": [306, 273, 437, 285], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 17, "type": "text", "text": "The input claim    $C_{n}$   of length    $l$   is represented as  $[c_{1},c_{2},...,c_{l}]$   where    $c_{l}\\,\\in\\,\\mathfrak{R}^{d}$    is the    $d$  -dimensional word embedding of the  l -th word in the input claim. The source/origin of the claim    $C S_{n}$   is rep- resented by a    $d_{s}$  -dimensional embedding vector  $c s_{n}\\in\\mathfrak{R}^{d_{s}}$  . ", "page_idx": 1, "bbox": [306, 290.51025390625, 525, 371.4017639160156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 18, "type": "text", "text": "A reporting article    $A_{m,n}$   consisting of    $k$   to- kens is represented by    $[a_{m,n,1},a_{m,n,2},...,a_{m,n,k}]$  , where    $a_{m,n,k}~\\in~\\mathfrak{R}^{d}$    is t e    $d$  -dimensional word embedding vector for the  k -th word in the report- ing article    $A_{m,n}$  . The claim and article word em- beddings have shared parameters. The source of the reporting article    $A S_{m,n}$   is represented as a    $d_{s}$  - dimensional vector,    $\\mathit{a s}_{m,n}\\ \\in\\ \\Re^{d_{s}}$  . For th sake of brevity, we drop the notation subscripts  n  and  $m$   in the following sections by considering only a single training instance – the input claim    $C_{n}$   from source    $C S_{n}$  , the corresponding article    $A_{m,n}$   and its sources    $A S_{m,n}$   given by:    $\\langle C,C S,A,A S\\rangle$  . ", "page_idx": 1, "bbox": [306, 372.1912841796875, 525, 555.3341064453125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 19, "type": "text", "text": "2.2 Article Representation ", "text_level": 1, "page_idx": 1, "bbox": [306, 559, 439, 571], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 20, "type": "text", "text": "To create a representation of an article, which may capture task-speciﬁc features such as whether it contains objective language, we use a bidirectional Long Short-Term Memory (LSTM) network as proposed by  Graves et al.  ( 2005 ). A basic LSTM cell consists of various gates to control the ﬂow of information through timesteps in a sequence, mak- ing LSTMs suitable for capturing long and short range dependencies in text that may be difﬁcult to capture with standard recurrent neural networks (RNNs). Given an input word embedding of to- kens    $\\left\\langle a_{k}\\right\\rangle$  , an LSTM cell performs various non- linear transformations to generate a hidden vector state  $h_{k}$   for each token at each timestep    $k$  . ", "page_idx": 1, "bbox": [306, 576.746337890625, 525, 767.8087768554688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 21, "type": "image", "page_idx": 2, "img_path": "layout_images/D18-1003_0.jpg", "bbox": [117, 62, 471, 222], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Claim Word\nEmbeddings\n\nConcatenate Dense\nLayer\n\nClaim Source\nEmbedding\n\n(ooo,\n\nOOO)»s) OO0000yH &\n\nArticle Word\nEmbeddings\n\nOOO0000 |\n\nOOO00O0\n\nBidirectional\nLSTM\n\nArticle Source\nEmbedding\n\n@00000000008)\n\nLayer\nConcatenate\nFeatures\n\nDense Dense\n\nLayer\n\nCredibility\nScore\n\nSoftmax/\n\nLinear\n", "vlm_text": "The image is a diagram depicting a machine learning model architecture for determining the credibility score of a claim and an article. It involves several components:\n\n1. **Claim and Article Word Embeddings**: Inputs representing the claim and article texts, which are processed to create embeddings (vector representations).\n\n2. **Bi-directional LSTM**: A layer that processes the concatenated word embeddings of claims and articles to capture context and dependencies in both directions.\n\n3. **Claim Source and Article Source Embedding**: These vectors represent the sources of the claim and the article.\n\n4. **Attention Mechanism**: Utilizes attention weights to focus on important parts of the processed embeddings, creating weighted representations.\n\n5. **Concatenation and Dense Layers**: Combines various feature vectors and processes them through dense (fully connected) layers.\n\n6. **Output - Credibility Score**: The result of the model, which assigns a credibility score to the input claim and article.\n\nOverall, the diagram illustrates a complex neural network designed to analyze and evaluate the credibility of text sources using advanced sequence and embedding techniques."}
{"layout": 22, "type": "text", "text": "Figure 1 : Framework for credibility assessment. Upper part of the pipeline combines the article and claim embeddings to get the claim speciﬁc attention weights. Lower part of the pipeline captures the article representation through biLSTM. Attention focused article representation along with the source embeddings are passed through dense layers to predict the credibility score of the claim. ", "page_idx": 2, "bbox": [72, 244.7210235595703, 525, 298.5135192871094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 23, "type": "text", "text": "We use bidirectional LSTMs in place of stan- dard LSTMs. Bidirectional LSTMs capture both the previous timesteps (past features) and the fu- ture timesteps (future features) via forward and backward states respectively. Correspondingly, there are two hidden states that capture past and future information that are concatenated to form the ﬁnal output as:    $h_{k}=[\\overrightarrow{h_{k}},\\overleftarrow{h_{k}}]$    . ", "page_idx": 2, "bbox": [71, 320.3170471191406, 290, 435.71484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 24, "type": "text", "text": "2.3Claim Speciﬁc Attention", "text_level": 1, "page_idx": 2, "bbox": [71, 450, 212, 463], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 25, "type": "text", "text": "As we previously discussed, it is important to con- sider the relevance of an article with respect to the claim; speciﬁcally, focusing or  attending  to parts of the article that discuss the claim. This is in con- trast to prior works ( Popat et al. ,  2017 ;  Rashkin et al. ,  2017 ;  Wang ,  2017 ) that ignore either the ar- ticle or the claim, and therefore miss out on this important interaction. ", "page_idx": 2, "bbox": [71, 474.6860656738281, 290, 582.675537109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 26, "type": "text", "text": "We propose an attention mechanism to help our model focus on salient words in the article with respect to the claim. To this end, we compute the importance of each term in an article with respect to an overall representation of the corre- sponding claim. Additionally, incorporating atten- tion helps in making our model transparent and in- terpretable, because it provides a way to generate the most salient words in an article as evidence of our model’s verdict. ", "page_idx": 2, "bbox": [71, 586.6871337890625, 290, 721.7755126953125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 27, "type": "text", "text": "Following  Wieting et al.  ( 2015 ), the overall rep- resentation of an input claim is generated by tak- ing an average of the word embeddings of all the words therein: ", "page_idx": 2, "bbox": [71, 725.787109375, 290, 766.0315551757812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 28, "type": "text", "text": "", "page_idx": 2, "bbox": [306, 320.31707763671875, 369.8832702636719, 333.4625549316406], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 29, "type": "equation", "text": "\n$$\n\\bar{c}=\\frac{1}{l}\\sum_{l}c_{l}\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [387, 338, 445, 371], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 30, "type": "text", "text": "We combine this overall representation of the claim with each article term: ", "page_idx": 2, "bbox": [306, 378.72100830078125, 525, 405.4154968261719], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 31, "type": "equation", "text": "\n$$\n\\hat{a}_{k}=a_{k}\\oplus\\bar{c}\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [387, 415, 446, 429], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 32, "type": "text", "text": "where,    $\\hat{a}_{k}\\in\\Re^{d+d}$   ∈ℜ   and    $\\bigoplus$  denotes the concatenate operation. We then perform a transformation to obtain claim-speciﬁc representations of each arti- cle term: ", "page_idx": 2, "bbox": [306, 436.3800048828125, 525, 494.13153076171875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 33, "type": "equation", "text": "\n$$\na_{k}^{\\prime}={\\bf f}\\left(W_{a}\\hat{a}_{k}+b_{a}\\right)\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [370, 502, 462, 518], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 34, "type": "text", "text": "where    $W_{a}$   and    $b_{a}$   are the corresponding weight matrix and bias terms, and    $\\mathbf{f}$  is an activation func-  $\\mathrm{tan}^{3}$  , such as  ReLU ,  tanh , or the identity func- tion. Following this, we use a softmax activation to calculate an attention score    $\\alpha_{k}$   for each word in the article capturing its relevance to the claim context: ", "page_idx": 2, "bbox": [306, 528, 525, 622.4895629882812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 35, "type": "equation", "text": "\n$$\n\\alpha_{k}=\\frac{\\exp(a_{k}^{\\prime})}{\\sum_{k}\\exp(a_{k}^{\\prime})}\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [373, 627, 460, 659], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 36, "type": "text", "text": "2.4 Per-Article Credibility Score of Claim ", "text_level": 1, "page_idx": 2, "bbox": [307, 666, 510, 679], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 37, "type": "text", "text": "Now that we have article term representations given by    $\\langle h_{k}\\rangle$  and their relevance to the claim given by    $\\left\\langle\\alpha_{k}\\right\\rangle$  , we need to combine them to pre- dict the claim’s credibility. In order to create an 3 In our model, the  tanh  activation function gives best re- sults. ", "page_idx": 2, "bbox": [306, 683.386962890625, 525, 765.4855346679688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 38, "type": "text", "text": "attention-focused representation of the article con- sidering both the claim and the article’s language, we calculate a weighted average of the hidden state representations for all article tokens based on their corresponding attention scores: ", "page_idx": 3, "bbox": [71, 63.68701934814453, 290, 131.02951049804688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 39, "type": "equation", "text": "\n$$\ng=\\frac{1}{k}\\sum_{k}\\alpha_{k}\\cdot h_{k}\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [139, 140, 222, 173], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 40, "type": "text", "text": "We then combine all the different feature repre- sentations: the claim source embedding    $(c s)$  , the attention-focused article representation   $(g)$  , and the article source embedding   $(a s)$  . In order to merge the different representations and capture their joint interactions, we process them with two fully connected layers with non-linear activations. ", "page_idx": 3, "bbox": [71, 184.1149444580078, 290, 278.5554504394531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 41, "type": "equation", "text": "\n$$\n\\begin{array}{r l}&{d_{1}=r e l u(W_{c}(g\\oplus c s\\oplus a s)+b_{c})}\\\\ &{d_{2}=r e l u(W_{d}d_{1}+b_{d})}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [102, 289, 259, 323], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 42, "type": "text", "text": "where,    $W$   and  $b$   are the corresponding weight ma- trix and bias terms. ", "page_idx": 3, "bbox": [71, 334.62799072265625, 290, 361.3234558105469], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 43, "type": "text", "text": "Finally, to generate the overall credibility label of the article for classiﬁcation tasks, or credibil- ity score for regression tasks, we process the ﬁnal representation with a ﬁnal fully connected layer: ", "page_idx": 3, "bbox": [71, 362.2499694824219, 290, 416.04345703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 44, "type": "equation", "text": "\n$$\n\\begin{array}{c}{{\\mathrm{Classiffraction:}\\,\\,s=s i g m o i d(d_{2})}}\\\\ {{\\mathrm{Regression:}\\,\\,s=l i n e a r(d_{2})}}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [105, 427, 255, 461], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 45, "type": "text", "text": "2.5 Credibility Aggregation ", "text_level": 1, "page_idx": 3, "bbox": [71, 472, 208, 485], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 46, "type": "text", "text": "The credibility score in the above step is obtained considering a single reporting article. As previ- ously discussed, we have  $M$   reporting articles per claim. Therefore, once we have the per-article credibility scores from our model, we take an av- erage of these scores to generate the overall credi- bility score for the claim: ", "page_idx": 3, "bbox": [71, 490.6319580078125, 290, 585.0734252929688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 47, "type": "equation", "text": "\n$$\nc r e d(C)=\\frac{1}{M}\\sum_{m}s_{m}\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [130, 594, 232, 627], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 48, "type": "text", "text": "This aggregation is done after the model is trained. ", "page_idx": 3, "bbox": [71, 637.3510131835938, 290, 664.04541015625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 49, "type": "text", "text": "3 Datasets ", "text_level": 1, "page_idx": 3, "bbox": [71, 676, 134, 689], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 50, "type": "text", "text": "We evaluate our approach and demonstrate its gen- erality by performing experiments on four differ- ent datasets: a general fact-checking website, a po- litical fact-checking website, a news review com- munity, and a SemEval Twitter rumour dataset. ", "page_idx": 3, "bbox": [71, 698.68896484375, 290, 766.0313720703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 51, "type": "text", "text": "3.1 Snopes ", "text_level": 1, "page_idx": 3, "bbox": [307, 64, 365, 77], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 52, "type": "text", "text": "Snopes ( www.snopes.com ) is a general fact- checking website where editors manually investi- gate various kinds of rumors reported on the In- ternet. We used the Snopes dataset provided by Popat et al.  ( 2017 ). This dataset consists of ru- mors analyzed on the Snopes website along with their credibility labels ( true  or  false ), sets of re- porting articles, and their respective web sources. ", "page_idx": 3, "bbox": [307, 81.57697296142578, 525, 189.56649780273438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 53, "type": "text", "text": "3.2 PolitiFact ", "text_level": 1, "page_idx": 3, "bbox": [306, 199, 377, 212], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 54, "type": "text", "text": "PolitiFact is a political fact-checking website ( www.politifact.com ) in which editors rate the credibility of claims made by various politi- cal ﬁgures in US politics. We extract all articles from PolitiFact published before December 2017. Each article includes a claim, the speaker (polit- ical ﬁgure) who made the claim, and the claim’s credibility rating provided by the editors. ", "page_idx": 3, "bbox": [307, 217.41603088378906, 525, 325.4055480957031], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 55, "type": "text", "text": "PolitiFact assigns each claim to one of six pos- sible ratings:  true, mostly true, half true, mostly false, false  and  pants-on-ﬁre . Following  Rashkin et al.  ( 2017 ), we combine  true, mostly true  and half true  ratings into the class label  true  and the rest as  false  – hence considering only binary cred- ibility labels. To retrieve the reporting articles for each claim (similar to  Popat et al.  ( 2017 )), we is- sue each claim as a query to a search engine 4   and retrieve the top 30 search results with their respec- tive web sources. ", "page_idx": 3, "bbox": [307, 326.0170593261719, 525, 474.65460205078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 56, "type": "text", "text": "3.3 NewsTrust ", "text_level": 1, "page_idx": 3, "bbox": [307, 484, 382, 497], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 57, "type": "text", "text": "NewsTrust is a news review community in which members review the credibility of news articles. We use the NewsTrust dataset made available by Mukherjee and Weikum  ( 2015 ). This dataset con- tains NewsTrust stories from May 2006 to May 2014. Each story consists of a news article along with its source, and a set of reviews and ratings by community members. NewsTrust aggregates these ratings and assigns an overall credibility score (on a scale of 1 to 5) to the posted article. We map the attributes in this data to the inputs expected by De- ClarE as follows: the title and the web source of the posted (news) article are mapped to the input claim and claim source, respectively. Reviews and their corresponding user identities are mapped to reporting articles and article sources, respectively. We use this dataset for the regression task of pre- dicting the credibility score of the posted article. ", "page_idx": 3, "bbox": [307, 502.50408935546875, 525, 745.985595703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 58, "type": "table", "page_idx": 4, "img_path": "layout_images/D18-1003_1.jpg", "table_footnote": "Table 1 : Data statistics (SN: Snopes, PF: Politi- Fact, NT: NewsTrust, SE: SemEval). ", "bbox": [71, 61, 290, 199], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Dataset SN PF NT SE\nTotal claims 4341 3568 5344 272\nTrue claims 1164 1867 - 127\nFalse claims 3177 1701 - 50\nUnverified claims - - - 95\nClaim sources - 95 161 10\nArticles 29242 29556 25128 3717\nArticle sources 336 336 251 89\n\n", "vlm_text": "The table provides data regarding different datasets labeled as SN, PF, NT, and SE. The data is categorized into the following:\n\n1. **Total claims**: \n   - SN: 4341\n   - PF: 3568\n   - NT: 5344\n   - SE: 272\n\n2. **True claims**:\n   - SN: 1164\n   - PF: 1867\n   - NT: Not provided\n   - SE: 127\n\n3. **False claims**:\n   - SN: 3177\n   - PF: 1701\n   - NT: Not provided\n   - SE: 50\n\n4. **Unverified claims**:\n   - SN: Not provided\n   - PF: Not provided\n   - NT: Not provided\n   - SE: 95\n\n5. **Claim sources**:\n   - SN: Not provided\n   - PF: 95\n   - NT: 161\n   - SE: 10\n\n6. **Articles**:\n   - SN: 29242\n   - PF: 29556\n   - NT: 25128\n   - SE: 3717\n\n7. **Article sources**:\n   - SN: 336\n   - PF: 336\n   - NT: 251\n   - SE: 89\n\nThe data illustrates the composition and sources of several datasets in terms of claims and articles, distinguishing between true, false, and unverified claims where available."}
{"layout": 59, "type": "text", "text": "3.4 SemEval-2017 Task 8 ", "text_level": 1, "page_idx": 4, "bbox": [71, 222, 197, 234], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 60, "type": "text", "text": "As the fourth dataset, we consider the benchmark dataset released by SemEval-2017 for the task of determining credibility and stance of social media content (Twitter) ( Derczynski et al. ,  2017 ). The objective of this task is to predict the credibility of a questionable tweet ( true ,  false  or  unveriﬁed ) along with a conﬁdence score from the model. It has two sub-tasks: (i) a  closed  variant in which models only consider the questionable tweet, and (ii) an  open  variant in which models consider both the questionable tweet and additional context con- sisting of snapshots of relevant sources retrieved immediately before the rumor was reported, a snapshot of an associated Wikipedia article, news articles from digital news outlets, and preceding tweets about the same event. Testing and devel- opment datasets provided by organizers have 28 tweets (1021 reply tweets) and 25 tweets (256 re- ply tweets), respectively. ", "page_idx": 4, "bbox": [72, 238.92897033691406, 290, 495.9595642089844], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 61, "type": "text", "text": "3.5 Data Processing ", "text_level": 1, "page_idx": 4, "bbox": [72, 506, 172, 518], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 62, "type": "text", "text": "In order to have a minimum support for training, claim sources with less than 5 claims in the dataset are grouped into a single dummy claim source, and article sources with less than 10 articles are grouped similarly (5 articles for SemEval as it is a smaller dataset). ", "page_idx": 4, "bbox": [72, 522.5491333007812, 290, 603.4405517578125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 63, "type": "text", "text": "For Snopes and PolitiFact, we need to extract relevant snippets from the reporting articles for a claim. Therefore, we extract snippets of 100 words from each reporting article having the maxi- mum relevance score:    $s i m=s i m_{\\mathrm{bew}}\\!\\times\\!s i m_{\\mathrm{s}}$  semantic where    $s i m_{\\mathrm{low}}$   is the fraction of claim words that are present in the snippet, and  sim semantic  repre- sents the cosine similarity between the average of claim word embeddings and snippet word em- beddings. We also enforce a constraint that the sim  score is at least    $\\delta$  . We varied    $\\delta$   from 0.2 to 0.8 and found 0.5 to give the optimal perfor- ", "page_idx": 4, "bbox": [72, 603.8450927734375, 290, 766.031494140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 64, "type": "table", "page_idx": 4, "img_path": "layout_images/D18-1003_2.jpg", "table_footnote": "Table 2 : Model parameters used for each dataset (SN: Snopes, PF: PolitiFact, NT: NewsTrust, SE: SemEval). ", "bbox": [306, 61, 526, 195], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Parameter SN PF NT _ SE\nWord embedding length 100 100 300 100\nClaim source embedding length - 4 8 4\nArticle source embedding length 8 4 8 4\nLSTM size (for each pass) 64 64 64 16\nSize of fully connected layers 32 32—64 8\nDropout 05 05 03 0.3\n\n", "vlm_text": "The table displays various parameters and their values for four different configurations labeled as SN, PF, NT, and SE. Here is a summary of the parameters and their respective values:\n\n1. **Word embedding length**:\n   - SN: 100\n   - PF: 100\n   - NT: 300\n   - SE: 100\n\n2. **Claim source embedding length**:\n   - SN: -\n   - PF: 4\n   - NT: 8\n   - SE: 4\n\n3. **Article source embedding length**:\n   - SN: 8\n   - PF: 4\n   - NT: 8\n   - SE: 4\n\n4. **LSTM size (for each pass)**:\n   - SN: 64\n   - PF: 64\n   - NT: 64\n   - SE: 16\n\n5. **Size of fully connected layers**:\n   - SN: 32\n   - PF: 32\n   - NT: 64\n   - SE: 8\n\n6. **Dropout**:\n   - SN: 0.5\n   - PF: 0.5\n   - NT: 0.3\n   - SE: 0.3 \n\nThese values likely correspond to different neural network models or configurations used in a machine learning experiment or study."}
{"layout": 65, "type": "text", "text": "mance on a withheld dataset. We discard all arti- cles related to Snopes and PolitiFact websites from our datasets to have an unbiased model. Statis- tics of the datasets after pre-processing is pro- vided in Table  1 . All the datasets are made pub- licly available at  https://www.mpi-inf. mpg.de/dl-cred-analysis/ . ", "page_idx": 4, "bbox": [307, 218.08302307128906, 525, 312.5235290527344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 66, "type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 4, "bbox": [307, 323, 391, 337], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 67, "type": "text", "text": "We evaluate our approach by conducting experi- ments on four datasets, as described in the previ- ous section. We describe our experimental setup and report our results in the following sections. ", "page_idx": 4, "bbox": [307, 345.6940612792969, 525, 399.487548828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 68, "type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 4, "bbox": [307, 410, 425, 422], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 69, "type": "text", "text": "When using the Snopes, PolitiFact and NewsTrust datasets, we reserve   $10\\%$   of the data as valida- tion data for parameter tuning. We report 10-fold cross validation results on the remaining   $90\\%$   of the data; the model is trained on 9-folds and the remaining fold is used as test data. When us- ing the SemEval dataset, we use the data splits provided by the task’s organizers. The objective for Snopes, PolitiFact and SemEval experiments is binary (credibility) classiﬁcation, while for New- sTrust the objective is to predict the credibility score of the input claim on a scale of 1 to 5 (i.e., credibility regression). We represent terms us- ing pre-trained GloVe Wikipedia 6B word embed- dings ( Pennington et al. ,  2014 ). Since our train- ing datasets are not very large, we do not tune the word embeddings during training. The remaining model parameters are tuned on the validation data; the parameters chosen are reported in Table  2 . We use Keras with a Tensorﬂow backend to imple- ment our system. All the models are trained using Adam optimizer ( Kingma and Ba ,  2014 ) (learn- ing rate: 0.002) with categorical cross-entropy loss for classiﬁcation and mean squared error loss for regression task. We use L2-regularizers with the ", "page_idx": 4, "bbox": [307, 427.705078125, 525, 766.0315551757812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 70, "type": "table", "page_idx": 5, "img_path": "layout_images/D18-1003_3.jpg", "table_footnote": "Table 3 : Comparison of various approaches for credibility classiﬁcation on Snopes and PolitiFact datasets. ", "bbox": [71, 60, 526, 276], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "F True Claims False Claims Macro\n\nDataset Configuration Accuracy (%) Accuracy (%) F1-Score ae\nLSTM-text 64.65 64.21 0.66 0.70\nCNN-text 67.15 63.14 0.66 0.72\nDistant Supervision 83.21 80.78 0.82 0.88\n\nSnopes F\nDeClarE (Plain) 74.37 78.57 0.78 0.83\nDeClarE (Plain+Attn) 78.34 78.91 0.79 0.85\nDeClarE (Plain+SrEmb) 7743 79.80 0.79 0.85\nDeClarE (Full) 78.96 78.32 0.79 0.86\nLSTM-text 63.19 61.96 0.63 0.66\nCNN-text 63.67 63.31 0.64 0.67\nDistant Supervision 62.53 62.08 0.62 0.68\n\nPolitiFact  DeClarE (Plain) 62.67 69.05 0.66 0.70\nDeClarE (Plain+Attn) 65.53 68.49 0.66 0.72\nDeClarE (Plain+SrEmb) 66.71 69.28 0.67 0.74\nDeClarE (Full) 67.32 69.62 0.68 0.75\n", "vlm_text": "The table presents the performance of different configurations of models on two datasets, Snopes and PolitiFact. It includes measurements of accuracy for true and false claims, macro F1-score, and AUC (Area Under the Curve). Here's a breakdown:\n\n**Snopes Dataset:**\n\n1. **LSTM-text:**\n   - True Claims Accuracy: 64.65%\n   - False Claims Accuracy: 64.21%\n   - Macro F1-Score: 0.66\n   - AUC: 0.70\n\n2. **CNN-text:**\n   - True Claims Accuracy: 67.15%\n   - False Claims Accuracy: 63.14%\n   - Macro F1-Score: 0.66\n   - AUC: 0.72\n\n3. **Distant Supervision:**\n   - True Claims Accuracy: 83.21%\n   - False Claims Accuracy: 80.78%\n   - Macro F1-Score: 0.82\n   - AUC: 0.88\n\n4. **DeClarE Variants:**\n   - Plain:\n     - True Claims Accuracy: 74.37%\n     - False Claims Accuracy: 78.57%\n     - Macro F1-Score: 0.78\n     - AUC: 0.83\n   - Plain+Attn:\n     - True Claims Accuracy: 78.34%\n     - False Claims Accuracy: 78.91%\n     - Macro F1-Score: 0.79\n     - AUC: 0.85\n   - Plain+SrEmb:\n     - True Claims Accuracy: 77.43%\n     - False Claims Accuracy: 79.80%\n     - Macro F1-Score: 0.79\n     - AUC: 0.85\n   - Full:\n     - True Claims Accuracy: 78.96%\n     - False Claims Accuracy: 78.32%\n     - Macro F1-Score: 0.79\n     - AUC: 0.86\n\n**PolitiFact Dataset:**\n\n1. **LSTM-text:**\n   - True Claims Accuracy: 63.19%\n   - False Claims Accuracy: 61.96%\n   - Macro F1-Score: 0.63\n   - AUC: 0.66\n\n2. **CNN-text:**\n   - True Claims Accuracy: 63.67%\n   - False Claims Accuracy: 63.31%\n   - Macro F1-Score: 0.64\n   - AUC: 0.67\n\n3. **Distant Supervision:**\n   - True Claims Accuracy: 62.53%\n   - False Claims Accuracy: 62.08%\n   - Macro F1-Score: 0.62\n   - AUC: 0.68\n\n4. **DeClarE Vari"}
{"layout": 71, "type": "text", "text": "fully connected layers as well as dropout. For all the datasets, the model is trained using each claim- article pair as a separate training instance. ", "page_idx": 5, "bbox": [71, 298.16400146484375, 290, 338.4075012207031], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 72, "type": "text", "text": "To evaluate and compare the performance of DeClarE with other state-of-the-art methods, we report the following measures: ", "page_idx": 5, "bbox": [71, 339.09600830078125, 290, 379.3395080566406], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 73, "type": "text", "text": "•  Credibility Classiﬁcation (Snopes, PolitiFact and SemEval): accuracy of the models in clas- sifying  true  and  false  claims separately, macro F1-score and Area-Under-Curve (AUC) for the ROC (Receiver Operating Characteristic) curve. •  Credibility Regression (NewsTrust): Mean Square Error (MSE) between the predicted and true credibility scores. ", "page_idx": 5, "bbox": [77, 383.01702880859375, 290, 507.5455322265625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 74, "type": "text", "text": "4.2 Results: Snopes and Politifact ", "text_level": 1, "page_idx": 5, "bbox": [71, 518, 236, 531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 75, "type": "text", "text": "We compare our approach with the following state-of-the-art models: (i) LSTM-text, a recent approach proposed by  Rashkin et al.  ( 2017 ). (ii) CNN-text: a CNN based approach proposed by Wang  ( 2017 ). (iii) Distant Supervision: state- of-the-art distant supervision based approach pro- posed by  Popat et al.  ( 2017 ). (iv) DeClare (Plain): our approach with only biLSTM (no at- tention and source embeddings). (v) DeClarE (Plain+Attn): our approach with only biLSTM and attention (no source embeddings). (vi) De- ClarE (  $_\\mathrm{|diamond+SrEmb]}$  ): our approach with only biLSTM and source embeddings (no attention). (vii) DeClarE (Full): end-to-end system with biL- STM, attention and source embeddings. ", "page_idx": 5, "bbox": [71, 535.8140258789062, 290, 738.6474609375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 76, "type": "text", "text": "The results when performing credibility classi- ﬁcation on the Snopes and PolitiFact datasets are shown in Table  3 . DeClarE outperforms LSTM- text and CNN-text models by a large margin on both datasets. On the other hand, for the Snopes dataset, performance of DeClarE (Full) is slightly lower than the Distant Supervision conﬁguration (p-value of 0.04 with a pairwise t-test). How- ever, the advantage of DeClarE over Distant Su- pervision approach is that it does not rely on hand crafted features and lexicons, and can generalize well to arbitrary domains without requiring any seed vocabulary. It is also to be noted that both of these approaches use external evidence in the form of reporting articles discussing the claim, which are not available to the LSTM-text and CNN-text baselines. This demonstrates the value of external evidence for credibility assessment. ", "page_idx": 5, "bbox": [71, 739.3360595703125, 290, 766.031494140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 77, "type": "text", "text": "", "page_idx": 5, "bbox": [307, 298.1640625, 526, 514.546630859375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 78, "type": "text", "text": "On the PolitiFact dataset, DeClarE outperforms all the baseline models by a margin of   $7.9\\%$  AUC (p-value of    $9.12\\mathrm{e}{-05}$   with a pairwise t-test) with similar improvements in terms of Macro F1. A performance comparison of DeClarE’s various conﬁgurations indicates the contribution of each component of our model, i.e, biLSTM capturing article representations, attention mechanism and source embeddings. The additions of both the attention mechanism and source embeddings im- prove performance over the plain conﬁguration in all cases when measured by Macro F1 or AUC. ", "page_idx": 5, "bbox": [307, 516.2511596679688, 526, 678.4376831054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 79, "type": "text", "text": "4.3 Results: NewsTrust ", "text_level": 1, "page_idx": 5, "bbox": [307, 693, 423, 705], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 80, "type": "text", "text": "When performing credibility regression on the NewsTrust dataset, we evaluate the models in terms of mean squared error (MSE; lower is bet- ter) for credibility rating prediction. We use the ", "page_idx": 5, "bbox": [307, 712.2382202148438, 526, 766.0316772460938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 81, "type": "table", "page_idx": 6, "img_path": "layout_images/D18-1003_4.jpg", "bbox": [104, 60, 258, 170], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Configuration MSE\nCNN-text 0.53\nCCRF+SVR 0.36\nLSTM-text 0.35\nDistantSup 0.35\nDeClarE (Plain) 0.34\nDeClarE (Full) 0.29\n", "vlm_text": "The table presents a comparison of different model configurations and their Mean Squared Error (MSE) values. The configurations listed are CNN-text, CCRF+SVR, LSTM-text, DistantSup, DeClarE (Plain), and DeClarE (Full). The respective MSE values for these configurations are 0.53, 0.36, 0.35, 0.35, 0.34, and 0.29. The DeClarE (Full) configuration has the lowest MSE value (0.29), suggesting it performs the best among the listed configurations in terms of minimizing the error."}
{"layout": 82, "type": "text", "text": "Table 4 : Comparison of various approaches for credibility regression on NewsTrust dataset. ", "page_idx": 6, "bbox": [71, 179.29603576660156, 290, 205.99148559570312], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 83, "type": "text", "text": "ﬁrst three models described in Section  4.2  as base- lines. For CNN-text and LSTM-text, we add a lin- ear fully connected layer as the ﬁnal layer of the model to support regression. Additionally, we also consider the state-of-the-art   $\\mathrm{CCRF+SWR}$   model based on Continuous Conditional Random Field (CCRF) and Support Vector Regression (SVR) proposed by  Mukherjee and Weikum  ( 2015 ). The results are shown in Table  4 . We observe that De- ClarE (Full) outperforms all four baselines, with a   $17\\%$   decrease in MSE compared to the best- performing baselines (i.e., LSTM-text and Dis- tant Supervision). The DeClarE (Plain) model performs substantially worse than the full model, illustrating the value of including attention and source embeddings. CNN-text performs substan- tially worse than the other baselines. ", "page_idx": 6, "bbox": [71, 230.40003967285156, 290, 460.3326110839844], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 84, "type": "text", "text": "4.4 Results: SemEval ", "text_level": 1, "page_idx": 6, "bbox": [71, 474, 179, 486], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 85, "type": "text", "text": "On the SemEval dataset, the objective is to per- form credibility classiﬁcation of a tweet while also producing a classiﬁcation conﬁdence score. We compare the following approaches and consider both variants of the SemEval task: (i)  NileTMRG ( Enayet and El-Beltagy ,  2017 ): the best perform- ing approach for the  close  variant of the task, (ii) IITP  ( Singh et al. ,  2017 ): the best performing ap- proach for the  open  variant of the task, (iii) De- Clare (Plain): our approach with only biLSTM (no attention and source embeddings), and (iv) DeClarE (Full): our end-to-end system with biL- STM, attention and source embeddings. ", "page_idx": 6, "bbox": [71, 494.14813232421875, 290, 669.8846435546875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 86, "type": "text", "text": "We use the evaluation measure proposed by the task’s organizers: macro F1-score for overall clas- siﬁcation and Root-Mean-Square Error (RMSE) over conﬁdence scores. Results are shown in Ta- ble  5 . We observe that DeClarE (Full) outperforms all the other approaches — thereby, re-afﬁrming its power in harnessing external evidence. ", "page_idx": 6, "bbox": [71, 671.5911865234375, 290, 766.0316162109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 87, "type": "table", "page_idx": 6, "img_path": "layout_images/D18-1003_5.jpg", "table_footnote": "Table 5 : Comparison of various approaches for credibility classiﬁcation on SemEval dataset. ", "bbox": [306, 61, 527, 192], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Macro\n\nConfiguration RMSE\nAccuracy\n\nIITP (Open) 0.39 0.746\n\nNileTMRG (Close) 0.54 0.673\n\nDeClarE (Plain) 0.46 0.687\n\nDeClarE (Full) 0.57 0.604\n", "vlm_text": "The table compares different configurations based on their Macro Accuracy and RMSE (Root Mean Square Error). \n\n- **IITP (Open)**: Macro Accuracy is 0.39, RMSE is 0.746\n- **NileTMRG (Close)**: Macro Accuracy is 0.54, RMSE is 0.673\n- **DeClarE (Plain)**: Macro Accuracy is 0.46, RMSE is 0.687\n- **DeClarE (Full)**: Macro Accuracy is 0.57, RMSE is 0.604\n\nThe bold values indicate the best performance for each metric. DeClarE (Full) has the highest Macro Accuracy and the lowest RMSE."}
{"layout": 88, "type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 6, "bbox": [306, 214, 381, 227], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 89, "type": "text", "text": "5.1 Analyzing Article Representations ", "text_level": 1, "page_idx": 6, "bbox": [306, 236, 493, 248], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 90, "type": "text", "text": "In order to assess how our model separates articles reporting false claims from those reporting true ones, we employ dimensionality reduction using Principal Component Analysis (PCA) to project the article representations   $\\acute{g}$   in Equation  2 ) from a high dimensional space to a 2d plane. The pro- jections are shown in Figure  2a . We observe that DeClarE obtains clear separability between credi- ble versus non-credible articles in Snopes dataset. ", "page_idx": 6, "bbox": [307, 252.7890167236328, 525, 374.3275451660156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 91, "type": "text", "text": "5.2 Analyzing Source Embeddings ", "text_level": 1, "page_idx": 6, "bbox": [306, 384, 475, 397], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 92, "type": "text", "text": "Similar to the treatment of article representations, we perform an analysis with the claim and arti- cle source embeddings by employing PCA and plotting the projections. We sample a few popu- lar news sources from Snopes and claim sources from PolitiFact. These news sources and claim sources are displayed in Figure  2b  and Figure  2c , respectively. From Figure  2b  we observe that DeClarE clearly separates fake news sources like nationalreport ,  empirenews ,  huzlers , etc. from mainstream news sources like  nytimes ,  cnn ,  wsj , foxnews ,  washingtonpost , etc. Similarly, from Fig- ure  2c  we observe that DeClarE locates politicians with similar ideologies and opinions close to each other in the embedding space. ", "page_idx": 6, "bbox": [307, 401.21807861328125, 525, 604.0526123046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 93, "type": "text", "text": "5.3 Analyzing Attention Weights ", "text_level": 1, "page_idx": 6, "bbox": [306, 614, 467, 627], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 94, "type": "text", "text": "Attention weights help understand what DeClarE focuses on during learning and how it affects its decisions – thereby, making our model transparent to the end-users. Table  6  illustrates some interest- ing claims and salient words (highlighted) that De- ClarE focused on during learning. Darker shades indicate higher weights given to the corresponding words. As illustrated in the table, DeClarE gives more attention to important words in the report- ing article that are relevant to the claim and also ", "page_idx": 6, "bbox": [307, 630.9431762695312, 525, 766.0315551757812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 95, "type": "image", "page_idx": 7, "img_path": "layout_images/D18-1003_6.jpg", "bbox": [71, 72, 527, 230], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "cnn\n°\nbernie sanders. barack obama »\n\nnytimess\n\nwashingtonpost\ngtonpost » steaeriiz hillary clinton ¢\n\n*rudy giuliani\nedailycurrant\n\nhuzlers emike pence\n. ebbe paul ryan\neempirenews foxnewse\nenationalreport usatoday» donald trump\n\nworldnewsdailyreport\n\newsj mitch mcconnell\n\n(a) Projections of article representations\nusing PCA; DeClarE obtains clear sep-\naration between representations of non-\ncredible articles (red) vs. true ones\n(oreen).\n\nb) Projections of article source repre- (c) Projections of claim source repre-\nentations using PCA; DeClarE clearly _ sentations using PCA; DeClarE clusters\neparates fake news sources from au- _ politicians of similar ideologies close to\nentic ones. each other in the embedding space.\n\naa\n\nan\n", "vlm_text": "The image consists of three subplots illustrating the use of PCA (Principal Component Analysis) in projecting different types of data:\n\n1. **Subplot (a)**: Shows projections of article representations. It distinguishes non-credible articles (in red) from true ones (in green).\n\n2. **Subplot (b)**: Displays projections of article source representations, separating fake news sources from authentic ones using PCA. Various news sources are labeled, such as \"cnn,\" \"nytimes,\" and others.\n\n3. **Subplot (c)**: Shows projections of claim source representations, clustering politicians of similar ideologies close to each other in the embedding space. Names like \"bernie sanders\" and \"donald trump\" are present.\n\nEach subplot demonstrates how DeClarE (which appears to be a model or method) effectively separates and clusters data points."}
{"layout": 96, "type": "text", "text": "Figure 2 : Dissecting the article, article source and claim source representations learned by DeClarE. ", "page_idx": 7, "bbox": [82.0579833984375, 242.7270050048828, 515.4911499023438, 255.87246704101562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 97, "type": "image", "page_idx": 7, "img_path": "layout_images/D18-1003_7.jpg", "bbox": [73, 266, 519, 500], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "[False] Barbara Boxer: \"Fiorina's plan would mean slashing Social Security and Medicare.\"\nArticle Source: nytimes.com\n\nleast of Slimmer of With while ignoring critical | that would give a different impression mr adair cited a couple examples of barely true claims\n\nincluding this one in california democratic sen boxer elaimed that republican challenger carly fiorina s plan would mean slashing social security\nand medicare but we found there was to support that fiorina Wash ¢ Said much about her ideas on social security and re\nshe has said doesn t provide much of slashing and then there s this one in pennsylvania in the pennsylvania senate race republican pat toomey\n\n[True] Hillary Clinton: \"The gun epidemic is the leading cause of death of young African-American men, more than the next nine causes put together.\"\nArticle Source: thetrace.org\n\naway the cause of death By.\na chilling on\n\nBOTB during the presidential debate monday night democratic Wominee hillary\nof black “t gun is the (@ading cause of death of young\nthe from the centers for control and in Confirms her assertion of\n\nmore\nbetween the BBS of BERR Were Killed with a gun WED) tne in 0\n\nand 4 that died in\n\n[False] : Coca-Cola’ original diet cola drink, TaB, took its name from an acronym for “totally artificial beverage.”\nArticle Source: foxnews.com\n\nthe first diet colas being the first in 1952 @BCaeOla execs at that time were hesitant to the term diet to so the name tab was chosen as a tribute\nto those who were keeping tab of their weight according to cola the drink was dubbed tab as an for totally artificial beverage a\ngreat story which unfortunately @6€aeola says is completely the name was actually chosen by computer and market research the saecharin Scandal\n\nin the 70s did its damage and the introduction of diet coke in the early 1980s pushed tab even\n\n[True] » Household paper shredders can pose a danger to children and pets.\nArticle Source: byegoff.com\n\npackages while still protecting any private information that may be eontained in the papers in the personal home paper shredder makes much sense\npersonal or pet injuries from paper a growing number of reported injuries that home Shredders pose a danger to any user and are\nespecially dangerous to children and fact the federal consumer product safety commission issued a paper shredder safety alert documenting\n\nof incidents involving finger amputations lacerations and other finger injuries directly connected to the use of home\n\n", "vlm_text": "The image contains a compilation of statements with their truth values and article sources:\n\n1. **Statement**: Barbara Boxer claimed \"Fiorina's plan would mean slashing Social Security and Medicare.\"\n   - **Truth Value**: False\n   - **Article Source**: nytimes.com\n\n2. **Statement**: Hillary Clinton stated \"The gun epidemic is the leading cause of death of young African-American men, more than the next nine causes put together.\"\n   - **Truth Value**: True\n   - **Article Source**: thetrace.org\n\n3. **Statement**: \"Coca-Cola’s original diet cola drink, TaB, took its name from an acronym for 'totally artificial beverage.'\"\n   - **Truth Value**: False\n   - **Article Source**: foxnews.com\n\n4. **Statement**: \"Household paper shredders can pose a danger to children and pets.\"\n   - **Truth Value**: True\n   - **Article Source**: byegoff.com\n\nHighlighted words seem to emphasize key points or aspects of the text in each statement."}
{"layout": 98, "type": "text", "text": "Table 6 : Interpretation via attention (weights)   $([T r u e]/[F a l s e]$   indicates the verdict from DeClarE). ", "page_idx": 7, "bbox": [86.26399993896484, 509.66302490234375, 511.28179931640625, 522.8084716796875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 99, "type": "text", "text": "play a major role in deciding the corresponding claim’s credibility. In the ﬁrst example on Table  6 , highlighted words such as “ ..barely true... ” and “ ..sketchy evidence... ” help our system to identify the claim as  not credible . On the other hand, high- lighted words in the last example, like, “ ..reveal... ” and “ ..documenting reports... ” help our system to assess the claim as  credible . ", "page_idx": 7, "bbox": [71, 544.6119995117188, 290, 652.6014404296875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 100, "type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 7, "bbox": [71, 664, 161, 676], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 101, "type": "text", "text": "Our work is closely related to the following areas: Credibility analysis of Web claims:  Our work builds upon approaches for performing credibility analysis of natural language claims in an open- domain Web setting. The approach proposed in Popat et al.  ( 2016 ,  2017 ) employs stylistic lan- guage features and the stance of articles to as- sess the credibility of the natural language claims. However, their model heavily relies on hand- crafted language features.  Rashkin et al.  ( 2017 ); Wang  ( 2017 ) propose neural network based ap- proaches for determining the credibility of a tex- tual claim, but it does not consider external sources like web evidence and claim sources. These can be important evidence sources for cred- ibility analysis. The method proposed by  Samadi et al.  ( 2016 ) uses the Probabilistic Soft Logic (PSL) framework to estimate source reliability and claim correctness.  Vydiswaran et al.  ( 2011 ) pro- poses an iterative algorithm which jointly learns the veracity of textual claims and trustworthiness of the sources. These approaches do not consider ", "page_idx": 7, "bbox": [71, 684.9949951171875, 290, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 102, "type": "text", "text": "", "page_idx": 7, "bbox": [307, 544.6119995117188, 525, 760.9954223632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 103, "type": "text", "text": "the deeper semantic aspects of language, however. Wiebe and Riloff  ( 2005 );  Lin et al.  ( 2011 );  Re- casens et al.  ( 2013 ) study the problem of detecting bias in language, but do not consider credibility. ", "page_idx": 8, "bbox": [72, 63.68701934814453, 290, 117.48049926757812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 104, "type": "text", "text": "Truth discovery:  Prior approaches for truth dis- covery ( Yin et al. ,  2008 ;  Dong et al. ,  2009 ,  2015 ; Li et al. ,  2011 ,  2014 ,  2015 ;  Pasternack and Roth , 2011 ,  2013 ;  Ma et al. ,  2015 ;  Zhi et al. ,  2015 ; Gao et al. ,  2015 ;  Lyu et al. ,  2017 ) have focused on structured data with the goal of addressing the problem of conﬂict resolution amongst multi- source data.  Nakashole and Mitchell  ( 2014 ) pro- posed a method to extract conﬂicting values from the Web in the form of Subject-Predicate-Object (SPO) triplets and uses language objectivity analy- sis to determine the true value. Like the other truth discovery approaches, however, this approach is mainly suitable for use with structured data. ", "page_idx": 8, "bbox": [72, 120.14830017089844, 290, 309.8265686035156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 105, "type": "text", "text": "Credibility analysis in social media:  Mukher- jee et al.  ( 2014 );  Mukherjee and Weikum  ( 2015 ) propose PGM based approaches to jointly in- fer a statement’s credibility and the reliability of sources using language speciﬁc features. Ap- proaches like ( Castillo et al. ,  2011 ;  Qazvinian et al. ,  2011 ;  Yang et al. ,  2012 ;  Xu and Zhao ,  2012 ; Gupta et al. ,  2013 ;  Zhao et al. ,  2015 ;  Volkova et al. ,  2017 ) propose supervised methods for de- tecting deceptive content in social media plat- forms like Twitter, Sina Weibo, etc. Similarly, ap- proaches like  Ma et al.  ( 2016 );  Ruchansky et al. ( 2017 ) use neural network methods to identify fake news and rumors on social media. Ku- mar et al.  ( 2016 ) studies the problem of detect- ing hoax articles on Wikipedia. All these rely on domain-speciﬁc and community-speciﬁc features like retweets, likes, upvotes, etc. ", "page_idx": 8, "bbox": [72, 312.4943542480469, 290, 556.36962890625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 106, "type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 8, "bbox": [71, 576, 147, 588], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 107, "type": "text", "text": "In this work, we propose a completely automated end-to-end neural network model, DeClarE, for evidence-aware credibility assessment of natural language claims without requiring hand-crafted features or lexicons. DeClarE captures signals from external evidence articles and models joint interactions between various factors like the con- text of a claim, the language of reporting articles, and trustworthiness of their sources. Extensive ex- periments on real world datasets demonstrate our effectiveness over state-of-the-art baselines. ", "page_idx": 8, "bbox": [72, 603.6921997070312, 290, 752.32958984375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 108, "type": "text", "text": "References ", "text_level": 1, "page_idx": 8, "bbox": [307, 64, 363, 76], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 109, "type": "text", "text": "Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credibility on twitter. In Proceedings of the 20th International Conference on ", "page_idx": 8, "bbox": [307, 82.19970703125, 525, 116.01302337646484], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 110, "type": "text", "text": "World Wide Web, WWW ’11, pages 675–684, NewYork, NY, USA. ACM. Leon Derczynski, Kalina Bontcheva, Maria Liakata, Rob Procter, Geraldine Wong Sak Hoi, and Arkaitz Zubiaga. 2017. Semeval-2017 task 8: Rumoureval: Determining rumour veracity and support for ru- mours. In  Proceedings of the 11th International Workshop on Semantic Evaluation, SemEval@ACL 2017, Vancouver, Canada, August 3-4, 2017 , pages 69–76. Xin Luna Dong, Laure Berti-Equille, and Divesh Sri- vastava. 2009. Integrating conﬂicting data: The role of source dependence. Proc. VLDB Endow. , 2(1):550–561. Xin Luna Dong, Evgeniy Gabrilovich, Kevin Murphy, Van Dang, Wilko Horn, Camillo Lugaresi, Shao- hua Sun, and Wei Zhang. 2015. Knowledge-based trust: Estimating the trustworthiness of web sources. Proc. VLDB Endow. , 8(9):938–949. Omar Enayet and Samhaa R. El-Beltagy. 2017. Niletmrg at semeval-2017 task 8: Determining ru- mour and veracity support for rumours on twitter. In  Proceedings of the 11th International Workshop on Semantic Evaluation, SemEval@ACL 2017, Van- couver, Canada, August 3-4, 2017 , pages 470–474. Jing Gao, Qi Li, Bo Zhao, Wei Fan, and Jiawei Han. 2015. Truth discovery and crowdsourcing aggrega- tion: A uniﬁed perspective.  PVLDB , 8(12):2048– 2049. Alex Graves, Santiago Fern´ andez, and J¨ urgen Schmid- huber. 2005. Bidirectional lstm networks for improved phoneme classiﬁcation and recognition. In  Proceedings of the 15th International Con- ference on Artiﬁcial Neural Networks: Formal Models and Their Applications - Volume Part II , ICANN’05, pages 799–804, Berlin, Heidelberg. Springer-Verlag. Aditi Gupta, Hemank Lamba, Ponnurangam Ku- maraguru, and Anupam Joshi. 2013. Faking sandy: Characterizing and identifying fake images on twit- ter during hurricane sandy. In  Proceedings of the 22Nd International Conference on World Wide Web , WWW   $^{'}13$   Companion, pages 729–736, New York, NY, USA. ACM. Diederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. CoRR , abs/1412.6980.Srijan Kumar, Robert West, and Jure Leskovec. 2016. Disinformation on the web: Impact, characteristics, and detection of wikipedia hoaxes. In  Proceed- ings of the 25th International Conference on World ", "page_idx": 8, "bbox": [307, 115.07666015625, 525, 754.6967163085938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 111, "type": "text", "text": "Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee. ", "page_idx": 9, "bbox": [82, 64.56158447265625, 290, 87.52550506591797], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 112, "type": "text", "text": "Qi Li, Yaliang Li, Jing Gao, Lu Su, Bo Zhao, Mu- rat Demirbas, Wei Fan, and Jiawei Han. 2014. A conﬁdence-aware approach for truth discovery on long-tail data.  Proc. VLDB Endow. , 8(4):425–436. Xian Li, Weiyi Meng, and Clement Yu. 2011. T- veriﬁer: Verifying truthfulness of fact statements. In  Proceedings of the 2011 IEEE 27th International Conference on Data Engineering , ICDE ’11, pages 63–74, Washington, DC, USA. IEEE Computer So- ciety. Yaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, and Jiawei Han. 2016. A sur- vey on truth discovery. SIGKDD Explor. Newsl. , 17(2):1–16. Yaliang Li, Qi Li, Jing Gao, Lu Su, Bo Zhao, Wei Fan, and Jiawei Han. 2015. On the discovery of evolv- ing truth. In  Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’15, pages 675–684, New York, NY, USA. ACM. Chenghua Lin, Yulan He, and Richard Everson. 2011. Sentence subjectivity detection with weakly- supervised learning. In  Proceedings of 5th Interna- tional Joint Conference on Natural Language Pro- cessing , pages 1153–1161. Asian Federation of Nat- ural Language Processing. Shanshan Lyu, Wentao Ouyang, Huawei Shen, and Xueqi Cheng. 2017. Truth discovery by claim and source embedding. In  Proceedings of the 2017 ACM on Conference on Information and Knowledge Man- agement , CIKM ’17, pages 2183–2186, New York, NY, USA. ACM. Fenglong Ma, Yaliang Li, Qi Li, Minghui Qiu, Jing Gao, Shi Zhi, Lu Su, Bo Zhao, Heng Ji, and Jiawei Han. 2015. Faitcrowd: Fine grained truth discovery for crowdsourced data aggregation. In  Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’15, pages 745–754, New York, NY, USA. ACM. Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J. Jansen, Kam-Fai Wong, and Meeyoung Cha. 2016. Detecting rumors from microblogs with recurrent neural networks. In  Proceedings of the Twenty-Fifth International Joint Conference on Ar- tiﬁcial Intelligence , IJCAI’16, pages 3818–3824. AAAI Press.Subhabrata Mukherjee and Gerhard Weikum. 2015. Leveraging joint interactions for credibility analysis in news communities. In  Proceedings of the 24th ACM International on Conference on Information and Knowledge Management , CIKM ’15. Subhabrata Mukherjee, Gerhard Weikum, and Cristian Danescu-Niculescu-Mizil. 2014. People on drugs: ", "page_idx": 9, "bbox": [72, 96.2215576171875, 290, 765.7650756835938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 113, "type": "text", "text": "Credibility of user statements in health communi- ties. In  Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’14, pages 65–74, New York, NY, USA. ACM. ", "page_idx": 9, "bbox": [318, 64.5611572265625, 525, 120.40203094482422], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 114, "type": "text", "text": "Ndapandula Nakashole and Tom M. Mitchell. 2014. Language-aware truth assessment of fact candidates. In  Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014, June 22-27, 2014, Baltimore, MD, USA, Vol- ume 1: Long Papers , pages 1009–1019. ", "page_idx": 9, "bbox": [307, 130.18011474609375, 525, 196.97898864746094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 115, "type": "text", "text": "Jeff Pasternack and Dan Roth. 2011. Making bet- ter informed trust decisions with generalized fact- ﬁnding. In  IJCAI 2011, Proceedings of the 22nd International Joint Conference on Artiﬁcial Intel- ligence, Barcelona, Catalonia, Spain, July 16-22, 2011 , pages 2324–2329. ", "page_idx": 9, "bbox": [307, 206.758056640625, 525, 273.55694580078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 116, "type": "text", "text": "Jeff Pasternack and Dan Roth. 2013. Latent credibility analysis. In  Proceedings of the 22Nd International Conference on World Wide Web , WWW ’13, pages 1009–1020, New York, NY, USA. ACM. ", "page_idx": 9, "bbox": [307, 283.33502197265625, 525, 328.2169189453125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 117, "type": "text", "text": "Jeffrey Pennington, Richard Socher, and Christo- pher D. Manning. 2014. Glove: Global vectors for word representation. In  Empirical Methods in Natu- ral Language Processing , EMNLP ’14. ", "page_idx": 9, "bbox": [307, 337.9949645996094, 525, 382.87689208984375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 118, "type": "text", "text": "Kashyap Popat, Subhabrata Mukherjee, Jannik Str¨ otgen, and Gerhard Weikum. 2016. Credibil- ity assessment of textual claims on the web. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Man- agement , CIKM ’16, pages 2173–2178, New York, NY, USA. ACM. ", "page_idx": 9, "bbox": [307, 392.6549377441406, 525, 470.412841796875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 119, "type": "text", "text": "Kashyap Popat, Subhabrata Mukherjee, Jannik Str¨ otgen, and Gerhard Weikum. 2017. Where the truth lies: Explaining the credibility of emerging claims on the web and social media. In  Proceedings of the 26th International Conference on World Wide Web Companion , WWW ’17 Companion. ", "page_idx": 9, "bbox": [307, 480.1908874511719, 525, 546.9907836914062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 120, "type": "text", "text": "Vahed Qazvinian, Emily Rosengren, Dragomir R. Radev, and Qiaozhu Mei. 2011. Rumor has it: Iden- tifying misinformation in microblogs. In  Proceed- ings of the Conference on Empirical Methods in Natural Language Processing , EMNLP ’11, pages 1589–1599, Stroudsburg, PA, USA. Association for Computational Linguistics. ", "page_idx": 9, "bbox": [307, 556.768798828125, 525, 634.5267944335938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 121, "type": "text", "text": "Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana Volkova, and Yejin Choi. 2017. Truth of varying shades: Analyzing language in fake news and polit- ical fact-checking. In  Proceedings of the 2017 Con- ference on Empirical Methods in Natural Language Processing , EMNLP ’17. ", "page_idx": 9, "bbox": [307, 644.3048706054688, 525, 711.1047973632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 122, "type": "text", "text": "Marta Recasens, Cristian Danescu-Niculescu-Mizil, and Dan Jurafsky. 2013. Linguistic models for an- alyzing and detecting biased language. In  Proceed- ings of the 51st Annual Meeting of the Association ", "page_idx": 9, "bbox": [307, 720.8828735351562, 525, 765.6552124023438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 123, "type": "text", "text": "for Computational Linguistics (Volume 1: Long Pa- pers) , pages 1650–1659. Association for Computa- ", "page_idx": 10, "bbox": [82, 64.56158447265625, 290, 87.52550506591797], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 124, "type": "text", "text": "tional Linguistics. Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017. Csi: A hybrid deep model for fake news detection. In  Proceedings of the 2017 ACM on Conference on Information and Knowledge Management , CIKM ’17, pages 797–806, New York, NY, USA. ACM. Mehdi Samadi, Partha Talukdar, Manuela Veloso, and Manuel Blum. 2016. Claimeval: Integrated and ﬂexible framework for claim evaluation using cred- ibility of sources. In  Proceedings of the Thir- tieth AAAI Conference on Artiﬁcial Intelligence , AAAI’16, pages 222–228. AAAI Press. Vikram Singh, Sunny Narayan, Md. Shad Akhtar, Asif Ekbal, and Pushpak Bhattacharyya. 2017. IITP at semeval-2017 task 8 : A supervised approach for rumour evaluation. In  Proceedings of the 11th In- ternational Workshop on Semantic Evaluation, Se- mEval@ACL 2017, Vancouver, Canada, August 3-4, 2017 , pages 497–501. Svitlana Volkova, Kyle Shaffer, Jin Yea Jang, and Nathan Hodas. 2017. Separating facts from ﬁction: Linguistic models to classify suspicious and trusted news posts on twitter. In  Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 647– 653. Association for Computational Linguistics. V.G. Vinod Vydiswaran, ChengXiang Zhai, and Dan Roth. 2011. Content-driven trust propagation frame- work. In  Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’11, pages 974–982, New York, NY, USA. ACM. William Yang Wang. 2017. ”liar, liar pants on ﬁre”: A new benchmark dataset for fake news detection. In Proceedings of the 55th Annual Meeting of the As- sociation for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 2: Short Papers , pages 422–426. Janyce Wiebe and Ellen Riloff. 2005. Creating subjec- tive and objective sentence classiﬁers from unanno- tated texts. In  Proceedings of the 6th International Conference on Computational Linguistics and Intel- ligent Text Processing , CICLing’05, pages 486–497, Berlin, Heidelberg. Springer-Verlag. John Wieting, Mohit Bansal, Kevin Gimpel, and Karen Livescu. 2015. Towards universal paraphrastic sen- tence embeddings. In  Proceedings of the Inter- national Conference on Learning Representations (ICLR) . Qiongkai Xu and Hai Zhao. 2012. Using deep lin- guistic features for ﬁnding deceptive opinion spam. In  Proceedings of COLING 2012: Posters , pages 1341–1350. The COLING 2012 Organizing Com- mittee. ", "page_idx": 10, "bbox": [71, 86.47955322265625, 290, 765.7650146484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 125, "type": "text", "text": "Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012. Automatic detection of rumor on sina weibo. In  Pro- ceedings of the ACM SIGKDD Workshop on Mining Data Semantics , MDS ’12, pages 13:1–13:7, New York, NY, USA. ACM. Xiaoxin Yin, Jiawei Han, and Philip S. Yu. 2008. Truth discovery with multiple conﬂicting informa- tion providers on the web.  IEEE Trans. on Knowl. and Data Eng. , 20(6):796–808. Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. En- quiring minds: Early detection of rumors in social media from enquiry posts. In  Proceedings of the 24th International Conference on World Wide Web , WWW ’15, pages 1395–1405, Republic and Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee. Shi Zhi, Bo Zhao, Wenzhu Tong, Jing Gao, Dian Yu, Heng Ji, and Jiawei Han. 2015. Modeling truth ex- istence in truth discovery. In  Proceedings of the 21th ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining , KDD ’15, pages 1543–1552, New York, NY, USA. ACM. ", "page_idx": 10, "bbox": [307, 64.56109619140625, 525, 333.60174560546875], "page_size": [595.2760009765625, 841.8900146484375]}
