{"layout": 0, "type": "text", "text": "S CI T AB : A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables ", "text_level": 1, "page_idx": 0, "bbox": [94, 67, 501, 101], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 1, "type": "text", "text": "Xinyuan  $\\mathbf{L}\\mathbf{u}^{*1,2}$    Liangming Pan ∗ 3 Qian Liu 4 Preslav Nakov 5 Min-Yen Kan 2 ", "page_idx": 0, "bbox": [180.968994140625, 101.65997314453125, 416.79510498046875, 135.49969482421875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 2, "type": "text", "text": "1 ISEP Program, NUS Graduate School 2  National University of Singapore 3 University of California, Santa Barbara 4 Sea AI Lab 5 MBZUAI ", "page_idx": 0, "bbox": [117.08599853515625, 135.65536499023438, 481.17999267578125, 168.34738159179688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 3, "type": "text", "text": "luxinyuan@u.nus.edu liang ming pan@ucsb.edu liuqian@sea.com preslav.nakov@mbzuai.ac.ae kanmy@comp.nus.edu.sg ", "page_idx": 0, "bbox": [123.25601196289062, 174.6223907470703, 475.0138854980469, 200.66807556152344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 4, "type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0, "bbox": [157, 214, 202, 225], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 5, "type": "text", "text": "Current scientific fact-checking benchmarks ex- hibit several shortcomings, such as biases aris- ing from crowd-sourced claims and an over- reliance on text-based evidence. We present S CI T AB , a challenging evaluation dataset con- sisting of   $1.2\\mathrm{K}$   expert-verified scientific claims that 1) originate from authentic scientific publi- cations and 2) require compositional reason- ing for verification. The claims are paired with evidence-containing scientific tables an- notated with labels. Through extensive evalu- ations, we demonstrate that S CI T AB  poses a significant challenge to state-of-the-art models, including table-based pre training models and large language models. All models except GPT- 4 achieved performance barely above random guessing. Popular prompting techniques, such as Chain-of-Thought, do not achieve much performance gains on S CI T AB . Our analy- sis uncovers several unique challenges posed by S CI T AB , including table grounding, claim ambiguity, and compositional reasoning. Our codes and data are publicly available at  https: //github.com/X in yuan Lu 00/SciTab . ", "page_idx": 0, "bbox": [87, 235.528564453125, 274, 522.5025024414062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 6, "type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0, "bbox": [70, 532, 154, 546], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 7, "type": "text", "text": "Scientific fact-checking is a crucial process that in- volves validating the accuracy of scientific claims by cross-referencing them with established scien- tific literature, research, or data ( Guo et al. ,  2022 ). This process is crucial for preserving the integrity of scientific information, preventing the spread of misinformation, and fostering public trust in re- search findings. However, the sheer volume of scientific data and claims can be overwhelming for manual fact-checking, making automated scientific fact-checking an imperative research area of NLP. Scientific fact-checking has advanced signifi- cantly with benchmarks including Sci-Fact ( Wad- den et al. ,  2020 ), Sci-Fact Open ( Wadden et al. , However, these datasets still exhibit several limi- tations. First, the claims are  crowd-sourced  rather than collected from real scientific papers. This leads to problems such as bias in human annotation, a lack of diversity, and shallow claims that do not reflect the complexity of scientific reasoning. For example, most claims in Sci-Fact can be validated by a single sentence in a paper’s abstract, which oversimplifies the scientific discourse. Second, the claims in the existing benchmarks are solely vali- dated against  text-based evidence , primarily paper abstracts. However, in many scientific processes, claims are intrinsically tied to quantitative experi- mental data, commonly presented in tables and fig- ures. This disparity highlights a significant gap be- tween the existing benchmarks and real-world sci- entific fact-checking needs. To bridge these gaps, a dataset that 1) compiles real-world claims from scientific papers, and 2) includes original scientific data such as tables and figures, is needed. ", "page_idx": 0, "bbox": [70, 553.5719604492188, 291, 742.8564453125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 8, "type": "text", "text": "", "page_idx": 0, "bbox": [305, 213.47804260253906, 526, 484.0574645996094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 9, "type": "text", "text": "In this paper, we propose a novel dataset S C - I T AB , which fulfills these stated criteria. It contains 1,225 challenging scientific claims, each demand- ing compositional reasoning for verification using scientific tables. Our data is derived from the Sci- Gen dataset ( Moosavi et al. ,  2021 ), a resource that includes scientific tables and claims crawled from arXiv.org. We first manually filter out the check- worthy scientific claims from the raw data. Follow- ing this, we employ a strategy of human–model collaboration, as depicted in Figure  2 , to generate claims that are either contradicted or un verifiable based on the table’s content. Figure  1  shows a claim from S CI T AB  and the corresponding reason- ing process to verify it. Compared with existing benchmarks, S CI T AB  is closer to real-world scien- tific fact-checking in terms of more realistic claims and table-based evidence. Through data analysis, we further show that the claims in S CI T AB  neces- sitate a more comprehensive and nuanced set of reasoning skills for verification,  e.g.,  numerical rea- ", "page_idx": 0, "bbox": [305, 489.9599914550781, 526, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 10, "type": "image", "page_idx": 1, "img_path": "layout_images/2305.13186v3_0.jpg", "img_caption": "Figure 1: An example of our S CI T AB  dataset (left) and its corresponding reasoning graph (right). Each data entry contains  paper name ,  paper id ,  table , one  claim , and its corresponding  label  (Supported, Refuted, Not Enough Info). ", "bbox": [69, 69, 527, 307], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Paper: When Choosing Plausible Alternatives, Clever Hans can be Clever\nPaper ID: 1911.00225v1\n\n© Cue App Prods Co\n\nA’s productivity of 57.5% expresses that it appears in 7.5%\nmore often than expected by random chance. J\n\nClosed-domain knowledge: —\n\n\"\nin 47% 55.3% 9.40% HH\nwas 55% 61.8% 11.0% ' | Commonsense\nwe Gee aves BENS ' Productivity corresponds to Prod. column enoiiistes\nthe 85% 38.8% 17.0% ' ' il\na 106% 57.5% 21.2%\nTable 2: Applicability (App.), Productivity (Prod.) and Coverage (Cov.) of the various Q einpletockup\n\nwords in the alternatives of the COPA dev set. The number of random chance is 50%\n\nSupported Claim A’s productivity is 57.5%\n\n| A’s productivity of 57.5% expresses that it appears in 7.5% more @ Baa\n[Ee subtraction\n\n“often than expected by random chance.\n\nRefuted Claim |\nA’s productivity of 57.5% expresses that it appears in 9.5% more - =\n\nThe subtraction result between 57.5% and 50% is 7.5%\noften than expected by random chance. | e\nNot Enough Info Claim |\n\nThe low performance of “to” can be explained by the fact that it @ Fact checker : Supported @\nis responsible for only 4.6% of the inference in the training set. ed Reasoning Graph\n\n", "vlm_text": "The image illustrates an example from a dataset called S CI T AB, along with a reasoning graph. The left side includes a table from a paper titled \"When Choosing Plausible Alternatives, Clever Hans can be Clever\" with Paper ID: 1911.00225v1. The table shows data on Applicability (App.), Productivity (Prod.), and Coverage (Cov.) of certain words. \n\nThere's a claim about \"A’s productivity of 57.5% expressing that it appears in 7.5% more often than expected by random chance.\" The claim is supported because the reasoning graph verifies that productivity corresponds to the Prod. column. Using commonsense and closed-domain knowledge, the graph establishes the productivity as 57.5% and random chance as 50%. Subtraction confirms the claim, leading to the conclusion that the fact checker supports the claim as valid. \n\nThe image presents different interpretations: one claim is supported, another refuted, and one marked as not having enough info."}
{"layout": 11, "type": "text", "text": "soning and commonsense knowledge,  etc . ", "page_idx": 1, "bbox": [69, 327.9440002441406, 254.2022705078125, 341.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 12, "type": "text", "text": "We employ S CI T AB  as a diagnostic dataset for benchmarking the zero-shot and in-context learn- ing performance for a wide range of state-of-the- art models, including table-based pre training mod- els, encoder–decoder models, open source lan- guage models, and API-based language models. We observe that all models, with the exception of GPT-4, can only achieve marginally superior  $F_{1}$   scores than random guessing, which under- scores the challenging nature of S CI T AB . Addi- tionally, established prompting methods like Chain- of-Thought ( Wei et al. ,  2022 ) and Program-of- Thought ( Chen et al. ,  2022 ) which typically en- hance performance across most reasoning tasks, do not bring performance gain on S CI T AB . Our error analysis sheds light on several unique chal- lenges in S CI T AB  that may lead to this, such as table grounding, dealing with ambiguous claims, and compositional reasoning. We make our dataset fully accessible to the research community. ", "page_idx": 1, "bbox": [69, 342.2779846191406, 291, 612.8584594726562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 13, "type": "text", "text": "2 The S CI T AB  Dataset ", "text_level": 1, "page_idx": 1, "bbox": [70, 626, 195, 639], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 14, "type": "text", "text": "We adopt a  human–model collaboration  strategy to construct S CI T AB , as shown in Figure  2 . We describe the steps involved in data preparation (Sec- tion  2.1 ), automatic claim generation (Section  2.2 ), and manual claim verification (Section  2.3 ). ", "page_idx": 1, "bbox": [69, 649.0570068359375, 291, 716.3994140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 15, "type": "text", "text": "2.1 Data Preparation ", "text_level": 1, "page_idx": 1, "bbox": [70, 728, 177, 742], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 16, "type": "text", "text": "We use the publicly available SciGen ( Moosavi et al. ,  2021 ) dataset as our primary data source. ", "page_idx": 1, "bbox": [69, 747.39501953125, 291, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 17, "type": "text", "text": "The dataset was created by crawling computer sci- ence papers from arXiv. The tables and the texts explaining the tables are extracted from the papers to create (table, description) pairs for the task of data-to-text generation. From all the table descrip- tions of SciGen, we first filter the check-worthy scientific claims following the criteria established by  Lee et al.  ( 2009 ) for academic writing 1 . We focus on the descriptions that serve the purpose of “highlighting and commenting on key data”, i.e. , describing research findings based on the data presented in scientific tables. Given the task’s ob- jective nature and to save the cost of human labor, we hire a graduate student majoring in computer science to manually select scientific claims based on the aforementioned criteria using the user inter- face in Appendix  A.2 . This decision was based on a pilot annotation which showed that a well-trained annotator can achieve over   $95\\%$   accuracy in filter- ing scientific claims. To safeguard the quality, we include an option to mark the claim as “Discard-It’s not a claim, or it’s an incomplete, or not grammat- ically correct sentence.” during the subsequent claim verification process. Using this approach, we filtered out 872 real-world scientific claims from 1,301 table descriptions in the SciGen dataset. ", "page_idx": 1, "bbox": [305, 327.9440002441406, 526, 679.8194580078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 18, "type": "text", "text": "2.2 Automatic Claim Generation ", "text_level": 1, "page_idx": 1, "bbox": [305, 692, 467, 705], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 19, "type": "text", "text": "False Claims. A fact-checking dataset requires both true and false claims. However, acquir- ing false claims that naturally occur within well- ", "page_idx": 1, "bbox": [305, 710.8253173828125, 526, 751.4624633789062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 20, "type": "image", "page_idx": 2, "img_path": "layout_images/2305.13186v3_1.jpg", "img_caption": "Figure 2: The  human–model collaboration  construction process of S CI T AB , which contains three steps: 1) data preparation (including data preprocessing and claim extraction) 2) automatic claim generation (including refuted and Not Enough Info claim generation) and 3) manual claim verification. ", "bbox": [69, 77, 526, 266], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Sr ee eee ee! eae a eee\n\n} | 8\n\n. Human verifier\nFree-formed claim ————————— Not — Info claim C’\n\nTable\na extraction sof A\nOriginal claim C .\nSciGen dataset Human verifier | Supported claim C\nTexts InstructGPT\n\nClaim with opposite meaning C’ Refuted claim C’\n\n@ Data Preparation\n", "vlm_text": "The image illustrates the human-model collaboration process for constructing S CI T AB, consisting of three steps:\n\n1. **Data Preparation:**\n   - Involves data preprocessing and claim extraction from the SciGen dataset, organizing data into tables and texts.\n\n2. **Automatic Claim Generation:**\n   - Utilizes InstructGPT to generate claims, including creating free-formed claims and claims with opposite meanings for refuted and \"Not Enough Info\" scenarios.\n\n3. **Manual Claim Verification:**\n   - Human verifiers assess the claims, resulting in categorization as \"Supported,\" \"Refuted,\" or \"Not Enough Info.\"\n\nEach step in the process is connected visually, showing the flow from data preparation to claim verification."}
{"layout": 21, "type": "text", "text": "verified scientific publications is a challenging task. Following SciFact ( Wadden et al. ,  2020 ) and COVID-Fact ( Saakyan et al. ,  2021 ), we seek to create false claims by generating counter-claims of the original true claims. Unlike previous works that purely rely on crowd-workers to compose counter-claims — a process that is costly and prone to annotation artifacts — we leverage the strong instruction-following capabilities of large language models (LLMs) to assist humans in generating can- didate counter-claims. Specifically, we prompt Instruct GP T  ( Ouyang et al. ,  2022 ) with the orig- inal claim and the instruction:  Please modify the original claims to convey the opposite meaning with minimum edits . To foster a varied set of gen- erated claims, we include five diverse in-context examples and employ a high decoding tempera- ture setting of  0 . 7 . By mandating minimal edits, we ensure that the counter-claims remain lexically close to the original claims, which is crucial in preventing fact-checking models from relying on superficial lexical patterns for verification. ", "page_idx": 2, "bbox": [70, 287.031982421875, 290, 584.71142578125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 22, "type": "text", "text": "Un verifiable Claims. To construct a more chal- lenging dataset, we also integrate claims that are un verifiable  with the table information (labeled as Not Enough Info,  NEI ). We leverage  Instruct GP T to generate candidate NEI claims by prompting the model with the original table and the instruction: Please generate 5 relevant scientific claims based on the information in the table . This process yields a diverse set of free-formed claims that enrich the diversity of S CI T AB . However, as LLMs tend to generate content that might not always be grounded in the provided data, many of the generated claims turn out to be  relevant but un verifiable  with respect to the table. We adopt manual verification (elabo- rated in Section  2.3 ) to select them as NEI claims. ", "page_idx": 2, "bbox": [70, 597.9613037109375, 290, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 23, "type": "text", "text": "", "page_idx": 2, "bbox": [305, 287.031982421875, 526, 313.7274475097656], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 24, "type": "text", "text": "2.3 Manual Claim Verification ", "text_level": 1, "page_idx": 2, "bbox": [305, 326, 455, 338], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 25, "type": "text", "text": "We subsequently employ a human verification pro- cess for two purposes: first, to verify the quality of the 872 false claims and 900 NEI claims that were generated by  Instruct GP T ; second, to critically re- view the 872 real-world scientific claims obtained in Section  2.1 . This task involves selecting claims that can be verified exclusively based on the infor- mation presented in the table, without the need for additional context from the associated paper. ", "page_idx": 2, "bbox": [305, 344.1050109863281, 526, 465.64447021484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 26, "type": "text", "text": "For each pair of the true claim    $c$   and its corre- sponding generated counter-claim    $c^{\\prime}$  , we ask the annotator to choose one of the following three op- tions: (A)    $c$   is not exclusively supported by the table, (B)  $c$   is exclusively supported by the table, but    $c^{\\prime}$    is not refuted by the table, and (C)    $c$   is not exclusively supported by the table, and    $c^{\\prime}$    is not refuted by the table. For each candidate NEI claim, we ask the annotator to judge whether it is unverifi- able with respect to the table. ", "page_idx": 2, "bbox": [305, 466.7200012207031, 526, 601.8084716796875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 27, "type": "text", "text": "Annotator Recruitment. Given that our data source is from computer science papers, we recruit university students majoring in computer science with basic math and programming backgrounds for annotation. We ask each annotator to fill in a questionnaire, including their age, department, maximum workload per week, etc. After that, we provide a training session to ensure they understand the task and can use the annotation interfaces (Ap- pendix  B.2  and  B.3 ). We also give them three samples to test their understanding. We recruit twelve annotators that passed the training session. ", "page_idx": 2, "bbox": [305, 611.5103149414062, 526, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 28, "type": "table", "page_idx": 3, "img_path": "layout_images/2305.13186v3_2.jpg", "table_footnote": "Table 1: Comparison of S CI T AB  to three recent table fact verification datasets: TabFact ( Chen et al. ,  2020 ), FEVEROUS ( Aly et al. ,  2021 ), and SEM-TAB-FACTS ( Wang et al. ,  2021 ). The table presents statistics related to the domain, annotator (AMT represents Amazon Mechanical Turk), maximum reasoning hops, veracity labels percentage of each dataset, the total number of claims, and average claims per table. ", "bbox": [70, 69, 526, 230], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Statistics TabFact FEVEROUS SEM-TAB-FACTS ScITAB\nDomain Wiki Tables — Wiki Tables Scientific Articles Scientific Articles\nAnnotator AMT AMT AMT Experts\nMax. Reasoning Hops 7 2 1 11\n\nSupported 54% 56% 58% 37%\nVeracity Refuted 46% 39% 38% 34%\nNEI _ 5% 4% 29%\nTotal # of Claims 117,854 87,026 5,715 1,225\nAvg. claims per table TAL 0.07 8.27 6.16\n\n", "vlm_text": "The table shows statistics comparing four datasets: TabFact, FEVEROUS, SEM-TAB-FACTS, and SciTab. \n\n- **Domains**: TabFact and FEVEROUS use Wiki Tables, while SEM-TAB-FACTS and SciTab use Scientific Articles.\n- **Annotators**: AMT (Amazon Mechanical Turk) is used for TabFact, FEVEROUS, and SEM-TAB-FACTS, while SciTab uses Experts.\n- **Max. Reasoning Hops**: TabFact has 7, FEVEROUS has 2, SEM-TAB-FACTS has 1, and SciTab has 11.\n- **Veracity**:\n  - TabFact: 54% Supported, 46% Refuted\n  - FEVEROUS: 56% Supported, 39% Refuted, 5% NEI (Not Enough Information)\n  - SEM-TAB-FACTS: 58% Supported, 38% Refuted, 4% NEI\n  - SciTab: 37% Supported, 34% Refuted, 29% NEI\n- **Total # of Claims**: TabFact has 117,854, FEVEROUS has 87,026, SEM-TAB-FACTS has 5,715, and SciTab has 1,225.\n- **Avg. Claims per Table**: TabFact has 7.11, FEVEROUS has 0.07, SEM-TAB-FACTS has 5.27, and SciTab has 6.16."}
{"layout": 29, "type": "text", "text": "In compliance with ethical guidelines, we ensure fair compensation for the annotators. Each claim annotation is reimbursed at a rate of 0.37 USD, resulting in an hourly wage of   $11.2\\,\\mathrm{USD}^{2}$  . ", "page_idx": 3, "bbox": [70, 243.21400451660156, 290, 297.0065002441406], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 30, "type": "text", "text": "Quality Control and Annotator Agreement. To ensure the quality of the annotation, we apply strict quality control procedures following the guide- lines outlined in the Dataset Statement ( Bender and Friedman ,  2018 ). We assign two different anno- tators to perform a two-round annotation for each claim, while two authors review and resolve any identified errors or issues. To measure the inter- annotator agreement, we use Cohen’s Kappa ( Co- hen ,  1960 ). Our inter-annotator agreement is 0.630 for the false claim verification task (872 claims in total) and 0.719 for the NEI claim verification task (900 claims in total). Both values indicate substantial agreement among the annotators. ", "page_idx": 3, "bbox": [70, 305.0692443847656, 290, 494.7474670410156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 31, "type": "text", "text": "3 Data Analysis ", "text_level": 1, "page_idx": 3, "bbox": [69, 505, 161, 519], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 32, "type": "text", "text": "Table  1  shows the statistics of our S CI T AB  dataset and the comparison with three existing table fact- checking datasets: TabFact ( Chen et al. ,  2020 ), FEVEROUS ( Aly et al. ,  2021 ), and SEM-TAB- FACTS ( Wang et al. ,  2021 ). Compared with these datasets, S CI T AB  is 1) annotated by domain ex- perts rather than crowd-sourced workers, 2) con- tains more challenging claims that require up to 11 reasoning steps for verification, and 3) has a more balanced distribution of veracity labels and a higher percentage of NEI claims. We conduct a more in-depth analysis of S CI T AB  as follows. ", "page_idx": 3, "bbox": [70, 527.4609985351562, 290, 689.6474609375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 33, "type": "text", "text": "3.1 Reasoning Analysis ", "text_level": 1, "page_idx": 3, "bbox": [70, 700, 187, 713], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 34, "type": "text", "text": "Reasoning Types. To study the nature of reason- ing involved in fact-checking claims in S CI T AB , we adapt the set of table-based reasoning cate- gories from INFOTABS ( Gupta et al. ,  2020 ) to define 14 atomic reasoning types, as shown in Ta- ble  2 . Among them, “closed-domain knowledge” and “open-domain knowledge” are specially de- signed for S CI T AB . Closed-domain knowledge refers to obtaining background information from the table caption or title,  e.g. , knowing that “Prod.” refers to “Productivity” from the table caption in Figure  1 . Open-domain knowledge refers to com- monsense knowledge not presented in the table, e.g. , the relationship between precision and recall. Given the designed reasoning types, we manually analyze 100 samples in S CI T AB , by annotating the graph of reasoning steps for verifying each claim. We identify 476 atomic reasoning steps from the 100 analyzed samples and show the proportion for each reasoning type in Table  2 . We observe that S C - I T AB  has a multifaceted complex range of reason- ing types and a high proportion of claims requiring different types of domain knowledge. ", "page_idx": 3, "bbox": [70, 717.0543212890625, 290, 744.1424560546875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 35, "type": "text", "text": "", "page_idx": 3, "bbox": [305, 243.21400451660156, 526, 527.3424072265625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 36, "type": "text", "text": "Reasoning Depth. We further measure the  rea- soning depth  (the number of required reasoning steps) for each claim and show the reasoning depth distribution in Figure  3 . We find that the analyzed claims have an average depth of 4.76 and a max- imum depth of 11. Moreover,   $86\\%$   of the claims requiring 3 or more reasoning steps, which demon- strates the complexity of reasoning in S CI T AB . ", "page_idx": 3, "bbox": [305, 535.5592651367188, 526, 643.94140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 37, "type": "text", "text": "Reasoning Graph. We showcase the reasoning graph for the example in Figure  1  on the right side of the figure. Verifying this claim requires vari- ous types of reasoning including: 1)  background knowledge from the table caption : “productivity” corresponds to the “Prod.” column in the table; 2) commonsense knowledge : “random chance” means  $50\\%$   accuracy; 3)  simple lookup : “A’s productiv- ity” refers to the cell located at the last row and ", "page_idx": 3, "bbox": [305, 652.1572875976562, 526, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 38, "type": "table", "page_idx": 4, "img_path": "layout_images/2305.13186v3_3.jpg", "table_caption": "Table 2: The function names, descriptions, and their proportions in our S CI T AB  dataset. ", "bbox": [72, 68, 525, 262], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Function Names\n\nDescriptions\n\nProp. (%)\n\nSimple lookup\nComparison\nClosed-domain knowledge\nOpen-domain knowledge\nCommonsense knowledge\nSubtract\n\nDivide\n\nRank\n\nDifferent / Same\n\nAdd\n\nMax / Min\n\nCol / Rowname\n\nTrend same/different\n\nSet check\n\nRetrieve the value for a specific cell.\n\nCompare two numbers.\n\nExtract information from context sentences in the table caption or article.\nExtract additional information required by domain experts.\n\nExtract commonsense knowledge necessary for claim verification.\nPerform subtraction of two numbers.\n\nPerform division of two numbers.\n\nDetermine the rank of a set of numbers.\n\nDetermine if two numbers are different or the same.\n\nCalculate the sum of two numbers.\n\nRetrieve the maximum or minimum number from a set of numbers.\nRetrieve the column or row name from the table.\n\nDetermine the trend for two columns or rows, whether they are the same or different.\n\nVerify if a value belongs to a set of numbers.\n\n20.6\n19.5\n12.1\n5:3\n5:3\n5:3\n5:3\n5:3\n5:3\n4.0\n3.1\n3.1\n2.9\n2.9\n", "vlm_text": "The table lists functions related to data analysis tasks, along with descriptions and the proportion (%) of each function's usage. Here's a breakdown:\n\n- **Simple lookup (20.6%)**: Retrieve the value for a specific cell.\n- **Comparison (19.5%)**: Compare two numbers.\n- **Closed-domain knowledge (12.1%)**: Extract information from context sentences in the table caption or article.\n- **Open-domain knowledge (5.3%)**: Extract additional information required by domain experts.\n- **Commonsense knowledge (5.3%)**: Extract commonsense knowledge necessary for claim verification.\n- **Subtract (5.3%)**: Perform subtraction of two numbers.\n- **Divide (5.3%)**: Perform division of two numbers.\n- **Rank (5.3%)**: Determine the rank of a set of numbers.\n- **Different / Same (5.3%)**: Determine if two numbers are different or the same.\n- **Add (4.0%)**: Calculate the sum of two numbers.\n- **Max / Min (3.1%)**: Retrieve the maximum or minimum number from a set of numbers.\n- **Col / Rowname (3.1%)**: Retrieve the column or row name from the table.\n- **Trend same/different (2.9%)**: Determine the trend for two columns or rows, whether they are the same or different.\n- **Set check (2.9%)**: Verify if a value belongs to a set of numbers."}
{"layout": 39, "type": "image", "page_idx": 4, "img_path": "layout_images/2305.13186v3_4.jpg", "img_caption": "Figure 3: The distribution histogram of reasoning steps in our S CI T AB  dataset. The x-axis is the reasoning steps in each claim, and the y-axis is the frequency for each reasoning step. The shallow claims (with 1–2 reasoning steps) are highlighted in  red , while the deep claims (with  $^{3+}$   reasoning steps) are highlighted in  blue . ", "bbox": [70, 282, 291, 484], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Percentages (%)\n\n25\n20\n15\n10\n\n20\n\n18\n15 15\n\n‘i\n\n123 4 5 6 7 8 9 1011\n\nReasoning Steps\n\n", "vlm_text": "The image is a histogram depicting the distribution of reasoning steps in a dataset known as SCI TAB. \n\n- The x-axis represents the number of reasoning steps involved in each claim, ranging from 1 to 11.\n- The y-axis indicates the frequency of each reasoning step as a percentage.\n\nThe histogram bars are color-coded:\n- Red bars indicate \"shallow\" claims, which involve 1–2 reasoning steps. Specifically, 6% of claims involve 1 reasoning step, and 8% involve 2 reasoning steps.\n- Blue bars represent \"deep\" claims, which have 3 or more reasoning steps. The distribution is as follows: 15% for 3 steps, 18% for 4 steps, 20% for 5 steps, 15% for 6 steps, 7% for 7 steps, 5% for 8 steps, 3% for 9 steps, 2% for 10 steps, and 1% for 11 steps."}
{"layout": 40, "type": "text", "text": "the “Prod.” column; and 4)  numerical reasoning : the difference between   $57.5\\%$   and   $50\\%$   is   $7.5\\%$  . This case study provides further insights into the complexity and variety of reasoning involved in S CI T AB , revealing the difficulty of the dataset. ", "page_idx": 4, "bbox": [70, 504.45294189453125, 291, 571.79541015625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 41, "type": "text", "text": "3.2 Refuted and NEI Claims Analysis ", "text_level": 1, "page_idx": 4, "bbox": [70, 581, 254, 594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 42, "type": "text", "text": "One potential risk of model-generated claims is that they may lack diversity and exhibit the same pattern. For example, in the Sci-Fact ( Wadden et al. ,  2020 ) dataset where the refuted claims are generated by flapping the meaning of the original true claims, we found that out of 100 randomly sampled refuted claims, 85 simply negated the orig- inal claim by adding negation words such as “not” (more details in Appendix  C ). To evaluate the diver- sity of claims for our S CI T AB  dataset, we randomly select 60 refuted claims and then manually anno- tate their reasons for refutation. Results are shown in Table  3  (top half). We find that S CI T AB  exhibits a greater diversity in refuted claims compared to Sci-Fact. Besides common error types such as “in- correct calculation results”   $(41.7\\%)$  , there are also unique types of errors that are more reflective of the complexities in real-world scientific claims. For example,   $33.33\\%$   of the refuted claims contain “in- correct approximation words”, and   $10.0\\%$   are cases where “the claim is partially right”, consistent with the fact that ambiguity and half-truths are common phenomena in scientific discourse. Additional ex- amples of refuted claims are in Appendix  E . ", "page_idx": 4, "bbox": [70, 598.3539428710938, 291, 774.0904541015625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 43, "type": "text", "text": "", "page_idx": 4, "bbox": [305, 283.53997802734375, 526, 432.1774597167969], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 44, "type": "text", "text": "The NEI claims (bottom half; Table  3 ) also ex- hibit diverse reasoning patterns. The two most common features for un verifiable claims are insuf- ficient evidence in the table and the lack of back- ground knowledge. The lack of closed-domain knowledge is another reason for NEI, where ad- ditional information in the paper is necessary to verify the claim. Other reasons include the use of vague pronouns ( e.g. , “it”, “this”) brings ambiguity to the claim. These distinct refuted and NEI reason- ing types highlight the unique features of S CI T AB , making it a more comprehensive and realistic rep- resent ation of the challenges faced in real-world scientific fact-checking. ", "page_idx": 4, "bbox": [305, 432.5809631347656, 526, 621.8654174804688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 45, "type": "text", "text": "4 Experiment ", "text_level": 1, "page_idx": 4, "bbox": [305, 631, 385, 645], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 46, "type": "text", "text": "We formally define the task of scientific table-based fact-checking as follows.  scientific table    $\\mathcal{T}$  con- sists of a table caption  P  and the table content  $(\\{T_{i,j}|i\\,\\leq\\,R_{T},j\\,\\leq\\,C_{T}\\}$   with    $R_{T}$   rows a  $C_{T}$  columns, where  $T_{i,j}$   is the content in the  (  $(i,j)$  th cell. Given a claim    $C$   describing a fact to be ver- ified a inst the table    $\\mathcal{T}$  , a  table fact-checkin model  F  predicts a label    $y$   to verify whether  C is supported, refuted, or can not be verified by the ", "page_idx": 4, "bbox": [305, 652.5509643554688, 526, 774.0904541015625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 47, "type": "table", "page_idx": 5, "img_path": "layout_images/2305.13186v3_5.jpg", "table_footnote": "Table 3: Refuted and NEI reasons and their estimated proportions (Prop.) in S CI T AB . ", "bbox": [71, 68, 289, 245], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Refuted Reasons\n\nProp. (%)\nThe calculation result is wrong. ALT\nThe approximation word is wrong. 33.3\nThe claim is partially right. 10.0\nThe values in the claim do not match. 8.3\nThe operation type is wrong. 6.7\nNEI Reasons Prop. (%)\nThe claim does not have enough matching evidence. 33.3\nThe claim lacks open-domain knowledge. 25.0\nThe claim lacks closed-domain knowledge. 15.0\nThe claim refers to another table. 11.7\nThe claim contains vague pronouns. 8.3\nThe claim omits specific information. 6.7\n\n", "vlm_text": "The table contains two sections titled \"Refuted Reasons\" and \"NEI Reasons,\" each listing reasons along with their proportional percentages:\n\n**Refuted Reasons:**\n- The calculation result is wrong: 41.7%\n- The approximation word is wrong: 33.3%\n- The claim is partially right: 10.0%\n- The values in the claim do not match: 8.3%\n- The operation type is wrong: 6.7%\n\n**NEI Reasons:**\n- The claim does not have enough matching evidence: 33.3%\n- The claim lacks open-domain knowledge: 25.0%\n- The claim lacks closed-domain knowledge: 15.0%\n- The claim refers to another table: 11.7%\n- The claim contains vague pronouns: 8.3%\n- The claim omits specific information: 6.7%"}
{"layout": 48, "type": "text", "text": "information in  $\\mathcal{T}$  ", "page_idx": 5, "bbox": [70, 259.583984375, 145, 272.7294616699219], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 49, "type": "text", "text": "Considering the real-world situation that large- scale training data is either not available or expen- sive to collect, we focus on the  zero-shot/in-context evaluation where the model can only access ze- ro/few in-domain data from S CI T AB . To this end, we randomly hold out 5 tables with 25 claims as model-accessible data and use the rest of the data as the unseen test set. This also prevents the model from learning spurious features that lead to over- estimated performance ( Schuster et al. ,  2019 ). ", "page_idx": 5, "bbox": [70, 273.531005859375, 290, 408.6194763183594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 50, "type": "text", "text": "4.1 Models ", "text_level": 1, "page_idx": 5, "bbox": [70, 420, 130, 431], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 51, "type": "text", "text": "We conduct a comprehensive evaluation of S CI T AB for various models, including table-based pretrain- ing models, encoder–decoder models, open source LLMs, and closed source LLMs. We also study the human performance to analyze the upper bounds on S CI T AB . ", "page_idx": 5, "bbox": [70, 437.5019836425781, 290, 518.3934326171875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 52, "type": "text", "text": "Table-based LLMs. These are pre-trained trans- former models fine-tuned on tabular data. We choose three different models: 1)  TAPAS  ( Herzig et al. ,  2020 ), a BERT-based model fine-tuned on millions of tables from English Wikipedia and cor- responding texts, 2)  TAPEX  ( Liu et al. ,  2022b ), a model that fine-tunes BART ( Lewis et al. ,  2020 ) on a large-scale synthetic dataset generated by synthe- sizing executable SQL queries and their execution outputs, and 3)  TAPEX-Zero  ( Liu et al. ,  2023b ), an enlarged version of  TAPEX . For  TAPAS  and  TAPEX , we use their fine-tuned version on TabFact ( Chen et al. ,  2020 ) for table fact-checking. ", "page_idx": 5, "bbox": [70, 524.3092651367188, 290, 700.4374389648438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 53, "type": "text", "text": "Encoder–Decoder LLMs. We also use en- coder–decoder models where both the input and output are sequences of tokens. To adapt the model to take the table as input, we flatten the table as a sequence following  Chen et al.  ( 2020 ). The in- put is then formulated as    $[\\Tilde{T};P;C;Q]$  , where  $\\tilde{T}$   is the linearized table, and    $Q$   is a question template “Based on the information in the table, is the above claim true? A) True B) False C) Unknown?”. We choose  FLAN-T5  ( Chung et al. ,  2022 ), an improved T5 model ( Raffel et al. ,  2020 ) pre-trained on more than 1.8K tasks with instruction tuning, which has achieved strong zero-shot/in-context performance on other fact-checking benchmarks. ", "page_idx": 5, "bbox": [70, 706.3543090820312, 290, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 54, "type": "text", "text": "", "page_idx": 5, "bbox": [305, 70, 526, 193.28445434570312], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 55, "type": "text", "text": "Open Source LLMs. We also evaluate the per- formance of state-of-the-art open source LLMs, including 1)  LLaMA  ( Touvron et al. ,  2023 ), the first open-source model by Meta AI; 2)  Alpaca  ( Taori et al. ,  2023 ), an instruction-following language model fine-tuned on LLaMA; and 3)  Vicuna  ( Chi- ang et al. ,  2023 ), the arguably best-performed open- source LLMs that claimed to achieve  $90\\%$   quality compared to OpenAI  ChatGPT . We use the same input format as in the encoder-decoder model. ", "page_idx": 5, "bbox": [305, 200.77928161621094, 526, 336.2604675292969], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 56, "type": "text", "text": "Closed Source LLMs. These are closed-source LLMs that require API calls for inference, includ- ing  Instruct GP T (text-davinci-003)  ( Ouyang et al. ,  2022 ) and  GPT-4  ( OpenAI ,  2023 ). We evaluate the setting that directly predicts the la- bel and the  Chain-of-Thought  (CoT) ( Wei et al. , 2022 ) setting, which generates explanations be- fore predicting the final label. We also include the Program-of-Thoughts  (PoT) ( Chen et al. ,  2022 ) model that has shown strong ability in solving com- plex numerical reasoning tasks. It first parses the reasoning steps as Python programs and then exe- cutes them on a Python interpreter to derive accu- rate answers. Since most claims in S CI T AB  also re- quire numerical reasoning, we want to test whether program-guided reasoning can be extended to table- based fact-checking. ", "page_idx": 5, "bbox": [305, 343.7562561035156, 526, 574.0814208984375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 57, "type": "text", "text": "Human Performance. To examine how humans perform on our S CI T AB  dataset, we hired an anno- tator from our candidate annotators pool, following the same training procedure as other annotators. In the case of 2-class classification, we randomly selected 40 samples: 20 each for supported and refuted claims. For 3-class classification, we ran- domly selected 60 random samples, ensuring an even distribution of 20 samples across the three la- bel categories (supported, refuted, and not enough information). The annotator took approximately 1.5 hours for the 2-class fact-checking task and 2 hours for the 3-class setting. We report the Macro- F1 scores at the bottom of Table  4 . ", "page_idx": 5, "bbox": [305, 584.4113159179688, 526, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 58, "type": "table", "page_idx": 6, "img_path": "layout_images/2305.13186v3_6.jpg", "table_footnote": "Table 4: Macro-  $\\cdot F_{1}$   of baselines on S CI T AB  for different settings. The  # of Para.  indicates the number of parameters in the models. The TAPAS and TAPEX models are fine-tuned on the TabFact dataset, while others perform zero-shot learning. The bold text indicates the best performance among I to III, while the underlined text indicates the overall best performance among all the models. ", "bbox": [70, 69, 526, 400], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Models db of Para, Zero-shot In-Context\n2-class 3-class 2-class 3-class\nTAPAS-large (Tabfact) (Herzig et al., 2020) 340M 50.30 — —_— —_—\nI. Table-based TAPEX-large (Tabfact) (Liu et al., 2022b) 400M 56.06 — — —\nLLMs TAPEX-Zero-large (Liu et al., 2023b) 780M = 48.28 29.72 42.44 23.47\nTAPEX-Zero-XL (Liu et al., 2023b) 3B 49.77 34.30 42.12 25.62\nFlan-T5-base (Chung et al., 2022) 250M = 47.38 26.56 44.82 24.09\nII. Encoder-Decoder Flan-T5-large (Chung et al., 2022) 780M = 51.58 32.55 49.62 27.30\nLLMs FLan-T5-XL (Chung et al., 2022) 3B 52.41 38.05 48.05 29.21\nFlan-T5-XXL (Chung et al., 2022) 11B_ 59.60 34.91 60.48 34.04\nAlpaca-7B (Taori et al., 2023) 7B 37.22 27.59 40.46 28.95\nIII. Open source Vicuna-7B (Chiang et al., 2023) 7B 63.62 32.47 50.35 34.26\nLLMs Vicuna-13B (Chiang et al., 2023) 13B. 41.82 29.63 99.11 35.16\nLLaMA-7B (Touvron et al., 2023) 7B 49.05 32.26 45.24 27.17\nLLaMA-13B (Touvron et al., 2023) 13B. 53.97 37.18 44.39 32.66\nInstructGPT (Ouyang et al., 2022) 175B- 68.44 41.41 68.10 41.58\nIV. Close source InstructGPT+CoT (Ouyang et al., 2022) 175B — — 68.46 42.60\nLLMs PoT (Chen et al., 2022) 175B —_— —_— 63.79 —\nGPT-4 (OpenAl, 2023) — 78.22 64.80 77.98 63.21\nGPT-4+CoT (OpenAl, 2023) — — —_ 76.85 62.77\n\nHuman\n\n92.40\n\n84.73\n\n", "vlm_text": "The table compares the performance of various large language models (LLMs) across different categories on a classification task. It includes four main types of LLMs: Table-based LLMs, Encoder-Decoder LLMs, Open Source LLMs, and Close Source LLMs. Human performance is also listed for comparison.\n\nKey elements include:\n\n- **Models**: The name and source of each model.\n- **# of Para.**: The number of parameters in each model (e.g., 340M, 7B, 175B).\n- **Zero-shot**: Performance in a scenario where the model hasn't been trained specifically on the task. Scores for 2-class and 3-class classification are presented.\n- **In-Context**: Performance when models are given some context or examples regarding the task. Scores for 2-class and 3-class classification are presented.\n\nOverall, the table shows how models perform with different numbers of classes and in zero-shot versus in-context scenarios. The human performance is shown to be notably higher than any model."}
{"layout": 59, "type": "text", "text": "4.2 Main Results ", "text_level": 1, "page_idx": 6, "bbox": [70, 422, 158, 435], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 60, "type": "text", "text": "We evaluate all models under both  zero-shot  and in-context  settings. In the zero-shot setting, the model does not have access to any in-domain data. In the in-context setting, we provide three hold- out examples as demonstrations. We report two sets of results: the  2-class  case, where examples labeled as NEI are excluded (since some models cannot process NEI claims), and the  3-class  case including all three labels. The results are shown in Table  4 . We have five major observations. ", "page_idx": 6, "bbox": [70, 446.1050109863281, 291, 581.1924438476562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 61, "type": "text", "text": "1. In general, all open source LLMs, including encoder–decoder models and decoder-only models, do not achieve very promising results on SCITAB and they still have a large gap from human per- formance. The best result is 63.62 for the 2-class setting ( Vicuna-7B  and 38.05 for the 3-class set- ting ( FLAN-T5-XL ). Both results are only moder- ately better   $(+13.62\\$   and  $+4.72$  ) than random guess- ing. In contrast, a well-trained human annotator can achieve 92.46 and 84.73 F1 scores in the 2- class and 3-class settings, respectively. This re- veals the challenging nature of S CI T AB  and its potential to be the future benchmark for scientific fact-checking. ", "page_idx": 6, "bbox": [70, 584.8040161132812, 291, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 62, "type": "text", "text": "2. Counter-intuitively, table-based LLMs do not outperform models pre-trained on pure texts, for example,  FLAN-T5 . This discrepancy may be at- tributed to the dissimilarity between the distribution of tables in scientific literature and publicly avail- able table corpus. For example, scientific tables commonly include both row and column headers, whereas most tables in Wikipedia lack row headers. Meanwhile, the claims in our dataset are usually much longer than those in previous works, raising challenges to table-based LLMs. ", "page_idx": 6, "bbox": [305, 422.2590026855469, 526, 570.896484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 63, "type": "text", "text": "3. The results in the 3-class setting are notably poorer than those in the 2-class setting. This dis- crepancy reveals the challenges that most models face when confronted with the NEI class. One plausible explanation could be the inherent diffi- culty in distinguishing between ‘refuted’ and ‘NEI’ claims — a task that even trained human annotators struggle with, as noted by  Jiang et al.  ( 2020 ). Our forthcoming error analysis will further demonstrate that the inclusion of the NEI class tends to dimin- ish the models’ confidence, causing a shift in their predictions from ‘supported/refuted’ to ‘NEI’. ", "page_idx": 6, "bbox": [305, 578.052001953125, 526, 740.2394409179688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 64, "type": "text", "text": "the majority of models. This observation is some- what expected for open source LLMs as they have not been reported to possess in-context learning ca- pabilities. Nonetheless, it is surprising to find that even with chain-of-thought prompting, in-context demonstrations do not yield positive effects for In- structGPT and GPT-4. Our error analysis on the PoT offers some insight into this phenomenon and will be discussed in the next section. ", "page_idx": 7, "bbox": [69, 71.74500274658203, 290, 193.28445434570312], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 65, "type": "text", "text": "5. Closed source LLMs perform better than open source LLMs, with GPT-4 achieving 78.22 macro-  $F_{1}$   for the 2-class setting and 64.80 for the 3-class setting. This aligns with the assertion that GPT-4 has a strong ability to perform complex reason- ing ( OpenAI ,  2023 ) and we show that this ability can generalize to tabular data as well. However, the black-box nature of OpenAI models restricts our further analysis of its behavior. ", "page_idx": 7, "bbox": [69, 194.16102600097656, 290, 315.7004699707031], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 66, "type": "text", "text": "4.3 Error Analysis ", "text_level": 1, "page_idx": 7, "bbox": [70, 327, 166, 339], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 67, "type": "text", "text": "Instruct GP T and GPT-4. We show the confu- sion matrices for Instruct GP T and GPT-4 under the zero-shot 3-class setting in Figure  4 . We find that both models have difficulty in accurately predicting the NEI class. Instruct GP T displays a pattern of “less confident”, frequently classifying supported and refuted claims as ‘NEI’. In contrast, GPT-4 ex- hibits over confidence, incorrectly categorizing NEI claims as either supported or refuted. This corrob- orates our earlier observation that distinguishing whether a claim is  verifiable  is one of the key chal- lenges for S CI T AB . ", "page_idx": 7, "bbox": [69, 344.60028076171875, 290, 507.18048095703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 68, "type": "text", "text": "Further, we also examine individual error in- stances, with typical examples provided in Fig- ures  11  and  12  of Appendix  F . The majority of ‘supported’ claims that were incorrectly classified as ‘refuted’ (Case 6) involve numerical reasoning or comparison. Conversely, when ‘refuted’ claims are inaccurately predicted as ‘supported’ (Case 3), we find that LLMs often overlook claims contain- ing negation, indicating a lack of deep compre- hension. For cases where ‘supported’ or ‘refuted’ claims are erroneously predicted as ‘NEI’ (Cases 1 and 2), such claims typically demand extensive rea- soning and a deep understanding of the research findings. Interestingly, when faced with these com- plex cases, the model tends to default to the safer choice of ‘uncertain’ (NEI). ", "page_idx": 7, "bbox": [69, 508.0570068359375, 290, 724.4404296875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 69, "type": "text", "text": "PoT. Unexpectedly, incorporating a Python in- terpreter does not confer any advantage on our dataset (as shown in Table  4 ), despite its positive ", "page_idx": 7, "bbox": [69, 733.4523315429688, 290, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 70, "type": "image", "page_idx": 7, "img_path": "layout_images/2305.13186v3_7.jpg", "img_caption": "Figure 4: Confusion matrix for Instruct GP T (left) and GPT-4 (right) in the zero-shot 3-class classification task. ", "bbox": [304, 70, 526, 193], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "InstructGPT Label Distribution Percentage (%)\n\n=\nsupported] 9a | 15\n»\nE\nB Refuted} 4.6 54 8\n8 10\nwil 28 a7 :\n\nSupported Refuted NEI\nPrediction Label\n\nGPT-4 Label Distribution Percentage (%)\n\nSupported\n\nRefuted\n\nGold Label\n\nNel\n\n‘Supported Refuted NEI\nPrediction Label\n", "vlm_text": "The image shows two confusion matrices side by side comparing the performance of InstructGPT (left) and GPT-4 (right) on a zero-shot 3-class classification task. Each matrix illustrates the percentage distribution across prediction labels—Supported, Refuted, NEI (Not Enough Information)—versus the actual gold labels.\n\n- **InstructGPT Confusion Matrix:**\n  - Supported: Predicted as Supported (9.1%), Refuted (1.5%), NEI (26.8%)\n  - Refuted: Predicted as Supported (4.6%), Refuted (5.4%), NEI (23.6%)\n  - NEI: Predicted as Supported (2.8%), Refuted (1.7%), NEI (24.6%)\n\n- **GPT-4 Confusion Matrix:**\n  - Supported: Predicted as Supported (32.1%), Refuted (4.7%), NEI (0.4%)\n  - Refuted: Predicted as Supported (8.3%), Refuted (25.2%), NEI (0.1%)\n  - NEI: Predicted as Supported (10.3%), Refuted (8.5%), NEI (10.4%)\n\nThe color intensity represents the percentage values, with darker shades indicating higher percentages."}
{"layout": 71, "type": "table", "page_idx": 7, "img_path": "layout_images/2305.13186v3_8.jpg", "bbox": [307, 202, 523, 268], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Error Type\n\nEstimated Proportion (%)\n\nI. Grounding errors\nIl. Ambiguity errors\nII. Calculation errors\nIV. Program errors\n\n50\n\n22\n\n20\n8\n\n", "vlm_text": "The table lists types of errors and their estimated proportions in percentages:\n\n- Grounding errors: 50%\n- Ambiguity errors: 22%\n- Calculation errors: 20%\n- Program errors: 8%"}
{"layout": 72, "type": "text", "text": "Table 5: The error types and their estimated proportions for incorrectly-predicted samples in PoT. ", "page_idx": 7, "bbox": [305, 275.78057861328125, 526, 299.74053955078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 73, "type": "text", "text": "impacts on other numerical reasoning tasks. In or- der to understand this, we randomly selected 50 claims wherein the PoT incorrectly predicted the final veracity labels and evaluated the quality of the generated Python programs. We divide the er- rors into four categories, as assessed by human annotators: ( i )  Grounding errors , where the pro- gram incorrectly associates data with the respective cells in the table; ( ii )  Ambiguity errors , where the claim contains ambiguous expressions that the pro- gram fails to represent; ( iii )  Calculation errors , where incorrect floating point arithmetic calcula- tion in Python lead to inaccurate results and   $(i\\nu)$  Program errors , which encompass mistakes such as incorrect or missing arguments/variables, and erroneous operations. We present the error analysis in Table  5 , and examples of program errors can be found in Figure  13  and Figure  14  in Appendix  G . Compared to other datasets, categories   $(i)$   and   $(i i)$  present unique challenges in our dataset. Cate- gory   $(i)$   underlines the difficulty in accurately ref- erencing the specific cells to which a claim refers. Category   $(i i)$  , on the other hand, emphasizes the difficulties posed by the ambiguous nature of scien- tific claims, such as “A is significantly better than  $\\mathbf{B}^{\\ast}$  , to program-based methods. This connection further emphasizes the contribution of our work in addressing the mismatches between reasoning types and the occurrence of grounding errors. ", "page_idx": 7, "bbox": [305, 321.8370056152344, 526, 714.3604736328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 74, "type": "text", "text": "5 Related Work ", "text_level": 1, "page_idx": 7, "bbox": [305, 725, 397, 738], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 75, "type": "text", "text": "Scientific Fact-Checking Datasets. Existing datasets for scientific fact-checking are summa- rized in a recent survey from  Vladika and Matthes ( 2023 ). These datasets differ in: 1)  domain : bi- ology ( Wadden et al. ,  2020 ;  Akhtar et al. ,  2022 ), COVID-19 ( Saakyan et al. ,  2021 ;  Sarrouti et al. , 2021 ;  Mohr et al. ,  2022 ;  Wang et al. ,  2023 ), and cli- mate ( Diggelmann et al. ,  2020 ), 2)  claim creation : crowd-sourced claims  v.s.  natural claims, and 3) evidence source : Wikipedia articles ( Diggelmann et al. ,  2020 ) or research papers ( Wadden et al. , 2020 ,  2022 ;  Sarrouti et al. ,  2021 ). However, most of these datasets rely on text evidence to verify claims. SEM-TAB-FACTS ( Wang et al. ,  2021 ) is the only existing dataset based on scientific tables, but it is limited to simple, crowd-sourced claims. To bridge this gap, we construct S CI T AB  which contains complex claims from authentic scientific papers with table-based evidence. ", "page_idx": 7, "bbox": [305, 747.0023193359375, 526, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 76, "type": "text", "text": "", "page_idx": 8, "bbox": [70, 71.74500274658203, 291, 301.6774597167969], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 77, "type": "text", "text": "Table-based Reasoning. Table-based reasoning requires reasoning over both free-form natural lan- guage queries and (semi-)structured tables. Early works either rely on executable languages ( e.g. , SQL and SPARQL) to access the tabular data ( Yin et al. ,  2016 ;  Yu et al. ,  2018 ) or employ graph neural networks to capture logical structure in statements, e.g. , Logic Fact Checker ( Zhong et al. ,  2020 ) and ProgVGAT ( Yang et al. ,  2020 ). However, these ap- proaches often struggle with generalization, as they are tightly bound to specific table formats and lan- guage patterns. To address this, we have seen a shift toward table pre-training, with the advent of Table- BERT ( Chen et al. ,  2020 ), TAPAS ( Herzig et al. , 2020 ), SaMoE ( Zhou et al. ,  2022 ), PASTA ( Gu et al. ,  2022 ), and DATER ( Ye et al. ,  2023 ). These methods encode sentence-table pairs using lan- guage models and transform table-based reason- ing into question-answering or natural language inference. In our work, we focus on evaluating pre- training-based methods on S CI T AB  because they not only demonstrate superior performance but also offer the benefits of few-shot learning. ", "page_idx": 8, "bbox": [70, 309.1792297363281, 291, 620.7994384765625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 78, "type": "text", "text": "6 Conclusion and Future Work ", "text_level": 1, "page_idx": 8, "bbox": [70, 631, 239, 644], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 79, "type": "text", "text": "We present S CI T AB , a novel dataset for scien- tific fact-checking that addresses the limitations of existing benchmarks. By incorporating real- world scientific claims and their corresponding evidence in the form of tables, S CI T AB  offers a more comprehensive and fine-grained representa- tion of scientific reasoning. The challenging nature of S CI T AB  is evident from the performance of the state-of-the-art, highlighting the need for further research. For example, we believe that addressing the challenges posed by ambiguous claims repre- sents a crucial direction for research in scientific fact-checking ( Glockner et al. ,  2023 ;  Liu et al. , 2023a ). One potential approach is to enhance the disambiguation of ambiguous claims by leverag- ing contextual information or external knowledge sources. Additionally, studying the compositional- ity in table-based reasoning is an interesting direc- tion. Consider the work of Self-Ask ( Press et al. , 2022 ), which proposed the “compositional it y gap” metric to measure the capability of LLMs in com- positional reasoning. Such evaluations can be en- riched by annotating S CI T AB  with ground-truth reasoning depths and structured reasoning graphs. Beyond this, another direction worth exploring is equipping the LLMs with external tools to further improve the model. For example, the use of GPT- 4 plugins, Program-guided Fact-Checking ( Pan et al. ,  2023 ) or adopting approaches from other tool- augmented LLMs like Toolformer ( Schick et al. , 2023 ) and Chameleon ( Lu et al. ,  2023 ). ", "page_idx": 8, "bbox": [70, 652.5499877929688, 291, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 80, "type": "text", "text": "", "page_idx": 8, "bbox": [305, 71.74500274658203, 526, 369.4234619140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 81, "type": "text", "text": "Ethics Statement ", "text_level": 1, "page_idx": 8, "bbox": [305, 380, 393, 393], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 82, "type": "text", "text": "We have received approval from the Institutional Review Board (IRB) 3   for our data collection. The IRB reviewed our experimental design and research procedures to ensure that they do not pose more than minimal risks to research participants. We take steps to protect research participants’ privacy and the confidentiality of their data. The review process took two months to complete. ", "page_idx": 8, "bbox": [305, 401.5639953613281, 526, 509.553466796875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 83, "type": "text", "text": "Limitations ", "text_level": 1, "page_idx": 8, "bbox": [306, 520, 366, 533], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 84, "type": "text", "text": "Firstly, the method and dataset are primarily de- signed for languages with limited morphology, such as English. Secondly, our S CI T AB  dataset is specifically focused on fact-checking scientific claims based on tables, which represents only one aspect of scientific fact-checking. Further re- search can explore the integration of other forms of evidence, including textual evidence and fig- ure evidence, to enhance the fact-checking process. Thirdly, our S CI T AB  dataset is primarily focused on numerical reasoning types, as it is derived from the SciGen dataset, which also emphasizes numeri- cal reasoning. It would be beneficial for future stud- ies to incorporate a wider range of reasoning types to provide a more comprehensive fact-checking framework. Lastly, it would be valuable to ex- plore additional annotation types, such as reason- ing graphs, to further enrich the depth of analysis and capture more intricate relationships within the claims and evidence. ", "page_idx": 8, "bbox": [305, 541.6940307617188, 526, 744.5284423828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 85, "type": "text", "text": "", "page_idx": 9, "bbox": [70, 71.74500274658203, 290, 139.08749389648438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 86, "type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9, "bbox": [70, 151, 170, 163], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 87, "type": "text", "text": "This research is supported by the Ministry of Ed- ucation, Singapore, under its MOE AcRF Tier 3 Grant (MOE-MOET32022-0001). The computa- tional work for this article was partially performed on resources of the National Super computing Cen- tre, Singapore ( https://www.nscc.sg ). ", "page_idx": 9, "bbox": [70, 172.15101623535156, 290, 253.04244995117188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 88, "type": "text", "text": "References ", "text_level": 1, "page_idx": 9, "bbox": [70, 278, 127, 289], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 89, "type": "text", "text": "Mubashara Akhtar, Oana Cocarascu, and Elena Simperl. 2022.  Pub health tab: A public health table-based dataset for evidence-based fact checking . In  Findings of the 2022 Annual Conference of the North Amer- ican Chapter of the Association for Computational Linguistics (NAACL) , pages 1–16. ", "page_idx": 9, "bbox": [70, 296.360595703125, 290, 363.1595153808594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 90, "type": "text", "text": "Rami Aly, Zhijiang Guo, Michael Sejr Sch licht kru ll, James Thorne, Andreas Vlachos, Christos Christo dou lo poul os, Oana Cocarascu, and Arpit Mittal. 2021. FEVEROUS: fact extraction and verification over unstructured and structured infor- mation . In  Proceedings of the Neural Information Processing Systems (NeurIPS) Track on Datasets and Benchmarks . ", "page_idx": 9, "bbox": [70, 372.1105651855469, 290, 460.8275146484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 91, "type": "text", "text": "Emily M. Bender and Batya Friedman. 2018.  Data statements for natural language processing: Toward mitigating system bias and enabling better science . Transactions of the Association for Computational Linguistics (TACL) , 6:587–604. ", "page_idx": 9, "bbox": [70, 469.7775573730469, 290, 525.6184692382812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 92, "type": "text", "text": "Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. 2022. Program of thoughts prompting: Disentangling computation from rea- soning for numerical reasoning tasks . CoRR , abs/2211.12588. ", "page_idx": 9, "bbox": [70, 534.568603515625, 290, 590.4094848632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 93, "type": "text", "text": "Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, and William Yang Wang. 2020.  Tabfact: A large-scale dataset for table-based fact verification . In  Proceed- ings of the 8th International Conference on Learning Representations (ICLR) . ", "page_idx": 9, "bbox": [70, 599.3595581054688, 290, 666.1594848632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 94, "type": "text", "text": "Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. 2023.  Vicuna: An open- source chatbot impressing gpt-4 with  $90\\%^{*}$   chatgpt quality . ", "page_idx": 9, "bbox": [70, 675.1095581054688, 290, 741.9094848632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 95, "type": "text", "text": "Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, ", "page_idx": 9, "bbox": [70, 750.8595581054688, 290, 773.8235473632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 96, "type": "text", "text": "Mostafa Dehghani, Siddhartha Brahma, Albert Web- son, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz- gun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. 2022.  Scaling instruction-finetuned language models . CoRR , abs/2210.11416. ", "page_idx": 9, "bbox": [316, 72.61956787109375, 526, 172.29649353027344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 97, "type": "text", "text": "Jacob Cohen. 1960.  A coefficient of agreement for nominal scales .  Educational and Psychological Mea- surement , 20:37 – 46. Thomas Diggelmann, Jordan L. Boyd-Graber, Jan- nis Bulian, Massimiliano Ciaramita, and Markus Leippold. 2020.  CLIMATE-FEVER: A dataset for verification of real-world climate claims . CoRR , abs/2012.00614. Max Glockner, Ieva Stali unait e, James Thorne, Gisela Vallejo, Andreas Vlachos, and Iryna Gurevych. 2023. Ambifc: Fact-checking ambiguous claims with evi- dence .  CoRR , abs/2104.00640. Zihui Gu, Ju Fan, Nan Tang, Preslav Nakov, Xiao- man Zhao, and Xiaoyong Du. 2022.  PASTA: table- operations aware fact verification via sentence-table cloze pre-training . In  Proceedings of the 2022 Con- ference on Empirical Methods in Natural Language Processing (EMNLP) , pages 4971–4983. Zhijiang Guo, Michael Sejr Sch licht kru ll, and Andreas Vlachos. 2022.  A survey on automated fact-checking . Transactions of the Association for Computational Linguistics (TACL) , 10:178–206. Vivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek Srikumar. 2020.  INFOTABS: inference on tables as semi-structured data . In  Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL) , pages 2309–2324. Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno, and Julian Martin Eisen- schlos. 2020.  Tapas: Weakly supervised table parsing via pre-training . In  Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics (ACL) , pages 4320–4333. Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles Dognin, Maneesh Kumar Singh, and Mohit Bansal. 2020.  Hover: A dataset for many-hop fact extraction and claim verification . In  Findings of the 2020 Con- ference on Empirical Methods in Natural Language Processing (EMNLP) , volume EMNLP 2020, pages 3441–3460. W.Y. Lee, L. Ho, and M.E.T. Ng. 2009.  Research Writ- ing: A Workbook for Graduate Students . Prentice Hall. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghaz vi nine j ad, Abdel rahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Z ett le moyer. 2020. BART: denoising sequence-to-sequence pre-training ", "page_idx": 9, "bbox": [306, 179.89556884765625, 526, 773.8235473632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 98, "type": "text", "text": "prehension . In  Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics (ACL) , pages 7871–7880. Alisa Liu, Swabha S way am dip ta, Noah A. Smith, and Yejin Choi. 2022a.  WANLI: worker and AI collabo- ration for natural language inference dataset creation . In  Findings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 6826–6847. Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha S way am dip ta, Noah A. Smith, and Yejin Choi. 2023a.  We’re afraid language models aren’t modeling ambiguity .  CoRR , abs/2304.14399. Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, and Jian-Guang Lou. 2022b. TAPEX: table pre-training via learning a neural SQL executor . In  Proceedings of the 10th International Conference on Learning Representations (ICLR) . Qian Liu, Fan Zhou, Zhengbao Jiang, Longxu Dou, and Min Lin. 2023b.  From zero to hero: Examining the power of symbolic tasks in instruction tuning .  CoRR , abs/2304.07995. Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai- Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Jian- feng Gao. 2023.  Chameleon: Plug-and-play compo- sitional reasoning with large language models .  CoRR , abs/2304.09842. Isabelle Mohr, Amelie Wührl, and Roman Klinger. 2022.  Covert: A corpus of fact-checked biomedical COVID-19 tweets . In  Proceedings of the 13th Lan- guage Resources and Evaluation Conference (LREC) , pages 244–257. Nafise Sadat Moosavi, Andreas Rücklé, Dan Roth, and Iryna Gurevych. 2021.  Scigen: a dataset for reasoning-aware text generation from scientific ta- bles . In  Proceedings of the Neural Information Pro- cessing Systems (NeurIPS) Track on Datasets and Benchmarks . OpenAI. 2023. GPT-4 technical report . CoRR , abs/2303.08774. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welin- der, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022.  Training language models to follow instruc- tions with human feedback . In  Proceedings of the Annual Conference on Neural Information Process- ing Systems (NeurIPS) . Liangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan Luu, William Yang Wang, Min-Yen Kan, and Preslav Nakov. 2023.  Fact-checking complex claims with program-guided reasoning . In  Proceedings of the ", "page_idx": 10, "bbox": [70, 83.57855224609375, 290, 773.8235473632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 99, "type": "text", "text": "61st Annual Meeting of the Association for Computa- tional Linguistics (ACL) , pages 6981–7004. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, and Mike Lewis. 2022.  Measuring and narrowing the compositional it y gap in language models .  CoRR , abs/2210.03350. Colin Raffel, Noam Shazeer, Adam Roberts, Kather- ine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020.  Exploring the limits of transfer learning with a unified text-to-text transformer .  Journal of Machine Learning Research (JMLR) , 21:140:1–140:67. Arkadiy Saakyan, Tuhin Chakra barty, and Smaranda Muresan. 2021. Covid-fact: Fact extraction and veri- fication of real-world claims on COVID-19 pandemic. In  Proceedings of the 59th Annual Meeting of the As- sociation for Computational Linguistics (ACL) , pages 2116–2129. Mourad Sarrouti, Asma Ben Abacha, Yassine Mrabet, and Dina Demner-Fushman. 2021.  Evidence-based fact-checking of health-related claims . In  Findings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 3499– 3512. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Z ett le moyer, Nicola Cancedda, and Thomas Scialom. 2023.  Toolformer: Language models can teach themselves to use tools . CoRR , abs/2302.04761. Tal Schuster, Darsh J. Shah, Yun Jie Serene Yeo, Daniel Filizzola, Enrico Santus, and Regina Barzilay. 2019.  Towards debiasing fact verification models . In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 3417–3423. Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford alpaca . Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023.  Llama: Open and efficient foundation language models .  CoRR , abs/2302.13971. Juraj Vladika and Florian Matthes. 2023.  Scientific fact- checking: A survey of resources and approaches . In Findings of the 61st Association for Computational Linguistics (ACL) , pages 6215–6230. David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine van Zuylen, Arman Cohan, and Hannaneh Hajishirzi. 2020.  Fact or fiction: Verifying scientific claims . In  Proceedings of the 2020 Con- ference on Empirical Methods in Natural Language Processing (EMNLP) , pages 7534–7550. ", "page_idx": 10, "bbox": [306, 72.61956787109375, 526, 773.8235473632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 100, "type": "text", "text": "David Wadden, Kyle Lo, Bailey Kuehl, Arman Cohan, Iz Beltagy, Lucy Lu Wang, and Hannaneh Hajishirzi. 2022.  Scifact-open: Towards open-domain scientific claim verification . In  Findings of the 2022 Confer- ence on Empirical Methods in Natural Language Processing (EMNLP) , pages 4719–4734. ", "page_idx": 11, "bbox": [70.86599731445312, 72.61956787109375, 290, 139.4194793701172], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 101, "type": "text", "text": "Yuxuan Zhou, Xien Liu, Kaiyin Zhou, and Ji Wu. 2022. Table-based fact verification with self-adaptive mix- ture of experts . In  Findings of the 60th Associa- tion for Computational Linguistics (ACL) , pages 139– 149. ", "page_idx": 11, "bbox": [306.1419982910156, 72.61956787109375, 526, 128.4604949951172], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 102, "type": "text", "text": "Gengyu Wang, Kate Harwood, Lawrence Chillrud, Amith Ananthram, Melanie Subbiah, and Kathleen R. McKeown. 2023. Check-covid: Fact-checking COVID-19 news claims with scientific evidence . In Findings of the 61st Association for Computational Linguistics (ACL) , pages 14114–14127. ", "page_idx": 11, "bbox": [70, 147.810546875, 290, 214.6105194091797], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 103, "type": "text", "text": "Nancy Xin Ru Wang, Diwakar Mahajan, Marina Danilevsky, and Sara Rosenthal. 2021.  Semeval-2021 task 9: Fact verification and evidence finding for tabu- lar data in scientific documents (SEM-TAB-FACTS) . In  Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval@ACL/IJCNLP) , pages 317–326. ", "page_idx": 11, "bbox": [70, 223.0015869140625, 290, 300.760498046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 104, "type": "text", "text": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models .  CoRR , abs/2201.11903. ", "page_idx": 11, "bbox": [70, 309.15155029296875, 290, 354.03350830078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 105, "type": "text", "text": "Xiaoyu Yang, Feng Nie, Yufei Feng, Quan Liu, Zhigang Chen, and Xiaodan Zhu. 2020.  Program enhanced fact verification with verb aliz ation and graph atten- tion network . In  Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing (EMNLP) , pages 7810–7825. ", "page_idx": 11, "bbox": [70, 362.424560546875, 290, 429.2245178222656], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 106, "type": "text", "text": "Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, and Yongbin Li. 2023.  Large language mod- els are versatile decomposers: Decomposing evi- dence and questions for table-based reasoning . In Proceedings of the 46th International ACM Confer- ence on Research and Development in Information Retrieval (SIGIR) , pages 174–184. ", "page_idx": 11, "bbox": [70, 437.6155700683594, 290, 515.3734741210938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 107, "type": "text", "text": "Pengcheng Yin, Zhengdong Lu, Hang Li, and Ben Kao. 2016.  Neural enquirer: Learning to query tables in natural language . In  Proceedings of the 25th Inter- national Joint Conference on Artificial Intelligence (IJCAI) , pages 2308–2314. ", "page_idx": 11, "bbox": [70, 523.7655639648438, 290, 579.6055297851562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 108, "type": "text", "text": "Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir R. Radev. 2018.  Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task . In  Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP) , pages 3911– 3921. ", "page_idx": 11, "bbox": [70, 587.99755859375, 290, 687.6735229492188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 109, "type": "text", "text": "Wanjun Zhong, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang, and Jian Yin. 2020.  Logical fact checker: Leveraging logical operations for fact checking with graph module network . In  Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL) , pages 6053–6065. ", "page_idx": 11, "bbox": [70, 696.0645751953125, 290, 773.8235473632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 110, "type": "text", "text": "A Claim Extraction Procedure ", "text_level": 1, "page_idx": 12, "bbox": [70, 72, 236, 84], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 111, "type": "text", "text": "A.1 Claim Definition ", "text_level": 1, "page_idx": 12, "bbox": [71, 94, 176, 107], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 112, "type": "text", "text": "In academic writing ( Lee et al. ,  2009 ), the accompa- nying text for data, presented as tables and figures), typically includes three fundamental elements as outlined below. These elements encompass the def- inition of claims, which involve highlighting key data (KD) and commenting on key data (COM) that emphasizes and comments on the key data. ", "page_idx": 12, "bbox": [70, 112.00501251220703, 291, 206.44546508789062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 113, "type": "text", "text": "Location of results (LOC). Statements that lo- cate where the figure/table is found,  e.g.,  Figure 7 displays the mean percentile scores. ", "page_idx": 12, "bbox": [70, 215.2722625732422, 291, 255.90847778320312], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 114, "type": "text", "text": "Highlighting of key data (KD). Statements that highlight the important data,  e.g., (1) Highest or lowest values (2) Overall trend or pattern in the data (3) Points that do not seem to fit the pattern or trend, etc. (4) Results which provide answers to your research questions ", "page_idx": 12, "bbox": [70, 264.7352600097656, 291, 346.01947021484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 115, "type": "text", "text": "Commenting on key data (COM). Statements that interpret the data. There are three types of comments: (1) Generalization (deductions and im- plications drawn from the results),  e.g.,  “This in- dicates that ...” (2) Comparison of results with those from prior studies,  e.g.,  “Different from ...” (3) Explanation or speculation (possible reasons or cause-effect relationships for the results),  e.g., “The possible reason is that ...” ", "page_idx": 12, "bbox": [70, 354.84527587890625, 291, 476.7774658203125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 116, "type": "text", "text": "A.2 Claim Extraction Interface ", "text_level": 1, "page_idx": 12, "bbox": [70, 488, 225, 500], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 117, "type": "text", "text": "Figure  5  shows the user interface for the claim extraction task. ", "page_idx": 12, "bbox": [70, 505.77801513671875, 291, 532.472412109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 118, "type": "text", "text": "B Manual Claim Verification Procedure ", "text_level": 1, "page_idx": 12, "bbox": [70, 544, 285, 558], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 119, "type": "text", "text": "B.1 Annotator Training Process ", "text_level": 1, "page_idx": 12, "bbox": [70, 567, 228, 579], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 120, "type": "text", "text": "Our annotator selection and training process is sys- tematic and thorough to ensure the highest quality annotations. We initiate the process by advertising on our university’s platform. Interested candidates are then required to complete a registration form. From these responses, the authors identify suitable annotators based on set criteria. Once shortlisted, the potential annotators are invited for a training session, which can be conducted either in-person or via Zoom, lasting approximately one hour. This session is divided into three parts. Firstly, the au- thors provide a comprehensive overview of the task definition, ensuring clarity on what is expected. Similar to WANLI ( Liu et al. ,  2022a ), during our training sessions 4 , commonsense interpretations and a minimum amount of logical inference are acceptable. Next, a demonstration is given on how to navigate and utilize the annotation interface ef- fectively. Following this, a series of trial tests are released to the annotators. This is to verify their understanding and capability in the task. Last, we specify the deadline for completing annotations, outline how we check the quality of their work, brief them on a post-annotation survey, and explain the reimbursement procedure. A Q&A session is also incorporated to address any uncertainties or concerns. After receiving their reimbursement, the annotators signed an agreement sheet to ensure its receipt. ", "page_idx": 12, "bbox": [70, 584.8040161132812, 291, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 121, "type": "text", "text": "", "page_idx": 12, "bbox": [305, 70.50165557861328, 526, 274.5794982910156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 122, "type": "text", "text": "B.2 NEI Claim Verification Interface ", "text_level": 1, "page_idx": 12, "bbox": [305, 286, 486, 299], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 123, "type": "text", "text": "Figure  6  shows the user interface for the NEI claim verification task. ", "page_idx": 12, "bbox": [305, 304.73101806640625, 526, 331.4254455566406], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 124, "type": "text", "text": "B.3 Refuted Claim Verification Interface ", "text_level": 1, "page_idx": 12, "bbox": [305, 343, 503, 356], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 125, "type": "text", "text": "Figure  7  shows the user interface for the refuted claim verification task. ", "page_idx": 12, "bbox": [305, 361.5769958496094, 526, 388.2724609375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 126, "type": "text", "text": "B.4 Annotation Post-Survey ", "text_level": 1, "page_idx": 12, "bbox": [305, 399, 444, 412], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 127, "type": "text", "text": "Figure  8  shows the examples of post-annotation survey questions and the answers of annotators. ", "page_idx": 12, "bbox": [305, 418.42401123046875, 526, 445.11846923828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 128, "type": "text", "text": "C Analysis of Refuted Reasons in the Sci-Fact dataset ", "text_level": 1, "page_idx": 12, "bbox": [305, 457, 504, 484], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 129, "type": "text", "text": "Table  6  provides an analysis of the reasons for re- futed claims in the Sci-Fact dataset, along with their estimated proportions. A random sample of 100 refuted claims was selected, and the results indicate that   $85\\%$   of claims were simply negated using terms like “not” or paraphrased based on the evidence sentences. Additionally,  $6\\%$   of the refuted claims were attributed to incorrect calculation re- sults, while  $6\\%$   were identified as having wrong commonsense knowledge. A smaller proportion of refuted claims   $(3\\%)$   were found to have incorrect open-domain knowledge. ", "page_idx": 12, "bbox": [305, 494.3450012207031, 526, 656.5314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 130, "type": "text", "text": "D Discussions on Human-Machine Collaboration ", "text_level": 1, "page_idx": 12, "bbox": [305, 668, 491, 696], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 131, "type": "text", "text": "Our final data creation pipeline undergoes repeti- tive testing and revision until it reaches its current ", "page_idx": 12, "bbox": [305, 705.7579956054688, 526, 732.4524536132812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 132, "type": "table", "page_idx": 13, "img_path": "layout_images/2305.13186v3_9.jpg", "table_footnote": "Table 6: The refuted reasons and their estimated propor- tions (Prop.) in the Sci-Fact dataset. ", "bbox": [70, 68, 290, 171], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Refuted Reasons Prop. (%)\n\nNegation (+not) and paraphrasing. 85\nThe calculation result is wrong.\n\nThe commonsense knowledge is wrong.\nThe open-domain knowledge is wrong.\n\nWAX\n\n", "vlm_text": "The table lists different reasons for refuting information along with their respective proportions (in percentage). \n\n- Negation (+not) and paraphrasing: 85%\n- The calculation result is wrong: 6%\n- The commonsense knowledge is wrong: 6%\n- The open-domain knowledge is wrong: 3%"}
{"layout": 133, "type": "text", "text": "form. In our pilot annotation, we found that man- ual verification played the most essential role in the validation of claims marked as “Not Enough Infor- mation(NEI)”. Initially, we planned to rely solely on LLMs for generating NEI claims. Our criteria for the NEI claim is that “the claim should be flu- ent, logical, and relevant to the table. However, the claim cannot be verified as true or false solely based on the information in the table.” However, after a careful examination of the LLM output, we found that LLM tends to generate claims that are either not logical or irrelevant to the table content. Therefore, human efforts are required to further select NEI claims that meet our criteria. Out of 900 initial NEI claims generated by LLMs, man- ual verification narrowed them down to only 355 claims, taking up  $40\\%$   of the original count. While it may not have served as crucial a role as filtering NEI claims, human verification also safeguarded the data quality in other annotation processes. For example, among the “supported” claims originally appearing in the scientific paper, human validation still identified 10 cases that were actually not sup- ported ( e.g ., wrong number matching.) ", "page_idx": 13, "bbox": [70, 186.4090118408203, 291, 511.18646240234375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 134, "type": "text", "text": "E Case Study for Refuted Claims ", "text_level": 1, "page_idx": 13, "bbox": [70, 524, 249, 537], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 135, "type": "text", "text": "Figure  9  and Figure  10  show five examples of re- futed cases. Below, we provide explanations for each of these error cases. ", "page_idx": 13, "bbox": [70, 546.510009765625, 291, 586.7544555664062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 136, "type": "text", "text": "Case  A  The calculation result is wrong. It pro- duces incorrect calculation results. The accurate result should be    $27.9{-}21.7\\:=\\:6\\,.\\,2.$  . ", "page_idx": 13, "bbox": [70, 596.294677734375, 291, 636.9754638671875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 137, "type": "text", "text": "Case  $\\pmb{B}$   The approximation word is wrong. It generates incorrect approximation words, as 19.4 is not significantly lower compared to 23.3. ", "page_idx": 13, "bbox": [70, 646.560302734375, 291, 687.1964111328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 138, "type": "text", "text": "Case    $c$   The claim is partially right. The claim is generally correct, with the exception of the BShift column  which does not fulfill the claim. ", "page_idx": 13, "bbox": [70, 696.7376708984375, 291, 737.4174194335938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 139, "type": "text", "text": "Case  $\\pmb{D}$   The values in the claim do not match. The value in the claim does not align with the cor- responding value in the table. The correct value should be  27.9 . ", "page_idx": 13, "bbox": [70, 747.0023193359375, 291, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 140, "type": "text", "text": "", "page_idx": 13, "bbox": [305, 71.74500274658203, 527, 98.43948364257812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 141, "type": "text", "text": "Case  $\\pmb{{\\cal E}}$   The operation type is wrong. It applies the incorrect operation type. For instance, in the case of    $\\mathsf{G C N}\\!\\!+\\!\\mathsf{R C}\\!+\\!\\mathsf{L A}$   (9) , it is not accurate to claim that it is better than  DCGCN1  because    $22.9\\:>\\:22.\\emptyset$  and   $53\\,.\\,\\emptyset\\ >\\ 52\\,.\\,6$  . ", "page_idx": 13, "bbox": [305, 105.72825622558594, 527, 172.32891845703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 142, "type": "text", "text": "F Error Cases for Instruct GP T ", "text_level": 1, "page_idx": 13, "bbox": [305, 184, 473, 197], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 143, "type": "text", "text": "Figure  11  and Figure  12  show six error examples of Instruct GP T in the zero-shot setting when applied to our S CI T AB  dataset. ", "page_idx": 13, "bbox": [305, 204.82398986816406, 527, 245.06747436523438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 144, "type": "text", "text": "Error Type 1: Supported predicted as NEI. This error type indicates a discrepancy between the gold label, which is Supported, and the predicted label, which is NEI. ", "page_idx": 13, "bbox": [305, 252.35630798339844, 527, 306.5414733886719], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 145, "type": "text", "text": "Error Type 2: Refuted predicted as NEI. This error type indicates a discrepancy between the gold label, which is Refuted, and the predicted label, which is NEI. ", "page_idx": 13, "bbox": [305, 313.8302917480469, 527, 368.0154724121094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 146, "type": "text", "text": "Error Type 3: Refuted predicted as Supported. This error type indicates a discrepancy between the gold label, which is Refuted, and the predicted label, which is Supported. ", "page_idx": 13, "bbox": [305, 375.30426025390625, 527, 429.490478515625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 147, "type": "text", "text": "Error Type 4: NEI predicted as Supported. This error type indicates a discrepancy between the gold label, which is NEI, and the predicted label, which is Supported. ", "page_idx": 13, "bbox": [305, 436.77825927734375, 527, 490.9644775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 148, "type": "text", "text": "Error Type 5: NEI predicted as Refuted. This error type indicates a discrepancy between the gold label, which is NEI, and the predicted label, which is Refuted. ", "page_idx": 13, "bbox": [305, 498.25225830078125, 527, 552.4384765625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 149, "type": "text", "text": "Error Type 6: Supported predicted as Refuted. This error type indicates a discrepancy between the gold label, which is Supported, and the predicted label, which is Refuted. ", "page_idx": 13, "bbox": [305, 559.7262573242188, 527, 613.9124755859375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 150, "type": "text", "text": "G Error Cases for Program-of-Thoughts ", "text_level": 1, "page_idx": 13, "bbox": [305, 624, 524, 638], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 151, "type": "text", "text": "Figure  13  and Figure  14  show five error examples of Program-of-Thoughts when applied to our S C - I T AB  dataset. Below, we provide explanations for each of the error cases. ", "page_idx": 13, "bbox": [305, 645.2730102539062, 527, 699.06640625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 152, "type": "text", "text": "Error Case 1. It exhibits incorrect entity linking ( Grounding error ) and incorrect operation   $(P r o-$  gram error ). The codes “ wino grad baseline  $=\\;73.\\theta6^{\\ast}$   and “ wino core f baseline  $=\\ 88.48\"$  should be “ Ill iCons wino grad   $=\\ 53.26^{\\circ}$   and ", "page_idx": 13, "bbox": [305, 706.3543090820312, 527, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 153, "type": "text", "text": "", "page_idx": 14, "bbox": [85, 72, 106, 81], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 154, "type": "table", "page_idx": 14, "img_path": "layout_images/2305.13186v3_10.jpg", "table_caption": "", "bbox": [84, 84, 505, 187], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Representation Hyper\nparameters\nFilter size\nCoNLLOS 45\nSB 45\n\nUDvI3 s\n\nHyper parameters\n‘Num, Feature\nmaps\n1000\n806\n\n716\n\nHyper\nparameters\nActivation func.\nSoftplus\n\nSigmoid\n\nSoftplus\n\nHyper\nparameters L2\nReg.\n1.15e+01\n8.13e-02\n\n1.666+00\n\nHyper\nLearning rate\n1.13¢-03\n\n1,79¢-03\n\n9.63E-04\n\nHyper\n\nDropout Prob.\n\n0.87\n\nFi(avg. in 5-\nfold) with\ndefault values\n73.34\n\n72.83\n\n68.93\n\nFi (ayg. in 5-\nfold) with\n\noptimal values\n7449\n75.05\n\n69.57\n", "vlm_text": "The table presents a comparison of different representations and their corresponding hyperparameters, along with the F1 scores in 5-fold validation.\n\n- **Columns**:\n  - Representation\n  - Hyperparameters: Filter size, Num. Feature maps, Activation function, L2 Regularization, Learning rate, Dropout Probability\n  - F1 score (average in 5-fold) with default values\n  - F1 score (average in 5-fold) with optimal values\n\n- **Rows**:\n  1. **CoNLL08**\n     - Filter size: 4-5\n     - Num. Feature maps: 1000\n     - Activation function: Softplus\n     - L2 Regularization: 1.15e+01\n     - Learning rate: 1.13e-03\n     - Dropout Probability: 1\n     - F1 with default: 73.34\n     - F1 with optimal: 74.49\n\n  2. **SB**\n     - Filter size: 4-5\n     - Num. Feature maps: 806\n     - Activation function: Sigmoid\n     - L2 Regularization: 8.13e-02\n     - Learning rate: 1.79e-03\n     - Dropout Probability: 0.87\n     - F1 with default: 72.83\n     - F1 with optimal: 75.05\n\n  3. **UD v1.3**\n     - Filter size: 5\n     - Num. Feature maps: 716\n     - Activation function: Softplus\n     - L2 Regularization: 1.66e+00\n     - Learning rate: 9.63e-04\n     - Dropout Probability: 1\n     - F1 with default: 68.93\n     - F1 with optimal: 69.57"}
{"layout": 155, "type": "text", "text": "", "page_idx": 14, "bbox": [86, 195, 500, 214], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 156, "type": "text", "text": "", "page_idx": 14, "bbox": [86, 221, 498, 250], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 157, "type": "image", "page_idx": 14, "img_path": "layout_images/2305.13186v3_11.jpg", "img_caption": "Figure 5: The user interface for the claim extraction task. ", "bbox": [86, 254, 494, 349], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "© Deseription\nO Background\n@ Claim\n\nProgress:\n", "vlm_text": "The image shows a user interface for a claim extraction task. It includes radio button options labeled \"Description,\" \"Background,\" and \"Claim,\" with \"Claim\" selected. Below these options is a green button labeled \"Annotate.\" At the bottom, there's a progress bar with a label \"Progress:\" and a partial blue fill indicating progress."}
{"layout": 158, "type": "text", "text": "", "text_level": 1, "page_idx": 14, "bbox": [89, 364, 119, 373], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 159, "type": "text", "text": "", "page_idx": 14, "bbox": [88, 381, 300, 408], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 160, "type": "table", "page_idx": 14, "img_path": "layout_images/2305.13186v3_12.jpg", "bbox": [89, 411, 503, 643], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "B Table\n\nModel Training data Overall Easy Hard\nBERT-large-FT B-COPA 745 (£07) 747 (#04) 74.4 (£09)\nBERT-large-FT B-COPA (50%) 743 (£22) 768 (£19) 72.8 (43.1)\nBERT-large-FT COPA 765 (£27) 83.9 (244) N19 (£25)\n\nRoBERTu-large-FT B-COPA 89.0 (4.0.3) 88.9 (42.1) 89.0 (4.0.8)\nRoBERTw-large-FT B-COPA (50%) 86.1 (+22) 87.4 (41.1) 85.4 (£29)\nRoBERTu-large-FT COPA 87.7 (£09) 91.6 (1.1) 85.3 (£20)\n\nCaption: Table 5: Results of fine-tuned models on Balanced COPA. Easy: instances with superficial cues, Hard: instances without superficial cues.\n\n9 Claim\nFor both BERT and RoBERTa, more data leads to more performance improvements, although the growth rate on RoBERTa is slightly faster.\n", "vlm_text": "The table displays the results of fine-tuned models on Balanced COPA. It includes comparisons of BERT-large-FT and RoBERTa-large-FT models using different training data:\n\n1. **Model**: Names of the models (BERT-large-FT and RoBERTa-large-FT).\n2. **Training Data**: Different training datasets used (B-COPA, B-COPA (50%), and COPA).\n3. **Overall**: Overall performance scores, with standard deviation in parentheses.\n4. **Easy**: Performance scores on easy instances (with superficial cues), plus standard deviation.\n5. **Hard**: Performance scores on hard instances (without superficial cues), with standard deviation.\n\nThe caption notes that \"Easy\" instances have superficial cues, while \"Hard\" instances do not. The table suggests that more data leads to improved performance, with a slightly faster growth rate for RoBERTa."}
{"layout": 161, "type": "text", "text": "“ Ill iCons wino core f  $\\dot{{\\,}}=74\\,.\\,32{}^{\\circ}$   respectively. Ad- ditionally, the “ > ” operation should be changed to  $\\left.>=\\right.^{\\ast}$  . ", "page_idx": 14, "bbox": [69, 693.239013671875, 292, 733.482421875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 162, "type": "text", "text": "Error Case 2. It exhibits incomplete entity link- ing ( Grounding error ). The program should also parse other baseline results, such as ‘ SFEGAN_WER  $=\\ 14.9^{\\circ}$  . ", "page_idx": 14, "bbox": [69, 747.0023193359375, 292, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 163, "type": "text", "text": "", "page_idx": 14, "bbox": [305, 693.239013671875, 526, 719.9334716796875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 164, "type": "text", "text": "Error Case 3. It fails to generate a correct pro- gram ( Program error ). The variables and logical functions in the programs are incorrect. For in- ", "page_idx": 14, "bbox": [305, 733.4523315429688, 526, 774.0894775390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 165, "type": "text", "text": "", "page_idx": 15, "bbox": [106, 74, 140, 82], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 166, "type": "text", "text": "", "page_idx": 15, "bbox": [105, 91, 170, 99], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 167, "type": "text", "text": "", "page_idx": 15, "bbox": [105, 107, 302, 116], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 168, "type": "image", "page_idx": 15, "img_path": "layout_images/2305.13186v3_13.jpg", "img_caption": "Figure 7: The user interface for the refuted claim verification task ", "bbox": [107, 120, 490, 419], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Table\n\nModel Training data Overall Easy ard\nBERT-large-FT B-COPA 745 (20.2) 74.1 (£04) 144 (£09)\nBERT-large-FT B-COPA (50%) 743 (22) 76.8 (+ 1.9) T28 (3.1)\nBERT-large-FT COPA 765 (£2.7) 83.9 (444) 19 (£25)\n\nRoBERTa-large-FT B-COPA 89.0 (+0.3) 88.9 (42.1) 89.0 (+0.8)\nRoBERTa-large-FT B-COPA (50%) 86.1 (2.2) 874 (t LI) 85.4 (£29)\nRoBERTa-large-FT COPA 87.7 (£09) 91.6 (£11) 85.3 (£20)\n\nCaption: Table 5; Results of fine-tuned models on Balanced COPA, Easy: instances with superficial cues, Hard: instances without superficial cues.\n\n© Original Claim\nThe smaller performance gap between Easy and Hard subsets indicates that training on BCOPA encourages BERT and RoBERTa to rely less on\nsuperficial cues.\n\n© Generated Refuted Claim\n\nThe larger performance gap between Easy and Hard subsets indicates that training on BCOPA encourages BERT and RoBERTa to rely more on\nsuperficial cues.\n", "vlm_text": "The image contains a table showing the performance of fine-tuned models on Balanced COPA. It compares the results for models BERT-large-FT and RoBERTa-large-FT, using different training datasets. The performance is presented in terms of overall score, as well as scores on \"Easy\" and \"Hard\" instances. Below the table, there's a section titled \"Original Claim\" which discusses the performance gap between the Easy and Hard subsets, suggesting that training on BCOPA might encourage the models to rely less on superficial cues. The \"Generated Refuted Claim\" presents a reverse interpretation, indicating reliance on superficial cues."}
{"layout": 169, "type": "text", "text": "stance, “ G 2 S GAT BLEU L DC 2015 E 86 ” should be “ G 2 S G IN BLEU L DC 2015 E 86 ”. The logical func- tion “ and ” should be replaced with “ or ”. ", "page_idx": 15, "bbox": [70, 440, 291, 481], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 170, "type": "text", "text": "Error Case 4. It fails to generate a precise pro- gram for the approximation word “comparable”\n\n ( Ambiguity error ). Currently, the program defines\n\n “comparable” as “larger than”, which is not accurate enough. ", "page_idx": 15, "bbox": [70, 488, 291, 556], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 171, "type": "text", "text": "Error Case 5. It generates the correct program, but the calculation result is inaccurate due to incor- rect float digits in the Python code ( Calculation er- ror ). For instance, Python may output ’1.9499999’, which is not equal to   ${}^{'}1.95'$  . ", "page_idx": 15, "bbox": [70, 564, 291, 631], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 172, "type": "text", "text": "Annotation Post Survey  ", "text_level": 1, "page_idx": 16, "bbox": [216, 128, 383, 145], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 173, "type": "text", "text": "Annotator 1:  ", "text_level": 1, "page_idx": 16, "bbox": [105, 147, 168, 158.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 174, "type": "text", "text": "•   Is the task demonstration clear to you?  Yes,  clear.  \n\n •   What do you think is the difficulty of this task?  (1-10 points, 10 points is the most  difficult)  5-6.  \n\n •   Which part is the most difficult for you? Why?  Judgment, understanding the way of original author think.  \n\n •   Do you think the annotation batch is appropriate? What is the maximum batch  amount for you in a week?   Yes. 2 batches in a week during the examination. 4 during vacation.  \n\n •   Could you provide some advice on how to improve the annotation platform?    Looping for multiple operations.   \n\n ", "page_idx": 16, "bbox": [121, 159.21636962890625, 478, 292.0554504394531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 175, "type": "text", "text": "Annotator 2:   ", "text_level": 1, "page_idx": 16, "bbox": [105, 313, 168, 324], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 176, "type": "text", "text": "•   Is the task demonstration clear to you?  Yes.  \n\n •   What do you think is the difficulty of this task?  (1-10 points, 10 points is the most  difficult)  6  \n\n •   Which part is the most difficult for you? Why?  Table understanding; different parameters in the attributes.  \n\n •   Do you think the annotation batch is appropriate? What is the maximum batch  amount for you in a week?   Ok. 2-3 batches  \n\n •   Would you like to attend this session again as a 2-week participation?   ok.  \n\n •   Could you provide some advice on how to improve the annotation platform?   I preferred to write down the annotations on the platform.  \n\n ", "page_idx": 16, "bbox": [121, 324.59710693359375, 478, 480.50299072265625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 177, "type": "text", "text": "Annotator 3:   ", "text_level": 1, "page_idx": 16, "bbox": [105, 500, 168, 512], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 178, "type": "text", "text": "•   Is the task demonstration clear to you?  Yes, clear. the difficulty is different between demo and real annotation. \n\n •   What do you think is the difficulty of this task?  (1-10 points, 10 points is the most  difficult)  7 \n\n •   Which part is the most difficult for you? Why?  Table understanding-vocabulary.  \n\n •   Do you think the sample amount is appropriate? What is the maximum batch amount  for you in a week (1 batch contains 20 samples)?   10-15  samples for an hour. 50 samples a week.    \n\n •   Would you like to attend this session again as a 2-week participation?    Maybe not. But 15 samples offline for a week is ok.     \n\n •   Could you provide some advice on how to improve the annotation platform?    I think the current platform is fine for me.  ", "page_idx": 16, "bbox": [121, 512.838623046875, 493.51409912109375, 689.1339721679688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 179, "type": "text", "text": "Figure 8: The examples of post-annotation survey questions and the answers of annotators. ", "page_idx": 16, "bbox": [116.46399688720703, 704.2445678710938, 478, 716.24951171875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 180, "type": "text", "text": "H Prompts ", "text_level": 1, "page_idx": 17, "bbox": [70, 71, 137, 85], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 181, "type": "text", "text": "H.1 Zero-shot Prompts ", "text_level": 1, "page_idx": 17, "bbox": [70, 92, 187, 105], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 182, "type": "text", "text": "Table :  <input table> ", "page_idx": 17, "bbox": [70, 116.62356567382812, 141.99853515625, 123.94605255126953], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 183, "type": "text", "text": "Claim :  <input claim> ", "text_level": 1, "page_idx": 17, "bbox": [70, 131, 142, 141], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 184, "type": "text", "text": "Based on the information in the Table , is the above claim true? A) the claim is true. B) the claim is false. C) it is impossible to tell. ", "page_idx": 17, "bbox": [70, 148.67791748046875, 334.12896728515625, 179.64537048339844], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 185, "type": "text", "text": "H.2 Few-shot Prompts ", "text_level": 1, "page_idx": 17, "bbox": [71, 199, 184, 212], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 186, "type": "text", "text": "Read the following table and then answer a question. ", "page_idx": 17, "bbox": [70, 223.23291015625, 288.099853515625, 230.29039001464844], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 187, "type": "text", "text": "Caption : Table 5: Results of fine -tuned models on Balanced COPA. Easy: instances with superficial cues , Hard: instances without superficial cues.\n\n ", "page_idx": 17, "bbox": [70, 238.99856567382812, 497, 254.20140075683594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 188, "type": "text", "text": "Table ", "text_level": 1, "page_idx": 17, "bbox": [70, 263, 90, 270], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 189, "type": "text", "text": "|| Model | Training data | Overall | Easy | Hard ||\n\n || BERT -large -FT | B-COPA | 74.5 ( ± 0.7) | 74.7 ( ± 0.4) | 74.4 ( ± 0.9) ||\n\n || BERT -large -FT | B-COPA (50%) | 74.3 ( ± 2.2) | 76.8 ( ± 1.9) | 72.8 ( ± 3.1) ||\n\n || BERT -large -FT | COPA | 76.5 ( ± 2.7) | 83.9 ( ± 4.4) | 71.9 ( ± 2.5) ||\n\n || RoBERTa -large -FT | B-COPA | 89.0 ( ± 0.3) | 88.9 ( ± 2.1) | 89.0 ( ± 0.8) ||\n\n || RoBERTa -large -FT | B-COPA (50%) | 86.1 ( ± 2.2) | 87.4 ( ± 1.1) | 85.4 ( ± 2.9) ||\n\n || RoBERTa -large -FT | COPA | 87.7 ( ± 0.9) | 91.6 ( ± 1.1) | 85.3 ( ± 2.0) || ", "page_idx": 17, "bbox": [70, 271.05389404296875, 407, 331.330078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 190, "type": "text", "text": "Claim : RoBERTa -large outperforms BERT -large when fine -tuned on full and balanced COPA. ", "page_idx": 17, "bbox": [70, 334.6405334472656, 426.88525390625, 341.9630126953125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 191, "type": "text", "text": "Question : Is the above claim true or false? Please directly give the answer. ", "page_idx": 17, "bbox": [70, 350.5805358886719, 382, 357.90301513671875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 192, "type": "text", "text": "Answer ", "text_level": 1, "page_idx": 17, "bbox": [70, 367, 94, 373.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 193, "type": "text", "text": "The claim is true. ", "page_idx": 17, "bbox": [70, 374.6648864746094, 145, 381.7223815917969], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 194, "type": "text", "text": "Caption : Table 5: Results of fine -tuned models on Balanced COPA. Easy: instances with superficial cues , Hard: instances without superficial cues.\n\n ", "page_idx": 17, "bbox": [70, 390.4315490722656, 497, 405.6333923339844], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 195, "type": "text", "text": "Table ", "text_level": 1, "page_idx": 17, "bbox": [70, 414, 90, 421], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 196, "type": "text", "text": "|| Model | Training data | Overall | Easy | Hard ||\n\n || BERT -large -FT | B-COPA | 74.5 ( ± 0.7) | 74.7 ( ± 0.4) | 74.4 ( ± 0.9) ||\n\n || BERT -large -FT | B-COPA (50%) | 74.3 ( ± 2.2) | 76.8 ( ± 1.9) | 72.8 ( ± 3.1) ||\n\n || BERT -large -FT | COPA | 76.5 ( ± 2.7) | 83.9 ( ± 4.4) | 71.9 ( ± 2.5) ||\n\n || RoBERTa -large -FT | B-COPA | 89.0 ( ± 0.3) | 88.9 ( ± 2.1) | 89.0 ( ± 0.8) ||\n\n || RoBERTa -large -FT | B-COPA (50%) | 86.1 ( ± 2.2) | 87.4 ( ± 1.1) | 85.4 ( ± 2.9) ||\n\n || RoBERTa -large -FT | COPA | 87.7 ( ± 0.9) | 91.6 ( ± 1.1) | 85.3 ( ± 2.0) || ", "page_idx": 17, "bbox": [70, 422.48590087890625, 407, 482.7620849609375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 197, "type": "text", "text": "Claim : The difference between RoBERTa -large -FT and BERT -large -FT is 3.8 points on B-COPA , which is significantly smaller than the difference in COPA. ", "page_idx": 17, "bbox": [70, 486.0725402832031, 439.43829345703125, 501.2743835449219], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 198, "type": "text", "text": "Question : Is the above claim true or false? Please directly give the answer. ", "page_idx": 17, "bbox": [70, 509.9825134277344, 382, 517.3049926757812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 199, "type": "text", "text": "Answer ", "text_level": 1, "page_idx": 17, "bbox": [70, 526, 94, 532.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 200, "type": "text", "text": "The claim is false. ", "page_idx": 17, "bbox": [70, 534.06787109375, 150.01856994628906, 541.1253662109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 201, "type": "text", "text": "Caption : Table 4: The ablation study on the WoZ2.0 dataset with the joint goal accuracy on the test set. For  \\`\\` - Hier a chic al -Attn'', we remove the residual connections between the attention modules in the CMR decoders and all the attention memory access are based on the output from the LSTM. For  \\`\\` - MLP'', we further replace the MLP with a single linear layer with the non -linear activation.\n\n ", "page_idx": 17, "bbox": [70, 549.8335571289062, 504.9922180175781, 582.24462890625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 202, "type": "text", "text": "Table : ", "text_level": 1, "page_idx": 17, "bbox": [71, 589, 91, 597], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 203, "type": "text", "text": "|| Model | Joint Acc. ||\n\n || COMER | 88.64% ||\n\n || - Hierachical -Attn | 86.69% ||\n\n || - MLP | 83.24% || ", "page_idx": 17, "bbox": [70, 597.828857421875, 208.48463439941406, 628.79638671875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 204, "type": "text", "text": "Claim : [CONTINUE] The effectiveness of our hierarchical attention design is proved by an accuracy drop of 1.95% after removing residual connections and the hierarchical stack of our attention modules. ", "page_idx": 17, "bbox": [70, 637.5045166015625, 497, 652.7064208984375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 205, "type": "text", "text": "Question : Is the above claim true or false? Please directly give the answer. ", "page_idx": 17, "bbox": [70, 661.4144897460938, 382, 668.7369995117188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 206, "type": "text", "text": "Answer ", "text_level": 1, "page_idx": 17, "bbox": [70, 678, 93, 684], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 207, "type": "text", "text": "The claim is true. ", "page_idx": 17, "bbox": [70, 685.4998779296875, 145, 692.557373046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 208, "type": "text", "text": "Caption : Table 4: Scores for different training objectives on the linguistic probing tasks.\n\n ", "page_idx": 17, "bbox": [70, 701.2655029296875, 446.4122619628906, 708.5880126953125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 209, "type": "text", "text": "Table ", "text_level": 1, "page_idx": 17, "bbox": [70, 717, 90, 723.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 210, "type": "text", "text": "|| Method | Depth| BShift| SubjNum | Tense | CoordInv | Length | ObjNum | TopConst | SOMO | WC ||\n\n || CMOW -C | 36.2 | 66.0 | 81.1 | 78.7 | 61.7 | 83.9 | 79.1 | 73.6 | 50.4 | 66.8 ||\n\n || CMOW -R | 35.1 | 70.8 | 82.0 | 80.2 | 61.8 | 82.8 | 79.7 | 74.2 | 50.7 | 72.9 ||\n\n || CBOW -C | 34.3 | 50.5 | 79.8 | 79.9 | 53.0 | 75.9 | 79.8 | 72.9 | 48.6 | 89.0 ||\n\n || CBOW -R | 33.0 | 49.6 | 79.3 | 78.4 | 53.6 | 74.5 | 78.6 | 72.0 | 49.6 | 89.5 || ", "page_idx": 17, "bbox": [70, 725.3499145507812, 476, 764.2883911132812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 211, "type": "text", "text": "Claim : While CMOW -R and CMOW -C perform comparably on most probing tasks , CMOW -C yields 5 points higher scores on Word Content and Big ram Shift. ", "page_idx": 18, "bbox": [70, 75.82754516601562, 369, 91.02940368652344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 212, "type": "text", "text": "Question : Is the above claim true or false? Please directly give the answer. ", "page_idx": 18, "bbox": [70, 99.73855590820312, 387, 107.06104278564453], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 213, "type": "text", "text": "Answer ", "page_idx": 18, "bbox": [70, 115.67855834960938, 91.78739929199219, 123.00104522705078], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 214, "type": "text", "text": "The claim is false. (  more in-context examples here ", "page_idx": 18, "bbox": [70, 123.8228759765625, 188.77999877929688, 146.91102600097656], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 215, "type": "text", "text": "Caption :  <input caption> ", "page_idx": 18, "bbox": [70, 163.49954223632812, 155.94630432128906, 170.82203674316406], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 216, "type": "text", "text": "Table :  <input table> ", "page_idx": 18, "bbox": [70, 179.43954467773438, 141, 186.7620391845703], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 217, "type": "text", "text": "Claim :  <input claim> ", "page_idx": 18, "bbox": [70, 195.37954711914062, 141, 202.70204162597656], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 218, "type": "text", "text": "Question : Is the above claim true or false? Please directly give the answer. ", "page_idx": 18, "bbox": [70, 211.31954956054688, 387, 218.6420440673828], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 219, "type": "text", "text": "Answer : ", "page_idx": 18, "bbox": [70, 227.25955200195312, 95, 234.58204650878906], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 220, "type": "text", "text": "H.3 Chain-of-Thought Prompts ", "text_level": 1, "page_idx": 18, "bbox": [70, 255, 226, 268], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 221, "type": "text", "text": "Read the following table and then answer a question. ", "page_idx": 18, "bbox": [70, 279.02386474609375, 288.099853515625, 286.08135986328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 222, "type": "text", "text": "Caption : Table 5: Results of fine -tuned models on Balanced COPA. Easy: instances with superficial cues , Hard: instances without superficial cues.\n\n ", "page_idx": 18, "bbox": [70, 294.7895202636719, 497, 309.99139404296875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 223, "type": "text", "text": "Table ", "text_level": 1, "page_idx": 18, "bbox": [70, 318, 91, 325], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 224, "type": "text", "text": "|| Model | Training data | Overall | Easy | Hard ||\n\n || BERT -large -FT | B-COPA | 74.5 ( ± 0.7) | 74.7 ( ± 0.4) | 74.4 ( ± 0.9) ||\n\n || BERT -large -FT | B-COPA (50%) | 74.3 ( ± 2.2) | 76.8 ( ± 1.9) | 72.8 ( ± 3.1) ||\n\n || BERT -large -FT | COPA | 76.5 ( ± 2.7) | 83.9 ( ± 4.4) | 71.9 ( ± 2.5) ||\n\n || RoBERTa -large -FT | B-COPA | 89.0 ( ± 0.3) | 88.9 ( ± 2.1) | 89.0 ( ± 0.8) ||\n\n || RoBERTa -large -FT | B-COPA (50%) | 86.1 ( ± 2.2) | 87.4 ( ± 1.1) | 85.4 ( ± 2.9) ||\n\n || RoBERTa -large -FT | COPA | 87.7 ( 0.9) | 91.6 ( 1.1) | 85.3 ( 2.0) || ", "page_idx": 18, "bbox": [70, 326.84490966796875, 409, 381.7223815917969], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 225, "type": "text", "text": "Claim : RoBERTa -large outperforms BERT -large when fine -tuned on full and balanced COPA. ", "page_idx": 18, "bbox": [70, 390.4315490722656, 426.88525390625, 397.7540283203125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 226, "type": "text", "text": "Question : Is the above claim true or false? Let us think step by step. ", "page_idx": 18, "bbox": [70, 406.3715515136719, 357, 413.69403076171875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 227, "type": "text", "text": "Reasoning : ", "text_level": 1, "page_idx": 18, "bbox": [70, 422, 105, 429.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 228, "type": "text", "text": "We need to compare the performance of RoBERTa -large and BERT -large on full and balanced COPA. For full COPA , RoBERTa -large has an overall performance of 87.7 (table [6,2]), while BERT -large has an overall performance of 76.5 (table [3 ,2]). Therefore , RoBERTa -large outperforms BERT -large on full COPA. For balanced COPA , RoBERTa -large has an overall performance of 89.0 (table [4,2]), while BERT -large has an overall performance of 74.5 (table [1 ,2]). Therefore , RoBERTa -large outperforms BERT -large on balanced COPA. ", "page_idx": 18, "bbox": [70, 430.4559020996094, 459.66021728515625, 485.3343811035156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 229, "type": "text", "text": "Finally , since RoBERTa -large outperforms BERT -large on both full and balanced COPA , the Claim is true. ", "page_idx": 18, "bbox": [70, 486.24688720703125, 497, 493.30438232421875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 230, "type": "text", "text": "Answer : ", "text_level": 1, "page_idx": 18, "bbox": [70, 502, 95, 508.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 231, "type": "text", "text": "Therefore , the claim is true. ", "page_idx": 18, "bbox": [70, 510.1568603515625, 191.8605194091797, 517.21435546875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 232, "type": "text", "text": "Caption : Table 5: Results of fine -tuned models on Balanced COPA. Easy: instances with superficial cues , Hard: instances without superficial cues.\n\n ", "page_idx": 18, "bbox": [70, 525.9235229492188, 497, 541.1253662109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 233, "type": "text", "text": "Table : ", "text_level": 1, "page_idx": 18, "bbox": [70, 549, 91, 557], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 234, "type": "text", "text": "|| Model | Training data | Overall | Easy | Hard ||\n\n || BERT -large -FT | B-COPA | 74.5 ( ± 0.7) | 74.7 ( ± 0.4) | 74.4 ( ± 0.9) ||\n\n || BERT -large -FT | B-COPA (50%) | 74.3 ( ± 2.2) | 76.8 ( ± 1.9) | 72.8 ( ± 3.1) ||\n\n || BERT -large -FT | COPA | 76.5 ( ± 2.7) | 83.9 ( ± 4.4) | 71.9 ( ± 2.5) ||\n\n || RoBERTa -large -FT | B-COPA | 89.0 ( ± 0.3) | 88.9 ( ± 2.1) | 89.0 ( ± 0.8) ||\n\n || RoBERTa -large -FT | B-COPA (50%) | 86.1 ( ± 2.2) | 87.4 ( ± 1.1) | 85.4 ( ± 2.9) ||\n\n || RoBERTa -large -FT | COPA | 87.7 ( 0.9) | 91.6 ( 1.1) | 85.3 ( 2.0) || ", "page_idx": 18, "bbox": [70, 557.9779052734375, 409, 612.8563842773438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 235, "type": "text", "text": "Claim : The difference between RoBERTa -large -FT and BERT -large -FT is 3.8 points on B-COPA , which is significantly smaller than the difference in COPA. ", "page_idx": 18, "bbox": [70, 621.5645141601562, 439.43829345703125, 636.766357421875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 236, "type": "text", "text": "Question : Is the above claim true or false? Let us think step by step. ", "page_idx": 18, "bbox": [70, 645.4745483398438, 357, 652.7970581054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 237, "type": "text", "text": "Reasoning : ", "text_level": 1, "page_idx": 18, "bbox": [70, 661, 105, 667.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 238, "type": "text", "text": "To verify this claim , we need to compare the performance difference between RoBERTa -large -FT and BERT -large -FT on B-COPA and COPA. The difference between RoBERTa -large -FT and BERT -large -FT on B-COPA is   $89\\cdot\\theta\\;\\;-\\;\\;74\\;.5\\;\\;=\\;\\;1\\,4\\;.\\;5$  (table [4,2] - table [1 ,2]). The difference between RoBERTa -large -FT and BERT -large -FT on COPA is   $87\\cdot7\\;\\textrm{\\--}\\;76\\,.\\,5\\;\\textrm{=}\\;\\;1\\,1\\,.\\,2$  (table [6,2] - table [3 ,2]). The difference between RoBERTa -large -FT and BERT -large -FT on B-COPA is significantly larger than the difference on COPA. Therefore , the Claim is false. ", "page_idx": 18, "bbox": [70, 669.5598754882812, 455.3645324707031, 732.4074096679688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 239, "type": "text", "text": "Answer : ", "page_idx": 18, "bbox": [70, 741.1165161132812, 95, 748.4390258789062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 240, "type": "text", "text": "Therefore , the claim is false. ", "page_idx": 18, "bbox": [70, 749.2608642578125, 196.04478454589844, 756.318359375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 241, "type": "text", "text": "Caption : Table 4: The ablation study on the WoZ2.0 dataset with the joint goal accuracy on the test set. ", "page_idx": 18, "bbox": [70, 765.0265502929688, 504.9922180175781, 772.3490600585938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 242, "type": "text", "text": "For  \\`\\` - Hier a chic al -Attn'', we remove the residual connections between the attention modules in the CMR decoders and all the attention memory access are based on the output from the LSTM. ", "page_idx": 19, "bbox": [70, 75.89030456542969, 497, 91.02940368652344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 243, "type": "text", "text": "Table :\n\n ", "page_idx": 19, "bbox": [70, 99.73855590820312, 92, 107.06104278564453], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 244, "type": "text", "text": "|| Model | Joint Acc. ||\n\n || COMER | 88.64% ||\n\n || - Hierachical -Attn | 86.69% ||\n\n || - MLP | 83.24% || ", "page_idx": 19, "bbox": [70, 107.88287353515625, 208, 138.8503875732422], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 245, "type": "text", "text": "Claim : [CONTINUE] The effectiveness of our hierarchical attention design is proved by an accuracy drop of 1.95% after removing residual connections and the hierarchical stack of our attention modules. ", "page_idx": 19, "bbox": [70, 147.55856323242188, 493.6249694824219, 162.76036071777344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 246, "type": "text", "text": "Question : Is the above claim true or false? Let us think step by step. ", "page_idx": 19, "bbox": [70, 171.46957397460938, 357, 178.7920684814453], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 247, "type": "text", "text": "Reasoning ", "text_level": 1, "page_idx": 19, "bbox": [69, 187, 104, 195], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 248, "type": "text", "text": "To verify this claim , we need to compare the performance of COMER with and without hierarchical attention design. The performance of COMER with hierarchical attention design is 88.64% (table [2 ,2]). The performance of COMER without hierarchical attention design is 86.69% (table [3 ,2]). Therefore , the performance of COMER with hierarchical attention design is higher than the performance of COMER without hierarchical attention design by   $8\\,8\\;.\\;6\\,4\\;\\;-\\;\\;8\\,6\\;.\\;6\\,9\\;\\;=\\;\\;1\\;.\\;95\\;.$  Therefore , the Claim is true. ", "page_idx": 19, "bbox": [70, 195.55389404296875, 432, 250.43235778808594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 249, "type": "text", "text": "Answer : Therefore , the claim is true. ", "page_idx": 19, "bbox": [70, 259.1405334472656, 191, 274.3424072265625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 250, "type": "text", "text": "Caption : Table 4: Scores for different training objectives on the linguistic probing tasks.\n\n ", "page_idx": 19, "bbox": [70, 283.0505676269531, 446.4122619628906, 290.373046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 251, "type": "text", "text": "Table : ", "text_level": 1, "page_idx": 19, "bbox": [70, 299, 91, 306], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 252, "type": "text", "text": "|| Method | Depth| BShift| SubjNum | Tense | CoordInv | Length | ObjNum | TopConst | SOMO | WC ||\n\n || CMOW -C | 36.2 | 66.0 | 81.1 | 78.7 | 61.7 | 83.9 | 79.1 | 73.6 | 50.4 | 66.8 ||\n\n || CMOW -R | 35.1 | 70.8 | 82.0 | 80.2 | 61.8 | 82.8 | 79.7 | 74.2 | 50.7 | 72.9 ||\n\n || CBOW -C | 34.3 | 50.5 | 79.8 | 79.9 | 53.0 | 75.9 | 79.8 | 72.9 | 48.6 | 89.0 ||\n\n || CBOW -R | 33.0 | 49.6 | 79.3 | 78.4 | 53.6 | 74.5 | 78.6 | 72.0 | 49.6 | 89.5 || ", "page_idx": 19, "bbox": [70, 307.1358642578125, 476, 346.0733947753906], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 253, "type": "text", "text": "Claim : While CMOW -R and CMOW -C perform comparably on most probing tasks , CMOW -C yields 5 points higher scores on Word Content and Big ram Shift. ", "page_idx": 19, "bbox": [70, 354.78155517578125, 368.30535888671875, 369.9833984375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 254, "type": "text", "text": "Question : Is the above claim true or false? Let us think step by step. ", "page_idx": 19, "bbox": [70, 378.6925354003906, 357, 386.0150146484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 255, "type": "text", "text": "Reasoning : ", "text_level": 1, "page_idx": 19, "bbox": [69, 394, 105, 401.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 256, "type": "text", "text": "To verify this claim , we need to compare the performance of CMOW -R and CMOW -C on Word Content and Big ram Shift. The performance of CMOW -R on Word Content is 72.9 (table [2 ,10]). The performance of CMOW -C on Word Content is 66.8 (table [1 ,10]). The performance of CMOW -R on Big ram Shift is 70.8 (table [2 ,2]). The performance of CMOW -C on Big ram Shift is 66.0 (table [1 ,2]). Therefore , the performance of CMOW -C is higher than the performance of CMOW -R on Word Content by   $\\begin{array}{l l l l l l}{{66\\;.\\;8}}&{{\\;-\\;}}&{{72\\;.\\;9}}&{{=}}&{{-\\,6\\;.\\;1}}\\end{array}$  . The performance of CMOW -C is lower than the performance of CMOW -R on Big ram Shift by   $\\begin{array}{r c l}{66\\;.\\;\\emptyset}&{{}{\\mathrm{~-~}}}&{7\\emptyset\\;.\\;8}&{{}{\\mathrm{~=~}}}&{{\\mathrm{~-~}}4\\;.\\;8}\\end{array}$  . Therefore , the Claim is false. ", "page_idx": 19, "bbox": [70, 402.7768859863281, 346.68463134765625, 489.535400390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 257, "type": "text", "text": "Answer ", "text_level": 1, "page_idx": 19, "bbox": [70, 499, 94, 505], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 258, "type": "text", "text": "Therefore , the claim is false. ", "page_idx": 19, "bbox": [70, 506.387939453125, 196, 513.4454345703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 259, "type": "text", "text": "(  more in-context examples here ) ", "page_idx": 19, "bbox": [70, 522.1544799804688, 208, 529.4769897460938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 260, "type": "text", "text": "Table :  <input table> ", "page_idx": 19, "bbox": [70, 562.0045166015625, 141, 569.3270263671875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 261, "type": "text", "text": "Claim :  <input claim> ", "page_idx": 19, "bbox": [70, 577.9445190429688, 141, 585.2670288085938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 262, "type": "text", "text": "Question : Is the above claim true or false? Let us think step by step. ", "page_idx": 19, "bbox": [70, 593.885498046875, 357, 601.2080078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 263, "type": "text", "text": "Reasoning ", "page_idx": 19, "bbox": [70, 609.8255004882812, 102.24810028076172, 617.1480102539062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 264, "type": "text", "text": "Answer ", "page_idx": 19, "bbox": [70, 625.7655029296875, 92, 633.0880126953125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 265, "type": "text", "text": "H.4 Program-of-Thoughts Prompts ", "text_level": 1, "page_idx": 19, "bbox": [70, 653, 243, 666], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 266, "type": "text", "text": "Read the following table and then write Python code to answer a question: (please call the function equal(a, b) to check whether a and b are equal) ", "page_idx": 19, "bbox": [70, 677.5299072265625, 375, 692.557373046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 267, "type": "text", "text": "Caption : Table 4: The ablation study on the WoZ2.0 dataset with the joint goal accuracy on the test set. For  \\`\\` - Hier a chic al -Attn'', we remove the residual connections between the attention modules in the CMR decoders and all the attention memory access are based on the output from the LSTM. For  \\`\\` - MLP'', we further replace the MLP with a single linear layer with the non -linear activation.\n\n ", "page_idx": 19, "bbox": [70, 701.2655029296875, 504.9922180175781, 733.6766357421875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 268, "type": "text", "text": "Table ", "text_level": 1, "page_idx": 19, "bbox": [70, 741, 90, 748], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 269, "type": "text", "text": "|| Model | Joint Acc. ||\n\n || COMER | 88.64% ||\n\n || - Hierachical -Attn | 86.69% || ", "page_idx": 19, "bbox": [70, 749.2608642578125, 208, 772.2584228515625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 270, "type": "text", "text": "|| - MLP | 83.24% || ", "page_idx": 20, "bbox": [70, 76.00189208984375, 155, 83.05937194824219], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 271, "type": "text", "text": "Claim : [CONTINUE] The effectiveness of our hierarchical attention design is proved by an accuracy drop of   $1\\,.\\,95\\%$   after removing residual connections and the hierarchical stack of our attention modules. ", "page_idx": 20, "bbox": [70, 91.76852416992188, 422.5827941894531, 114.94035339355469], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 272, "type": "text", "text": "Question : Based on the information in the table , is the above claim true or false? ", "page_idx": 20, "bbox": [70, 123.64852905273438, 408, 130.9710235595703], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 273, "type": "text", "text": "# Python Code , return ans COMER_acc  $=\\phantom{-}88.64$  COMER acc no residual  $=\\phantom{-}86.69$  accuracy drop  $=$   COMER_acc - COMER acc no residual ans  $=$   equal(accuracy drop , 1.95) ", "page_idx": 20, "bbox": [70, 139.76287841796875, 275.232421875, 178.70140075683594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 274, "type": "text", "text": "Read the following table and then write Python code to answer a question: (please call the function equal(a, b) to check whether a and b are equal) ", "page_idx": 20, "bbox": [70, 187.58392333984375, 375, 202.6113739013672], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 275, "type": "text", "text": "Caption : Table 3: Ablation study of capsule net and word -level attention on Wikidata dataset. ", "page_idx": 20, "bbox": [70, 211.31954956054688, 454.7809753417969, 218.6420440673828], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 276, "type": "text", "text": "Table :\n\n ", "page_idx": 20, "bbox": [70, 227.25955200195312, 92.13590240478516, 234.58204650878906], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 277, "type": "text", "text": "|| Recall | 0.1 | 0.2 | 0.3 | AUC ||\n\n || -Word -ATT | 0.648 | 0.515 | 0.395 | 0.389 ||\n\n || -Capsule | 0.635 | 0.507 | 0.413 | 0.386 ||\n\n || Our Model | 0.650 | 0.519 | 0.422 | 0.405 || ", "page_idx": 20, "bbox": [70, 235.4049072265625, 267, 266.37237548828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 278, "type": "text", "text": "Claim : According to the table , the drop of precision demonstrates that the word -level attention is quite useful. ", "page_idx": 20, "bbox": [70, 275.0805358886719, 338.71563720703125, 290.28240966796875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 279, "type": "text", "text": "Question : Based on the information in the table , is the above claim true or false? ", "page_idx": 20, "bbox": [70, 298.9905700683594, 408, 306.31304931640625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 280, "type": "text", "text": "# Python Code , return ans our model recalls  $=$  [0.650 , 0.519, 0.422, 0.405]without word at t recalls  $=$   [0.648 , 0.515, 0.395 , 0.389] ans  $=$   True for i in range (4): if our model recalls[i]   $<$   without word at t recalls[i]: ans   $=$   False break ", "page_idx": 20, "bbox": [70, 315.10589599609375, 313.0915222167969, 377.9533996582031], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 281, "type": "text", "text": "Read the following table and then write Python code to answer a question: (please call the function equal(a, b) to check whether a and b are equal) ", "page_idx": 20, "bbox": [70, 386.8368835449219, 375, 401.8643798828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 282, "type": "text", "text": "Caption : Table 4: Scores for different training objectives on the linguistic probing tasks.\n\n ", "page_idx": 20, "bbox": [70, 410.5725402832031, 446.4122619628906, 417.89501953125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 283, "type": "text", "text": "Table ", "text_level": 1, "page_idx": 20, "bbox": [71, 426, 90, 433], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 284, "type": "text", "text": "|| Method | Depth| BShift| SubjNum | Tense | CoordInv | Length | ObjNum | TopConst | SOMO | WC ||\n\n || CMOW -C | 36.2 | 66.0 | 81.1 | 78.7 | 61.7 | 83.9 | 79.1 | 73.6 | 50.4 | 66.8 ||\n\n || CMOW -R | 35.1 | 70.8 | 82.0 | 80.2 | 61.8 | 82.8 | 79.7 | 74.2 | 50.7 | 72.9 ||\n\n || CBOW -C | 34.3 | 50.5 | 79.8 | 79.9 | 53.0 | 75.9 | 79.8 | 72.9 | 48.6 | 89.0 ||\n\n || CBOW -R | 33.0 | 49.6 | 79.3 | 78.4 | 53.6 | 74.5 | 78.6 | 72.0 | 49.6 | 89.5 || ", "page_idx": 20, "bbox": [70, 434.6568908691406, 476.2858581542969, 473.59539794921875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 285, "type": "text", "text": "Claim : While CMOW -R and CMOW -C perform comparably on most probing tasks , CMOW -C yields 5 points higher scores on Word Content and Big ram Shift. ", "page_idx": 20, "bbox": [70, 482.3035583496094, 368.30535888671875, 497.5054016113281], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 286, "type": "text", "text": "Question : Based on the information in the table , is the above claim true or false? ", "page_idx": 20, "bbox": [70, 506.2135925292969, 408, 513.5360717773438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 287, "type": "text", "text": "# Python Code , return ans C MOW C score on WC = 66.8 C MOW C score on B Shift  $=\\phantom{-}66.0$  C MOW R score on WC  $=\\quad72\\cdot9$  C MOW R score on B Shift   $=\\quad7\\,\\varnothing\\;.\\;8$  ans  $=$   equal(C MOW C score on WC - C MOW R score on WC , 5) ", "page_idx": 20, "bbox": [70, 522.328857421875, 300, 569.2363891601562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 288, "type": "text", "text": "( · · ·  more in-context examples here  · · · ) ", "page_idx": 20, "bbox": [70, 585.9144897460938, 205, 598.5440673828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 289, "type": "text", "text": "Read the following table and then write Python code to answer a question: (please call the function equal(a, b) to check whether a and b are equal) ", "page_idx": 20, "bbox": [70, 609.9998779296875, 375, 625.0274047851562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 290, "type": "text", "text": "Caption :  <input caption> ", "page_idx": 20, "bbox": [70, 633.7355346679688, 155, 641.0580444335938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 291, "type": "text", "text": "Table :  <input table> ", "page_idx": 20, "bbox": [70, 649.675537109375, 142, 656.998046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 292, "type": "text", "text": "Claim :  <input claim> ", "page_idx": 20, "bbox": [70, 665.6165161132812, 142, 672.9390258789062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 293, "type": "text", "text": "Question : Based on the information in the table , is the above claim true or false? ", "page_idx": 20, "bbox": [70, 681.5565185546875, 408, 688.8790283203125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 294, "type": "text", "text": "# Python Code , return ans ", "page_idx": 20, "bbox": [70, 697.6708984375, 174, 704.7283935546875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 295, "type": "text", "text": "Claim:  For example, the single DCGCN model gains  5.9  more BLEU points than the single  models of Seq2SeqB on AMR17. ", "page_idx": 21, "bbox": [124, 277.53369140625, 458.51202392578125, 300.251220703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 296, "type": "text", "text": "B. The approximation word is wrong. ", "text_level": 1, "page_idx": 21, "bbox": [131, 339, 272, 349], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 297, "type": "text", "text": "Claim:  However, when we set the number to 18,   $\\mathsf{G C N+R C+L A}$   achieves a BLEU score of 19.4,  which is  significantly  worse than the BLEU score obtained by DCGCN2 (23.3). ", "page_idx": 21, "bbox": [124, 501.71368408203125, 469.803955078125, 524.2479858398438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 298, "type": "text", "text": "C. The claim is partially right. ", "text_level": 1, "page_idx": 21, "bbox": [129, 562, 239, 572], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 299, "type": "table", "page_idx": 21, "img_path": "layout_images/2305.13186v3_14.jpg", "bbox": [127, 597, 471, 651], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Method\n\nCMOW-C\nCMOW-R\n\nCBOW-C\nCBOW-R\n\nDepth BShift SubjNum\n\n36.2\n35.1\n\n34.3\n33.0\n\n66.0\n70.8\n\n50.5\n49.6\n\n81.1\n82.0\n\n79.8\n79.3\n\nTense\n78.7\n80.2\n\n79.9\n78.4\n\nCoordIny\n\n61.7\n618\n\n53.0\n53.6\n\nLength ObjNum TopConst\n\n83.9\n82.8\n\n75.9\n745\n\n73.6\n74.2\n\n729\n72.0\n\n", "vlm_text": "The table presents results for four methods (CMOW-C, CMOW-R, CBOW-C, CBOW-R) evaluated across several metrics. Here's a breakdown:\n\n### Methods\n- CMOW-C\n- CMOW-R\n- CBOW-C\n- CBOW-R\n\n### Metrics\n1. **Depth**\n   - CMOW-C: 36.2\n   - CMOW-R: 35.1\n   - CBOW-C: 34.3\n   - CBOW-R: 33.0\n\n2. **BShift**\n   - CMOW-C: 66.0\n   - CMOW-R: 70.8\n   - CBOW-C: 50.5\n   - CBOW-R: 49.6\n\n3. **SubjNum**\n   - CMOW-C: 81.1\n   - CMOW-R: 82.0\n   - CBOW-C: 79.8\n   - CBOW-R: 79.3\n\n4. **Tense**\n   - CMOW-C: 78.7\n   - CMOW-R: 80.2\n   - CBOW-C: 79.9\n   - CBOW-R: 78.4\n\n5. **CoordInv**\n   - CMOW-C: 61.7\n   - CMOW-R: 61.8\n   - CBOW-C: 53.0\n   - CBOW-R: 53.6\n\n6. **Length**\n   - CMOW-C: 83.9\n   - CMOW-R: 82.8\n   - CBOW-C: 75.9\n   - CBOW-R: 74.5\n\n7. **ObjNum**\n   - CMOW-C: 79.1\n   - CMOW-R: 79.7\n   - CBOW-C: 79.8\n   - CBOW-R: 78.6\n\n8. **TopConst**\n   - CMOW-C: 73.6\n   - CMOW-R: 74.2\n   - CBOW-C: 72.9\n   - CBOW-R: 72.0\n\n9. **SOMO**\n   - CMOW-C: 50.4\n   - CMOW-R: 50.7\n   - CBOW-C: 48.6\n   - CBOW-R: 49.6\n\n10. **WC**\n    - CMOW-C: 66.8\n    - CMOW-R: 72.9\n    - CBOW-C: 89.0\n    - CBOW-R: 89.5\n\nThe highest value for each metric is bolded in the original table."}
{"layout": 300, "type": "text", "text": "Claim:  While CMOW-R and CMOW-C perform comparably on most probing tasks, CMOW-C  yields 5 points lower scores on Word Content and Big ram Shift. BShift column doesn't satisfy the claim. ", "page_idx": 21, "bbox": [124, 660.8740844726562, 462.96075439453125, 694.2145385742188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 301, "type": "text", "text": "Figure 9: The refuted claims cases  $A$   to    $C$  . Case  $A$   represents the calculation result is wrong. Case    $B$   represents the approximation word is wrong. Case  $C$   represents the claim is partially right. ", "page_idx": 21, "bbox": [70, 716.256591796875, 524.4109497070312, 740.217529296875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 302, "type": "image", "page_idx": 22, "img_path": "layout_images/2305.13186v3_15.jpg", "bbox": [119, 202, 474, 601], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "D. The values in the claim do not match.\n\nModel T © Bc\nSeq2SeqB (Beck ctal.. 2018) S 284M 21.7 49.1\nGGNN2Seq (Beck et al., 2018) § 283M 23.3 50.4\nSeq2SeqB (Beck et al., 2018) E 142M 266 52.5\nGGNN2Seq (Beck et al., 2018) E_ 141M 27.5 53.5\n\n3 19.1M 27.9 573\nDEGHN oun) E 92.5M 30.4 59.6\n\nTable 2: Main results on AMR17. GCNSEQ (Damonte\nand Cohen, 2019) achieves 24.5 BLEU points. #P\nshows the model size in terms of parameters; “S” and\n“E” denote single and ensemble models, respectively.\n\nClaim: Our single model achieves 27.6 BLEU points, which is the new state-of-the-art\nresult for single models.\n\nE. The operation type is wrong.\n\nGCN Bc _GCN BC\n\n+RC (2) 16.8 48.1 +RC+LA (2) 18.3 47.9\n+RC (4) 18.4 49.6 +RC+LA (4) 18.0 51.1\n+RC (6) 19.9 49.7 +RC+LA (6) 21.3 50.8\n+RC (9) 21.1 50.5 +RC+LA (9) 22.0 52.6\n\n+RC (10) 20.7 50.7 +RC+LA (10) 21.2 52.9\nDCGCNI1 (9) 22.9 53.0 DCGCN3 (27) 24.8 54.7\nDCGCN2 (18) 24.2 54.4 DCGCN4 (36) 25.5 55.4\n\nTable 6: Comparisons with baselines. +RC denotes\nGCNs with residual connections. +RC+LA refers to\nGCNs with both residual connections and layer aggre-\ngations. DCGCNi represents our model with i blocks,\ncontaining i x (m + m) layers. The number of layers\nfor each model is shown in parenthesis.\n\nClaim: GCN+RC+LA (9) is better than DCGCN1.\n", "vlm_text": "The image contains two sections labeled D and E, each highlighting discrepancies in claims:\n\n**D. The values in the claim do not match.**\n- A table lists various model names, parameters (#P), and BLEU scores (B):\n  - Seq2SeqB (single/ensemble)\n  - GCN2Seq (single/ensemble)\n  - DCGCN (ours) with a BLEU score of 27.9 for the single model.\n- The claim states that their single model achieves 27.6 BLEU points, suggesting a mismatch with the table value (27.9).\n\n**E. The operation type is wrong.**\n- A table lists various GCN models with BLEU scores (B) and additional operations like +RC and +RC+LA.\n- The claim suggests GCN+RC+LA (9) is better than DCGCN1.\n- The table shows GCN+RC+LA (9) with a BLEU score of 21.2, which is lower than DCGCN1’s 22.9.\n\nThese sections critique inaccuracies or misrepresentations in the claims based on the presented data."}
{"layout": 303, "type": "text", "text": "Figure 10: The refuted claims cases  $D$   and  $E$  . Case    $D$   represents the values in the claim do not match. Case    $E$  represents the operation type is wrong. ", "page_idx": 22, "bbox": [70, 622.1795654296875, 525, 646.1405029296875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 304, "type": "text", "text": "Error case 1  (43.9%)  : Gold Label:  Supported   Prediction Label:   NEI ", "page_idx": 23, "bbox": [117, 97.87594604492188, 389.7257385253906, 110.12057495117188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 305, "type": "text", "text": "", "page_idx": 23, "bbox": [115, 113, 475, 121.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 306, "type": "table", "page_idx": 23, "img_path": "layout_images/2305.13186v3_16.jpg", "bbox": [145, 122.25, 449, 267], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "SLQS\n\nDF\n\nDocSub\n\n0.5257\n0.5300\n\n0.6109\n0.6117\n\n0.5984\n0.6159\n\n0.7311\n0.6533\n\n0.5795\n0.5484\n\n0.6727\n0.6877\n\n0.5184\n0.5515\n\n0.0053\n0.4706\n\n0.5513\n0.5390\n\n0.6403\n0.6475\n\n0.5555\n0.5819\n\n0.0105\n0.5471\n", "vlm_text": "The table displays precision, recall, and F1 scores for different methods applied to two corpora (\"Europarl\" and \"Ted Talks\") in two languages (EN, PT). The methods listed are Patt, DSim, SLQS, TF, DF, DocSub, and HClust. Each method's performance is quantified with numerical values. Key observations include:\n\n- For precision (\\( \\mathcal{P} \\)), the DocSub method has the highest score for the \"Europarl\" corpus in PT (0.7311).\n- For recall (\\( \\mathcal{R} \\)), the TF method exhibits the highest score for the \"Ted Talks\" corpus in PT (0.6877).\n- For F1 scores (\\( \\mathcal{F} \\)), again, the highest value appears for the TF method for the \"Ted Talks\" corpus in PT (0.6403). \n\nValues are formatted for precision, recall, and F1 respectively, with bold numbers indicating the highest in each category within the same language-corpus pair."}
{"layout": 307, "type": "text", "text": "Claim : Analyzing Table 3, we can observe that all values of precision using the Portuguese  corpora have higher scores when compared with the English corpora. ", "page_idx": 23, "bbox": [117, 275.8223571777344, 483.70953369140625, 300.7057800292969], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 308, "type": "text", "text": "Error case 2  (38.7%):  Gold Label:  Refuted  Prediction Label:  NEI ", "text_level": 1, "page_idx": 23, "bbox": [121, 332, 385, 343], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 309, "type": "text", "text": "", "page_idx": 23, "bbox": [119, 348, 481, 357.75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 310, "type": "table", "page_idx": 23, "img_path": "layout_images/2305.13186v3_17.jpg", "bbox": [150, 358.25, 450, 501], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Corpus\n\nDSim SLQS DF —_ DocSub\n\nEuroparl\nTed Talks\n\n0.5163\n0.5387\n\n0.3330\n0.2907\n\n0.5257\n0.5300\n\n0.6109\n0.6117\n\n0.5984\n0.6159\n\n0.7311\n0.6533\n\nEuroparl\nTed Talks\n\n0.0111\n0.0004\n\n0.3554\n0.3142\n\n0.5795\n0.5484\n\n0.6727\n0.6877\n\n0.5184\n0.5515\n\n0.0053\n0.4706\n\nEuroparl\nTed Talks\n\n0.0217\n0.0008\n\n0.3438\n0.3020\n\n0.5513\n0.5390\n\n0.6403\n0.6475\n\n0.5555\n0.5819\n\n0.0105\n0.5471\n", "vlm_text": "The table shows scores for various metrics across different languages (EN for English, PT for Portuguese) and corpora (Europarl, Ted Talks). \n\n- The table is divided into three sections labeled \\(\\mathcal{P}\\), \\(\\mathcal{R}\\), and \\(\\mathcal{F}\\).\n- Each section contains metrics: Patt, DSim, SLQS, TF, DF, DocSub, and HClust.\n- Bold numbers indicate highlighted or significant scores."}
{"layout": 311, "type": "text", "text": "Claim : Analyzing Table 3, we can observe that all values of precision using the English  corpora have higher scores when compared with the Portuguese corpora. ", "page_idx": 23, "bbox": [122, 508.9382019042969, 470.78741455078125, 533.821533203125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 312, "type": "text", "text": "Error case 3  (7.6%) :  Gold Label:  Refuted  Prediction Label:   Supported ", "text_level": 1, "page_idx": 23, "bbox": [115, 565, 406, 577], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 313, "type": "table", "page_idx": 23, "img_path": "layout_images/2305.13186v3_18.jpg", "bbox": [198, 582, 359, 701], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Model BC\n\nDCGCN4 25.5 55.4\nEncoder Modules\n\n-Linear Combination 23.7 53.2\n-Global Node 24.2 54.6\n-Direction Aggregation 24.6 54.6\n-Graph Attention 24.9 54.7\n\n-Global Node&Linear Combination 22.9 52.4\nDecoder Modules\n-Coverage Mechanism 23.8 53.0\n\nable 9: Ablation study for modules used in the grap!\nncoder and the LSTM decoder\n", "vlm_text": "The table presents results from an ablation study for modules in a graph encoder and an LSTM decoder. It consists of configurations alongside their performance scores in columns B and C.\n\n- The overall model \"DCGCN4\" scores 25.5 in column B and 55.4 in column C.\n- Encoder Modules and their scores:\n  - Linear Combination: 23.7 (B), 53.2 (C)\n  - Global Node: 24.2 (B), 54.6 (C)\n  - Direction Aggregation: 24.6 (B), 54.6 (C)\n  - Graph Attention: 24.9 (B), 54.7 (C)\n  - Global Node & Linear Combination: 22.9 (B), 52.4 (C)\n- Decoder Modules and their scores:\n  - Coverage Mechanism: 23.8 (B), 53.0 (C)\n\nThe table is labeled as Table 9."}
{"layout": 314, "type": "text", "text": "Claim:  With the coverage mechanism, the result drops by 1.7/2.4 points for B/C scores. ", "page_idx": 23, "bbox": [113.28987121582031, 705.943115234375, 467.2445068359375, 718.187744140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 315, "type": "text", "text": "Error case 4  (4.6%) :  Gold Label:  NEI   Prediction Label:   Supported ", "page_idx": 24, "bbox": [119, 113.42212677001953, 382.1263427734375, 125.43970489501953], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 316, "type": "table", "page_idx": 24, "img_path": "layout_images/2305.13186v3_19.jpg", "bbox": [207, 138, 390, 217], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "in-domain out-of-domain\n\nSQuAD QA-SRL\n\nEM Fl | EM Fl\n\nMQAN 31.76 75.37 | 10.99 50.10\n+coverage 32.67 76.83 | 10.63 50.89\nBIDAF (ELMO) | 70.43 79.76 | 28.35 49.98\n+coverage 71.07 80.15 | 30.58 52.43\n\n", "vlm_text": "The table presents evaluation results for two models, MQAN and BIDAF (ELMO), on in-domain (SQuAD) and out-of-domain (QA-SRL) datasets. It shows Exact Match (EM) and F1 scores for both models:\n\n- **MQAN (SQuAD):**\n  - EM: 31.76\n  - F1: 75.37\n\n- **MQAN + coverage (SQuAD):**\n  - EM: 32.67\n  - F1: 76.83\n\n- **BIDAF (ELMO) (SQuAD):**\n  - EM: 70.43\n  - F1: 79.76\n\n- **BIDAF (ELMO) + coverage (SQuAD):**\n  - EM: 71.07\n  - F1: 80.15\n\n- **MQAN (QA-SRL):**\n  - EM: 10.99\n  - F1: 50.10\n\n- **MQAN + coverage (QA-SRL):**\n  - EM: 10.63\n  - F1: 50.89\n\n- **BIDAF (ELMO) (QA-SRL):**\n  - EM: 28.35\n  - F1: 49.98\n\n- **BIDAF (ELMO) + coverage (QA-SRL):**\n  - EM: 30.58\n  - F1: 52.43\n\nThe \"+coverage\" denotes an enhancement applied to these models, resulting in generally improved scores."}
{"layout": 317, "type": "text", "text": "", "page_idx": 24, "bbox": [121, 222, 476, 242], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 318, "type": "text", "text": "Claim:  This is particularly true for the BIDAF model. ", "page_idx": 24, "bbox": [119, 248.0989990234375, 324.29376220703125, 260.1165771484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 319, "type": "text", "text": "Error case 5  (2.8%) :  Gold Label:  NEI  Prediction Label:   Refuted ", "text_level": 1, "page_idx": 24, "bbox": [119, 296, 375, 309], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 320, "type": "text", "text": "", "page_idx": 24, "bbox": [172, 315, 414, 344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 321, "type": "table", "page_idx": 24, "img_path": "layout_images/2305.13186v3_20.jpg", "bbox": [180, 352, 402, 383], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "GloVe Imparted\n\nParticipants 1 to 5 = SOV88/82/78/97 =. 2212/1 70/207/229/242\nMean/Std 85/6.9 2\n\n", "vlm_text": "The table presents data under two columns: \"GloVe\" and \"Imparted.\" \n\nFor \"Participants 1 to 5\":\n- GloVe: 80, 88, 82, 78, 97\n- Imparted: 212, 170, 207, 229, 242\n\nFor \"Mean/Std\" (Mean and Standard Deviation):\n- GloVe: Mean = 85, Std = 6.9\n- Imparted: Mean = 212, Std = 24.4"}
{"layout": 322, "type": "text", "text": "Claim:  These results show that the questionnaire takers had an average accuracy of   $98.2\\%$   in answering word intrusion questions for words associated with meanings  imparted by standard word embeddings ", "page_idx": 24, "bbox": [119, 401.087158203125, 457, 436.92919921875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 323, "type": "text", "text": "Error case 6  (2.4%) :  Gold Label:  Supported  Prediction Label:   Refuted ", "page_idx": 24, "bbox": [119, 478.46728515625, 406.3229064941406, 490.48486328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 324, "type": "table", "page_idx": 24, "img_path": "layout_images/2305.13186v3_21.jpg", "bbox": [198, 502, 381, 650], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "GCN Bc GCN BC\n\n+RC (2) 16.8 48.1 +RC+LA(2) 18.3 47.9\n+RC (4) 18.4 49.6 +RC+LA (4) 18.0 51.1\n+RC (6) 19.9 49.7 +RC+LA (6) 21.3 50.8\n\n+RC (9) 21.1 50.5 +RC+LA (9) 22.0 52.6\n+RC(10) 20.7 50.7 +RC+LA (10) 21.2 52.9\nDCGCNI (9) 22.9 53.0 DCGCNS (27) 24.8 54.7\nDCGCN2 (18) 24.2 54.4 DCGCN4 (36) 25.5 55.4\n\nTable 6: Comparisons with baselines. +RC denotes\nGCNs with residual connections. +RC+LA refers to\nGCNs with both residual connections and layer aggre-\ngations. DCGCNi represents our model with i blocks,\ncontaining i x (nm + m) layers. The number of layers\nfor each model is shown in parenthesis.\n", "vlm_text": "The table presents a comparison of different GCN (Graph Convolutional Network) models with baseline results. Here's a breakdown of what's in the table:\n\n- **Models Compared:**\n  - **+RC:** GCNs with residual connections.\n  - **+RC+LA:** GCNs with both residual connections and layer aggregations.\n  - **DCGCNi:** A model with \\(i\\) blocks, each containing \\(i \\times (n + m)\\) layers.\n\n- **Columns:**\n  - The table has four main columns: two sections titled \"GCN\" with their sub-columns labeled \"B\" and \"C\".\n\n- **Rows:**\n  - Different configurations of GCN models are compared with the number of layers indicated in parentheses, such as (2), (4), (6), (9), (10), (9), (27), (18), and (36).\n\n- **Values:**\n  - Each model configuration has two values associated with it in columns B and C, representing some performance metrics.\n\n- **Best Performance:**\n  - The model configuration with +RC (9) shows superior performance in B (21.1) and C (50.5) without layer aggregation.\n  - The DCGCN4 (36) configuration shows the best performance overall with B (25.5) and C (55.4).\n\nThe table also includes a footnote that explains the meanings of various terms and specifies that the number of layers for each model is shown in parentheses."}
{"layout": 325, "type": "text", "text": "Claim:  For example, GCN+RC+LA (10) achieves a BLEU score of 21.2, which is worse  than  $\\mathsf{G C N}\\!+\\!\\mathsf{R C}\\!+\\!\\mathsf{L A}$   (9). ", "page_idx": 24, "bbox": [119, 665.5185546875, 457, 689.74365234375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 326, "type": "text", "text": "Error case 1 ", "text_level": 1, "page_idx": 25, "bbox": [98, 77, 147, 87], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 327, "type": "table", "page_idx": 25, "img_path": "layout_images/2305.13186v3_22.jpg", "bbox": [96, 104, 485, 209], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "| WinoCoref_ L “AntePre 68.37\nTable 7: Performance results on Winograd and WinoCoref datasets. ‘All our three ‘systems are trained on\n\nWinoCoref, and we evaluate the predictions on both datasets. Our systems improve over the baselines by\n\nover than 20% on Winograd and over 15% on WinoCoref.\nClaim: The best performing system is KnowComb. It improves by over 20% over a state-of-art\n\ngeneral coreference system on Winograd. On the WinoCoref dataset, it improves by 15%.\n\ngold: supports, prediction: refutes,\nprograms: [\"winograd_baseline = 73.05\\n winograd_knowcomb = 76.41\\n winocoref_baseline\n\n= 88.48\\nwinocoref_knowcomb = 89.32\\nans = (winograd_knowcomb - winograd_baseline >\n20) and (winocoref_knowcomb - winocoref_baseline > 15)\n", "vlm_text": "The table presents performance results on the Winograd and WinoCoref datasets. It shows Precision, AntePre, and overall scores for three systems, with the highest results highlighted:\n\n- **Winograd:**\n  - Baseline: 73.05\n  - KnowComb: 76.41\n\n- **WinoCoref:**\n  - Baseline: 88.48\n  - KnowComb: 89.32\n\nBoth systems show improvements with KnowComb, but not by the amounts claimed in the accompanying caption text."}
{"layout": 328, "type": "text", "text": "Error case 2 ", "text_level": 1, "page_idx": 25, "bbox": [99, 223, 147, 234], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 329, "type": "text", "text": " $(\\%)$   $^+$  gold : refutes, ", "page_idx": 25, "bbox": [120, 244, 194, 258], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 330, "type": "text", "text": "", "page_idx": 25, "bbox": [300, 226.2264404296875, 356.3853759765625, 236.5764617919922], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 331, "type": "text", "text": "programs : [ ", "page_idx": 25, "bbox": [300, 248.646240234375, 351.0775146484375, 258.99627685546875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 332, "type": "table", "page_idx": 25, "img_path": "layout_images/2305.13186v3_23.jpg", "table_caption": "Claim :  The AAS method with weights   ${\\mathsf{w A C}}{=}1$   and wAD  $!\\!=\\!!105$   shows the lowest WER and DCE ", "bbox": [99, 264, 479, 362], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Method WER (%) | DCE\nNo enhancement 17.3 0.828\nWiener filter 19.5 0.722\nMinimizing DCE 15.8 0.269\nFSEGAN 14.9 0.291\nAAS (wac = 1,wap = 0) 15.6 0.330\nAAS (wac = 1, wap = 10°) 14.4 0.303\nClean speech 5.7 0.0\n\n", "vlm_text": "This table presents the results of various speech enhancement methods, showing the Word Error Rate (WER) and the Distortion-Constrained Enhancement (DCE) values:\n\n- **No enhancement**: WER of 17.3%, DCE of 0.828.\n- **Wiener filter**: WER of 19.5%, DCE of 0.722.\n- **Minimizing DCE**: WER of 15.8%, DCE of **0.269**.\n- **FSEGAN**: WER of 14.9%, DCE of 0.291.\n- **AAS (\\(w_{AC} = 1, w_{AD} = 0\\))**: WER of 15.6%, DCE of 0.330.\n- **AAS (\\(w_{AC} = 1, w_{AD} = 10^5\\))**: WER of 14.4%, DCE of 0.303.\n- **Clean speech**: WER of 5.7%, DCE of 0.0. \n\nThe bold value indicates the lowest DCE for that row."}
{"layout": 333, "type": "table", "page_idx": 25, "img_path": "layout_images/2305.13186v3_24.jpg", "bbox": [101, 375, 495, 707], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Error case 3\n\nprograms : [\n\n\"G2S_GIN_BLEU_LDC2015E86 = 22.93\\n\nG2S_GAT_BLEU_LDC2015E86 = 23.42\\n\nG2S_GGNN_BLEU_LDC2015E86 = 24.32\\n\nG2S_GIN_METEOR_LDC2015E86 = 29.72\\n\nG2S_GAT_METEOR_LDC2015E86 = 29.87\\n\nG2S_GGNN_METEOR_LDC2015E86 = 30.53\\n\nG2S_GIN_BLEU_LDC2017T10 = 26.90\\n\nG2S_GAT_BLEU_LDC2017T10 = 26.72\\n\nG2S_GGNN_BLEU_LDC2017T10 = 27.87\\n\nG2S_GIN_METEOR_LDC2017T10 = 32.62\\n\nG2S_GAT_METEOR_LDC2017T10 = 32.52\\n\nG2S_GGNN_METEOR_LDC2017T10 = 33.21\\n\nans = (G2S_GAT_BLEU_LDC2015E86 >\nG2S_GIN_BLEU_LDC2015E86)\n\nand (G2S_GGNN_BLEU_LDC2015E86 >\nG2S_GAT_BLEU_LDC2015E86)\n\nand (G2S_GAT_METEOR_LDC2015E86 >\nG2S_GIN_METEOR_LDC2015E86)\n\nModel BLEU METEOR\nLDC2015E86\n\nKonstas et al. (2017) 22.00 -\n\nSong et al. (2018) 23.28 30.10\n\nCao et al. (2019) 23.50 -\n\nDamonte et al.(2019) 24.40 23.60\n\nGuo et al. (2019) 25.70 -\n\nS2s 22.55 +0.17 29.90 + 0.31\nG2S-GIN 22.93 + 0.20 29.72 + 0.09\nG2S-GAT 23.42 +0.16 29.87 +0.14\nG2S-GGNN 24.32 +0.16 30.53 + 0.30\n\nLDC2017T10\n\nBack et al. (2018) 23.30 -\n\nSong et al. (2018) 24.86 31.56\nDamonte et al.(2019) 24.54 24.07\n\nCao et al. (2019) 26.80 -\n\nGuo et al. (2019) 27.60 -\n\nS2s 22.73 £0.18 30.15 +0.14\nG2S-GIN 26.90 + 0.19 32.62 + 0.04\nG2S-GAT 26.72 + 0.20 32.52 + 0.02\nG2S-GGNN 27.87 + 0.15 33.21 +0.15\n\nTable 2: BLEU and METEOR scores on the test set of\n\nLDC2015E86 and LDC2017T 10 datasets.\n\ngold: supports, prediction: refutes\n\nand (G2S_GGNN_METEOR_LDC2015E86 >\nG2S_GAT_METEOR_LDC2015E86)\n\nand (G2S_GAT_BLEU_LDC2017T10 >\nG2S_GIN_BLEU_LDC2017T10)\n\nand (G2S_GGNN_BLEU_LDC2017T10 >\nG2S_GAT_BLEU_LDC2017T10)\n\nand (G2S_GAT_METEOR_LDC2017T10 >\nG2S_GIN_METEOR_LDC2017T10) and\n(G2S_GGNN_METEOR_LDC2017T10 > G\"\n\nclaim: This suggests that graph encoders based on gating mechanisms are very effective in\n\nteyt qeneratinn modele\n", "vlm_text": "The table contains BLEU and METEOR scores for different models evaluated on two datasets: LDC2015E86 and LDC2017T10.\n\n### LDC2015E86\n- **Konstas et al. (2017):** BLEU 22.00\n- **Song et al. (2018):** BLEU 23.28, METEOR 30.10\n- **Cao et al. (2019):** BLEU 23.50\n- **Damonte et al. (2019):** BLEU 24.40, METEOR 23.60\n- **Guo et al. (2019):** BLEU 25.70\n\n**Model Comparisons:**\n- **S2S:** BLEU 22.55 ± 0.17, METEOR 29.90 ± 0.31\n- **G2S-GIN:** BLEU 22.93 ± 0.09, METEOR 29.72 ± 0.09\n- **G2S-GAT:** BLEU 23.42 ± 0.16, METEOR 29.87 ± 0.10\n- **G2S-GGNN:** BLEU 24.32 ± 0.16, METEOR 30.53 ± 0.30\n\n### LDC2017T10\n- **Back et al. (2018):** BLEU 23.30\n- **Song et al. (2018):** BLEU 24.86, METEOR 31.56\n- **Damonte et al. (2019):** BLEU 24.54, METEOR 24.07\n- **Cao et al. (2019):** BLEU 26.80\n- **Guo et al. (2019):** BLEU 27.60\n\n**Model Comparisons:**\n- **S2S:** BLEU 22.73 ± 0.18, METEOR 30.15 ± 0.14\n- **G2S-GIN:** BLEU 26.90 ± 0.19, METEOR 32.62 ± 0.14\n- **G2S-GAT:** BLEU 26.72 ± 0.32, METEOR 32.52 ± 0.25\n- **G2S-GGNN:** BLEU 27.87 ± 0.15, METEOR 33.21 ± 0.15\n\n### Summary\nThe table suggests that graph encoders based on gating mechanisms (G2S-GGNN) are very effective in text generation models, achieving higher scores compared to other evaluated models. The results are given with their respective standard deviations."}
{"layout": 334, "type": "table", "page_idx": 26, "img_path": "layout_images/2305.13186v3_25.jpg", "bbox": [107, 156, 486, 447], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Error case 4\n\nROUGE-1 | ROUGE-2 Sentence-Level\n\nSystem R(%) P(%)  F(%) R(%) P(%)  F(%) R(%) P(%)  F(%)\n\nILP 24.5 41.1 29.3405 79 15.0 9.9+0.5 13.6 22.6 15.640.4\nSum-Basic 28.4 44.4 33.1405 8.5 15.6 10.4+0.4 14.7 22.9 16.7£0.5\nKL-Sum 39.5 34.6  35.540.5 13.0 12.7 12.3+0.5 15.2 21.1 16.340.5\nLexRank 42.1 39.5 38.7+0.5 14.7 15.3. 14.2+0.5 14.3 21.5  16,0+0.5\nMEAD 45.5 36.5 38.5+0.5 17.9 14.9 15.4+0.5 27.8 29.2 26.8+0.5\nSVM 19.0 48.8 24.7408 15 21.1 10.0+0.5 32.7 34.3 31.4404\nLogReg 26.9 34.5 28.740.6 6.4 99 7.3404 12.2 14.9  12.740.5\nLogReg” 28.0 34.8  29.4+0.6 6.9 10.4 7.8+0.4 12.1 14.5 12.5+0.5\nHAN 31.0 42.8  33.740.7 11.2 17.8 12.740.5 26.9 34.1 32.440.5\nHAN+pretrainT 32.2 42.4 34.4+0.7 LES: 17.5 12.9+0.5 29.6 35.8  32.2+0.5\nHAN+pretrainU 32.1 42.1 33.840.7 116 17.6 _12.9+0.5 30.1 35.6 _32.340.5\nHAN” 38.1 40.5  37.840.5 14.0 17.1 14.740.5 32.5 34.4 33.4+0.5\nHAN+pretrainT” 37.9 40.4 37.6405 13.5 16.8 14.4+0.5 325: 344 33.4+40.5\nHAN+pretrainU” 37.9 40.4  37.640.5 13.6 16.9 14.4+0.5 33.9 33.8 33.840.5\n\nTable 1: Results of thread summarization. ‘HAN’ models are our proposed approaches adapted from the hierarchical attention networks (Yang\net al. 2016). The models can be pretrained using unlabeled threads from TripAdvisor (‘T’) and Ubuntuforum (‘U’). r indicates a redundancy\nremoval step is applied. We report the variance of F-scores across all threads (‘+’). A redundancy removal step improves recall scores (shown\nin gray) of the HAN models and boosts performance.\n\nclaim: Pretraining the HAN models, although intuitively promising, yields only comparable\n\nresults with those without.\n\ngold: supports, prediction: refutes\n\nPrograms:\n\n[\"HAN_F_score = 37.8\\n\nHAN_pretrainT_F_score = 37.6\\n\nHAN_pretrainU_F_score = 37.6\\n\nans = (HAN_F_score - HAN_pretrainT_F_score == 0.2) and\n\n(HAN_F_score - HAN_pretrainU_F_score =\n\n= 0.2)\"]\n\n", "vlm_text": "The table presents the results of thread summarization using different models, evaluated using ROUGE-1, ROUGE-2, and Sentence-Level metrics. The systems compared include ILP, Sum-Basic, KL-Sum, LexRank, MEAD, SVM, LogReg, LogReg* (with redundancy removal), and several variations of HAN (Hierarchical Attention Networks).\n\nThe table specifically highlights results for HAN models with and without pretraining using unlabeled threads from TripAdvisor (T) and UbuntuForum (U). Redundancy removal is indicated by an asterisk.\n\nKey observations:\n- Pretrained models (HAN+pretrainT, HAN+pretrainU) are compared against non-pretrained and redundancy-removed models.\n- F-scores (shown in gray) reveal that redundancy removal generally improves performance.\n- The claim suggests that pretraining yields similar results to those without pretraining, supported by comparisons of F-scores among different HAN variations."}
{"layout": 335, "type": "table", "page_idx": 26, "img_path": "layout_images/2305.13186v3_26.jpg", "bbox": [107, 463, 487, 605], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Error case 5\n\nClaim: The effectiveness of our hierarchical attention\n\nModel Joint Acc. design is proved by an accuracy drop of 1.95% after\nCOMER 88.64% removing residual connections and the hierarchical stack\n-Hierachical-Attn 86.69% of our attention modules.\",\n\n-MLP 83.24% gold: supports,\n\nprediction: refutes,\nTable 4: The ablation study on the WoZ2.0 dataset programs: [‘\nwith the joint goal accuracy on the test set. For “- =\nHierachical-Attn”, we remove the residual connections COMER_acc ~ 88.64\\n\nbetween the attention modules in the CMR decoders COMER_acc_no_residual = 86.69\\n\n\nand all the attention memory access are based on the accuracy_drop = COMER_acc -\n\noutput from the LSTM. For “- MLP”, we further re- A\nplace the MLP with a single linear layer with the non- COMER_acc_no_residual\\n\n\nlinear activation. ans = (accuracy_drop == 1.95)\"]\n", "vlm_text": "The table presents ablation study results on the WoZ2.0 dataset showing the joint goal accuracy:\n\n- **COMER:** 88.64%\n- **- Hierarchical-Attn:** 86.69%\n- **- MLP:** 83.24%\n\nBelow the table, there's an explanation that removing residual connections and hierarchical stack components of attention modules results in accuracy changes. The claim is about the hierarchical attention design's effectiveness, related to a 1.95% accuracy drop, which the prediction refutes."}
{"layout": 336, "type": "text", "text": "Figure 14: Error Cases 4 and 5 for Program-of-Thoughts. Error Case 4 exhibits  Ambiguity error  since it fails to generate a precise program for the approximation word “comparable”. Error Case 5 exhibits  Calculation error  since it generates the correct program, but the calculation result is inaccurate due to incorrect float digits in the Python code. ", "page_idx": 26, "bbox": [70, 636.3095703125, 524, 684.1795043945312], "page_size": [595.2760009765625, 841.8900146484375]}
