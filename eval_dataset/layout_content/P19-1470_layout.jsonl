{"layout": 0, "type": "text", "text": "COMET : Commonsense Transformers for Automatic Knowledge Graph Construction ", "text_level": 1, "page_idx": 0, "bbox": [153, 68, 445, 104], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 1, "type": "text", "text": "Antoine Bosselut   ♦♠ Hannah Rashkin  $\\diamondsuit$  Maarten Sap  $\\diamondsuit$  Chaitanya Malaviya   ♦ Asli Celikyilmaz   ♣ Yejin Choi   ♦♠ ♦ Allen Institute for Artiﬁcial Intelligence, Seattle, WA, USA ♠ Paul G. Allen School of Computer Science & Engineering, Seattle, WA, USA ♣ Microsoft Research, Redmond, WA, USA ", "page_idx": 0, "bbox": [85.97600555419922, 119, 517.0433349609375, 190.84140014648438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 2, "type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0, "bbox": [159, 223, 204, 235], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 3, "type": "text", "text": "We present the ﬁrst comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: A TOMIC  ( Sap et al. ,  2019 ) and Con- ceptNet ( Speer et al. ,  2017 ). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text de- scriptions of knowledge. We posit that an important step toward automatic common- sense completion is the development of  gen- erative  models of commonsense knowledge, and propose  COM mons E nse  T ransformers  $(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{E}\\mathbb{T}\\mathcal{O})$  ) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of com- monsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that  COMET  is able to generate novel knowledge that humans rate as high quality, with up to  $77.5\\%$   (A TOMIC ) and  $91.7\\%$   (ConceptNet) precision at top 1, which approaches human performance for these re- sources. Our ﬁndings suggest that using gen- erative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods. ", "page_idx": 0, "bbox": [87, 249.20355224609375, 273, 607.9083862304688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 4, "type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0, "bbox": [71, 621, 155, 635], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 5, "type": "text", "text": "When reading text, humans make commonsense inferences that frame their understanding of the narrative being presented. For machines to achieve this capability, they must be able to acquire rele- vant and correct commonsense for an unbounded set of situations. In this work, we cast common- sense acquisition as knowledge base construction and investigate whether large-scale language mod- els can effectively learn to generate the knowledge ", "page_idx": 0, "bbox": [72, 644.4918212890625, 290, 766.03125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 6, "type": "image", "page_idx": 0, "img_path": "layout_images/P19-1470_0.jpg", "img_caption": "Figure 1:  COMET learns from an existing knowledge base (solid lines) to be able to generate novel nodes and edges (dashed lines). ", "bbox": [306, 223, 528, 464], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Automatic KB\n\nCommonsense Knowledge Bases *\nCompletion\n\n(seen events)\n\nloving\ntowards.\n\nPersonX\nputs their\n\narms around\nPersonY\n\ng PersonX\n& goes to the J\nx\ncomfort\nPersonY\nPersonx\nbuys\nlunch\n2 Going to ‘\nsi a movie\nBy Throwing\nis apart\n& having }eause® REY:\n\nUnseen Events\n", "vlm_text": "The image illustrates how COMET, an AI model, learns to generate new knowledge from existing knowledge bases. It comprises two sections:\n\n1. **Commonsense Knowledge Bases (seen events)**: \n   - Examples from knowledge bases like Atomic and ConceptNet.\n   - Consists of nodes and edges showing relationships:\n     - **Atomic**: Includes actions like \"PersonX puts their arms around PersonY\" with attributes (xAttr) such as \"caring\" and reactions (oReact) like \"feels loved.\"\n     - **ConceptNet**: Shows events like \"nap\" with sub-events (HasSubevent) leading to \"having a rest\" and causing \"energy.\"\n\n2. **Automatic KB Completion (unseen events)**:\n   - Demonstrates how COMET infers new connections and nodes:\n     - Predicts relationships such as \"xNeed\" for \"PersonX goes to the store\" needing \"bring a wallet.\"\n     - Generates events like \"loving towards PersonY\" and \"having fun\" from known events.\n\nDashed lines signify newly inferred nodes and connections, illustrating COMET's capability to extend knowledge beyond the initial data."}
{"layout": 7, "type": "text", "text": "necessary to automatically construct a common- sense knowledge base (KB). ", "page_idx": 0, "bbox": [307, 490.6799621582031, 525, 517.3743896484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 8, "type": "text", "text": "Automatic KB construction is a long-standing goal of artiﬁcial intelligence research due to the difﬁculty of achieving high concept coverage in high-precision curated KBs ( Lenat ,  1995 ;  Miller , 1995 ). Previous work has developed models capa- ble of reading and extracting semi-structured text ( Suchanek et al. ,  2007 ;  Hoffart et al. ,  2013 ;  Auer et al. ,  2007 ;  Bollacker et al. ,  2008 ) and unstruc- tured text ( Dong et al. ,  2014 ;  Carlson et al. ,  2010 ; Nakashole et al. ,  2011 ,  2012 ;  Niu ,  2012 ) into re- lational schemas that can be queried for down- stream applications. A common thread of these approaches, however, is the focus on encyclope- dic knowledge, which lends itself to a well-deﬁned space of entities and relations that can be modeled. ", "page_idx": 0, "bbox": [307, 520.1640014648438, 525, 722.9984130859375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 9, "type": "text", "text": "Commonsense knowledge, however, does not cleanly ﬁt into a schema comparing two entities with a known relation, leading current approaches ", "page_idx": 0, "bbox": [307, 725.7869873046875, 525, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 10, "type": "image", "page_idx": 1, "img_path": "layout_images/P19-1470_1.jpg", "img_caption": "Figure 2: Model diagram.  (a)  In the multi-headed attention module, the key, value, and query all pass through a head-speciﬁc projection before a scaled dot-product attention is computed between them. The outputs of the heads are concatenated and projected.  (b)  Inside the transformer block, the outputs of all the previous layer blocks from earlier time steps are input to the multi-headed attention with the preceding block for the current time step as the query.  (c)  Each token is an input to a ﬁrst-layer block along with all preceding tokens. Dotted lines indicate outputs to all future blocks in the next layer and inputs from all preceding blocks in the previous layer. ", "bbox": [69, 66, 529, 313], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "a\n\nMulti-headed Attention Transformer Block Commonsense Transformer (COMeT)\nga K [MASK] [MASK] have boat <END>\nVocab || Vocab Vocab Vocab | | Vocab\nt t t t t\nBlock }{ Block } **= | Block } «*= | Block Block\nrt\nter\n\nMulti-headed Attention\n\nBlock }{ Block\n\n5\nee @o Po G1 Pr &ls| Psi nan\n(THR conf ea Soe \\Personx sails ... <xNeed> sail boat\n\n(b) (c)\n\n", "vlm_text": "The image is a diagram explaining the architecture of a model, focusing on three main components: (a) Multi-headed Attention, (b) Transformer Block, and (c) Commonsense Transformer (COMeT).\n\n(a) Multi-headed Attention: This part of the diagram shows how key (K), value (V), and query (Q) inputs are processed through head-specific projections. Each attention head computes scaled dot-product attention, and the outputs are concatenated and linearly projected.\n\n(b) Transformer Block: This section depicts a single layer of a transformer block, illustrating how multi-headed attention interacts with layer normalization and a feedforward network. The input includes all previous layer blocks from earlier steps, and the current block query is used.\n\n(c) Commonsense Transformer (COMeT): This explains how tokens progress through the transformer architecture. Each token is input to the first-layer block with preceding tokens. Dotted lines signify outputs to future blocks and inputs from prior blocks. The attention mechanism produces a contextual understanding of sequences.\n\nTogether, these components illustrate the flow and transformation of data through a transformer-based model, specifically tailored for a commonsense knowledge task in COMeT."}
{"layout": 11, "type": "text", "text": "to model “entities\" as natural language phrases and relations as any concept that can link them ( Li et al. ,  2016 ;  Sap et al. ,  2019 ). OpenIE ap- proaches display this property of open text enti- ties and relations ( Etzioni et al. ,  2011 ;  Fader et al. , 2011 ;  Mausam et al. ,  2012 ), but being extrac- tive, they only capture knowledge that is explic- itly mentioned in text, limiting their applicability for capturing commonsense knowledge, which is often implicit ( Gordon and Van Durme ,  2013 ). ", "page_idx": 1, "bbox": [72, 334.090087890625, 290, 469.1786193847656], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 12, "type": "text", "text": "Meanwhile, recent progress in training deep contextualized language models ( Peters et al. , 2018 ;  Radford et al. ,  2018 ;  Devlin et al. ,  2018 ) provides an opportunity to explore beyond extrac- tive methods as an avenue for commonsense KB construction. These large-scale language models display impressive performance when their under- lying representations are tuned to solve end tasks, achieving state-of-the-art results on a variety of complex problems. In this work, we deﬁne the COM mons E nse  T ransformer    $(\\mathbb{C}\\mathbb{O}\\mathbb{M}\\mathbb{E}\\mathbb{T}\\mathcal{O})$  ), which constructs commonsense KBs by using existing tuples as a seed set of knowledge on which to train. Using this seed set, a pre-trained language model learns to adapt its learned representations to knowledge generation, and produces novel tuples that are high quality. ", "page_idx": 1, "bbox": [72, 475.74212646484375, 290, 705.6744384765625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 13, "type": "text", "text": "We summarize our contributions in this work as follows. First, we develop a generative approach to knowledge base construction. A model must learn to produce new nodes and identify edges be- tween existing nodes by generating phrases that coherently complete an existing seed phrase and relation type 1 . Second, we develop a framework for using large-scale transformer language models to learn to produce commonsense knowledge tu- ples 2 . Finally, we perform an empirical study on the quality, novelty, and diversity of the common- sense knowledge produced by our approach for two domains, A TOMIC  and ConceptNet, as well as an efﬁciency study on the number of seed tuples needed to learn an effective knowledge model. The results indicate that  COMET  is able to pro- duce high quality tuples as human judges ﬁnd that\n\n  $77.5\\%$   of generated tuples for A TOMIC  events and\n\n  $91.7\\%$   of generated tuples for ConceptNet rela- tions are correct. ", "page_idx": 1, "bbox": [72, 712.2379760742188, 290, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 14, "type": "text", "text": "", "page_idx": 1, "bbox": [306, 334.0899658203125, 525, 550.4735107421875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 15, "type": "text", "text": "2 Learning to Generate Commonsense ", "text_level": 1, "page_idx": 1, "bbox": [306, 565, 513, 579], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 16, "type": "text", "text": "COMET  is an adaptation framework for construct- ing commonsense knowledge bases from language models by training the language model on a seed set of knowledge tuples. These tuples provide COMET  with the KB structure and relations that must be learned, and  COMET  learns to adapt the language model representations learned from pre- training to add novel nodes and edges to the seed knowledge graph. ", "page_idx": 1, "bbox": [306, 589.4890747070312, 525, 711.0285034179688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 17, "type": "text", "text": "More speciﬁcally, the problem assumes  COMET  is given a training knowledge base of natural lan- guage tuples in    $\\{s,r,o\\}$   format, where    $s$   is the phrase subject of the tuple,    $r$   is the relation of the tuple, and    $o$   is the phrase object of the tuple. For example, a ConceptNet tuple relating to “taking a nap\" would be: (  $\\stackrel{\\cdot}{s=}^{\\cdot}$  “take a nap\",    $r{=}\\mathrm{C}$  auses ,  $o{=}^{c}$  “have energy\"). The task is to generate    $o$   given  $s$   and    $r$   as inputs. ", "page_idx": 2, "bbox": [71, 83.43604278564453, 290, 204.97457885742188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 18, "type": "text", "text": "Notation We deﬁne    $X^{s}\\,=\\,\\{x_{0}^{s},...,x_{|s|}^{s}\\}$   as the | | tokens that make up the subject of the relation,  $X^{r}\\ =\\ \\{x_{0}^{r},...,x_{|r|}^{r}\\}$   as the tokens that make up | | the relation of the tuple, and    $X^{o}\\,=\\,\\{x_{0}^{o},...,x_{|o|}^{o}\\}$  | | as the tokens that make up the object of the tuple. The embedding for any word  $x$   is denoted as    $e$  . ", "page_idx": 2, "bbox": [71, 216.31236267089844, 290, 298.9818420410156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 19, "type": "text", "text": "2.2 Transformer Language Model ", "text_level": 1, "page_idx": 2, "bbox": [71, 313, 238, 325], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 20, "type": "text", "text": "While  COMET  is agnostic to the language model with which it is initialized, in this work, we use the transformer language model architecture in- troduced in  Radford et al.  ( 2018 ) (GPT), which uses multiple transformer blocks of multi-headed scaled dot product attention and fully connected layers to encode input text ( Vaswani et al. ,  2017 ). Figure  2  depicts different components of the GPT architecture and we deﬁne each component in more depth below. ", "page_idx": 2, "bbox": [71, 331.933349609375, 290, 467.0218811035156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 21, "type": "text", "text": "Transformer Block As shown in Figure  2 (b), each transformer layer    $l$   contains an architecturally identical transformer block (though with unique trainable parameters) that applies the following transformations to the input to the block: ", "page_idx": 2, "bbox": [71, 478.35968017578125, 290, 546.0948486328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 22, "type": "equation", "text": "\n$$\n\\begin{array}{r l}&{\\tilde{g}^{l}=\\mathbf{MULIATTN}\\big(h^{l-1}\\big)}\\\\ &{g^{l}=\\mathbf{LAYERNORM}\\big(\\tilde{g}^{l}+h^{l-1}\\big)}\\\\ &{\\tilde{h}^{l}=\\mathbf{FFN}(g^{l})}\\\\ &{h^{l}=\\mathbf{LAYERNORM}\\big(\\tilde{h}^{l}+g^{l}\\big)}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [110, 557, 251, 630], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 23, "type": "text", "text": "where M ULTI A TTN is a multi-headed self- attention mechanism (deﬁned below), FFN is a two-layer feed-forward network, and L AYER - N ORM  represents a layer normalization ( Ba et al. , 2016 ) operation that is applied to the output of the self-attention and the feedforward network. Note that the inputs to the L AYER N ORM  opera- tions contain a residual connection that sums the output of and input to the previous operation. ", "page_idx": 2, "bbox": [71, 644.492431640625, 290, 766.0308837890625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 24, "type": "text", "text": "Multi-headed Attention The multi-headed at- tention module of each transformer block, shown in Figure  2 (a), is identical to the one originally de- ﬁned by  Vaswani et al.  ( 2017 ). The attention func- tion receives three inputs, a query    $Q$  , key    $K$  , and value  $V$  . The attention is made of multiple  heads that each compute a unique scaled dot product at- tention distribution over    $V$  using    $Q$   and    $K$  : ", "page_idx": 2, "bbox": [307, 63.29471969604492, 525, 171.67697143554688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 25, "type": "equation", "text": "\n$$\n\\operatorname{ATESmTilde{ON}}(Q,K,V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right)V\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [312, 180, 519, 211], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 26, "type": "text", "text": "where  $d_{k}$   is the dimensionality of the input vectors representing the query, key and value. For each of the heads,    $Q,K$  , and    $V$  are uniquely projected prior to the attention being computed: ", "page_idx": 2, "bbox": [307, 234.43202209472656, 525, 288.2254943847656], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 27, "type": "equation", "text": "\n$$\nH_{i}=\\mathrm{ATANTION}(Q W_{i}^{Q},K W_{i}^{K},V W_{i}^{V})\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [315, 296, 504, 314], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 28, "type": "text", "text": "where    $H_{i}$   is the output of a single attention head and    $W_{i}^{Q},W_{i}^{K}$  , and    $W_{i}^{V}$  are head-speciﬁc projec- tions for    $Q,\\,K$  , and    $V$  , respectively. The outputs of the attention heads  $H_{i}$   are then concatenated: ", "page_idx": 2, "bbox": [307, 324.45391845703125, 525, 379.8833923339844], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 29, "type": "equation", "text": "\n$$\n\\mathrm{MLTH}(\\mathrm{Q},\\mathrm{K},\\mathrm{V})=[H_{1};...;H_{b}]W^{O}\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [322, 387, 497, 403], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 30, "type": "text", "text": "where    $W^{O}$    is an output projection of the concate- nated outputs of the attention heads. As shown in Figure  2 (c), we follow  Radford et al.  ( 2018 ) and use the output of the previous layer’s transformer block as the query input for the multi-headed at- tention of the next block. The keys and values are outputs of the previous layer’s block for all pre- ceding time steps: ", "page_idx": 2, "bbox": [307, 410.5169372558594, 525, 522.4664306640625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 31, "type": "equation", "text": "\n$$\n\\mathbf{MULTilde{M}}_{t}=\\mathbf{MULTilde{H}}\\big(h_{t}^{l-1},\\mathbf{h}_{t}^{l-1},\\mathbf{h}_{t}^{l-1}\\big)\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [305, 530, 528, 548], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 32, "type": "text", "text": "where    $\\mathbf{h}_{t}^{l-1}~=~\\{h^{l-1}\\}_{<t}$   { }  is the set of previous layer transformer block outputs for time steps pre- ceding    $t$  . ", "page_idx": 2, "bbox": [307, 572, 525, 614.182373046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 33, "type": "text", "text": "Input Encoder As input to the model, we repre- sent a knowledge tuple    $\\{s,r,o\\}$   as a concatenated sequence of the words of each item of the tuple: ", "page_idx": 2, "bbox": [307, 621.76318359375, 525, 662.4003295898438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 34, "type": "equation", "text": "\n$$\n\\mathbf{X}=\\{X^{s},X^{r},X^{o}\\}\n$$\n ", "text_format": "latex", "page_idx": 2, "bbox": [370, 672, 462, 688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 35, "type": "text", "text": "Since the transformer (a self-attention model) has no concept of ordering of tokens, a position em- bedding    $p_{t}$   is initialized for each absolute position in the sequence ( Vaswani et al. ,  2017 ). For any input word    $x_{t}\\in\\mathbf{X}$  , our encoding of the input is ", "page_idx": 2, "bbox": [307, 698.6889038085938, 525, 766.0313110351562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 36, "type": "table", "page_idx": 3, "img_path": "layout_images/P19-1470_2.jpg", "table_caption": "ATOMIC Input Template and ConceptNet Relation-only Input Template  ", "table_footnote": "go to mall [MASK] [MASK] has prerequisite [MASK] have money ", "bbox": [75, 65, 285, 140], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "PersonX goes to the mall [MASK] <xIntent> to buy clothes\n\nConceptNet Relation to Language Input Template\n", "vlm_text": "The table appears to depict a model for translating between a structured knowledge representation format and a natural language format using tokens. The illustration is split into two main sections. \n\n1. The first section at the top translates a natural language sentence into token components:\n   - **s tokens**: Represent the subject tokens, which in the example given is \"PersonX goes to the mall\".\n   - **mask tokens**: Represent locations in the structure where a relation or intent is implied or needs to be inferred; marked by [MASK].\n   - **r token**: Represents the relation token, which in the example is \"<xIntent>\".\n   - **o tokens**: Represent the object tokens, depicted here as \"to buy clothes\".\n\n2. The second section below bears the title \"ConceptNet Relation to Language Input Template\", illustrating a generic template structure:\n   - The setup is similar with **s tokens**, **mask tokens**, **r tokens**, and **o tokens** laid out linearly.\n   - The template seems to imply an additional set of mask tokens, indicating it can include structures with more complex relationships or additional contexts needing inference.\n\nThis design is likely used for tasks related to natural language understanding or machine learning, where mapping between structured knowledge databases like ConceptNet and natural language is necessary."}
{"layout": 37, "type": "text", "text": "Figure 3: Input token setup for training conﬁgurations. For the A TOMIC  dataset, the tokens of the subject,    $X^{s}$  (e.g., PersonX goes to the mall) are followed by mask- ing tokens, which is followed by a single relation token  $X^{r}$    (e.g.,  xIntent ), and then the object tokens    $X^{o}$  (e.g., to buy clothes). The model receives the same in- put for ConceptNet, except that a second set of mask- ing tokens separate  $X^{r}$    and    $X^{o}$    because    $X^{r}$    can have a variable number of tokens for ConceptNet (§ 5.2 ) ", "page_idx": 3, "bbox": [71, 152.40057373046875, 290, 260.046630859375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 38, "type": "text", "text": "the sum of its word embedding,  $e_{t}$   with a position embedding encoding its absolute position in the sequence  $\\mathbf{X}$  : ", "page_idx": 3, "bbox": [71, 281.01513671875, 290, 321.2596130371094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 39, "type": "equation", "text": "\n$$\nh_{t}^{0}=e_{t}+p_{t}\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [151, 332, 211, 349], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 40, "type": "text", "text": "where    $p_{t}$   is the position embedding for time step  $t$  , and  $h^{0}$    is the input to the ﬁrst transformer layer. ", "page_idx": 3, "bbox": [71, 354.7701416015625, 290, 381.4646301269531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 41, "type": "text", "text": "3 Training  COMET ", "text_level": 1, "page_idx": 3, "bbox": [71, 391, 175, 405], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 42, "type": "text", "text": "COMET  is trained to learn to produce the phrase object    $o$   of a knowledge tuple given the tuple’s phrase subject    $s$   and relation    $r$  . More speciﬁcally, given the concatenation of the tokens of    $s$   and    $r$  :  $[X^{s},X^{r}]$   as input, the model must learn to gener- ate the tokens of  $o$  :    $X^{o}$    (See   $\\S2.1$   for deﬁnitions of these variables). ", "page_idx": 3, "bbox": [71, 412.691162109375, 290, 507.1316833496094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 43, "type": "text", "text": "Loss Function To achieve this goal,  COMET  is trained to maximize the conditional loglikelihood of predicting the phrase object tokens,    $X^{o}$  : ", "page_idx": 3, "bbox": [71, 514.353515625, 290, 554.9896850585938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 44, "type": "equation", "text": "\n$$\n\\mathcal{L}=-\\sum_{t=|s|+|r|}^{|s|+|r|+|o|}\\log P(x_{t}|x_{<t})\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [110, 564, 251, 605], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 45, "type": "text", "text": "where    $|s|,\\,|r|$  , and    $|o|$   are the number of tokens in the subject phrase, relation, and object phrase, respectively. Figure  3  outlines how the tokens in  $s$  ,  $r$  , and    $o$   are organized for different training tasks. ", "page_idx": 3, "bbox": [71, 610, 290, 663.9766235351562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 46, "type": "text", "text": "Datasets COMET  relies on a seed set of knowl- edge tuples from an existing KB to learn to pro- duce commonsense knowledge. In this work, we use A TOMIC  and ConceptNet as knowledge seed sets, but other commonsense knowledge re- sources could have been used as well as  COMET  is domain-agnostic. ", "page_idx": 3, "bbox": [71, 671.198486328125, 290, 766.0316162109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 47, "type": "text", "text": "Initialization Parameters are initialized to the ﬁ- nal language model weights from  Radford et al. ( 2018 ). Additional special tokens that are added to the vocabulary for ﬁne tuning (e.g., relation em- beddings such as  oReact  for A TOMIC  and  IsA for ConceptNet) are initialized by sampling from the standard normal distribution. ", "page_idx": 3, "bbox": [306, 63.29447555541992, 525, 158.12771606445312], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 48, "type": "text", "text": "Hyperparameters Following  Radford et al. ( 2018 )’s design of the GPT model, we initialize COMET  with 12 layers, 768-dimensional hidden states, and 12 attention heads. We use a dropout rate of 0.1 and use GeLU ( Hendrycks and Gimpel , 2016 ) units as activation functions. During train- ing, our batch size is 64. Other dataset-speciﬁc hyperparameters are provided in Appendix  A.1 . ", "page_idx": 3, "bbox": [306, 165.8285369873047, 525, 274.2107849121094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 49, "type": "text", "text": "4 A TOMIC  Experiments ", "text_level": 1, "page_idx": 3, "bbox": [307, 286, 438, 298], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 50, "type": "text", "text": "The A TOMIC  dataset 3 , released by  Sap et al. ( 2019 ), contains 877K tuples covering a variety of social commonsense knowledge around speciﬁc event prompts (e.g., “X goes to the store”). Specif- ically, A TOMIC  distills its commonsense in nine dimensions, covering the event’s causes (e.g., “X needs to drive there”), its effects on the agent (e.g., “to get food”) and its effect on other direct (or implied) participants (e.g., “Others will be fed”). More details about A TOMIC  can be found in Ap- pendix  D . For our experiments, A TOMIC  events (e.g., “X goes to the store”) are phrase subjects,    $s$  , the dimension (e.g.,  xIntent ) is the phrase rela- tion,  $r$  , and the causes/effects (e.g., “to get food”) are phrase objects,    $o$  . We use the training splits from  Sap et al.  ( 2019 ), resulting in 710k training,  $80\\mathrm{k}$  development, and   $87\\mathrm{k}$   test tuples respectively. ", "page_idx": 3, "bbox": [306, 305.0599365234375, 525, 536.23583984375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 51, "type": "text", "text": "4.1Setup", "text_level": 1, "page_idx": 3, "bbox": [307, 546, 359, 558], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 52, "type": "text", "text": "Metrics Following  Sap et al.  ( 2019 ), we eval- uate our method using BLEU-2 as an automatic evaluation metric. We also report the perplexity of the model on its gold generations. The remain- ing automatic metrics in Table  1  measure the pro- portion of generated tuples and generated objects which are not in the training set. We report the proportion of all generated tuples that are novel  $(\\%\\;\\mathrm{N}/\\mathrm{T}\\;s r o)$   and that have a novel object (  $\\%$   N/T  $o)^{4}$  . To show that these novel objects are diverse (i.e., the same novel object is not the only one be- ing generated), we also report the number of novel ", "page_idx": 3, "bbox": [306, 563.0726928710938, 525, 725.6517944335938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 53, "type": "table", "page_idx": 4, "img_path": "layout_images/P19-1470_3.jpg", "table_caption": "Table 1: Automatic evaluations of quality and novelty for generations of A TOMIC  commonsense. No novelty scores are reported for the NearestNeighbor baseline because all retrieved sequences are in the training set. ", "bbox": [70, 62, 527, 198], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Model PPL° BLEU-2) N/Tsro®’ N/To NiUo\n\n9ENC9DEC (Sap et al., 2019) - 10.01 100.00 8.61 40.77\nNearestNeighbor (Sap et al., 2019) - 6.61 - - -\nEvent2(IN) VOLUN (Sap et al., 2019) - 9.67 100.00 9.52 45.06\nEvent2PERSONX/Y (Sap et al., 2019) - 9.24 100.00 8.22 41.66\nEvent2PRE/PosT (Sap et al., 2019) - 9.93 100.00 7.38 41.99\nCOMET (- pretrain) 15.42 13.88 100.00 7.25 45.71\n\nCOMET 11.14 15.10 100.00 9.71 51.20\n", "vlm_text": "The table presents performance metrics for various models on specific evaluation criteria. Here's a breakdown of the content:\n\n### Model Names and References\n- **9ENC9DEC:** Sap et al., 2019\n- **NearestNeighbor:** Sap et al., 2019\n- **Event2(IN)VOLUN:** Sap et al., 2019\n- **Event2PERSONX/Y:** Sap et al., 2019\n- **Event2PRE/POST:** Sap et al., 2019\n- **COMET (- pretrain)**\n- **COMET**\n\n### Performance Metrics\n- **PPL:** Perplexity, with a superscript indicating a specific condition or note (mentioned as 5).\n- **BLEU-2:** Bilingual Evaluation Understudy Score using 2-gram precision.\n- **N/T sro:** Normalized by type (or attribute) evaluation score, with a superscript (6) indicating further specifics.\n- **N/T o:** Normalized by type (or attribute) score.\n- **N/U o:** Normalized by type (or attribute) unconditioned score.\n\n### Results\n- **Perplexity (PPL):** Only provided for COMET models: 15.42 for \"COMET (- pretrain)\" and 11.14 for \"COMET\".\n- **BLEU-2 Scores:** Range from 6.61 for NearestNeighbor to a peak of 15.10 for COMET.\n- **N/T sro:** Consistently 100.00 for all models presented.\n- **N/T o Scores:** Range from 7.25 for \"COMET (- pretrain)\" to 9.71 for COMET.\n- **N/U o Scores:** Range from 40.77 for 9ENC9DEC to the highest at 51.20 for COMET.\n\nThe COMET model, particularly without pre-training and fully trained, shows superior performance in the BLEU-2 and N/U o metrics compared to other models listed."}
{"layout": 54, "type": "table", "page_idx": 4, "img_path": "layout_images/P19-1470_4.jpg", "table_footnote": "Table 2: Human score of generations of A TOMIC  commonsense. We present comparisons to the baselines from Sap et al.  ( 2019 ). Underlined results are those where    $\\mathbb{C O M E T}$   is not signiﬁcantly better at  $p<0.05$  ", "bbox": [70, 209, 527, 327], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Model oEffect oReact oWant xAttr xEffect xIntent xNeed xReact xWant || Avg\n\n9Enc9Dec (Sap et al., 2019) 22.92 32.92 35.50 52.20 47.52 51.70 48.74 63.57 51.56 || 45.32\nEvent2(In)voluntary (Sap et al., 2019) 26.46 36.04 34.70 52.58 46.76 61.32 49.82 71.22 = 52.44 || 47.93\nEvent2PersonX/Y (Sap et al., 2019) 24.72 33.80 35.08 52.98 48.86 53.93 54.05 66.42 54.04 || 46.41\nEvent2Pre/Post (Sap et al., 2019) 26.26 34.48 35.78 52.20 46.78 57.77 47.94 72.22 47.94 || 46.76\n\nCOMET (- pretrain) 25.90 35.40 40.76 48.04 47.20 58.88 59.16 64.52 65.66 || 49.50\nCOMET 29.02 37.68 44.48 57.48 55.50 68.32 64.24 76.18 75.16 || 56.45\n", "vlm_text": "The table compares different models based on various metrics related to event understanding. Here's a breakdown:\n\n- **Models**: \n  - 9Enc9Dec (Sap et al., 2019)\n  - Event2(In)voluntary (Sap et al., 2019)\n  - Event2PersonX/Y (Sap et al., 2019)\n  - Event2Pre/Post (Sap et al., 2019)\n  - COMET (- pretrain)\n  - COMET\n\n- **Metrics**:\n  - oEffect\n  - oReact\n  - oWant\n  - xAttr\n  - xEffect\n  - xIntent\n  - xNeed\n  - xReact\n  - xWant\n  - Avg\n\n- **Values**: Each model's performance is measured, with specific values given for each metric.\n\n- **Observations**: \n  - COMET (pretrained and non-pretrained) models generally show better performance across most metrics compared to baseline models (9Enc9Dec, Event2*).\n  - The COMET model has the highest average score, indicating superior overall performance."}
{"layout": 55, "type": "text", "text": "objects as a function of the set of  unique  objects produced for all test set events   $({\\%}\\,\\mathbf{N}/\\mathbf{U}\\,{\\it o})$  . ", "page_idx": 4, "bbox": [71, 348.4850158691406, 290, 375.18048095703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 56, "type": "text", "text": "Finally, we perform a human evaluation using workers from Amazon Mechanical Turk (AMT). Workers are asked to identify whether a model generation of A TOMIC  commonsense adequately completes a plausible tuple of phrase subject, rela- tion, and phrase object. Following the setup of  Sap et al.  ( 2019 ), we evaluate 100 randomly selected events from the test set. For each event and rela- tion type, 10 candidates are generated using beam search and the full beam is evaluated by ﬁve differ- ent workers. Overall,  $\\scriptstyle{\\mathfrak{n}}=5000$   ratings are produced per relation (100 events    $\\times\\,5$   workers    $\\times\\ 10$   candi- dates). The reported  Avg  in Table  2  is an aver- age of these scores, yielding   $\\mathsf{n{=}45000}$   total ratings for each model. We use Pitman’s test ( Noreen , 1989 ) with   $100\\mathbf{k}$   permutations to test for statis- tical signiﬁcance. Because 50 different hypothe- ses are tested (9 relations   $^+$   the total), the Holm- Bonferroni method ( Holm ,  1979 ) is used to correct signiﬁcance thresholds. Example events from the development set and their generated phrase objects are available in Table  5 . ", "page_idx": 4, "bbox": [71, 379.5400085449219, 290, 677.218505859375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 57, "type": "text", "text": "Baselines We report the performance of our method against the models trained in  Sap et al. ( 2019 ) that use LSTM sequence-to-sequence mod- els ( Sutskever et al. ,  2014 ) to encode the input sub- ject and relation and produce an output object. ", "page_idx": 4, "bbox": [71, 698.29638671875, 290, 766.031494140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 58, "type": "text", "text": "Ablations To evaluate how pre-training on a large corpus helps the model learn to produce knowledge, we train a version of    $\\mathbb{C O M E T}$   that is not initialized with pre-trained weights ( COMET  (- pretrain)). We also evaluate the data efﬁciency of our method by training models on different pro- portions of the training data. Finally, because the ultimate goal of our method is to be able to perform high-quality, diverse knowledge base construction, we explore how various decoding schemes affect the quality of candidate knowledge tuples. We present the effect of the following gen- eration strategies: argmax greedy decoding, beam search with beam sizes,  $\\tt b\\mathrm{=}2$  , 5, 10, and top-  $\\cdot k$   sam- pling with  $\\mathbf{k}=5$  , 10. For each decoding method, we conduct the human evaluation on the number of ﬁnal candidates produced by each method. ", "page_idx": 4, "bbox": [307, 348.0923156738281, 525, 578.4176025390625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 59, "type": "text", "text": "4.2 Results ", "text_level": 1, "page_idx": 4, "bbox": [307, 589, 366, 601], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 60, "type": "text", "text": "Overall performance The BLEU-2 results in Table  1  indicate that  COMET  exceeds the perfor- mance of all baselines, achieving a   $51\\%$   relative improvement over the top performing model of Sap et al.  ( 2019 ). More interesting, however, is the result of the human evaluation, where  COMET  re- ported a statistically signiﬁcant relative  Avg  per- formance increase of   $18\\%$   over the top baseline, ", "page_idx": 4, "bbox": [307, 606.4384765625, 525, 714.820556640625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 61, "type": "table", "page_idx": 5, "img_path": "layout_images/P19-1470_5.jpg", "table_footnote": "Table 3: Human evaluation testing effect of different decoding schemes on candidate tuple quality. The number of ratings made per relation for each decoding method is provided in the ﬁrst column. ", "bbox": [69, 71, 527, 193], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "COMET Decoding method | oEffect oReact oWant xAttr xEffect xIntent xNeed xReact xWant | Avg\nTop-5 random sampling (n=2500 per relation) 34.60 44.04 35.56 64.56 55.68 58.84 46.68 80.96 58.52 || 53.27\nTop-10 random sampling (n=5000 per relation) 25.20 37.42 27.34 49.20 47.34 47.06 38.24 72.60 48.10 || 43.61\nBeam search - 2 beams (n=1000 per relation) 43.70 54.20 47.60 84.00 51.10 73.80 50.70 85.80 78.70 || 63.29\nBeam search - 5 beams (n=2500 per relation) 37.12 45.36 42.04 63.64 61.76 63.60 57.60 78.64 68.40 || 57.57\nBeam search - 10 beams (n=5000 per relation) 29.02 37.68 4448 57.48 55.50 68.32 64.24 76.18 75.16 | 56.45\nGreedy decoding (n=500 per relation) 61.20 69.80 80.00 77.00 53.00 89.60 85.60 92.20 89.40 || 77.53\nHuman validation of gold ATOMIC || 84.62 86.13 83.12 7844 83.92 91.37 81.98 95.18 90.90 || 86.18\n\n", "vlm_text": "The table presents the performance of different decoding methods used in the COMET framework for generating commonsense inferences, evaluated against a human baseline on the ATOMIC dataset. Each row represents one specific decoding method or human validation, and each column corresponds to a different types of commonsense relation: oEffect, oReact, oWant, xAttr, xEffect, xIntent, xNeed, xReact, xWant, and Avg (average performance across all relations).\n\nHere are the details for each row:\n- **Top-5 random sampling (n=2500 per relation):** Reports scores for each relation and an average score of 53.27.\n- **Top-10 random sampling (n=5000 per relation):** Lower scores than Top-5 random sampling with an average of 43.61.\n- **Beam search - 2 beams (n=1000 per relation):** Improved scores over random sampling, highest score of 84.00 for xAttr, with an average of 63.29.\n- **Beam search - 5 beams (n=2500 per relation):** Scores lower than with 2 beams, with an average of 57.57.\n- **Beam search - 10 beams (n=5000 per relation):** Shows further reduction in scores, averaging 56.45.\n- **Greedy decoding (n=500 per relation):** Generally highest scores among decoding methods, especially for oWant, xIntent, xNeed, xReact, xWant, and an average of 77.53.\n- **Human validation of gold ATOMIC:** Serves as the positive control with high scores across all relations, averaging 86.18.\n\nFrom these results, we observe that greedy decoding performs best among automated methods but still does not reach the performance level of human validation."}
{"layout": 62, "type": "table", "page_idx": 5, "img_path": "layout_images/P19-1470_6.jpg", "table_footnote": "Table 4: Effect of amount of training data on automatic evaluation of commonsense generations ", "bbox": [70, 212, 293, 330], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "% traindata) PPL BLEU-2 N/To N/Uo\n1% train 23.81 5.08 7.24 49.36\n\n10% train 13.74 12.72 9.54 58.34\n\n50% train 11.82 13.97 9.32 50.37\n\nFULL (- pretrain) 15.18 13.22 714 44.55\nFULL train 11.13 14.34 9.51 50.05\n", "vlm_text": "The table displays the results of different training data percentages on model performance metrics. Here is the information provided:\n\n- **% train data**: This indicates the different amounts of training data used in the model training scenarios. The percentage columns are labeled as \"1% train,\" \"10% train,\" \"50% train,\" \"FULL (- pretrain),\" and \"FULL train.\"\n\n- **PPL** (Perplexity): This column shows the perplexity score for each training scenario. Lower perplexity indicates better performance:\n  - 1% train: 23.81\n  - 10% train: 13.74\n  - 50% train: 11.82\n  - FULL (- pretrain): 15.18\n  - FULL train: 11.13\n\n- **BLEU-2**: This column indicates the BLEU score (a metric for evaluating the quality of text, especially in tasks like machine translation) calculated on bi-grams:\n  - 1% train: 5.08\n  - 10% train: 12.72\n  - 50% train: 13.97\n  - FULL (- pretrain): 13.22\n  - FULL train: 14.34\n\n- **N/T °** (presumably a specific metric, possibly related to novelty or type): \n  - 1% train: 7.24\n  - 10% train: 9.54 (bolded)\n  - 50% train: 9.32\n  - FULL (- pretrain): 7.14\n  - FULL train: 9.51\n\n- **N/U °** (presumably a specific metric, possibly related to novelty or uniqueness): \n  - 1% train: 49.36\n  - 10% train: 58.34 (bolded)\n  - 50% train: 50.37\n  - FULL (- pretrain): 44.55\n  - FULL train: 50.05\n\nThe bold values in the N/T and N/U columns indicate the highest scores in those category scenarios, suggesting the percentages or settings where the model performs best according to those specific metrics."}
{"layout": 63, "type": "text", "text": "Event2I N (V OLUN ). This performance increase is consistent, as well, with an improvement being observed across every relation type. In addition to the quality improvements, Table  1  shows that COMET  produces more novel tuple objects than the baselines, as well. ", "page_idx": 5, "bbox": [71, 359.07904052734375, 290, 439.9705505371094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 64, "type": "text", "text": "Learning knowledge from language Signiﬁ- cant differences were also observed between the performance of the model whose weights were ini- tialized with the pre-trained parameters from the GPT model of  Radford et al.  ( 2018 ) and a model with the same architecture that was trained from random initialization. This   $14\\%$   relative improve- ment in overall human performance conﬁrms that the language representations learned by the GPT model are transferable to generating natural lan- guage commonsense knowledge. ", "page_idx": 5, "bbox": [71, 460.7453308105469, 290, 609.7755126953125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 65, "type": "text", "text": "Effect of decoding algorithm In Table  3 , we show the effect of different generation policies on knowledge quality. The most interesting result is that using greedy decoding to produce knowl- edge tuples only results in a   $10\\%$   relative perfor- mance gap compared to a human evaluation of the A TOMIC  test set, showing that the knowledge produced by the model approaches human perfor- mance. While producing more total candidates does lower overall performance, quality assess- ", "page_idx": 5, "bbox": [71, 630.5504150390625, 290, 766.031494140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 66, "type": "table", "page_idx": 5, "img_path": "layout_images/P19-1470_7.jpg", "bbox": [308, 212, 525, 434], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Seed Concept Relation Generated Plausible\nX holds out X’s hand to Y xAttr helpful v\nX meets Y eyes xAttr intense v\nX watches Y every ___ xAttr observant v\nX eats red meat xEffect gets fat v\nX makes crafts xEffect gets dirty v\nX turns X’s phone xEffect — getsa text\n\nX pours___ over Y’s head oEffect gets hurt vo\nX takes Y’s head off oEffect bleeds v\nX pisses on Y’s bonfire oEffect gets burned\n\nX spoils somebody rotten xIntent to be mean\n\nX gives Y some pills xIntent  tohelp v\nX provides for Y’s needs xIntent to be helpful v\nX explains Y’s reasons xNeed to know Y v\nX fulfils X’s needs xNeed to have a plan v\nX gives Y everything xNeed to buy something v\nX eats pancakes xReact satisfied v\nX makes ___ at work xReact proud v\nX moves house xReact happy v\nX gives birth to the Y oReact happy v\nX gives Y’s friend __ oReact grateful v\nX goes ___ with friends oReact happy v\nX gets all the supplies xWant to make a list v\nX murders Y’s wife xWant to hide the body v\nX starts shopping xWant to go home v\nX develops Y theory oWant to thank X v\nX offer Y a position oWant to accept the job v\nX takes ____ out for dinner oWant to eat vo\n", "vlm_text": "The table contains four columns titled \"Seed Concept,\" \"Relation,\" \"Generated,\" and \"Plausible.\" Here's a summary of the content:\n\n1. **Seed Concept**: Actions or scenarios involving \"X\" and \"Y\" (e.g., \"X holds out X's hand to Y\").\n\n2. **Relation**: Categories describing the type of relation (e.g., xAttr, xEffect, oEffect, xIntent, xNeed, xReact, oReact, xWant, oWant).\n\n3. **Generated**: Descriptions or outcomes generated from the seed concept and relation (e.g., \"helpful,\" \"observant,\" \"gets fat\").\n\n4. **Plausible**: Checkmarks indicating whether the generated description or outcome is plausible for the given seed concept and relation.\n\nSome rows contain incomplete actions or scenarios with blanks (e.g., \"X watches Y every ____,\" \"X makes ___ at work\"). Each relation type is marked with specific prefixes (e.g., \"x\" for actions by X, \"o\" for actions affecting Y)."}
{"layout": 67, "type": "text", "text": "Table 5: Generations that were  randomly selected from a subset of  novel  generations from the A TOMIC development set. A novel generation is a  sro  tuple not found in the training set. Manual evaluation of each tu- ple indicates whether the tuple is considered plausible by a human annotator. ", "page_idx": 5, "bbox": [307, 441.6739196777344, 525, 513.8134155273438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 68, "type": "text", "text": "ments still hover around   $55\\%^{7}$    for a beam size of 10. This result suggests that  COMET  could be ef- fective with human evaluators in the loop to con- ﬁrm the correctness of generated tuples. ", "page_idx": 5, "bbox": [307, 531.9109497070312, 525, 589.662353515625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 69, "type": "text", "text": "Efﬁciency of learning from seed tuples Be- cause not all domains will have large available commonsense KBs on which to train, we explore how varying the amount of training data avail- able for learning affects the quality and novelty of the knowledge that is produced. Our results in Table  4  indicate that even with only   $10\\%$   of the available training data, the model is still able to produce generations that are coherent, adequate, and novel. Using only   $1\\%$   of the training data clearly diminishes the quality of the produced gen- erations, with signiﬁcantly lower observed results across both quality and novelty metrics. Interest- ingly, we note that training the model without pre- trained weights performs comparably to training with   $10\\%$   of the seed tuples, quantifying the im- pact of using pre-trained language representations. ", "page_idx": 5, "bbox": [307, 597.8412475585938, 525, 706.2233276367188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 70, "type": "text", "text": "", "page_idx": 6, "bbox": [71, 63.68701934814453, 290, 185.22653198242188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 71, "type": "text", "text": "5 ConceptNet Experiments ", "text_level": 1, "page_idx": 6, "bbox": [71, 198, 219, 210], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 72, "type": "text", "text": "The ConceptNet dataset 8 , provided by  Li et al. ( 2016 ), consists of tuples obtained from the Open Mind Common Sense (OMCS) entries in Concept- Net 5 ( Speer et al. ,  2017 ). Tuples are in the stan- dard  sro  form – (e.g., take a nap,  Causes , have energy). The most conﬁdent 1200 tuples were used to create the test set, while the next 1200 tuples were used to create two development sets, which we combine in this work. The   $100\\mathbf{k}$   version of the training set was used to train models, which contains 34 relation types. ", "page_idx": 6, "bbox": [71, 218.335693359375, 290, 368.2165832519531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 73, "type": "text", "text": "5.1Setup", "text_level": 1, "page_idx": 6, "bbox": [71, 379, 124, 392], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 74, "type": "text", "text": "Metrics We evaluate our models that generate ConceptNet relations using the following metrics. First, we report the perplexity of the gold relations in the test set (PPL). To evaluate the quality of gen- erated knowledge, we also report the number of generated positive examples in the test set that are scored as correct by the pre-trained Bilinear AVG model developed by  Li et al.  ( 2016 ).   For a given sro  tuple, this model produces a probability for whether the tuple is correct. We threshold scores at  $50\\%$   probability to identify positive predictions. On the completion task originally proposed in  Li et al.  ( 2016 ), this model achieved  $92.5\\%$   accuracy on the test set, indicating that it is a strong proxy for automatically evaluating whether a generated tuple is correct. Finally, we report the same nov- elty metrics as for A TOMIC :  N/T  sro  and  N/T    $o$  . ", "page_idx": 6, "bbox": [71, 397.1263732910156, 290, 628.1062622070312], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 75, "type": "text", "text": "Baselines As a baseline, we re-implement the BiLSTM model proposed by  Saito et al. ( 2018 ) with minor modiﬁcations outlined in Ap- pendix  A.2 . This model is trained to learn to en- code knowledge in both directions:    $s r\\,\\rightarrow\\,o$   and ", "page_idx": 6, "bbox": [71, 636.469482421875, 290, 704.2046508789062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 76, "type": "table", "page_idx": 6, "img_path": "layout_images/P19-1470_8.jpg", "table_caption": "Table 6: ConceptNet generation Results ", "bbox": [308, 62, 524, 150], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Model PPL Score N/T sro N/To Human\nLSTM - s - 60.83 86.25 7.83 63.86\nCKBG (Saito et al., 2018) - 57.17 86.25 8.67 53.95\nCOMET (- pretrain) 8.05 89.25 36.17 6.00 83.49\nCOMET - RELTOK 4.39 95.17 56.42 2.62 92.11\nCOMET 4.32 95.25 59.25. 3.75 91.69\n", "vlm_text": "This table compares the performance of different models on several evaluation metrics. The columns in the table represent the following:\n\n- **Model**: The name or type of the model being evaluated.\n- **PPL**: Perplexity, a measure of how well a probability model predicts a sample.\n- **Score**: A performance metric for the model, although the specific nature of this score is not defined here.\n- **N/T\\(_{sro}\\)**: A metric related to precision or performance, possibly representing the accuracy for a specific task or dataset involving subject-relation-object (sro) triples.\n- **N/T\\(_{o}\\)**: Similar to N/T\\(_{sro}\\), this likely measures another aspect of task performance involving object triples.\n- **Human**: A metric comparing the model's performance to human performance on the same task.\n\nThe models mentioned include:\n\n- LSTM - \\(s\\): Long Short-Term Memory model with a specific setting denoted by \"s\".\n- CKBG (Saito et al., 2018): A model or method by Saito et al. from 2018.\n- COMET variants: These include COMET with various settings like no pretraining (- pretrain), RELTOK, and a base version without additional specifications.\n\nThe table highlights in bold the best performance under each column. Notably, the COMET model (without any specific variant label) shows superior performance across most metrics, including the lowest perplexity (4.32), highest score (95.25), and closest approximation to human performance (91.69)."}
{"layout": 77, "type": "text", "text": " $o r\\,\\rightarrow\\,s$   to help augment a knowledge base com- pletion model. It is only evaluated on the    $s r\\rightarrow o$  tuple generation task, however. For posterity, we also include the result from a LSTM model that is only trained on the    $s r\\rightarrow o$   task (LSTM -  s ). ", "page_idx": 6, "bbox": [306, 170.96998596191406, 527, 238.31246948242188], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 78, "type": "text", "text": "Ablations We include the following ablations of our full model. First, we evaluate how pre- training on a large-scale corpus ( Radford et al. , 2018 ) helps performance by training a comparison model from scratch, denoted  COMET  (- pretrain) in Table  6 . Second, in our main model, we map relation names to natural language (e.g.,    $\\tt T S\\bar{A}\\rightarrow$  “is a”;  HasSubevent  $\\rightarrow$  “has subevent”) so the model can learn to represent these concepts with language, as opposed to learning a special embed- ding from scratch for each relation ( Levy et al. , 2017 ). As an ablation, we train a model with- out converting relation tokens to natural language (e.g.,  $\\tt I S\\tt A\\ne$ “is a”), which we denote COMET -R EL T OK . ", "page_idx": 6, "bbox": [306, 245.3232879638672, 527, 448.5495910644531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 79, "type": "text", "text": "5.2 Results ", "text_level": 1, "page_idx": 6, "bbox": [307, 457, 366, 469], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 80, "type": "text", "text": "Quality Our results indicate that high-quality knowledge can be generated by the model: the low perplexity scores in Table  6  indicate high model conﬁdence in its predictions, while the high clas- siﬁer score   $(95.25\\%)$   indicates that the KB com- pletion model of  Li et al.  ( 2016 ) scores the gener- ated tuples as correct in most of the cases. While adversarial generations could be responsible for this high score, a human evaluation (following the same design as for A TOMIC ) scores   $91.7\\%$   of greedily decoded tuples as correct. Randomly se- lected examples provided in Table  7  also point to the quality of knowledge produced by the model. ", "page_idx": 6, "bbox": [306, 474.5093994140625, 527, 650.6386108398438], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 81, "type": "text", "text": "Novelty In addition to being high quality, the generated tuples from  COMET  are also novel, with  $59.25\\%$   of the tuples not being present in the train- ing set, showing that the model is capable of gen- erating new edges between nodes, and even cre- ating new nodes –   $3.75\\%$   of    $o$   nodes are novel – to extend the size of the knowledge graph. One shortcoming, however, is that novel generations ", "page_idx": 6, "bbox": [306, 657.6484375, 527, 766.0316162109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 82, "type": "image", "page_idx": 7, "img_path": "layout_images/P19-1470_9.jpg", "img_caption": "Figure 4: The percentage of novel ConceptNet de- velopment set tuples per minimum edit distance from training tuples. In green: classiﬁer-scored accuracy of each subset. ", "bbox": [70, 64, 293, 249], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "=X\n\n% of tuples with edit distance >:\n\n75%\n\n50%\n\n25%\n\n0%\n\n100% b ———_ 1.00\n% of novel tuples\n@ Accuracy\n0.33 0.5 0.67 1.0\n\n0.0\n\nEdit Distance\n\n0.75\n\n0.50\n\n0.25\n\n0.00\n\nClassifier Accuracy\n", "vlm_text": "The image is a graph showing two curves. The x-axis represents the edit distance, ranging from 0 to 1. The y-axis on the left represents the percentage of novel tuples with an edit distance greater than or equal to a given value, while the y-axis on the right represents classifier accuracy.\n\n- The blue shaded area indicates the percentage of novel ConceptNet development set tuples for different minimum edit distances from the training tuples, with percentages ranging from 0% to 100%.\n- The green line represents the classifier's accuracy for each subset of the tuples at different edit distances, with accuracy values ranging from 0.5 to 1.0.\n\nThe graph shows that as the edit distance increases, the percentage of novel tuples generally decreases, and the classifier's accuracy remains high, close to 100%, but slightly decreases as the edit distance increases."}
{"layout": 83, "type": "text", "text": "are sometimes simpliﬁed forms of tuples from the training set. In Table  7 , for example, the tuple “doctor  CapableOf  save life” is not present in the training set, but “doctor  CapableOf  save person life” is. Many tuples, however, are com- pletely novel, such as “bird bone  HasProperty fragile” and “driftwood  AtLocation  beach”, which have no related tuples in the training set. ", "page_idx": 7, "bbox": [71, 270.93408203125, 290, 378.9245910644531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 84, "type": "text", "text": "To explore further, we investigate by how much novel tuples from the development set differ from training set phrase objects for the same    $s,r$   using minimum edit distance of phrase objects. We mea- sure the edit distance of phrase object    $o_{d e v}$   in the tuple    $(s,r,o_{d e v})$   to the  $o_{t r n}$   from the nearest train- ing tuple    $(s,r,o_{t r n})$  . Edit distance is measured us- ing word tokens (excluding stop words) and nor- malized by the maximum number of words in  $o_{d e v}$  or    $o_{t r n}$  . The maximum edit distance is one (i.e., entirely different word sequences) and the mini- mum edit distance is zero (i.e., the same sequence excluding stopwords). Figure  4  shows the percent- age of novel development set tuples that have an edit distance from the closest training set tuple of at least the value on the   $\\mathbf{X}$  -axis. Over  $75\\%$   of the novel tuples have objects that are a normalized edit distance of    $>=0.5$   from the training phrase ob- jects, indicating that most of the novel phrase ob- jects have signiﬁcantly different word sequences from their closest analogues in the training set. ", "page_idx": 7, "bbox": [71, 379.4101257324219, 290, 663.5396728515625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 85, "type": "text", "text": "Learning knowledge from language Simi- larly to A TOMIC , we explore how pre-training COMET on a large language corpus affects its ability to generalize commonsense. This effect is apparent in Table  6 , with a clear improve- ment on automatic and human evaluations by the pretrained  COMET  over the randomly initialized ", "page_idx": 7, "bbox": [71, 671.1985473632812, 290, 766.686279296875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 86, "type": "table", "page_idx": 7, "img_path": "layout_images/P19-1470_10.jpg", "bbox": [307, 61, 526, 319], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Seed\n\npiece\nbread\noldsmobile\nhappiness\nmath\nmango\nmaine\nplanet\ndust\npuzzle\ncollege\ndental chair\nfinger\n\nsing\ndoctor\npost office\ndove\n\nsun\n\nbird bone\nearth\n\nyard\n\nget pay\nprint on printer\nplay game\nlive\n\nswim\n\nsit down\nall paper\nchair\n\nearth\n\nRelation\n\nPartOf\n\nIsA\n\nIsA\n\nIsA\n\nIsA\n\nIsA\n\nIsA\n\nAtLocation\nAtLocation\nAtLocation\nAtLocation\nAtLocation\nAtLocation\nCauses\nCapableOf\nCapableOf\nSymbol0f\nHasProperty\nHasProperty\nHasA\n\nUsedFor\nHasPrerequisite\nHasPrerequisite\nHasPrerequisite\nHasLast Subevent\nHasSubevent\n\nMot ivatedByGoal\nReceivesAction\nMadeoft\nDefinedAs\n\nCompletion\n\nmachine\nfood\n\ncar\n\nfeel\nsubject\nfruit\n\nstate\n\nspace\nfridge\nyour mind\ntown\ndentist\nyour finger\nyou feel good\nsave life\nreceive letter\npurity\n\nbig\n\nfragile\nmany plant\nplay game\nwork\n\nget printer\nhave game\ndie\n\nget wet\nyou be tire\nrecycle\nwood\nplanet\n\nPlausible\n\nKKK KKK KKK AK ASK SASK SAB SASK SKA KAS\n\n", "vlm_text": "The table consists of four columns: Seed, Relation, Completion, and Plausible. Here's a breakdown of its contents:\n\n1. **Seed**: Represents the initial concept or item.\n2. **Relation**: Describes the relationship between the Seed and the Completion.\n3. **Completion**: Provides the outcome or associated concept related to the Seed.\n4. **Plausible**: Indicates whether the relationship is considered plausible (✓), not plausible (X), or uncertain (🤔).\n\nExamples include:\n- \"piece\" is a \"PartOf\" a \"machine\" and is plausible (✓).\n- \"bread\" is an \"IsA\" \"food\" and is plausible (✓).\n- \"puzzle\" is \"AtLocation\" \"your mind\" with uncertain plausibility (🤔).\n\nSeveral different types of relationships are shown, such as \"IsA,\" \"AtLocation,\" \"Causes,\" \"CapableOf,\" \"SymbolOf,\" \"HasProperty,\" \"UsedFor,\" \"HasPrerequisite,\" \"HasSubevent,\" \"MotivatedByGoal,\" \"ReceivesAction,\" \"MadeOf,\" and \"DefinedAs.\""}
{"layout": 87, "type": "text", "text": "model. Qualitatively, we observe this effect in Ta- ble  7  with the generated example tuple “mango IsA  fruit\", which is not present in the training set. The only tuple containing the “mango\" entity in the training set is “mango  UsedFor  salsa\", which is not informative enough. As conﬁrmation, we observe that the output from  COMET  (- pretrain) is “mango  IsA  spice”, which could be a reasonable inference given the information about “mango\" in the seed set of knowledge. ", "page_idx": 7, "bbox": [307, 412.73193359375, 525, 547.8194580078125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 88, "type": "text", "text": "Representing relations with language While the automatic metrics point to insigniﬁcant differ- ences when comparing models with symbol re- lations and those with natural language relations (Table  6 ), examples can provide qualitative in- sights into the beneﬁts of representing relations as language. While the only non-ornithological ref- erence to a “dove\" in the ConceptNet training set is “dove  CapableOf  ﬂy”, our model learns to generalize to produce the tuple “dove  SymbolOf purity”. The model that uses symbol relation em- beddings only manages to produce the relation “dove  SymbolOf  submarine”, which seems to relate “submarine\" to a more nautical (and unre- lated) word sense of “dove\". ", "page_idx": 7, "bbox": [307, 562.8043212890625, 525, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 89, "type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 8, "bbox": [71, 63, 161, 75], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 90, "type": "text", "text": "Knowledge base construction Previous work has looked at constructing knowledge bases as re- lational schemas using expert knowledge ( Lenat , 1995 ;  Bodenreider ,  2004 ;  Miller ,  1995 ), semi- structured text extraction ( Suchanek et al. ,  2007 ; Hoffart et al. ,  2013 ;  Auer et al. ,  2007 ;  Bol- lacker et al. ,  2008 ) and unstructured text extraction ( Dong et al. ,  2014 ;  Carlson et al. ,  2010 ;  Nakashole et al. ,  2011 ,  2012 ;  Niu ,  2012 ). In our work, we fo- cus on construction of commonsense knowledge bases which require the use of open-text events rather than a well-deﬁned relational schema struc- ture. Other work in information extraction can also be applied to knowledge base construction with open-text entities ( Soderland et al. ,  2010 ;  Et- zioni et al. ,  2011 ;  Fader et al. ,  2011 ;  Mausam et al. , 2012 ;  Fan et al. ,  2010 ;  Cui et al. ,  2018 ), but these methods typically extract explicitly stated text re- lations. Conversely, our approach generates new knowledge that is often unstated in text, as com- monsense information typically is ( Gordon and Van Durme ,  2013 ). ", "page_idx": 8, "bbox": [72, 85.04930114746094, 290, 383.1216125488281], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 91, "type": "text", "text": "Commonsense knowledge base completion Existing work on generation of novel common- sense knowledge has also used ConceptNet and A TOMIC  as underlying KBs. Speciﬁcally,  Li et al. ( 2016 ) proposed a set of neural network models for scoring tuples in ConceptNet. Our work differs from this approach as their models evaluate full tu- ples rather than learning to generate the phrases to make new nodes in the knowledge graph.  Saito et al.  ( 2018 ) builds upon this work by proposing a joint model for completion and generation of com- monsense tuples. Their work, however, focuses on using tuple generation to augment their KB com- pletion model, rather than to increase coverage in commonsense KB construction. Finally,  Sap et al. ( 2019 ) use LSTM encoder-decoder models to gen- erate commonsense knowledge about social situa- tions. We use transformers and investigate the ef- fect of using pre-trained language representations ( Radford et al. ,  2018 ) to initialize them. ", "page_idx": 8, "bbox": [72, 391.67340087890625, 290, 662.6456298828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 92, "type": "text", "text": "Transformers and pre-training Finally, our work builds on previous work on adapting pre- trained language models for various sequence la- beling, classiﬁcation, and NLI end tasks ( Rad- ford et al. ,  2018 ;  Peters et al. ,  2018 ;  Devlin et al. , 2018 ). Our research investigates how pre-trained language models can be used for large-scale com- monsense KB construction by generating new graph nodes and edges between nodes. ", "page_idx": 8, "bbox": [72, 671.197509765625, 290, 766.0316162109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 93, "type": "text", "text": "", "page_idx": 8, "bbox": [307, 63.68720245361328, 525, 90.38168334960938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 94, "type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 8, "bbox": [306, 102, 383, 116], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 95, "type": "text", "text": "We introduce COMmonsense Transformers ( COMET ) for automatic construction of common- sense knowledge bases.  COMET  is a framework for adapting the weights of language models to learn to produce novel and diverse common- sense knowledge tuples. Empirical results on two commonsense knowledge bases, A TOMIC and ConceptNet, show that  COMET frequently produces novel commonsense knowledge that human evaluators deem to be correct. These positive results point to future work in extend- ing the approach to a variety of other types of knowledge bases, as well as investigating whether COMET can learn to produce OpenIE-style knowledge tuples for arbitrary knowledge seeds. ", "page_idx": 8, "bbox": [307, 126.24018096923828, 525, 329.0747375488281], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 96, "type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 8, "bbox": [307, 342, 401, 355], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 97, "type": "text", "text": "We thank Thomas Wolf, Ari Holtzman, Chandra Bhagavatula, Peter Clark, Rob Dalton, Ronan Le Bras, Rowan Zellers and Scott Yih for helpful dis- cussions over the course of this project, as well as the anonymous reviewers for their insightful com- ments. This research was supported in part by NSF (IIS-1524371, IIS-1714566, NRI-1525251), DARPA under the CwC program through the ARO (W911NF-15-1-0543), and Samsung Research. This material is based, in part, upon work sup- ported by the National Science Foundation Gradu- ate Research Fellowship Program under Grant No. DGE-1256082. ", "page_idx": 8, "bbox": [307, 364.9322814941406, 525, 540.6678466796875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 98, "type": "text", "text": "References ", "text_level": 1, "page_idx": 8, "bbox": [307, 566, 363, 579], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 99, "type": "text", "text": "Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary G. Ives. 2007. Dbpedia: A nucleus for a web of open data. In  ISWC/ASWC . Jimmy Ba, Ryan Kiros, and Geoffrey E. Hinton. 2016. Layer normalization.  CoRR , abs/1607.06450. Olivier Bodenreider. 2004.  The uniﬁed medical lan- guage system (umls): Integrating biomedical termi- nology .  Nucleic acids research , 32:D267–70. Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information.  Transactions of the Associa- tion for Computational Linguistics , 5:135–146. ", "page_idx": 8, "bbox": [307, 586.6199340820312, 525, 765.764892578125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 100, "type": "text", "text": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008.  Freebase: A col- laboratively created graph database for structuring human knowledge . In  Proceedings of the 2008 ACM SIGMOD International Conference on Man- agement of Data , SIGMOD ’08, pages 1247–1250, New York, NY, USA. ACM. Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka, Jr., and Tom M. Mitchell. 2010.  Toward an architecture for never- ending language learning . In  Proceedings of the Twenty-Fourth AAAI Conference on Artiﬁcial Intel- ligence , AAAI’10, pages 1306–1313. AAAI Press. Lei Cui, Furu Wei, and Ming Zhou. 2018. Neural open information extraction. In  ACL . Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understand- ing.  arXiv preprint arXiv:1810.04805 . Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowl- edge fusion . In  Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’14, pages 601– 610, New York, NY, USA. ACM. Oren Etzioni, Anthony Fader, Janara Christensen, Stephen Soderland, and Mausam. 2011. Open infor- mation extraction: The second generation. In  IJCAI . Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information ex- traction. In  Proceedings of the conference on empir- ical methods in natural language processing , pages 1535–1545. Association for Computational Linguis- tics. James Fan, David A. Ferrucci, David Gondek, and Aditya Kalyanpur. 2010. Prismatic: Inducing knowledge from a large scale lexicalized relation re- source. In  NAACL-HLT 2010 . Jonathan Gordon and Benjamin Van Durme. 2013. Re- porting bias and knowledge acquisition. In  Proceed- ings of the 2013 workshop on Automated knowledge base construction , pages 25–30. ACM. Dan Hendrycks and Kevin Gimpel. 2016. Bridging nonlinearities and stochastic regularizers with gaus- sian error linear units.  CoRR , abs/1606.08415. Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory.  Neural Computation , 9(8). Johannes Hoffart, Fabian M. Suchanek, Klaus Berberich, and Gerhard Weikum. 2013.  Yago2: A spatially and temporally enhanced knowledge base from wikipedia . Artiﬁcial Intelligence , 194:28 – 61. Artiﬁcial Intelligence, Wikipedia and Semi- Structured Resources. ", "page_idx": 9, "bbox": [71, 64.56158447265625, 290, 765.7650756835938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 101, "type": "text", "text": "Sture Holm. 1979. A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics , 6(2):65–70. Douglas B Lenat. 1995. Cyc: A large-scale investment in knowledge infrastructure.  Communications of the ACM , 38(11):33–38. Omer Levy, Minjoon Seo, Eunsol Choi, and Luke S. Zettlemoyer. 2017. Zero-shot relation extraction via reading comprehension. In  CoNLL . Xiang Li, Aynaz Taheri, Lifu Tu, and Kevin Gimpel. 2016. Commonsense knowledge base completion. In  ACL , volume 1, pages 1445–1455. Mausam, Michael Schmitz, Stephen Soderland, Robert Bart, and Oren Etzioni. 2012. Open language learn- ing for information extraction. In  EMNLP-CoNLL . George A. Miller. 1995.  Wordnet: A lexical database for english .  Commun. ACM , 38(11):39–41. Ndapandula Nakashole, Martin Theobald, and Gerhard Weikum. 2011.  Scalable knowledge harvesting with high precision and high recall . In  Proceedings of the Fourth ACM International Conference on Web Search and Data Mining , WSDM ’11, pages 227– 236, New York, NY, USA. ACM. Ndapandula Nakashole, Gerhard Weikum, and Fabian Suchanek. 2012.  Patty: A taxonomy of relational patterns with semantic types . In  Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning , pages 1135–1145. As- sociation for Computational Linguistics. Feng Niu. 2012.  Web-scale Knowledge-base Construc- tion via Statistical Inference and Learning . Ph.D. thesis, Madison, WI, USA. AAI3524067. Eric W Noreen. 1989.  Computer intensive methods for hypothesis testing: An introduction.  Wiley, NY. Jeffrey Pennington, Richard Socher, and Christo- pher D. Manning. 2014. Glove: Global vectors for word representation. In  EMNLP . Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matthew Gardner, Christopher Clark, Kenton Lee, and Luke S. Zettlemoyer. 2018. Deep contextual- ized word representations.  CoRR , abs/1802.05365. Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language under- standing by generative pre-training.  URL https://s3- us-west-2. amazonaws. com/openai-assets/research- covers/language unsupervised/language under- standing paper. pdf . Itsumi Saito, Kyosuke Nishida, Hisako Asano, and Junji Tomita. 2018. Commonsense knowledge base completion and generation. In  Proceedings of the 22nd Conference on Computational Natural Lan- guage Learning , pages 141–150. ", "page_idx": 9, "bbox": [307, 64.5611572265625, 525, 765.7647094726562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 102, "type": "text", "text": "Maarten Sap, Ronan LeBras, Emily Allaway, Chan- dra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A Smith, and Yejin Choi. 2019. Atomic: An atlas of machine commonsense for if- then reasoning. In  AAAI . Stephen Soderland, Brendan Roof, Bo Qin, Shi Xu, Mausam, and Oren Etzioni. 2010. Adapting open information extraction to domain-speciﬁc relations. AI Magazine , 31:93–102. Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In  Thirty-First AAAI Confer- ence on Artiﬁcial Intelligence . Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007.  Yago: A core of semantic knowl- edge . In  Proceedings of the 16th International Con- ference on World Wide Web , WWW ’07, pages 697– 706, New York, NY, USA. ACM. Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural net- works. In  Advances in Neural Information Process- ing Systems . Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In  NIPS . ", "page_idx": 10, "bbox": [71, 64.56158447265625, 290, 395.37115478515625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 103, "type": "text", "text": "A Additional Training Details ", "text_level": 1, "page_idx": 11, "bbox": [72, 64, 233, 76], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 104, "type": "text", "text": "A.1 Training Hyperparameters ", "text_level": 1, "page_idx": 11, "bbox": [71, 86, 225, 99], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 105, "type": "text", "text": "A TOMIC For A TOMIC , we use a maximum learning rate of 6.25e-5 with a warmup period of 100 minibatches. After, we decay the learn- ing rate linearly until the end of training. We train for   $50\\mathrm{k}$   minibatches and use early stopping. We clip gradients when their norm is greater than 1. The remainder of our hyperparameters are the same as in  Radford et al.  ( 2018 ). We use the public HuggingFace implementation of the GPT model as a base for our experiments available at:  https://github.com/huggingface/ pytorch-openai-transformer-lm . ", "page_idx": 11, "bbox": [72, 102.77830505371094, 290, 265.3575744628906], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 106, "type": "text", "text": "ConceptNet For ConceptNet, we use a maxi- mum learning rate of 1e-5 and a warm-up period of 200 minibatches. The learning rate is decayed linearly until the end of training, which lasts for 100k minibatches. All other hyperparameters are the same as for training on the A TOMIC  corpus. ", "page_idx": 11, "bbox": [72, 273.5823669433594, 290, 354.8666076660156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 107, "type": "text", "text": "A.2 ConceptNet baseline ", "text_level": 1, "page_idx": 11, "bbox": [72, 366, 194, 377], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 108, "type": "text", "text": "We train the ConceptNet baseline with a learning rate of 1e-4 for  $100\\mathbf{k}$   minibatches. Early stopping is used with the validation loss. Similarly to  Saito et al.  ( 2018 ), we use 200-dimension hidden states and 200-dimensional word embeddings. We use a single-layer bidirectional LSTM ( Hochreiter and Schmidhuber ,  1997 ) to encode the ﬁrst phrase and a single-layer unidirectional LSTM to decode the target phrase. Relation embeddings are concate- nated with the word embeddings of the decoder before being input to the decoder LSTM. We set the dropout rate to 0.2 before the output projection layer and after the word embedding layers. We outline the following differences between our re- implementation of the model of  Saito et al.  ( 2018 ) and their original implementation and the reason for the change. ", "page_idx": 11, "bbox": [72, 382.91912841796875, 290, 612.8516845703125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 109, "type": "text", "text": "1. We use Glove ( Pennington et al. ,  2014 ) em- beddings rather than fastText embeddings ( Bojanowski et al. ,  2017 ) to initialize word embeddings. Because the model indicated that 200-dimensional word embeddings were used, we could not use the pretrained em- beddings provided by the fastText group 1 . In  Saito et al.  ( 2018 ), the authors de- scribed training their fastText embeddings on ", "page_idx": 11, "bbox": [80.65501403808594, 624.3212280273438, 290, 745.8606567382812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 110, "type": "text", "text": "Wikipedia. With no reference to the precise corpus used, we opted to use Glove embed- dings to initialize the word embeddings of the encoder and decoder instead. ", "page_idx": 11, "bbox": [329, 63.68701934814453, 526, 117.48049926757812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 111, "type": "text", "text": "2. We use the Adam optimizer with learning rate of 0.0001, rather than SGD with a learn- ing rate of 1.0 because after training both models, we found that the Adam-trained model performed better on development set perplexity. We also do not use weight de- cay, as this seemed to lower validation per- formance, as well. ", "page_idx": 11, "bbox": [315, 126.67005157470703, 526, 234.65957641601562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 112, "type": "text", "text": "3. We do not train the generation model jointly with the completion model. We only train an individual generator. The results of  Saito et al.  ( 2018 ) did not show a signiﬁcant differ- ence in generation performance between the two on the ConceptNet dataset. ", "page_idx": 11, "bbox": [315, 243.8480987548828, 526, 324.7395935058594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 113, "type": "text", "text": "4. We train a second baseline   $(\\operatorname{LSTM}\\cdot\\,s)$   that does not learn to produce relations in both di- rections (i.e.,    $s r\\rightarrow o$   and  $o r\\rightarrow s$  ). Instead if only learns parameters that can produce rela- tions in the forward direction (  $\\acute{\\left(s r\\rightarrow o\\right)}$  ) ", "page_idx": 11, "bbox": [315, 333.9291076660156, 526, 401.2716064453125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 114, "type": "text", "text": "5. We do not decay the learning rate because it was unclear from the original paper what the exact learning rate schedule was. ", "page_idx": 11, "bbox": [315, 410.46014404296875, 526, 450.7046203613281], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 115, "type": "text", "text": "B Additional Evaluation Details ", "text_level": 1, "page_idx": 11, "bbox": [306, 471, 479, 483], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 116, "type": "text", "text": "B.1 Human Evaluations ", "text_level": 1, "page_idx": 11, "bbox": [306, 493, 427, 503], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 117, "type": "text", "text": "We used Amazon Mechanical Turk to get ratings of model output accuracy. We selected seed con- cepts and relations from the test set and generated completions using each model to create    $(s,r,o)$  tuples. For A TOMIC , we selected tuples by choos- ing all possible relations (9) for each of 100 ran- domly selected seed concepts (900 total    $(s,r)$  pairs) following the procedure from  Sap et al.\n\n ( 2019 ). For ConceptNet, we used the full test set\n\n (1200 total    $(s,r)$   pairs). ", "page_idx": 11, "bbox": [307, 509.00018310546875, 526, 644.088623046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 118, "type": "text", "text": "For Beam-2/5/10 and top-5/10 sampling gener- ations, we used the model to generate 2, 5, or 10 (respectively) possible completions   $(o)$   per    $(s,r)$  pair. Workers were shown the full set and asked to select all of the    $o$   that are valid completions for the    $(s,r)$   pair. Each set of tuples was rated by 5 workers. ", "page_idx": 11, "bbox": [307, 644.4921264648438, 526, 738.9326171875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 119, "type": "text", "text": "For greedy sampling generations, we used the model to generate one possible completion   $(o)$   per  $(s,r)$   pair. Workers were shown the completed tu- ple    $(s,r,o)$   and asked whether it is valid or not. Each tuple was rated by 5 workers. ", "page_idx": 11, "bbox": [307, 739.337158203125, 526, 766.0316162109375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 120, "type": "text", "text": "", "page_idx": 12, "bbox": [71, 63.68701934814453, 290, 103.93148803710938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 121, "type": "text", "text": "We measure accuracy as the percentage of dis- tinct worker responses where the    $(s,r,o)$   tuple is marked as valid (i.e.,  $\\frac{\\#v a l i d}{5\\cdot|\\left(s,r,o\\right)|})$  ). ·| | ", "page_idx": 12, "bbox": [71, 104.50598907470703, 290, 153.200439453125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 122, "type": "text", "text": "C Example Outputs ", "text_level": 1, "page_idx": 12, "bbox": [71, 157, 184, 172], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 123, "type": "text", "text": "Additional examples can be seen in Figures  5 , 6 , and  7  that are produced using the demo at https://mosaickg.apps.allenai. org . ", "page_idx": 12, "bbox": [71, 178.48097229003906, 290, 232.27444458007812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 124, "type": "text", "text": "D Additional Training Experiments ", "text_level": 1, "page_idx": 12, "bbox": [71, 243, 264, 257], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 125, "type": "text", "text": "In addition to the more naive setups for knowl- edge graph completion, we explore various multi- task and hierarchical learning setups on top of the taxonomy of commonsense relations given by  Sap et al.  ( 2019 ), which group together along vari- ous axes (e.g., related to agent/theme, related to causes/effects, etc.). ", "page_idx": 12, "bbox": [71, 264.82293701171875, 290, 359.2634582519531], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 126, "type": "text", "text": "generating a phrase for a  xWant  relation would receive the    $<\\!\\mathrm{X}\\!>$   and    $\\scriptstyle<\\operatorname{POST>}$   tokens as input, but not  <Involuntary  $>$  ). Depending on the relation for a particular training example (e.g., xReact ), a set of meta-tokens are appended to the relation tokens,    $X^{r}$  , that provide hierarchi- cal relational information, allowing the model to share information across relation types. We pro- vide a more in-depth description of the category hierarchy training combinations in Table  10 . Re- sults on human evaluation metrics are provided in Table  12 . Because the model with the hierarchi- cal meta-tokens performed worse than the regular COMET , we did not run additional experiments on this ablations. ", "page_idx": 12, "bbox": [307, 63.68708038330078, 525, 266.5216369628906], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 127, "type": "text", "text": "D.1 Multi-relation Training ", "text_level": 1, "page_idx": 12, "bbox": [71, 369, 209, 382], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 128, "type": "text", "text": "For the A TOMIC  corpus, we experiment with mul- tiple multi-task training setups, similar to  Sap et al. ( 2019 ). First, we train an individual model for each relation type ( oReact, oEffect , etc.), which we denote as  COMET  - 9LM in the Table  9 . We also experiment with various information- sharing dataset conﬁgurations that organize differ- ent relations across common dimensions. We out- line these dimensions and the makeup of each split in Table  9 . For ConceptNet, all models are always trained on all relation types jointly. Results on automatic evaluation metrics are provided in Ta- ble  11 . Because there did not seem to be signif- icant differences between these performances and that of  COMET  - F ULL , we did not run additional experiments on these ablations. ", "page_idx": 12, "bbox": [71, 386.9119873046875, 290, 603.2955322265625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 129, "type": "text", "text": "D.2 Concept Hierarchy Training ", "text_level": 1, "page_idx": 12, "bbox": [71, 613, 232, 626], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 130, "type": "text", "text": "Leveraging the prior knowledge that certain re- lation types in the A TOMIC  knowledge graph are linked to each other, we explore provid- ing these group identities as additional tokens in the relation. For example, when generating the completion of a  xReact  relation, the model would receive as input the following meta-tokens:\n\n <xReact> ,    $<\\!\\mathrm{X}\\!>$  ,    $\\scriptstyle<\\operatorname{POST>}$  ,  <Involuntary>\n\n – thereby providing common context with other relations that are part of the same groupings (e.g., ", "page_idx": 12, "bbox": [71, 630.9430541992188, 290, 766.031494140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 131, "type": "image", "page_idx": 13, "img_path": "layout_images/P19-1470_11.jpg", "img_caption": "Figure 5: Example outputs for the event \"PersonX gives PersonY a pep talk\" from  COMET  trained on the A TOMIC knowledge graph ", "bbox": [71, 136, 526, 688], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "PersonX gives PersonY a pep talk\n\nCauses for PersonX\n\nAttributes of PersonX\n\nEffects on PersonX\n\nEffects on others\n\nBecause PersonX wanted\n\nBefore, PersonX needed\n\nPersonX is seen as\n\nAs a result, PersonX feels\n\nAs a result, PersonX wants\n\nPersonX then\n\nAs aresult, others feel\n\nAs a result, others want\n\nOthers then\n\nto be helpful\n\nto be a leader\n\nto inform\n\nto help persony\n\nto be a good friend\n\nto be with persony\nto be a leader\n\nto be a teacher\n\nto know persony\nnone\n\nhelpful\nsmart\nconfident\nleader\ninformative\n\nhelpful\ngood\nhappy\nsatisfied\nrelieved\n\nto be a leader\n\nto make sure they understand\n\nto make persony understand\n\nto give persony a lecture\n\nto make sure persony understands\n\ngets yelled at\n\ngets tired\n\nnone\n\npersonx gets yelled at\npersonx is listened to\n\ngrateful\nnone\ninformed\ngood\nannoyed\n\nto thank personx\nto listen to personx\nto listen\n\nto get better\n\nnone\n\nlistens to personx\nlearns something new\nlearns something\nnone\n\nlistens\n", "vlm_text": "The image is a diagram showing potential outcomes and attributes related to the event \"PersonX gives PersonY a pep talk,\" based on the COMET model trained on the ATOMIC knowledge graph. The diagram is structured as follows:\n\n1. **Causes for PersonX:**\n   - Because PersonX wanted:\n     - To be helpful\n     - To be a leader\n     - To inform\n     - To help PersonY\n     - To be a good friend\n   - Before, PersonX needed:\n     - To be with PersonY\n     - To be a leader\n     - To be a teacher\n     - To know PersonY\n     - None\n\n2. **Attributes of PersonX:**\n   - PersonX is seen as:\n     - Helpful\n     - Smart\n     - Confident\n     - Leader\n     - Informative\n\n3. **Effects on PersonX:**\n   - As a result, PersonX feels:\n     - Helpful\n     - Good\n     - Happy\n     - Satisfied\n     - Relieved\n   - As a result, PersonX wants:\n     - To be a leader\n     - To make sure they understand\n     - To make PersonY understand\n     - To give PersonY a lecture\n     - To make sure PersonY understands\n   - PersonX then:\n     - Gets yelled at\n     - Gets tired\n     - None\n     - PersonX gets yelled at\n     - PersonX is listened to\n\n4. **Effects on Others:**\n   - As a result, others feel:\n     - Grateful\n     - None\n     - Informed\n     - Good\n     - Annoyed\n   - As a result, others want:\n     - To thank PersonX\n     - To listen to PersonX\n     - To listen\n     - To get better\n     - None\n   - Others then:\n     - Listen to PersonX\n     - Learn something new\n     - Learn something\n     - None\n     - Listen\n\nThis diagram illustrates the potential causes, perceptions, effects, and actions resulting from the event of giving a pep talk."}
{"layout": 132, "type": "image", "page_idx": 14, "img_path": "layout_images/P19-1470_12.jpg", "img_caption": "Figure 6: Example outputs for the event \"Eric wants to see a movie\" from  COMET  trained on the A TOMIC  knowl- edge graph.  COMET  is able to generalize beyond the templates of the A TOMIC  knowledge graph (i.e., PersonX) and can be used directly with names. ", "bbox": [71, 100, 527, 722], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Eric wants to see a movie\n\nCauses for PersonX\n\nAttributes of PersonX\n\nEffects on PersonX\n\nEffects on others\n\nBecause PersonX wanted\n\nBefore, PersonX needed\n\nPersonX is seen as\n\nAs a result, PersonX feels\n\nAs a result, PersonX wants\n\nPersonX then\n\nAs a result, others feel\n\nAs a result, others want\n\nOthers then\n\nto be entertained\nto have fun\n\nto watch a movie\nto see a movie\nentertainment\n\nto have money\n\nto get tickets\n\nto go to the theater\nnone\n\nmoney\n\ncurious\nbored\ninterested\nexcited\nfun\n\nhappy\nentertained\nexcited\nsatisfied\nrelaxed\n\nbuy a ticket\n\ngo to the theater\ngo to theater\n\nto buy a ticket\n\nto go to the theater\n\nbuys a ticket\n\ngoes to theater\ngoes to the theater\ngets bored\n\nnone\n\nnone\nhappy\nentertained\nexcited\nsatisfied\n\nnone\nto have fun\n\nto go home\n\nto watch the movie\nto go to the movie\n\nnone\nreviews the movie\nthey watch the movi\nreviews movie\n\nthey go to the theat«\n", "vlm_text": "The image is a diagram representing various inferred outcomes and states related to the event \"Eric wants to see a movie.\" This diagram is created using the COMET model trained on the ATOMIC knowledge graph. It illustrates different causal and associative relationships stemming from the event. The categories include:\n\n1. **Causes for PersonX**: \n   - Why PersonX (Eric) wanted to see a movie (e.g., to be entertained, to have fun).\n   - What PersonX needed beforehand (e.g., to have money, to get tickets).\n\n2. **Attributes of PersonX**:\n   - How PersonX is perceived by others (e.g., curious, bored, interested).\n\n3. **Effects on PersonX**:\n   - How PersonX feels as a result (e.g., happy, entertained, excited).\n   - What PersonX might want to do as a result (e.g., buy a ticket, go to the theater).\n   - Immediate actions PersonX might take (e.g., buys a ticket, goes to the theater).\n\n4. **Effects on Others**:\n   - How others feel as a result (e.g., happy, entertained, excited).\n   - What others might want as a result (e.g., to have fun, to go home).\n   - Immediate actions others might take (e.g., reviews the movie, goes to the theater).\n\nThe diagram demonstrates COMET's ability to generalize and predict potential outcomes and attributes related to a specific event by applying the ATOMIC knowledge graph's structure."}
{"layout": 133, "type": "image", "page_idx": 15, "img_path": "layout_images/P19-1470_13.jpg", "img_caption": "Figure 7: Example outputs for the event \"Tom asked Jessica if he could use her car\" from  COMET  trained on the A TOMIC  knowledge graph ", "bbox": [71, 115, 527, 713], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Tom asked Jessica if he could use her car\n\nCauses for PersonX\n\nAttributes of PersonX\n\nEffects on PersonX\n\nEffects on others\n\nBecause PersonX wanted\n\nBefore, PersonX needed\n\nPersonX is seen as\n\nAs a result, PersonX feels\n\nAs a result, PersonX wants\n\nPersonX then\n\nAs a result, others feel\n\nAs a result, others want\n\nOthers then\n\nto borrow a car\n\nto have transportatio\nto have a ride\n\nto go to the store\n\nto go to a party\n\nto have a car\n\nto find a car\n\nnone\n\nto ask her permissior\nto find her car\n\nneedy\nhopeful\ndependent\ncurious\ndesperate\n\nrelieved\ngrateful\nhappy\nsatisfied\nthankful\n\nto borrow a car\n\nto drive to the store\nto get a ride\n\nto go to the store\nto ask for a ride\n\ngets rejected\nnone\n\ngets yelled at\ngets denied\ngets a ride\n\nnone\nhelpful\ngrateful\nhappy\nflattered\n\nto say no\n\nto help him\n\nto get their car back\nnone\n\nto go to the store\n\nnone\nsays no\n\nno effect\n\ngets into trouble\nsays yes\n", "vlm_text": "The image is a knowledge graph depicting various inferred outcomes and perceptions related to the event \"Tom asked Jessica if he could use her car.\" It is generated by COMET, trained on the ATOMIC knowledge graph, and is structured to show nodes branching into different categories:\n\n1. **Causes for PersonX (Tom)**:\n   - Because PersonX wanted: to borrow a car, to have transportation, to have a ride, to go to the store, to go to a party.\n   - Before, PersonX needed: to have a car, to find a car, none, to ask her permission, to find her car.\n\n2. **Attributes of PersonX**:\n   - PersonX is seen as: needy, hopeful, dependent, curious, desperate.\n\n3. **Effects on PersonX**:\n   - As a result, PersonX feels: relieved, grateful, happy, satisfied, thankful.\n   - As a result, PersonX wants: to borrow a car, to drive to the store, to get a ride, to go to the store, to ask for a ride.\n   - PersonX then: gets rejected, none, gets yelled at, gets denied, gets a ride.\n\n4. **Effects on others**:\n   - As a result, others feel: none, helpful, grateful, happy, flattered.\n   - As a result, others want: to say no, to help him, to get their car back, none, to go to the store.\n   - Others then: none, says no, no effect, gets into trouble, says yes.\n\nEach of these relationships explores different potential motivations, perceptions, emotional reactions, and subsequent actions stemming from the event where Tom asks Jessica if he can use her car."}
{"layout": 134, "type": "table", "page_idx": 16, "img_path": "layout_images/P19-1470_14.jpg", "table_caption": "Table 8: Deﬁnitions of the relations in A TOMIC . Events in A TOMIC  center around the personal situations of a central ﬁgure, Person X, with potentially more participants. ", "bbox": [69, 82, 527, 480], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Event Description Example Completion:\nPerson X puts Person X’s trust in Person Y\noEffect The effect the event has on others be- _ is considered trustworthy\nsides Person X is believed\ngains Person X’s loyalty\noReact The reaction of others besides Person _ trusted\nX to the event honored\ntrustworthy\noWant What others besides Person X may work with Person X\nwant to do after the event partner with Person X\nto help Person X\nxAttr How Person X might be described _ faithful\ngiven their part in the event hopeful\ntrusting\nxEffect The effect that the event would have _ gets relieved\non Person X stays faithful\nIs betrayed\nxIntent The reason why X would cause the to be trusting\nevent his or her help/guidance/advice\nto be friends\nxNeed What Person X might need to do be- __ to be friends with Person Y\nfore the event to have heard a lot of good things about Per-\nson Y\nto get to know Person Y\nxReact The reaction that Person X would _ trusting\nhave to the event safe, not alone\nunderstood\nxWant What Person X may want to do after to rely on Person Y\n\nthe event\n\nto go into business with Person Y\nto make sure that their heart feeling is right\n\n", "vlm_text": "This table outlines different types of events and their descriptions, along with example completions related to a scenario involving trust. Here are the elements:\n\n1. **oEffect**: How others besides Person X view Person Y when Person X puts trust in them. Examples include being considered trustworthy.\n\n2. **oReact**: Others' reactions to the event. Examples are feeling trusted and honored.\n\n3. **oWant**: What others might want to do after the event. Examples include working with or helping Person X.\n\n4. **xAttr**: How Person X might be described due to their actions. Examples are faithful and trusting.\n\n5. **xEffect**: The impact on Person X. Examples include relief and staying faithful.\n\n6. **xIntent**: Why Person X causes the event. Examples are to be trusting or to seek guidance.\n\n7. **xNeed**: What Person X might need before the event. Examples are friendship with Person Y or hearing positive things about them.\n\n8. **xReact**: Person X's reaction to the event. Examples are trusting and feeling safe.\n\n9. **xWant**: What Person X might want to do after the event. Examples include relying on or doing business with Person Y."}
{"layout": 135, "type": "table", "page_idx": 16, "img_path": "layout_images/P19-1470_15.jpg", "table_footnote": "Table 9: Multi-relation training setups. Following  Sap et al.  ( 2019 ), the  xAttr  relation is not included in the P RE /P OST  training conﬁguration ", "bbox": [70, 528, 527, 741], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Organization\n\nDescription\n\nRelations\n\nPERSON The training set is split into relations 7, ={xAttr, xEffect, xIntent,\nX/Y for the subjects of the event (Person X) xNeed, xReact, xWant}\nand relations for other participants in JT) ={oEffect, oReact, oWant}\nthe event\nPRE/POST Event preconditions are jointly trained JT; ={xIntent, xNeed}\n(i.e., intentions, needs). Event postcon- JT>={oEffect, oReact, oWant,\nditions are jointly trained. xEffect, xReact, xWant}\n(IN)VOLUN Involuntary relations are trained jointly, 7) ={oWant, xIntent, xNeed, xWant}\nsuch as reactions and effects. Volun- T>={oEffect, oReact, xAttr,\ntary relations are trained jointly, suchas xEffect, xReact}\nneeds, wants, and intents.\nFULL The training set is made up of all relae 7, ={oEffect, oReact, oWant, xAttr,\ntions and the model is trained jointlyon xEffect, xIntent, xNeed, xReact,\n\nall of them\n\nxWant }\n", "vlm_text": "This table appears to organize and describe different ways of structuring a training set for a machine learning model, likely in the domain of understanding events or actions and the associated relations or contexts. The table consists of three columns: \n\n1. **Organization**: This column lists the different organizational schemes of the training data, including \"Person X/Y,\" \"Pre/Post,\" \"(In)Volun,\" and \"Full.\"\n\n2. **Description**: This column provides a brief explanation of each organizational scheme. For example:\n   - \"Person X/Y\" involves splitting the training set into relations for subjects of the event (Person X) and other participants (Person Y).\n   - \"Pre/Post\" combines joint training of event preconditions and postconditions.\n   - \"(In)Volun\" differentiates between involuntary and voluntary relations, with the former focusing on reactions and effects and the latter on needs, wants, and intents.\n   - \"Full\" is a comprehensive approach where the training set includes all relations, and the model is jointly trained on them.\n\n3. **Relations**: This column lists specific types of relationships that are part of each organizational scheme. \n   - The notations like `xAttr`, `xEffect`, `xIntent`, etc., likely represent different types of relations or factors considered for person X and others. \"x\" might denote the subject or actor involved directly in the event, while \"o\" could represent other participants.\n   - Each scheme has a combination of these relations divided into two sets, T1 and T2, indicating different groupings or categories used in the training. \n\nIn essence, the table outlines potential ways to structure and train a model based on different relational features associated with events and their participants."}
{"layout": 136, "type": "table", "page_idx": 17, "img_path": "layout_images/P19-1470_16.jpg", "table_caption": "Table 10: Category hierarchy meta-tokens, along with the description and the relations to which they are appended ", "bbox": [71, 103, 527, 316], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Meta-Token Description Relations\n<X> Appended to relations that describe an xAttr, xEffect, xIntent, xNeed,\nattribute of Person X xReact, xWant\n<Y> Appended to relations that describes an  oEffect, oReact, oWant\nattribute of a participant that is not Per-\nson X\n<Pre> Appended to relations that correspond xIntent, xNeed\nto pre-conditions of the event\n<Post> Appended to relations that correspond oEffect, oReact, oWant,\nto post-conditions of the event xEffect, xReact, xWant\n<Voluntary> Appended to relations that correspond oWant, xIntent, xNeed, xWant\nto voluntary dimensions of the situation\n<Involuntary> Appended to relations that correspond oEffect, oReact, xAttr,\nto involuntary dimensions of the situa- xEffect, xReact\n\ntion\n\n", "vlm_text": "The table presented is a structured list of meta-tokens, their descriptions, and corresponding relations. Each row of the table includes:\n\n1. **Meta-Token**: This column lists the tokens which are used to modify or append to specific relations.\n   \n2. **Description**: This describes how the meta-token is used in relation to other elements, such as attributes or conditions.\n\n3. **Relations**: This lists the type of relations that the meta-token affects or is associated with. These include different categories like xAttr, xEffect, xIntent, etc.\n\nHere is a detailed breakdown of the table's content:\n\n- **<X>**: \n  - **Description**: Appended to relations that describe an attribute of Person X.\n  - **Relations**: xAttr, xEffect, xIntent, xNeed, xReact, xWant.\n\n- **<Y>**: \n  - **Description**: Appended to relations that describe an attribute of a participant that is not Person X.\n  - **Relations**: oEffect, oReact, oWant.\n\n- **<Pre>**:\n  - **Description**: Appended to relations that correspond to pre-conditions of the event.\n  - **Relations**: xIntent, xNeed.\n\n- **<Post>**:\n  - **Description**: Appended to relations that correspond to post-conditions of the event.\n  - **Relations**: oEffect, oReact, oWant, xEffect, xReact, xWant.\n\n- **<Voluntary>**:\n  - **Description**: Appended to relations that correspond to voluntary dimensions of the situation.\n  - **Relations**: oWant, xIntent, xNeed, xWant.\n\n- **<Involuntary>**:\n  - **Description**: Appended to relations that correspond to involuntary dimensions of the situation.\n  - **Relations**: oEffect, oReact, xAttr, xEffect, xReact.\n\nThe table is organized to provide a clear and concise way to understand how different meta-tokens are used to modify relations in a structured data setting, likely related to attributes and states of individuals or events in a narrative or modeling context."}
{"layout": 137, "type": "table", "page_idx": 17, "img_path": "layout_images/P19-1470_17.jpg", "table_caption": "Table 11: Automatic evaluations of quality and novelty for generations of A TOMIC  commonsense that are trained with the training set split along different relation types. The training splits are outlined in Table  9 . ", "bbox": [71, 408, 527, 553], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Model PPL? BLEU-2 N/T sro* N/To N/Uo\nCOMET- 9LM 11.72 14.89 100.00 9.45 49.89\nCOMET- (IN) VOLUN 11.38 14.99 100.00 8.60 48.36\nCOMET- PERSONX/Y 11.30 15.21 100.00 9.12 49.59\nCOMET- Pre/Post 11.35 14.88 100.00 9.86 51.86\nCOMET- FULL (- pretrain) 15.42 13.88 100.00 7.25 45.71\nCOMET- FULL 11.14 15.10 100.00 9.71 51.20\nCOMET- FULL (+ hierarchy meta-tokens) 10.98 15.27 100.00 10.03 51.97\n", "vlm_text": "The table presents a comparison of different models of the COMET framework, evaluating them across several metrics: PPL (Perplexity), BLEU-2, N/T sr, N/T o, and N/U o. The specific variations of the COMET model evaluated include:\n\n1. COMET-9LM\n2. COMET-(In)Volun\n3. COMET-PersonX/Y\n4. COMET-Pre/Post\n5. COMET-Full (- pretrain)\n6. COMET-Full\n7. COMET-Full (+ hierarchy meta-tokens)\n\nEach model is assessed with the following statistics:\n- PPL³ (Perplexity, a measure of how well a probability distribution predicts a sample)\n- BLEU-2 (Bilingual Evaluation Understudy, a score for evaluating the quality of text)\n- N/T sr⁴ (not expanded in the image)\n- N/T o (not expanded in the image)\n- N/U o (not expanded in the image)\n\nThe COMET-Full (+ hierarchy meta-tokens) model shows the best performance in terms of PPL and BLEU-2 compared to other model variations."}
{"layout": 138, "type": "table", "page_idx": 17, "img_path": "layout_images/P19-1470_18.jpg", "table_caption": "Table 12: Human score of generations of A TOMIC  commonsense for the regular  COMET  model and the  COMET  $^+$  category meta tokens ", "bbox": [70, 646, 527, 719], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Model | oEffect oReact oWant xAttr xEffect xIntent xNeed xReact xWant I Total\n\nCOMET 29.02 37.68 44.48 57.48 55.50 68.32 64.24 76.18 75.16 || 56.45\nCOMET (+ hierarchy meta-tokens) 28.46 38.96 43.64 51.90 50.84 63.00 63.98 66.20 75.82 || 53.64\n", "vlm_text": "The table presents performance metrics of two models, COMET and COMET (+ hierarchy meta-tokens), across various categories. The categories listed are: oEffect, oReact, oWant, xAttr, xEffect, xIntent, xNeed, xReact, xWant, and Total.\n\n- For each category, the table provides numerical values representing the performance of each model.\n- Bolded numbers indicate the higher value between the two models for that specific category.\n\nHere is a summarized breakdown:\n\n1. **oEffect**:\n   - COMET: 29.02 (higher)\n   - COMET (+ hierarchy meta-tokens): 28.46\n\n2. **oReact**:\n   - COMET: 37.68\n   - COMET (+ hierarchy meta-tokens): 38.96 (higher)\n\n3. **oWant**:\n   - COMET: 44.48 (higher)\n   - COMET (+ hierarchy meta-tokens): 43.64\n\n4. **xAttr**:\n   - COMET: 57.48 (higher)\n   - COMET (+ hierarchy meta-tokens): 51.90\n\n5. **xEffect**:\n   - COMET: 55.50 (higher)\n   - COMET (+ hierarchy meta-tokens): 50.84\n\n6. **xIntent**:\n   - COMET: 68.32 (higher)\n   - COMET (+ hierarchy meta-tokens): 63.00\n\n7. **xNeed**:\n   - COMET: 64.24 (higher)\n   - COMET (+ hierarchy meta-tokens): 63.98\n\n8. **xReact**:\n   - COMET: 76.18 (higher)\n   - COMET (+ hierarchy meta-tokens): 66.20\n\n9. **xWant**:\n   - COMET: 75.16\n   - COMET (+ hierarchy meta-tokens): 75.82 (higher)\n\n10. **Total**:\n    - COMET: 56.45 (higher)\n    - COMET (+ hierarchy meta-tokens): 53.64\n\nOverall, COMET performs better in most categories, but COMET (+ hierarchy meta-tokens) performs better in oReact and xWant. The Total score is higher for COMET, indicating that, overall, it has superior performance across these categories compared to COMET (+ hierarchy meta-tokens)."}
