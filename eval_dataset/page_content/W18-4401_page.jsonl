{"page": 0, "image_path": "doc_images/W18-4401_0.jpg", "ocr_text": "Benchmarking Aggression Identification in Social Media\n\nRitesh Kumar', Atul Kr. Ojha’, Shervin Malmasi*, Marcos Zampieri*\n'Bhim Rao Ambedkar University, \"Jawaharlal Nehru University,\n3Harvard Medical School, ‘University of Wolverhampton,\n\nAbstract\n\nIn this paper, we present the report and findings of the Shared Task on Aggression Identification\norganised as part of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC - 1)\nat COLING 2018. The task was to develop a classifier that could discriminate between Overtly\nAggressive, Covertly Aggressive, and Non-aggressive texts. For this task, the participants were\nprovided with a dataset of 15,000 aggression-annotated Facebook Posts and Comments each in\nHindi (in both Roman and Devanagari script) and English for training and validation. For testing,\ntwo different sets - one from Facebook and another from a different social media - were provided.\nA total of 130 teams registered to participate in the task, 30 teams submitted their test runs,\nand finally 20 teams also sent their system description paper which are included in the TRAC\nworkshop proceedings. The best system obtained a weighted F-score of 0.64 for both Hindi and\nEnglish on the Facebook test sets, while the best scores on the surprise set were 0.60 and 0.50\nfor English and Hindi respectively. The results presented in this report depict how challenging\nthe task is. The positive response from the community and the great levels of participation in the\nfirst edition of this shared task also highlights the interest in this topic.\n\n1 Introduction\n\nIn the last decade, with the emergence of an interactive web and especially popular social networking\nand social media platforms like Facebook and Twitter, there has been an exponential increase in the\nuser-generated content being made available over the web. Now any information online has the power\nto reach billions of people within a matter of seconds. This has resulted in not only positive exchange of\nideas but has also lead to a widespread dissemination of aggressive and potentially harmful content over\nthe web. While most of the potentially harmful incidents like bullying or hate speech have predated the\nInternet, the reach and extent of Internet has given these incidents an unprecedented power and influence\nto affect the lives of billions of people. It has been reported that these incidents have not only created\nmental and psychological agony to the users of the web but has in fact forced people to deactivate their\naccounts and in extreme cases also commit suicides (Hinduja and Patchin, 2010). Thus the incidents of\naggression and unratified verbal behaviour have not remained a minor nuisance, but have acquired the\nform of a major criminal activity that affects a large number of people. It is therefore important that\npreventive measures can be taken to cope with abusive behaviour aggression online.\n\nOne of the strategies to cope with aggressive behaviour online is to manually monitor and moderate\nuser-generated content, however, the amount and pace at which new data is being created on the web has\nrendered manual methods of moderation and intervention almost completely impractical. As such the\nuse (semi-) automatic methods to identify such behaviour has become important and has attracted more\nattention from the research community in recent years (Davidson et al., 2017; Malmasi and Zampieri,\n2017).\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://\ncreativecommons.org/licenses/by/4.0/\n\n1\n\nProceedings of the First Workshop on Trolling, Aggression and Cyberbullying, pages 1-11\nSanta Fe, USA, August 25, 2018.\n", "vlm_text": "Benchmarking Aggression Identiﬁcation in Social Media \nRitesh Kumar 1 , Atul Kr. Ojha 2 , Shervin Malmasi 3 , Marcos Zampieri 4 1 Bhim Rao Ambedkar University, Jawaharlal Nehru University, 3 Harvard Medical School, University of Wolverhampton, \nAbstract \nIn this paper, we present the report and ﬁndings of the Shared Task on Aggression Identiﬁcation organised as part of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC - 1) at COLING 2018. The task was to develop a classiﬁer that could discriminate between  Overtly Aggressive ,  Covertly Aggressive , and  Non-aggressive  texts. For this task, the participants were provided with a dataset of 15,000 aggression-annotated Facebook Posts and Comments each in Hindi (in both Roman and Devanagari script) and English for training and validation. For testing, two different sets - one from Facebook and another from a different social media - were provided. A total of 130 teams registered to participate in the task, 30 teams submitted their test runs, and ﬁnally 20 teams also sent their system description paper which are included in the TRAC workshop proceedings. The best system obtained a weighted F-score of 0.64 for both Hindi and English on the Facebook test sets, while the best scores on the surprise set were 0.60 and 0.50 for English and Hindi respectively. The results presented in this report depict how challenging the task is. The positive response from the community and the great levels of participation in the ﬁrst edition of this shared task also highlights the interest in this topic. \n1 Introduction \nIn the last decade, with the emergence of an interactive web and especially popular social networking and social media platforms like Facebook and Twitter, there has been an exponential increase in the user-generated content being made available over the web. Now any information online has the power to reach billions of people within a matter of seconds. This has resulted in not only positive exchange of ideas but has also lead to a widespread dissemination of aggressive and potentially harmful content over the web. While most of the potentially harmful incidents like bullying or hate speech have predated the Internet, the reach and extent of Internet has given these incidents an unprecedented power and inﬂuence to affect the lives of billions of people. It has been reported that these incidents have not only created mental and psychological agony to the users of the web but has in fact forced people to deactivate their accounts and in extreme cases also commit suicides (Hinduja and Patchin, 2010). Thus the incidents of aggression and unratiﬁed verbal behaviour have not remained a minor nuisance, but have acquired the form of a major criminal activity that affects a large number of people. It is therefore important that preventive measures can be taken to cope with abusive behaviour aggression online. \nOne of the strategies to cope with aggressive behaviour online is to manually monitor and moderate user-generated content, however, the amount and pace at which new data is being created on the web has rendered manual methods of moderation and intervention almost completely impractical. As such the use (semi-) automatic methods to identify such behaviour has become important and has attracted more attention from the research community in recent years (Davidson et al., 2017; Malmasi and Zampieri, 2017). "}
{"page": 1, "image_path": "doc_images/W18-4401_1.jpg", "ocr_text": "This paper reports the results of the first Shared Task on Aggression Identification which was organised\njointly with the First Workshop on Trolling, Aggression and Cyberbullying (TRAC - 1) at COLING 2018.\n\n2 Related Work\n\nVerbal aggression per se has been rarely explored within the field of Natural Language Processing.\nHowever, previous research in the field has been carried out to automatically recognise several related\nbehaviour such as trolling (Cambria et al., 2010; Kumar et al., 2014; Mojica, 2016; Mihaylov et al.,\n2015) , cyberbullying (Dinakar et al., 2012; Nitta et al., 2013; Dadvar et al., 2013; Dadvar et al., 2014;\nHee et al., 2015), flaming / insults (Sax, 2016; Nitin et al., 2012), abusive / offensive language (Chen et\nal., 2012; Nobata et al., 2016; Waseem et al., 2017), hate speech (Pinkesh Badjatiya and Varma, 2017;\nBurnap and Williams, 2014; Davidson et al., 2017; Vigna et al., 2017; Djuric et al., 2015; Fortana,\n2017; Gitari et al., 2015; Malmasi and Zampieri, 2018; Waseem and Hovy, 2016; Schmidt and Wie-\ngand, 2017), radicalization (Agarwal and Sureka, 2015; Agarwal and Sureka, 2017), racism (Greevy and\nSmeaton, 2004; Greevy, 2004) and others. In addition to these, there have been some pragmatic studies\non behaviour like trolling (Hardaker, 2010; Hardaker, 2013).\n\nThis huge interest in the field from different perspectives has created a conglomeration of terminolo-\ngies as well as understandings of the phenomenon. On the one hand, this provides us with a very rich\nand extensive insight into the phenomena yet, on the other hand, it has also created a theoretical gap\nin the understanding of interrelationship among these. Moreover, it has also resulted in duplication of\nresearch, to certain extent, and a certain kind of lack of focus and reusability of datasets across different\nstrands of research. In order to make improvements towards solving a complex phenomenon like this,\nit is of utmost importance that some kind of uniform understanding of problem be achieved so that, at\nleast, standardised datasets and an understanding of different approaches to solving the problem may be\ndeveloped.\n\nWhile a large part of the research has focused on any one of these phenomena and their computational\nprocessing, it seems there is a significant overlap among these phenomenon in the way they are under-\nstood in these studies - and because of this underlying overlap, insights from different studies might\nprove useful for solving these seemingly different phenomena. All of these behaviours are considered\nundesirable, aggressive and detrimental for those on the receiving end. So, trolling is intended “to cause\ndisruption and/or to trigger or exacerbate conflict for the purposes of their own amusement” (Hardaker,\n2010). Cyberbullying is “humiliating and slandering behavior towards other people” (Nitta et al., 2013).\nFlaming intends “to offend someone through e-mail, posting, commenting or any statement using insults,\nswearing and hostile, intense language, trolling, etc.” (Krol, 1992).\n\nWaseem et al. (2017) makes an attempt to unify these different trends of research in what may be con-\nsidered a significantly overlapping field and proposes a 2-way typology for understanding what they call\nabusive language’ over the web. They propose 2 scales on which abusive language could be categorised\n- the target of the abuse (an individual or a group) and the nature of the language (explicit or implicit).\nOur classification of aggression into overt and covert aggression is largely similar to the explicit-implicit\ndistinction. However, we make a more detailed distinction in relation to the target of the abuse (Kumar\net al., 2018b) and it is not made along the axis of individual vs. group. This is so because we noticed\nin a large number of instances both individuals and groups are simultaneously targeted - in such cases\nindividuals are targeted as members of certain groups or the individuals’ actions were considered those\nof the group and became the locus of attack. As such it was not feasible to distinguish between the\nindividual and group attack in lot of instances while annotating the dataset. The distinction that we made\nwas related to the “locus” of attack and included such targets as gender, religion, caste, country of origin,\nrace, etc. This classification, on the one hand, gave scope for focusing on different kinds of attack (for\nexample, racial attacks or communal attacks) and, on the other hand, each of these targets may actually\nbe attacked using a different set of vocabulary, thereby, making these more natural classes that could be\nclassified using the surface-level linguistic features. Of course, it cannot be denied that these targets are\nnot mutually exclusive and, as such, it makes the problem not just a multi-class classification problem\nbut also multi-label classification problem. In addition to this, we also make use of a different terminol-\n\n2\n", "vlm_text": "This paper reports the results of the ﬁrst Shared Task on Aggression Identiﬁcation which was organised jointly with the First Workshop on Trolling, Aggression and Cyberbullying (TRAC - 1) at COLING 2018. \n2 Related Work \nVerbal aggression  per se  has been rarely explored within the ﬁeld of Natural Language Processing. However, previous research in the ﬁeld has been carried out to automatically recognise several related behaviour such as trolling (Cambria et al., 2010; Kumar et al., 2014; Mojica, 2016; Mihaylov et al., 2015) , cyberbullying (Dinakar et al., 2012; Nitta et al., 2013; Dadvar et al., 2013; Dadvar et al., 2014; Hee et al., 2015), ﬂaming / insults (Sax, 2016; Nitin et al., 2012), abusive / offensive language (Chen et al., 2012; Nobata et al., 2016; Waseem et al., 2017), hate speech (Pinkesh Badjatiya and Varma, 2017; Burnap and Williams, 2014; Davidson et al., 2017; Vigna et al., 2017; Djuric et al., 2015; Fortana, 2017; Gitari et al., 2015; Malmasi and Zampieri, 2018; Waseem and Hovy, 2016; Schmidt and Wie- gand, 2017), radicalization (Agarwal and Sureka, 2015; Agarwal and Sureka, 2017), racism (Greevy and Smeaton, 2004; Greevy, 2004) and others. In addition to these, there have been some pragmatic studies on behaviour like trolling (Hardaker, 2010; Hardaker, 2013). \nThis huge interest in the ﬁeld from different perspectives has created a conglomeration of terminolo- gies as well as understandings of the phenomenon. On the one hand, this provides us with a very rich and extensive insight into the phenomena yet, on the other hand, it has also created a theoretical gap in the understanding of interrelationship among these. Moreover, it has also resulted in duplication of research, to certain extent, and a certain kind of lack of focus and reusability of datasets across different strands of research. In order to make improvements towards solving a complex phenomenon like this, it is of utmost importance that some kind of uniform understanding of problem be achieved so that, at least, standardised datasets and an understanding of different approaches to solving the problem may be developed. \nWhile a large part of the research has focused on any one of these phenomena and their computational processing, it seems there is a signiﬁcant overlap among these phenomenon in the way they are under- stood in these studies - and because of this underlying overlap, insights from different studies might prove useful for solving these seemingly different phenomena. All of these behaviours are considered undesirable, aggressive and detrimental for those on the receiving end. So, trolling is intended “to cause disruption and/or to trigger or exacerbate conﬂict for the purposes of their own amusement” (Hardaker, 2010). Cyberbullying is “humiliating and slandering behavior towards other people” (Nitta et al., 2013). Flaming intends “to offend someone through e-mail, posting, commenting or any statement using insults, swearing and hostile, intense language, trolling, etc.” (Krol, 1992). \nWaseem et al. (2017) makes an attempt to unify these different trends of research in what may be con- sidered a signiﬁcantly overlapping ﬁeld and proposes a 2-way typology for understanding what they call\n\n ’abusive language’ over the web. They propose 2 scales on which abusive language could be categorised\n\n - the target of the abuse (an individual or a group) and the nature of the language (explicit or implicit). Our classiﬁcation of aggression into overt and covert aggression is largely similar to the explicit-implicit distinction. However, we make a more detailed distinction in relation to the target of the abuse (Kumar et al., 2018b) and it is not made along the axis of individual vs. group. This is so because we noticed in a large number of instances both individuals and groups are simultaneously targeted - in such cases individuals are targeted as members of certain groups or the individuals’ actions were considered those of the group and became the locus of attack. As such it was not feasible to distinguish between the individual and group attack in lot of instances while annotating the dataset. The distinction that we made was related to the “locus” of attack and included such targets as gender, religion, caste, country of origin, race, etc. This classiﬁcation, on the one hand, gave scope for focusing on different kinds of attack (for example, racial attacks or communal attacks) and, on the other hand, each of these targets may actually be attacked using a different set of vocabulary, thereby, making these more natural classes that could be classiﬁed using the surface-level linguistic features. Of course, it cannot be denied that these targets are not mutually exclusive and, as such, it makes the problem not just a multi-class classiﬁcation problem but also multi-label classiﬁcation problem. In addition to this, we also make use of a different terminol- ogy taking into account its use within socio-pragmatics. This was done with an understanding that huge amount of literature within the ﬁeld of aggression and impoliteness studies might be able to contribute and provide insights to understanding the phenomenon in a better way. "}
{"page": 2, "image_path": "doc_images/W18-4401_2.jpg", "ocr_text": "ogy taking into account its use within socio-pragmatics. This was done with an understanding that huge\namount of literature within the field of aggression and impoliteness studies might be able to contribute\nand provide insights to understanding the phenomenon in a better way.\n\nThe aim of this shared task was much simpler than the one discussed in the previous para. It only\ninvolved classification of the texts into 3 categories - overt aggression, covert aggression and non-\naggression. We wanted to use the dataset for experimenting with different approaches to make the most\ntop-level classification of aggression on social media.\n\n3 Task Setup and Schedule\n\nThe participants interested in competing in the shared task were required to register using a Google Form.\nThe form gave them an option to participate for either English or Hindi or both the languages. All the\nregistered participants were sent the links to the annotated dataset in the language(s) of their choice, along\nwith a description of the format of the dataset. The participants were allowed to use additional data for\ntraining the system, with the condition that the additional dataset should be either publicly available or\nmake available immediately after submission (and well before the submission of the system papers) and\nthis must be mentioned in the submission. Use of non-public additional data for training was not allowed.\nThe participants were given around 6 weeks to experiment and develop the system. However, since more\nthan half of the participants registered after the first release of the data, most of them got less time than\nthis. Initially, the dataset was not released publicly but was emailed only to the registered participants.\nAfter the 6 weeks of release of train and dev sets, the test set was released and the participants had 5 days\nto test and upload their system. The complete timeline of the shared task is given in Table 1. We made\nuse of CodaLab ! for the evaluation. Each team was allowed to submit up to 3 systems for evaluation.\nWe used the best of the 3 runs for the final ranking and evaluation of the systems.\n\nDate Event\n\n1 February, 2018 Shared Task Announcement and Start of Registration\n13 March, 2018 Release of train and dev sets\n\n25 April, 2018 Release of test set\n\n30 April, 2018 Deadline for Submission of System\n\n2 May, 2018 Declaration of Results\n\n28 May, 2018 Deadline for Submission of System Description Paper\n\nTable 1: Timeline of the Aggression Identification Shared Task at TRAC - 1.\n\n4 Dataset\n\nThe participants of the shared task were provided with a dataset of 12,000 randomly sampled Face-\nbook comments for training and 3,000 comments for development and in English and Hindi each, an-\nnotated with 3 levels of aggression - Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non-\nAggressive (NAG). For test, 916 English comments and 970 Hindi comments were provided. Addi-\ntionally, 1,257 English tweets and 1,194 Hindi tweets were given as the surprise test set 7. The dataset\nreleased for the task is a subset of a larger dataset discussed in Kumar et al. (2018b).\n\n4.1 Issues with the Dataset\nWhile most of the participants considered the dataset to be of high quality, two major problems came up\n\nduring the task -\n\ne The language issue: Some of the comments in English dataset contained code-mixed Hindi-English\ndata as well as data from other languages like German. These formed a minuscule proportion of the\ndata but nevertheless these need to be filtered out.\n\n‘https: //competitions.codalab.org/\n>The complete dataset used for the shared task can be downloaded here - http: //tracl-dataset .kmiagra.org/\n\n3\n", "vlm_text": "\nThe aim of this shared task was much simpler than the one discussed in the previous para. It only involved classiﬁcation of the texts into 3 categories - overt aggression, covert aggression and non- aggression. We wanted to use the dataset for experimenting with different approaches to make the most top-level classiﬁcation of aggression on social media. \n3 Task Setup and Schedule \nThe participants interested in competing in the shared task were required to register using a Google Form. The form gave them an option to participate for either English or Hindi or both the languages. All the registered participants were sent the links to the annotated dataset in the language(s) of their choice, along with a description of the format of the dataset. The participants were allowed to use additional data for training the system, with the condition that the additional dataset should be either publicly available or make available immediately after submission (and well before the submission of the system papers) and this must be mentioned in the submission. Use of non-public additional data for training was not allowed. The participants were given around 6 weeks to experiment and develop the system. However, since more than half of the participants registered after the ﬁrst release of the data, most of them got less time than this. Initially, the dataset was not released publicly but was emailed only to the registered participants. After the 6 weeks of release of train and dev sets, the test set was released and the participants had 5 days to test and upload their system. The complete timeline of the shared task is given in Table 1. We made use of CodaLab   1   for the evaluation. Each team was allowed to submit up to 3 systems for evaluation. We used the best of the 3 runs for the ﬁnal ranking and evaluation of the systems. \nThe table outlines a sequence of events related to a shared task, along with their corresponding dates in 2018. The events and their dates are as follows:\n\n- **1 February, 2018**: Shared Task Announcement and Start of Registration\n- **13 March, 2018**: Release of train and dev sets\n- **25 April, 2018**: Release of test set\n- **30 April, 2018**: Deadline for Submission of System\n- **2 May, 2018**: Declaration of Results\n- **28 May, 2018**: Deadline for Submission of System Description Paper\n4 Dataset \nThe participants of the shared task were provided with a dataset of 12,000 randomly sampled Face- book comments for training and 3,000 comments for development and in English and Hindi each, an- notated with 3 levels of aggression - Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non- Aggressive (NAG). For test, 916 English comments and 970 Hindi comments were provided. Addi- tionally, 1,257 English tweets and 1,194 Hindi tweets were given as the surprise test set   2 . The dataset released for the task is a subset of a larger dataset discussed in Kumar et al. (2018b). \n4.1 Issues with the Dataset \nWhile most of the participants considered the dataset to be of high quality, two major problems came up during the task - \n•  The language issue : Some of the comments in English dataset contained code-mixed Hindi-English data as well as data from other languages like German. These formed a minuscule proportion of the data but nevertheless these need to be ﬁltered out. "}
{"page": 3, "image_path": "doc_images/W18-4401_3.jpg", "ocr_text": "e The annotation issue: The second and more serious issue that was raised by some participants\nis related to the the annotation itself. Several instances of supposedly inaccurate annotation were\npointed out. Despite the fact that aggression is a highly subjective phenomenon and different anno-\ntators may have different judgments about the same comment, some of the annotation indeed looked\nhighly implausible and consequently it needs further scrutiny and validation.\n\n5 Participants and Approaches\n\nThe shared task gave the participants an option to register for either one of the two languages - English\nor Hindi - or both. A total of 131 participants registered for the shared task, with 73 teams registering\nto participate only in English track, 2 teams only in Hindi track and 56 teams registered to participate\nin both the tracks. Out of these, finally a total of 30 teams submitted their systems - 15 teams for both\nEnglish and Hindi and 30 teams for only English track. All the systems who submitted their system\nwere invited to submit the system description paper, describing the experiments conducted by them. 18\nparticipants submitted the final description paper which are included in the workshop proceedings - it\nincluded papers by majority of the top 10 teams. Table 2, lists the participating teams and the language\nthey took part in.\n\nTeam Hindi English System Description Paper\nsaroyehun v (Aroyehun and Gelbukh, 2018)\nEBSI-LIA-UNAM v (Arroyo-Fernandez et al., 2018)\nDA-LD-Hildesheim v v (Modha et al., 2018)\nTakeLab v (Golem et al., 2018)\nsreeIN v (Madisetty and Desarkar, 2018)\nJulian v v (Risch and Krestel, 2018)\ntaraka_rama v v\n\nuOttawa v (Orabi et al., 2018)\nIsistanitos v (Tommasel et al., 2018)\nhakuchumu v\n\nDataGeeks v v\n\nnal4 v v (Samghabadi et al., 2018)\ndinel v (Orasan, 2018)\nvista.ue v v (Raiyani et al., 2018)\nMANITBHOPALINDIA v v\n\nIRIT v (Ramiandrisoa and Mothe, 2018)\nquine v v (Nikhil et al., 2018)\nIIIT-Delhi v\n\nPMRS v v (Maitra and Sarkhel, 2018)\nresham v v\n\nTreneR v\n\nNestor v v\n\nUAEMex-UAPT1 v v\n\nforest_and_trees v (Galery et al., 2018)\ngroutar v (Fortuna et al., 2018)\nShusrut v v (Roy et al., 2018)\nmalaypramanick v\n\nUAEMex-UAPT-TAC2 v v\n\nUnito v v\n\nbhanodaig v (Kumar et al., 2018a)\nTotal 15 30 18\n\nTable 2: The teams that participated in the Aggression Identification Shared Task at TRAC - 1.\n\nNext we give a short description of the approach taken by each team for building their system. More\ndetails about the approaches could be found in the paper submitted by the respective teams.\n\n4\n", "vlm_text": "•  The annotation issue : The second and more serious issue that was raised by some participants is related to the the annotation itself. Several instances of supposedly inaccurate annotation were pointed out. Despite the fact that aggression is a highly subjective phenomenon and different anno- tators may have different judgments about the same comment, some of the annotation indeed looked highly implausible and consequently it needs further scrutiny and validation. \n5 Participants and Approaches \nThe shared task gave the participants an option to register for either one of the two languages - English or Hindi - or both. A total of 131 participants registered for the shared task, with 73 teams registering to participate only in English track, 2 teams only in Hindi track and 56 teams registered to participate in both the tracks. Out of these, ﬁnally a total of 30 teams submitted their systems - 15 teams for both English and Hindi and 30 teams for only English track. All the systems who submitted their system were invited to submit the system description paper, describing the experiments conducted by them. 18 participants submitted the ﬁnal description paper which are included in the workshop proceedings - it included papers by majority of the top 10 teams. Table 2, lists the participating teams and the language they took part in. \nThe table displays information on different teams and their involvement in working either in Hindi, English, or both languages. It also provides references to system description papers for those teams. The columns are labeled as \"Team,\" \"Hindi,\" \"English,\" and \"System Description Paper.\"\n\n- The \"Team\" column lists the names of different teams.\n- The \"Hindi\" and \"English\" columns indicate whether the team worked in that language, with a checkmark (✓) showing their involvement.\n- The \"System Description Paper\" column cites the paper associated with the team's work, including author names and the year of publication (all from 2018 in this table).\n\nAt the bottom of the table, it provides a total count:\n- 15 teams worked on Hindi.\n- 30 teams worked on English.\n- There are 18 system description papers listed overall.\nTable 2: The teams that participated in the Aggression Identiﬁcation Shared Task at TRAC - 1. \nNext we give a short description of the approach taken by each team for building their system. More details about the approaches could be found in the paper submitted by the respective teams. "}
{"page": 4, "image_path": "doc_images/W18-4401_4.jpg", "ocr_text": "saroyehun system gives the best performance with LSTM and they resorted to translation as data\naugmentation strategy. With the surprise twitter set, a combination of the representations of the\nRNN and CNN as features, along with additional preprocessing like spelling correction, translation\nof emoji, and computation of sentiment score gave the best performance. In this case, the dataset\nwas also augmented using translation and pseudolabelled using an external dataset on hate speech.?\nThis is the only approach in the competition that performs better on the Twitter dataset, despite\nbeing trained the Facebook dataset, thereby, depicting the ability of the approach to generalise\nacross domain.\n\nEBSI-LIA-UNAM system uses a combination of the Passive-Aggressive (PA) and SVM classifiers\nwith character based n-gram (1 - 5 grams) TF-IDF for feature representation.\n\nDA-LD-Hildesheim uses LSTM with pretrained Fasttext vector for embeddings for classifying\nEnglish Facebook texts. For all other datasets including Twitter data in English and both Facebook\nand Twitter dataset in Hindi, CNN performs better.\n\nTakeLab uses a Bidirectional LSTM on Glove embeddings to give the best performance.\n\nsreeIN system uses a voting-based ensemble method with 3 classifiers - CNN with 4 layers, LSTM\nand Bidirectional LSTM.\n\nJulian team uses translation as data augmentation strategy and use an ensemble of TF-IDF based\napproaches, using character n-grams (2 - 6) and word n-grams (1 - 2) with a bi-directional RNN,\nusing fasttext embeddings, to get the best performance in the task..\n\ntaraka_rama uses different systems for different datasets. For English Facebook dataset and Hindi\nTwitter dataset, the team uses a stacked ensemble classifier that uses a SVM on top of the ensemble\nof SVM classifiers. The SVMs were trained on | - 6 character n-grams and word unigrams. For\nHindi Facebook and English Twitter dataset, however, a plain SVM trained using character and word\nbag-of-n-grams gave the best performance. In this case, the overlapping character and word n-gram\nfeatures are weigthed with sublinear tf-idf before being used for training and testing. The system\nis tuned using 5-fold CV on the combined training and develpment sets for maximum number\nof character and word n-grams included, case normalization, and SVM margin (regularization)\nparameter C.\n\nuOttawa system is trained using a novel deep-learning architecture for text classification based on\nMulti-task learning (MTL). The approach, MTL, is evaluated using three neural network models.\nMultiCNN, multiple convolution structure with a trainable embedding layer, gives the best perfor-\nmance.\n\nIsistanitos system uses a soft voting (average the class probabilities of other models) of two models\n- a recurrent neural network, and an SVM. The recurrent neural network uses 3 preprocesed set\nof features. The first set uses an ad-hoc glove model for representing the words, the second is\na sentiwornet based model, and the third is a traditional Tfldf plus Vader Sentiment analysis and\nsentiments associated with the emojis. The SVM model is trained on a TF-IDF of the post stemmed\nterms, excluding stopwords, and 3 - 5 character n-grams.\n\nhakuchumu system makes use of a Random Forest classifier with some preprocessing including\nremoval of urls and non letter characters and stop words. Along with the bag-of-word, the approach\nuses multiple occurrences of letters, exclamation marks and question marks in a row and emoticons\nas binary features.\n\nDataGeeks system uses Logistic Regression classifier with some preprocessing on the data such\n\nas removing non-ascii characters, replacing new line with ’.’, replacing n’t with not, removing\nstopwords and 1 - 3 word n-grams and 2 - 6 character n-grams for training the classifier.\n\nShttps://github.com/ZeerakW/hatespeech\n", "vlm_text": "•  saroyehun  system gives the best performance with LSTM and they resorted to translation as data augmentation strategy. With the surprise twitter set, a combination of the representations of the RNN and CNN as features, along with additional preprocessing like spelling correction, translation of emoji, and computation of sentiment score gave the best performance. In this case, the dataset was also augmented using translation and pseudolabelled using an external dataset on hate speech. This is the only approach in the competition that performs better on the Twitter dataset, despite being trained the Facebook dataset, thereby, depicting the ability of the approach to generalise across domain.\n\n \n•  EBSI-LIA-UNAM  system uses a combination of the Passive-Aggressive (PA) and SVM classiﬁers with character based n-gram (1 - 5 grams) TF-IDF for feature representation.\n\n \n•  DA-LD-Hildesheim  uses LSTM with pretrained Fasttext vector for embeddings for classifying English Facebook texts. For all other datasets including Twitter data in English and both Facebook and Twitter dataset in Hindi, CNN performs better.\n\n \n•  TakeLab  uses a Bidirectional LSTM on Glove embeddings to give the best performance.\n\n \n•  sreeIN  system uses a voting-based ensemble method with 3 classiﬁers - CNN with 4 layers, LSTM and Bidirectional LSTM.\n\n \n•  Julian  team uses translation as data augmentation strategy and use an ensemble of TF-IDF based approaches, using character n-grams (2 - 6) and word   $\\mathbf{n}$  -grams (1 - 2) with a bi-directional RNN, using fasttext embeddings, to get the best performance in the task..\n\n \n•  taraka rama  uses different systems for different datasets. For English Facebook dataset and Hindi Twitter dataset, the team uses a stacked ensemble classiﬁer that uses a SVM on top of the ensemble of SVM classiﬁers. The SVMs were trained on 1 - 6 character n-grams and word unigrams. For Hindi Facebook and English Twitter dataset, however, a plain SVM trained using character and word bag-of-n-grams gave the best performance. In this case, the overlapping character and word n-gram features are weigthed with sublinear tf-idf before being used for training and testing. The system is tuned using 5-fold CV on the combined training and develpment sets for maximum number of character and word n-grams included, case normalization, and SVM margin (regularization) parameter C.\n\n \n•  uOttawa  system is trained using a novel deep-learning architecture for text classiﬁcation based on Multi-task learning (MTL). The approach, MTL, is evaluated using three neural network models. MultiCNN, multiple convolution structure with a trainable embedding layer, gives the best perfor- mance.\n\n \n•  Isistanitos  system uses a soft voting (average the class probabilities of other models) of two models - a recurrent neural network, and an SVM. The recurrent neural network uses 3 preprocesed set of features. The ﬁrst set uses an ad-hoc glove model for representing the words, the second is a sentiwornet based model, and the third is a traditional TfIdf plus Vader Sentiment analysis and sentiments associated with the emojis. The SVM model is trained on a TF-IDF of the post stemmed terms, excluding stopwords, and 3 - 5 character n-grams.\n\n \n•  hakuchumu  system makes use of a Random Forest classiﬁer with some preprocessing including removal of urls and non letter characters and stop words. Along with the bag-of-word, the approach uses multiple occurrences of letters, exclamation marks and question marks in a row and emoticons as binary features.\n\n \n•  DataGeeks  system uses Logistic Regression classiﬁer with some preprocessing on the data such as removing non-ascii characters, replacing new line with ’.’, replacing n’t with not, removing stopwords and 1 - 3 word  $\\mathbf{n}$  -grams and 2 - 6 character n-grams for training the classiﬁer. "}
{"page": 5, "image_path": "doc_images/W18-4401_5.jpg", "ocr_text": "e nal4 also uses Logistic Regression classifier with preprocessing involving replacing URLs, num-\nbers, email addresses and spelling correction. The classifier is trained using word unigrams, tf-idf\nvectors of word unigram, character 4-gram, character 5-gram and Google news pre-trained word\nembedding model. For the Hindi dataset, Devanagari texts were transliterated into Roman at the\npreprocessing stage.\n\ne dinel achieves the best accuracy on the Facebook test set using a Random Forest classifier while\nSVMs performed better for the surprise Twiiter test set. Both the classifiers were trained using 300\nsemantic features which represent the vector representation of the text, average scores of the top\nemojis for each of the classes and positive and negative sentiment scores.\n\ne vista.ue system is developed using dense neural networks.\n\ne MANITBHOPALINDIA system for English is developed using SVM while for English it is trained\nusing deep neural networks.\n\ne IRIT system gets the best performance for the English Facebook test set by using a combination of\ntwo models - a doc2vec model and a logistic regression classifier. For the Twitter test set, it uses a\ncombination of CNN and LSTM to get the best performance.\n\ne quine system is trained using an LSTM with attention and simple embeddings (word to index)\ninstead of pre-trained embeddings.\n\ne IIIT-Delhi system uses a Single channel CNN for this task. Bayesian Optimization is used for\ntuning the parameters.\n\ne PMRS system employs a winner-takes- all autoencoder, called Emoti-KATE for Twitter senti-\nment classification. Each input dimension of Emoti-KATE is a log-normalized, sentiwordnet-score\nweighted word-count vector. A binary cross-entropy loss function is used to train the network.\n\ne resham system for English has been made using an open vocabulary approach and ensemble model\nof two predictors with soft voting. The first predictor is a Naive Bayes model with CountVectorizer\nfor preprocessing. The second predictor is a recurrent neural network with one embedding layer\nand two LSTM layers. Pre-trained word vectors have been used for the embedding layer. For Hindi\ndataset, a Naive Bayes classifier is trained using the dataset augmented with English translations.\n\ne IreneR system is based on a Multinomial Naive Bayes classifier that uses unigrams, bigrams,\nhedging bigrams and trigrams such as ’do you’, someone who is’,’to see that’, that potentially\nsignal covert aggressivity, identified with chi-squared test as features. It also includes features from\nLIWC2015 (list of anger and swear words).\n\ne Nestor uses an approach that combines Neural Networks and a new word representation model.\nThe patterns obtained from the word model representation are used for training the back propa-\ngation neural network with fix parameters. The length of the post was fixed and the word model\nrepresentation is language independent, so it was used for both the English and the Hindi tasks.\n\ne UAEMex-UAPT1 uses the same approach as used by the team Nestor.\n\ne forest_and_trees system uses a Pooled Recurrent Unit architecture combined with pre-trained En-\nglish and Hindi fasttext word embeddings as a representation of the sequence input. In this approach,\nHindi and English vectors were aligned using pre-computed SVD matrices that pulls representations\nfrom different languages into a single space. This enabled the same model to be used for both the\nlanguages, thereby, making data re-utilization and model deployability easier.\n\ne groutar system is trained using random forests. The dataset is augmented with an external toxicity\ndataset +. The approach involved understanding the effects of new data on aggression identification.\n\n4https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n\n6\n", "vlm_text": "•  na14  also uses Logistic Regression classiﬁer with preprocessing involving replacing URLs, num- bers, email addresses and spelling correction. The classiﬁer is trained using word unigrams, tf-idf vectors of word unigram, character 4-gram, character 5-gram and Google news pre-trained word embedding model. For the Hindi dataset, Devanagari texts were transliterated into Roman at the preprocessing stage. \n•  dinel  achieves the best accuracy on the Facebook test set using a Random Forest classiﬁer while SVMs performed better for the surprise Twiiter test set. Both the classiﬁers were trained using 300 semantic features which represent the vector representation of the text, average scores of the top emojis for each of the classes and positive and negative sentiment scores.\n\n \n vista.ue  system is developed using dense neural networks.\n\n \n•  MANITBHOPALINDIA  system for English is developed using SVM while for English it is trained using deep neural networks. \n•  IRIT  system gets the best performance for the English Facebook test set by using a combination of two models - a doc2vec model and a logistic regression classiﬁer. For the Twitter test set, it uses a combination of CNN and LSTM to get the best performance. \n•  quine  system is trained using an LSTM with attention and simple embeddings (word to index) instead of pre-trained embeddings. \n•  IIIT-Delhi  system uses a Single channel CNN for this task. Bayesian Optimization is used for tuning the parameters. \n•  PMRS  system employs a winner-takes- all autoencoder, called Emoti-KATE for Twitter senti- ment classiﬁcation. Each input dimension of Emoti-KATE is a log-normalized, sentiwordnet-score weighted word-count vector. A binary cross-entropy loss function is used to train the network. \n•  resham  system for English has been made using an open vocabulary approach and ensemble model of two predictors with soft voting. The ﬁrst predictor is a Naive Bayes model with CountVectorizer for preprocessing. The second predictor is a recurrent neural network with one embedding layer and two LSTM layers. Pre-trained word vectors have been used for the embedding layer. For Hindi dataset, a Naive Bayes classiﬁer is trained using the dataset augmented with English translations. \n•  IreneR  system is based on a Multinomial Naive Bayes classiﬁer that uses unigrams, bigrams, hedging bigrams and trigrams such as ’do you’, someone who is’,’to see that’, that potentially signal covert aggressivity, identiﬁed with chi-squared test as features. It also includes features from LIWC2015 (list of anger and swear words). \n•  Nestor  uses an approach that combines Neural Networks and a new word representation model. The patterns obtained from the word model representation are used for training the back propa- gation neural network with ﬁx parameters. The length of the post was ﬁxed and the word model representation is language independent, so it was used for both the English and the Hindi tasks.\n\n \n UAEMex-UAPT1  uses the same approach as used by the team Nestor.\n\n \n•  forest and trees  system uses a Pooled Recurrent Unit architecture combined with pre-trained En- glish and Hindi fasttext word embeddings as a representation of the sequence input. In this approach, Hindi and English vectors were aligned using pre-computed SVD matrices that pulls representations from different languages into a single space. This enabled the same model to be used for both the languages, thereby, making data re-utilization and model deployability easier. \n•  groutar  system is trained using random forests. The dataset is augmented with an external toxicity dataset   4 . The approach involved understanding the effects of new data on aggression identiﬁcation. "}
{"page": 6, "image_path": "doc_images/W18-4401_6.jpg", "ocr_text": "e Shusrut system uses an ensemble of CNN 2D with MAXPOOL classifier and a SVM classifier. The\nensemble model is passed through 3 dense layers to finally predict the output. Softmax activation is\nused in the outer layer for classification.\n\ne malaypramanick system uses a random forest classifier trained using a set of surface-level fea-\ntures including number of line,s uppercase and lowercase letters, digits, named entities, unicode\ncharacters, etc.\n\ne UAEMex-UAPT-TAC2 system is generated by combination of twelve distance measures, through\na K Nearest Neighbors classification algorithm and a canonical genetic algorithm.\n\ne Unito is the only unsupervised system submitted in the task. It is based only on a multilingual\nlexicon of aggressive words. The lexicon is obtained by automatic translation from an handmade\nlexicon of offensive words in Italian, with minimal human supervision. The original words are\nexpanded into a list of their senses. The senses are manually annotated to filter out senses that are\nnever used in an offensive context. Finally, all the lemmas of the remaining senses are generated\nwith BabelNet in 50+ languages. The words in the lexicon are divided in those translating sense that\ncan be used in an offensive context (but not necessarily are) and words translating senses that are\ndirectly offensive. This distinction is mapped to the Overtly Aggressive and Covertly Aggressive\nclasses respectively. The classification of sentences is straightforward: a sentence that does not\ncontain any word from the lexicon is tagged as NAG, a sentence containing more directly offensive\nwords than potentially offensive words is tagged as OAG, and the other cases are tagged as CAG.\n\ne bhanodaig system uses a bidirectional LSTM.\n\n6 Results\n\nIn this section, we present the results of the experiments carried out by different teams during the shared\ntask. The results of the top 15 teams on English dataset is given in Figure 1 and that on Hindi dataset is\nin Figure 2.\n\nEnglish Performance\n\n0.8 = Twitter = Facebook\n\n0.6\n\n> KF » e eg 2 >\nR \\ < S x $ S < ¢\neS - FS SF # g vr SF Ss\nRe Ss S s s < os a ic e & Ss é oe BY PG s RS »\ne Pol Ro wv s x»\nx ° C S &\n? &\nis »\nAS\n\nFigure 1: Performance of top 15 teams on English Dataset\n\n7\n", "vlm_text": "•  Shusrut  system uses an ensemble of CNN 2D with MAXPOOL classiﬁer and a SVM classiﬁer. The ensemble model is passed through 3 dense layers to ﬁnally predict the output. Softmax activation is used in the outer layer for classiﬁcation. \n•  malaypramanick  system uses a random forest classiﬁer trained using a set of surface-level fea- tures including number of line,s uppercase and lowercase letters, digits, named entities, unicode characters, etc. \n•  UAEMex-UAPT-TAC2  system is generated by combination of twelve distance measures, through a K Nearest Neighbors classiﬁcation algorithm and a canonical genetic algorithm. \n•  Unito  is the only unsupervised system submitted in the task. It is based only on a multilingual lexicon of aggressive words. The lexicon is obtained by automatic translation from an handmade lexicon of offensive words in Italian, with minimal human supervision. The original words are expanded into a list of their senses. The senses are manually annotated to ﬁlter out senses that are never used in an offensive context. Finally, all the lemmas of the remaining senses are generated with BabelNet in  $^{50+}$   languages. The words in the lexicon are divided in those translating sense that can be used in an offensive context (but not necessarily are) and words translating senses that are directly offensive. This distinction is mapped to the Overtly Aggressive and Covertly Aggressive classes respectively. The classiﬁcation of sentences is straightforward: a sentence that does not contain any word from the lexicon is tagged as NAG, a sentence containing more directly offensive words than potentially offensive words is tagged as OAG, and the other cases are tagged as CAG. \n bhanodaig  system uses a bidirectional LSTM. \n6 Results \nIn this section, we present the results of the experiments carried out by different teams during the shared task. The results of the top 15 teams on English dataset is given in Figure 1 and that on Hindi dataset is in Figure 2. \nThe image is a bar chart titled \"English Performance,\" depicting the performance of the top 15 teams on an English dataset. The chart compares the performance of these teams across two platforms: Twitter (black bars) and Facebook (gray bars). The teams, listed along the x-axis, include vista.ue, Julian, saroyehun, EBSI-LIA-UNAM, uottawa, na14, taraka_rama, TakeLab, DataGeeks, quine, DA-LD-Hildesheim, lsistantos, resham, IIIT-Delhi, IRIT, Shusrut, sreelN, dinel, hakuchumu, and MANITBHOPALINDIA. The y-axis represents the performance metric, ranging from 0 to 0.8. Each team has two bars, indicating their performance on Twitter and Facebook, with Facebook generally showing higher performance levels for most teams."}
{"page": 7, "image_path": "doc_images/W18-4401_7.jpg", "ocr_text": "The participants were allowed to use other datasets, in addition to the one provided by the organizers of\nthe task. However, because of the lack of similar alternative datasets, all the groups, except ’groutar’ and\n*saroyehun’ team, used only the dataset provided for the task. As we mentioned earlier, the participants\nwere given two kinds of test sets for the final testing of the system - one from Facebook and a surprise\ntest set from Twitter.\n\nHindi Performance\n\n0.8 | Twitter = Facebook\n\n0.6\n\n0.4\n\n0.2\n\nFigure 2: Performance of teams on Hindi Dataset\n\n7 Conclusion\n\nIn this paper, we have presented the report of the First Shared task on Aggression Identification organized\nwith the TRAC workshop at COLING 2018. The shared task received a very encouraging response from\nthe community which underlines the relevance and need of the task. More than 100 teams registered and\n30 teams finally submitted their system.\n\nThe performance of the best systems in the task show that aggression identification is a hard problem to\nsolve. Moreover, the performance of the neural networks-based systems as well as the other approaches\ndo not seem to differ much. If the features are carefully selected then classifiers like SVM and even\nrandom forest and logistic regression perform at par with deep neural networks. On the other had, we\nfind quite a few neural networks-based systems not performing quite well in the task. Nonetheless, 14\nsystems were trained using one or the other architectures of deep neural networks - either solely or as\npart of an ensemble. Moreover, 8 systems out of the top 15 are trained on neural networks, which shows\nthe efficacy of the approach but at the same time does not rule out the usefulness and relevance of linear\nmodels for the task. There was only one system, Unito, that made use of a lexicon-based approach to\nsolve the task. A few participants of the task pointed out the apparent “inconsistencies” in the annotation.\nIt points towards the need to get the annotations validated by multiple human annotators.\n\nAcknowledgements\n\nWe would like to thank Microsoft Research India for providing grants to prepare the dataset and to our\nannotators who worked very hard to finish the annotations within a strict deadline.\n\n8\n", "vlm_text": "The participants were allowed to use other datasets, in addition to the one provided by the organizers of the task. However, because of the lack of similar alternative datasets, all the groups, except ’groutar’ and ’saroyehun’ team, used only the dataset provided for the task. As we mentioned earlier, the participants were given two kinds of test sets for the ﬁnal testing of the system - one from Facebook and a surprise test set from Twitter. \nThe image is a bar chart illustrating the performance of various teams on a Hindi dataset. There are two sets of bars for each team representing performance on Twitter and Facebook, with Twitter performance in black and Facebook performance in gray. Each team is listed along the x-axis, including DA-LD-Hildesheim, na14, vista.ue, quine, DataGeeks, taraka_rama, resham, Julian, Shusrut, MANITBHOPALINDIA, Nestor, UAEMex+UAPT1, UAEMex+UAPT-TAC2, PMRS, and Unito. The performance metric ranges from 0 to 0.8 on the y-axis. Generally, Facebook performance appears to be higher than Twitter performance for most teams.\n7 Conclusion \nIn this paper, we have presented the report of the First Shared task on Aggression Identiﬁcation organized with the TRAC workshop at COLING 2018. The shared task received a very encouraging response from the community which underlines the relevance and need of the task. More than 100 teams registered and 30 teams ﬁnally submitted their system. \nThe performance of the best systems in the task show that aggression identiﬁcation is a hard problem to solve. Moreover, the performance of the neural networks-based systems as well as the other approaches do not seem to differ much. If the features are carefully selected then classiﬁers like SVM and even random forest and logistic regression perform at par with deep neural networks. On the other had, we ﬁnd quite a few neural networks-based systems not performing quite well in the task. Nonetheless, 14 systems were trained using one or the other architectures of deep neural networks - either solely or as part of an ensemble. Moreover, 8 systems out of the top 15 are trained on neural networks, which shows the efﬁcacy of the approach but at the same time does not rule out the usefulness and relevance of linear models for the task. There was only one system, Unito, that made use of a lexicon-based approach to solve the task. A few participants of the task pointed out the apparent “inconsistencies” in the annotation. It points towards the need to get the annotations validated by multiple human annotators. \nAcknowledgements \nWe would like to thank Microsoft Research India for providing grants to prepare the dataset and to our annotators who worked very hard to ﬁnish the annotations within a strict deadline. "}
{"page": 8, "image_path": "doc_images/W18-4401_8.jpg", "ocr_text": "We would also like to thank the participants of the Shared Task for their participation and feedback\nand the TRAC workshop PC members for thoroughly reviewing the shared task papers within a very\nshort span of time.\n\nReferences\n\nSwati Agarwal and Ashish Sureka. 2015. Using knn and svm based one-class classifier for detecting online\nradicalization on twitter. In International Conference on Distributed Computing and Internet Technology, pages\n431 — 442. Springer.\n\nSwati Agarwal and Ashish Sureka. 2017. Characterizing linguistic attributes for automatic classification of intent\nbased racist/radicalized posts on tumblr micro-blogging website.\n\nSegun Taofeek Aroyehun and Alexander Gelbukh. 2018. Aggression detection in social media: Using deep\nneural networks, data augmentation, and pseudo labeling. In Proceedings of the First Workshop on Trolling,\nAggression and Cyberbullying (TRAC — 1), Santa Fe, USA.\n\nIgnacio Arroyo-Fernandez, Dominic Forest, Juan-Manuel Torres-Moreno, Mauricio Carrasco-Ruiz, Thomas Leg-\neleux, and Karen Joannette. 2018. Cyber-bullying detection task: the ebsi-lia-unam system (elu) at coling’ 18\ntrac-1. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1), Santa Fe,\nUSA.\n\nPeter Burnap and Matthew L. Williams. 2014. Hate speech, machine classification and statistical modelling of\ninformation flows on twitter: Interpretation and communication for policy decision making. In Proceedings of\nInternet, Policy & Politics, pages 1 — 18.\n\nErik Cambria, Praphul Chandra, Avinash Sharma, and Amir Hussain. 2010. Do not feel the trolls. In ISWC,\nShanghai.\n\nYing Chen, Yilu Zhou, Sencun Zhu, and Heng Xu. 2012. Detecting offensive language in social media to pro-\ntect adolescent online safety. privacy, security, risk and trust (passat). In International Conference on Social\nComputing (SocialCom), pages 71-80.\n\nMaral Dadvar, Dolf Trieschnigg, Roeland Ordelman, and Franciska de Jong. 2013. Improving cyberbullying\ndetection with user context. In Advances in Information Retrieval, pages 693-696. Springer.\n\nMaral Dadvar, Dolf Trieschnigg, and Franciska de Jong. 2014. Experts and machines against bullies: a hybrid\napproach to detect cyberbullies. In Advances in Artificial Intelligence, pages 275-281. Springer, Berlin.\n\nThomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated hate speech detection\nand the problem of offensive language. In Proceedings of ICWSM.\n\nKarthik Dinakar, Birago Jones, Catherine Havasi Henry Lieberman, and Rosalind Picard. 2012. Common sense\nreasoning for detection, prevention, and mitigation of cyberbullying. ACM Transactions on Interactive Intelli-\ngent Systems (TiS), 2(3):18:1-18:30.\n\nNemanja Djuric, Jing Zhou, Robin Morris, Mihajlo Grbovic, Vladan Radosavljevic, and Narayan Bhamidipati.\n2015. Hate speech detection with comment embeddings. In Proceedings of the 24th International Conference\non World Wide Web, pages 29 — 30.\n\nPaula Fortana. 2017. Automatic detection of hate speech in text: an overview of the topic and dataset annotation\nwith hierarchical classes. Master’s thesis, Faculdade de Engenharia da Universidade do Porto.\n\nPaula Fortuna, José Ferreira, Luiz Pires, Guilherme Routar, and Sérgio Nunes. 2018. Merging datasets for aggres-\nsive text identification. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC\n— 1), Santa Fe, USA.\n\nThiago Galery, Efstathios Charitos, and Ye Tian. 2018. Aggression identification and multi lingual word embed-\ndings. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1), Santa Fe,\nUSA.\n\nNjagi Dennis Gitari, Zhang Zuping, Hanyurwimfura Damien, and Jun Long. 2015. A lexicon- based approach for\nhate speech detection. International Journal of Multimedia and Ubiquitous Engineering, 10(4):215 — 230.\n\n9\n", "vlm_text": "We would also like to thank the participants of the Shared Task for their participation and feedback and the TRAC workshop PC members for thoroughly reviewing the shared task papers within a very short span of time. \nReferences \nSwati Agarwal and Ashish Sureka. 2015. Using knn and svm based one-class classiﬁer for detecting online radicalization on twitter. In  International Conference on Distributed Computing and Internet Technology , pages 431 – 442. Springer. Swati Agarwal and Ashish Sureka. 2017. Characterizing linguistic attributes for automatic classiﬁcation of intent based racist/radicalized posts on tumblr micro-blogging website. Segun Taofeek Aroyehun and Alexander Gelbukh. 2018. Aggression detection in social media: Using deep neural networks, data augmentation, and pseudo labeling. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Ignacio Arroyo-Fern´ andez, Dominic Forest, Juan-Manuel Torres-Moreno, Mauricio Carrasco-Ruiz, Thomas Leg- eleux, and Karen Joannette. 2018. Cyber-bullying detection task: the ebsi-lia-unam system (elu) at coling’18 trac-1. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Peter Burnap and Matthew L. Williams. 2014. Hate speech, machine classiﬁcation and statistical modelling of information ﬂows on twitter: Interpretation and communication for policy decision making. In  Proceedings of Internet, Policy & Politics , pages 1 – 18. Erik Cambria, Praphul Chandra, Avinash Sharma, and Amir Hussain. 2010. Do not feel the trolls. In  ISWC, Shanghai . Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu. 2012. Detecting offensive language in social media to pro- tect adolescent online safety. privacy, security, risk and trust (passat). In  International Conference on Social Computing (SocialCom) , pages 71–80. Maral Dadvar, Dolf Trieschnigg, Roeland Ordelman, and Franciska de Jong. 2013. Improving cyberbullying detection with user context. In  Advances in Information Retrieval , pages 693–696. Springer. Maral Dadvar, Dolf Trieschnigg, and Franciska de Jong. 2014. Experts and machines against bullies: a hybrid approach to detect cyberbullies. In  Advances in Artiﬁcial Intelligence , pages 275–281. Springer, Berlin. Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated hate speech detection and the problem of offensive language. In  Proceedings of ICWSM . Karthik Dinakar, Birago Jones, Catherine Havasi Henry Lieberman, and Rosalind Picard. 2012. Common sense reasoning for detection, prevention, and mitigation of cyberbullying.  ACM Transactions on Interactive Intelli- gent Systems (TiiS) , 2(3):18:1–18:30. Nemanja Djuric, Jing Zhou, Robin Morris, Mihajlo Grbovic, Vladan Radosavljevic, and Narayan Bhamidipati. 2015. Hate speech detection with comment embeddings. In  Proceedings of the 24th International Conference on World Wide Web , pages 29 – 30. Paula Fortana. 2017. Automatic detection of hate speech in text: an overview of the topic and dataset annotation with hierarchical classes. Master’s thesis, Faculdade de Engenharia da Universidade do Porto. Paula Fortuna, Jos´ e Ferreira, Luiz Pires, Guilherme Routar, and S´ ergio Nunes. 2018. Merging datasets for aggres- sive text identiﬁcation. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1) , Santa Fe, USA. Thiago Galery, Efstathios Charitos, and Ye Tian. 2018. Aggression identiﬁcation and multi lingual word embed- dings. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Njagi Dennis Gitari, Zhang Zuping, Hanyurwimfura Damien, and Jun Long. 2015. A lexicon- based approach for hate speech detection.  International Journal of Multimedia and Ubiquitous Engineering , 10(4):215 – 230. "}
{"page": 9, "image_path": "doc_images/W18-4401_9.jpg", "ocr_text": "Viktor Golem, Mladen Karan, and Jan najder. 2018. Combining traditional machine learning models with deep\nlearning for aggressive text detection. In Proceedings of the First Workshop on Trolling, Aggression and Cyber-\nbullying (TRAC — 1), Santa Fe, USA.\n\nEdel Greevy and Alan F. Smeaton. 2004. Classifying racist texts using a support vector machine. In Proceedings\nof the 27th annual international ACM SIGIR conference on Research and development in information retrieval,\npages 468 — 469. ACM.\n\nEdel Greevy. 2004. Automatic text categorisation of racist webpages. Ph.D. thesis, Dublin City University.\n\nClaire Hardaker. 2010. Trolling in asynchronous computer-mediated communication: From user discussions to\nacademic definitions. Journal of Politeness Research. Language, Behaviour, Culture, 6(2):215-242.\n\nClaire Hardaker. 2013. uh. . . . not to be nitpicky,,,,,but...the past tense of drag is dragged, not drug. an overview\nof trolling strategies. Journal of Language Aggression and Conflict, 1(1):58-86.\n\nCynthia Van Hee, Els Lefever, Ben Verhoeven, Julie Mennes, Bart Desmet, Guy De Pauw, Walter Daelemans, and\nVronique Hoste. 2015. Detection and fine-grained classification of cyberbullying events. In Proceedings of\nInternational Conference Recent Advances in Natural Language Processing (RANLP), pages 672-680.\n\nSameer Hinduja and Justin W Patchin. 2010. Bullying, Cyberbullying, and Suicide. Archives of suicide research,\n14(3):206-221.\n\nE. Krol. 1992. The whole internet: User’s guide & catalog. O'Reilly & Associates, Inc., Sebastopol, CA.\n\nSudhakar Kumar, Francesca Spezzano, and VS Subrahmanian. 2014. Accurately detecting trolls in slashdot\nzoo Via decluttering. In Proceedings of IEEE/ACM International Conference on Advances in Social Networks\nAnalysis and Mining (ASONAM), pages 188-195.\n\nRitesh Kumar, Guggilla Bhanodai, Rajendra Pamula, and Maheshwar Reddy Chennuru. 2018a. Trac-1 shared task\non aggression identification: lit(ism)@coling18. In Proceedings of the First Workshop on Trolling, Aggression\nand Cyberbullying (TRAC — 1), Santa Fe, USA.\n\nRitesh Kumar, Aishwarya N. Reganti, Akshit Bhatia, and Tushar Maheshwari. 2018b. Aggression-annotated cor-\npus of hindi-english code-mixed data. In Nicoletta Calzolari (Conference chair), Khalid Choukri, Christopher\nCieri, Thierry Declerck, Sara Goggi, Koiti Hasida, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, HIne\nMazo, Asuncion Moreno, Jan Odijk, Stelios Piperidis, and Takenobu Tokunaga, editors, Proceedings of the\nEleventh International Conference on Language Resources and Evaluation (LREC 2018), Paris, France, may.\nEuropean Language Resources Association (ELRA).\n\nSreekanth Madisetty and Maunendra Sankar Desarkar. 2018. Aggression detection in social media using deep\nneural networks. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1),\nSanta Fe, USA.\n\nPromita Maitra and Ritesh Sarkhel. 2018. Emoti-kate: a k-competitive autoencoder for aggression detection in\nsocial media text. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1),\nSanta Fe, USA.\n\nShervin Malmasi and Marcos Zampieri. 2017. Detecting Hate Speech in Social Media. In Proceedings of the\nInternational Conference Recent Advances in Natural Language Processing (RANLP), pages 467-472.\n\nShervin Malmasi and Marcos Zampieri. 2018. Challenges in discriminating profanity from hate speech. Journal\nof Experimental & Theoretical Artificial Intelligence, 30:1 — 16.\n\nTodor Mihaylov, Georgi D Georgiev, AD Ontotext, and Preslav Nakov. 2015. Finding opinion manipulation trolls\nin news community forums. In Proceedings of the Nineteenth Conference on Computational Natural Language\nLearning, CoNLL, pages 310-314.\n\nSandip Modha, Prasenjit Majumder, and Thomas Mandl. 2018. Filtering aggression from multilingual social\nmedia feed. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1), Santa\nFe, USA.\n\nLuis G Mojica. 2016. Modeling trolling in social media conversations.\n\nNishant Nikhil, Ramit Pahwa, Mehul Kumar Nirala, and Rohan Khilnani. 2018. Lstms with attention for aggres-\nsion detection. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1),\nSanta Fe, USA.\n\n10\n", "vlm_text": "Viktor Golem, Mladen Karan, and Jan najder. 2018. Combining traditional machine learning models with deep learning for aggressive text detection. In  Proceedings of the First Workshop on Trolling, Aggression and Cyber- bullying (TRAC – 1) , Santa Fe, USA. \nEdel Greevy and Alan F. Smeaton. 2004. Classifying racist texts using a support vector machine. In  Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval , pages 468 – 469. ACM. \nClaire Hardaker. 2010. Trolling in asynchronous computer-mediated communication: From user discussions to academic deﬁnitions.  Journal of Politeness Research. Language, Behaviour, Culture , 6(2):215–242. \nClaire Hardaker. 2013. uh. . . . not to be nitpicky,,,,,but...the past tense of drag is dragged, not drug. an overview of trolling strategies.  Journal of Language Aggression and Conﬂict , 1(1):58–86. \nCynthia Van Hee, Els Lefever, Ben Verhoeven, Julie Mennes, Bart Desmet, Guy De Pauw, Walter Daelemans, and Vronique Hoste. 2015. Detection and ﬁne-grained classiﬁcation of cyberbullying events. In  Proceedings of International Conference Recent Advances in Natural Language Processing (RANLP) , pages 672–680. \nSameer Hinduja and Justin W Patchin. 2010. Bullying, Cyberbullying, and Suicide.  Archives of suicide research , 14(3):206–221. \nE. Krol. 1992.  The whole internet: User’s guide & catalog . O’Reilly & Associates, Inc., Sebastopol, CA. \nSudhakar Kumar, Francesca Spezzano, and VS Subrahmanian. 2014. Accurately detecting trolls in slashdot zoo via decluttering. In  Proceedings of IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) , pages 188–195. \nRitesh Kumar, Guggilla Bhanodai, Rajendra Pamula, and Maheshwar Reddy Chennuru. 2018a. Trac-1 shared task on aggression identiﬁcation: Iit(ism)@coling18. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. \nRitesh Kumar, Aishwarya N. Reganti, Akshit Bhatia, and Tushar Maheshwari. 2018b. Aggression-annotated cor- pus of hindi-english code-mixed data. In Nicoletta Calzolari (Conference chair), Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Koiti Hasida, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, Hlne Mazo, Asuncion Moreno, Jan Odijk, Stelios Piperidis, and Takenobu Tokunaga, editors,  Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018) , Paris, France, may. European Language Resources Association (ELRA). \nSreekanth Madisetty and Maunendra Sankar Desarkar. 2018. Aggression detection in social media using deep neural networks. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. \nPromita Maitra and Ritesh Sarkhel. 2018. Emoti-kate: a k-competitive autoencoder for aggression detection in social media text. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. \nShervin Malmasi and Marcos Zampieri. 2017. Detecting Hate Speech in Social Media. In  Proceedings of the International Conference Recent Advances in Natural Language Processing (RANLP) , pages 467–472. \nShervin Malmasi and Marcos Zampieri. 2018. Challenges in discriminating profanity from hate speech.  Journal of Experimental & Theoretical Artiﬁcial Intelligence , 30:1 – 16. \nTodor Mihaylov, Georgi D Georgiev, AD Ontotext, and Preslav Nakov. 2015. Finding opinion manipulation trolls in news community forums. In  Proceedings of the Nineteenth Conference on Computational Natural Language Learning, CoNLL , pages 310–314. \nSandip Modha, Prasenjit Majumder, and Thomas Mandl. 2018. Filtering aggression from multilingual social media feed. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  ) , Santa Fe, USA. \nLuis G Mojica. 2016. Modeling trolling in social media conversations. \nNishant Nikhil, Ramit Pahwa, Mehul Kumar Nirala, and Rohan Khilnani. 2018. Lstms with attention for aggres- sion detection. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. "}
{"page": 10, "image_path": "doc_images/W18-4401_10.jpg", "ocr_text": "Nitin, Ankush Bansal, Siddhartha Mahadev Sharma, Kapil Kumar, Anuj Aggarwal, Sheenu Goyal, Kanika Choud-\nhary, Kunal Chawla, Kunal Jain, and Manav Bhasinar. 2012. Classification of flames in computer mediated\ncommunications.\n\nTaisei Nitta, Fumito Masui, Michal Ptaszynski, Yasutomo Kimura, Rafal Rzepka, and Kenji Araki. 2013. Detect-\ning cyberbullying entries on informal school websites based on category relevance maximization. In Proceed-\nings of IJCNLP, pages 579-586.\n\nChikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang. 2016. Abusive Language Detec-\ntion in Online User Content. In Proceedings of the 25th International Conference on World Wide Web, pages\n145-153. International World Wide Web Conferences Steering Committee.\n\nAhmed Husseini Orabi, Mahmoud Husseini Orabi, Qianjia Huang, Diana Inkpen, and David Van Bruwaene. 2018.\nCyber-aggression detection using cross segment-and-concatenate multi-task learning from text. In Proceedings\nof the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1), Santa Fe, USA.\n\nConstantin Orasan. 2018. Aggressive Language Identification Using Word Embeddings and Sentiment Features.\nIn Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1), Santa Fe, USA.\n\nManish Gupta Pinkesh Badjatiya, Shashank Gupta and Vasudeva Varma. 2017. Deep learning for hate speech\ndetection in tweets. In Proceedings of the 26th International Conference on World Wide Web Companion, pages\n759 — 760. International World Wide Web Conferences Steering Committee.\n\nKashyap Raiyani, Teresa Gongalves, Paulo Quaresma, and Vitor Beires Nogueira. 2018. Fully connected neural\nnetwork with advance preprocessor to identify aggression over facebook and twitter. In Proceedings of the First\nWorkshop on Trolling, Aggression and Cyberbullying (TRAC — 1), Santa Fe, USA.\n\nFaneva Ramiandrisoa and Josiane Mothe. 2018. Irit at trac 2018. In Proceedings of the First Workshop on Trolling,\nAggression and Cyberbullying (TRAC — 1), Santa Fe, USA.\n\nJulian Risch and Ralf Krestel. 2018. Aggression identification using deep learning and data augmentation. In\nProceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1), Santa Fe, USA.\n\nArjun Roy, Prashant Kapil, Kingshuk Basak, and Asif Ekbal. 2018. An ensemble approach for aggression identifi-\ncation in english and hindi text. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying\n(TRAC — 1), Santa Fe, USA.\n\nNiloofar Safi Samghabadi, Deepthi Mave, Sudipta Kar, and Thamar Solorio. 2018. Ritual-uh at trac 2018 shared\ntask: Aggression identification. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbully-\ning (TRAC — 1), Santa Fe, USA.\n\nSasha Sax. 2016. Flame Wars: Automatic Insult Detection. Technical report, Stanford University.\n\nAnna Schmidt and Michael Wiegand. 2017. A Survey on Hate Speech Detection Using Natural Language Pro-\ncessing. In Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media.\nAssociation for Computational Linguistics, pages 1-10, Valencia, Spain.\n\nAntonela Tommasel, Juan Manuel Rodriguez, and Daniela Godoy. 2018. Textual aggression detection through\ndeep learning. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC — 1),\nSanta Fe, USA.\n\nFabio Del Vigna, Andrea Cimino, Felice DellOrletta, Marinella Petrocchi, and Maurizio Tesconi. 2017. Hate me,\nhate me not: Hate speech detection on facebook. In Proceedings of the First Italian Conference on Cybersecu-\nrity, pages 86 — 95.\n\nZeerak Waseem and Dirk Hovy. 2016. Hateful symbols or hateful people? predictive features for hate speech\ndetection on twitter. In Proceedings of NAACL-HLT, pages 88 — 93.\n\nZeerak Waseem, Thomas Davidson, Dana Warmsley, and Ingmar Weber. 2017. Understanding abuse: A typology\n\nof abusive language detection subtasks. In Proceedings of the First Workshop on Abusive Language Online,\npages 78-84. Association for Computational Linguistics.\n\n11\n", "vlm_text": "Nitin, Ankush Bansal, Siddhartha Mahadev Sharma, Kapil Kumar, Anuj Aggarwal, Sheenu Goyal, Kanika Choud- hary, Kunal Chawla, Kunal Jain, and Manav Bhasinar. 2012. Classiﬁcation of ﬂames in computer mediated communications. Taisei Nitta, Fumito Masui, Michal Ptaszynski, Yasutomo Kimura, Rafal Rzepka, and Kenji Araki. 2013. Detect- ing cyberbullying entries on informal school websites based on category relevance maximization. In  Proceed- ings of IJCNLP, pages 579–586.Chikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang. 2016. Abusive Language Detec- tion in Online User Content. In  Proceedings of the 25th International Conference on World Wide Web , pages 145–153. International World Wide Web Conferences Steering Committee. Ahmed Husseini Orabi, Mahmoud Husseini Orabi, Qianjia Huang, Diana Inkpen, and David Van Bruwaene. 2018. Cyber-aggression detection using cross segment-and-concatenate multi-task learning from text. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Constantin Orasan. 2018. Aggressive Language Identiﬁcation Using Word Embeddings and Sentiment Features. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Manish Gupta Pinkesh Badjatiya, Shashank Gupta and Vasudeva Varma. 2017. Deep learning for hate speech detection in tweets. In  Proceedings of the 26th International Conference on World Wide Web Companion , pages 759 – 760. International World Wide Web Conferences Steering Committee. Kashyap Raiyani, Teresa Gonc ¸alves, Paulo Quaresma, and Vitor Beires Nogueira. 2018. Fully connected neural network with advance preprocessor to identify aggression over facebook and twitter. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Faneva Ramiandrisoa and Josiane Mothe. 2018. Irit at trac 2018. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Julian Risch and Ralf Krestel. 2018. Aggression identiﬁcation using deep learning and data augmentation. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Arjun Roy, Prashant Kapil, Kingshuk Basak, and Asif Ekbal. 2018. An ensemble approach for aggression identiﬁ- cation in english and hindi text. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying  $(T R A C-I)$  , Santa Fe, USA. Niloofar SaﬁSamghabadi, Deepthi Mave, Sudipta Kar, and Thamar Solorio. 2018. Ritual-uh at trac 2018 shared task: Aggression identiﬁcation. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbully- ing   $(T R A C-I)$  , Santa Fe, USA. Sasha Sax. 2016. Flame Wars: Automatic Insult Detection. Technical report, Stanford University. Anna Schmidt and Michael Wiegand. 2017. A Survey on Hate Speech Detection Using Natural Language Pro- cessing. In  Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media. Association for Computational Linguistics , pages 1–10, Valencia, Spain. Antonela Tommasel, Juan Manuel Rodriguez, and Daniela Godoy. 2018. Textual aggression detection through deep learning. In  Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying   $(T R A C-I)$  , Santa Fe, USA. Fabio Del Vigna, Andrea Cimino, Felice DellOrletta, Marinella Petrocchi, and Maurizio Tesconi. 2017. Hate me, hate me not: Hate speech detection on facebook. In  Proceedings of the First Italian Conference on Cybersecu- rity , pages 86 – 95. Zeerak Waseem and Dirk Hovy. 2016. Hateful symbols or hateful people? predictive features for hate speech detection on twitter. In  Proceedings of NAACL-HLT , pages 88 – 93. Zeerak Waseem, Thomas Davidson, Dana Warmsley, and Ingmar Weber. 2017. Understanding abuse: A typology of abusive language detection subtasks. In  Proceedings of the First Workshop on Abusive Language Online , pages 78–84. Association for Computational Linguistics. "}
