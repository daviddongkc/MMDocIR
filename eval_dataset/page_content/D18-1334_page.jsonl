{"page": 0, "image_path": "doc_images/D18-1334_0.jpg", "ocr_text": "Getting Gender Right in Neural Machine Translation\n\nEva Vanmassenhove®\n\nChristian Hardmeier®\n\nAndy Way*\n\n* ADAPT, School of Computing, Dublin City University, Dublin, Ireland\nfirstname.lastname@adaptcentre.ie\n\n® Department of Linguistics and Philology, Uppsala University, Uppsala, Sweden\nchristian.hardmeier@lingfil.uu.se\n\nAbstract\n\nSpeakers of different languages must attend\nto and encode strikingly different aspects of\nthe world in order to use their language cor-\nrectly (Sapir, 1921; Slobin, 1996). One such\ndifference is related to the way gender is ex-\npressed in a language. Saying “I am happy”\nin English, does not encode any additional\nknowledge of the speaker that uttered the sen-\ntence. However, many other languages do\nhave grammatical gender systems and so such\nknowledge would be encoded. In order to\ncorrectly translate such a sentence into, say,\nFrench, the inherent gender information needs\nto be retained/recovered. The same sentence\nwould become either “Je suis heureux”, for a\nmale speaker or “Je suis heureuse” for a fe-\nmale one. Apart from morphological agree-\nment, demographic factors (gender, age, etc.)\nalso influence our use of language in terms of\nword choices or even on the level of syntac-\ntic constructions (Tannen, 1991; Pennebaker\net al., 2003). We integrate gender information\ninto NMT systems. Our contribution is two-\nfold: (1) the compilation of large datasets with\nspeaker information for 20 language pairs, and\n(2) a simple set of experiments that incorpo-\nrate gender information into NMT for multi-\nple language pairs. Our experiments show that\nadding a gender feature to an NMT system sig-\nnificantly improves the translation quality for\nsome language pairs.\n\n1 Introduction\n\nIn the field of linguistics, the differences between\nmale and female traits within spoken and written\nlanguage have been studied both empirically and\ntheoretically, revealing that the language used by\nmales and females differs in terms of style and\nsyntax (Coates, 2015). The increasing amount of\nwork on automatic author classification (or ‘au-\nthor profiling’) reaching relatively high accuracies\n\non domain-specific data corroborates these find-\nings (Rangel et al., 2013; Santosh et al., 2013).\nHowever, determining the gender of an author\nbased solely on text is not a solved issue. Like-\nwise, the selection of the most informative fea-\ntures for gender classification remains a difficult\ntask (Litvinova et al., 2016).\n\nWhen translating from one language into an-\nother, original author traits are partially lost, both\nin human and machine translations (Mirkin et al.,\n2015; Rabinovich et al., 2017). However, in the\nfield of Machine Translation (MT) one of the most\nobservable consequences of this missing informa-\nion are morphologically incorrect variants due to\na lack of agreement in number and gender with\nhe subject. Such errors harm the overall fluency\nand adequacy of the translated sentence. Further-\nmore, gender-related errors are not just harming\nhe quality of the translation as getting the gender\nright is also a matter of basic politeness. Current\nsystems have a tendency to perpetuate a male bias\nwhich amounts to negative discrimination against\nhalf the population and this has been picked up by\nhe media.!\n\nHuman translators rely on contextual informa-\nion to infer the gender of the speaker in order to\nmake the correct morphological agreement. How-\never, most current MT systems do not; they simply\nexploit statistical dependencies on the sentence\nlevel that have been learned from large amounts\nof parallel data. Furthermore, sentences are trans-\nlated in isolation. As a consequence, pieces of\ninformation necessary to determine the gender of\nthe speakers, might get lost. The MT system will,\nin such cases, opt for the statistically most likely\nvariant, which depending on the training data, will\n\n‘https: //www.theguardian.\ncom/technology/2017/apr/\n13/ai-programs-exhibit\n-racist-and-sexist-biases-—research\n\n3003\n\nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3003-3008\nBrussels, Belgium, October 31 - November 4, 2018. ©2018 Association for Computational Linguistics\n", "vlm_text": "Getting Gender Right in Neural Machine Translation \nEva Vanmassenhove α Christian Hardmeier β Andy Way α \nα  ADAPT, School of Computing, Dublin City University, Dublin, Ireland firstname.lastname@adaptcentre.ie \nβ  Department of Linguistics and Philology, Uppsala University, Uppsala, Sweden christian.hardmeier@lingfil.uu.se \nAbstract \nSpeakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language cor- rectly ( Sapir ,  1921 ;  Slobin ,  1996 ). One such difference is related to the way gender is ex- pressed in a language. Saying “I am happy” in English, does not encode any additional knowledge of the speaker that uttered the sen- tence. However, many other languages do have grammatical gender systems and so such knowledge would be encoded. In order to correctly translate such a sentence into, say, French, the inherent gender information needs to be retained/recovered. The same sentence would become either “Je suis heureux”, for a male speaker or “Je suis heureuse” for a fe- male one. Apart from morphological agree- ment, demographic factors (gender, age, etc.) also inﬂuence our use of language in terms of word choices or even on the level of syntac- tic constructions ( Tannen ,  1991 ;  Pennebaker et al. ,  2003 ). We integrate gender information into NMT systems. Our contribution is two- fold: (1) the compilation of large datasets with speaker information for 20 language pairs, and (2) a simple set of experiments that incorpo- rate gender information into NMT for multi- ple language pairs. Our experiments show that adding a gender feature to an NMT system sig- niﬁcantly improves the translation quality for some language pairs. \n1 Introduction \nIn the ﬁeld of linguistics, the differences between male and female traits within spoken and written language have been studied both empirically and theoretically, revealing that the language used by males and females differs in terms of style and syntax ( Coates ,  2015 ). The increasing amount of work on automatic author classiﬁcation (or ‘au- thor proﬁling’) reaching relatively high accuracies on domain-speciﬁc data corroborates these ﬁnd- ings ( Rangel et al. ,  2013 ;  Santosh et al. ,  2013 ). However, determining the gender of an author based solely on text is not a solved issue. Like- wise, the selection of the most informative fea- tures for gender classiﬁcation remains a difﬁcult task ( Litvinova et al. ,  2016 ). \n\nWhen translating from one language into an- other, original author traits are partially lost, both in human and machine translations ( Mirkin et al. , 2015 ;  Rabinovich et al. ,  2017 ). However, in the ﬁeld of Machine Translation (MT) one of the most observable consequences of this missing informa- tion are morphologically incorrect variants due to a lack of agreement in number and gender with the subject. Such errors harm the overall ﬂuency and adequacy of the translated sentence. Further- more, gender-related errors are not just harming the quality of the translation as getting the gender right is also a matter of basic politeness. Current systems have a tendency to perpetuate a male bias which amounts to negative discrimination against half the population and this has been picked up by the media. \nHuman translators rely on contextual informa- tion to infer the gender of the speaker in order to make the correct morphological agreement. How- ever, most current MT systems do not; they simply exploit statistical dependencies on the sentence level that have been learned from large amounts of parallel data. Furthermore, sentences are trans- lated in isolation. As a consequence, pieces of information necessary to determine the gender of the speakers, might get lost. The MT system will, in such cases, opt for the statistically most likely variant, which depending on the training data, will be either the male or the female form. Addition- ally, in the ﬁeld of MT, training data often con- sists of both original and translated parallel texts: large parts of the texts have already been trans- lated, which, as studied by Mirkin et al. ( 2015 ), does not preserve the original demographic and psychometric traits of the author, making it very hard for a Neural MT (NMT) system to determine the gender of the author. "}
{"page": 1, "image_path": "doc_images/D18-1334_1.jpg", "ocr_text": "be either the male or the female form. Addition-\nally, in the field of MT, training data often con-\nsists of both original and translated parallel texts:\nlarge parts of the texts have already been trans-\nlated, which, as studied by Mirkin et al. (2015),\ndoes not preserve the original demographic and\npsychometric traits of the author, making it very\nhard for a Neural MT (NMT) system to determine\nthe gender of the author.\n\nWith this in mind, a first step towards the preser-\nvation of author traits would be their integration\ninto an NMT system. As ‘gender’ manifests itself\nnot only in the agreement with other words in a\nsentence, but also in the choice of context-based\nwords or on the level of syntactic constructions,\nthe sets of experiments conducted in this paper\nfocus on the integration of a gender feature into\nNMT for multiple language pairs.\n\nThe structure of the paper is the following: re-\nlated work is described in Section 2; Section 3 de-\nscribes and analyses the datasets that were com-\npiled; the experimental setup is discussed in Sec-\ntion 4; the results are presented in Section 5; fi-\nnally, we conclude and provide some ideas for fu-\nture work in Section 6.\n\n2 Related Work\n\nDifferences in the language between male and\nfemale speakers have been studied within vari-\nous fields related to linguistics, including Natural\nLanguage Processing (NLP) for author profiling,\nconversational agents, recommendation systems\netc. Mirkin et al. (2015) motivated the need for\nmore personalized MT. Their experiments show\nthat MT is detrimental to the automatic recogni-\ntion of linguistic signals of traits of the original au-\nthor/speaker. Their work suggests using domain-\nadaptation techniques to make MT more personal-\nized but does not include any actual experiments\non the inclusion of author traits in MT.\nRabinovich et al. (2017) conducted a series of\nexperiments on preserving original author traits,\nfocusing particularly on gender. As suggested\nby Mirkin et al. (2015), they treat the person-\nalization of Statistical MT (SMT) systems as a\ndomain-adaptation task treating the female and\nmale gender as two different domains. They\napplied two common simple domain-adaptation\ntechniques in order to create personalized SMT:\n(1) using gender-specific phrase-tables and lan-\nguage models, and (2) using a gender-specific tun-\n\ning set. Although their models did not improve\nover the baseline, their work provides a detailed\nanalysis of gender traits in human and machine\ntranslation.\n\nOur work is, to the best of our knowledge, the\nfirst to attempt building a speaker-informed NMT\nsystem. Our approach is similar to the work of\nSennrich et al. (2016) on controlling politeness,\nwhere some sentence of the training data are fol-\nlowed with an ‘informal’ or ‘polite’ tag indicating\nthe level of politeness expressed.\n\n3 Compilation of Datasets\n\nOne of the main obstacles for more personalized\nMT systems is finding large enough annotated\nparallel datasets with speaker information. Rabi-\nnovich et al. (2017) published an annotated paral-\nlel dataset for EN-FR and EN-DE. However, for\nmany other language pairs no sufficiently large an-\nnotated datasets are available.\n\nTo address the aforementioned problem, we\npublished online a collection of parallel corpora\nlicensed under the Creative Commons Attribu-\nion 4.0 International License for 20 language\npairs (Vanmassenhove and Hardmeier, 2018).2\nWe followed the approach described by Rabi-\nnovich et al. (2017) and tagged parallel sentences\nrom Europarl (Koehn, 2005) with speaker infor-\nmation (name, gender, age, date of birth, euroID\nand date of the session) by retrieving speaker in-\n‘ormation provided by tags in the Europarl source\nfiles. The Europarl source files contain informa-\nion about the speaker on the paragraph level and\nhe filenames contain the data of the session. By\nretrieving the names of the speakers together with\nmeta-information on the members of the Euro-\npean Parliament (MEPs) released by Rabinovich\net al. (2017) (which includes among others name,\ncountry, date of birth and gender predictions per\nMEP), we were able to retrieve demographic an-\nnotations (gender, age, etc.). An overview of the\nlanguage pairs as well as the amount of annotated\nparallel sentences per language pair is given in Ta-\nble 1.\n\n3.1. Analysis of the EN-FR Annotated\nDataset\n\nWe first analysed the distribution of male and fe-\nmale sentence in our data. In the 10 different\n\n*https://github.com/evavnmssnhv/\nEuroparl-Speaker-Information\n\n3004\n", "vlm_text": "\nWith this in mind, a ﬁrst step towards the preser- vation of author traits would be their integration into an NMT system. As ‘gender’ manifests itself not only in the agreement with other words in a sentence, but also in the choice of context-based words or on the level of syntactic constructions, the sets of experiments conducted in this paper focus on the integration of a gender feature into NMT for multiple language pairs. \nThe structure of the paper is the following: re- lated work is described in Section  2 ; Section  3  de- scribes and analyses the datasets that were com- piled; the experimental setup is discussed in Sec- tion  4 ; the results are presented in Section  5 ; ﬁ- nally, we conclude and provide some ideas for fu- ture work in Section  6 . \n2 Related Work \nDifferences in the language between male and female speakers have been studied within vari- ous ﬁelds related to linguistics, including Natural Language Processing (NLP) for author proﬁling, conversational agents, recommendation systems etc. Mirkin et al. ( 2015 ) motivated the need for more personalized MT. Their experiments show that MT is detrimental to the automatic recogni- tion of linguistic signals of traits of the original au- thor/speaker. Their work suggests using domain- adaptation techniques to make MT more personal- ized but does not include any actual experiments on the inclusion of author traits in MT. \nRabinovich et al. ( 2017 ) conducted a series of experiments on preserving original author traits, focusing particularly on gender. As suggested by Mirkin et al. ( 2015 ), they treat the person- alization of Statistical MT (SMT) systems as a domain-adaptation task treating the female and male gender as two different domains. They applied two common simple domain-adaptation techniques in order to create personalized SMT: (1) using gender-speciﬁc phrase-tables and lan- guage models, and (2) using a gender-speciﬁc tun- ing set. Although their models did not improve over the baseline, their work provides a detailed analysis of gender traits in human and machine translation. \n\nOur work is, to the best of our knowledge, the ﬁrst to attempt building a speaker-informed NMT system. Our approach is similar to the work of Sennrich et al. ( 2016 ) on controlling politeness, where some sentence of the training data are fol- lowed with an ‘informal’ or ‘polite’ tag indicating the level of politeness expressed. \n3 Compilation of Datasets \nOne of the main obstacles for more personalized MT systems is ﬁnding large enough annotated parallel datasets with speaker information. Rabi- novich et al. ( 2017 ) published an annotated paral- lel dataset for EN–FR and EN–DE. However, for many other language pairs no sufﬁciently large an- notated datasets are available. \nTo address the aforementioned problem, we published online a collection of parallel corpora licensed under the Creative Commons Attribu- tion 4.0 International License for 20 language pairs ( Vanmassenhove and Hardmeier ,  2018 ). \nWe followed the approach described by Rabi- novich et al. ( 2017 ) and tagged parallel sentences from Europarl ( Koehn ,  2005 ) with speaker infor- mation (name, gender, age, date of birth, euroID and date of the session) by retrieving speaker in- formation provided by tags in the Europarl source ﬁles. The Europarl source ﬁles contain informa- tion about the speaker on the paragraph level and the ﬁlenames contain the data of the session. By retrieving the names of the speakers together with meta-information on the members of the Euro- pean Parliament (MEPs) released by Rabinovich et al. ( 2017 ) (which includes among others name, country, date of birth and gender predictions per MEP), we were able to retrieve demographic an- notations (gender, age, etc.). An overview of the language pairs as well as the amount of annotated parallel sentences per language pair is given in Ta- ble  1 . \n3.1 Analysis of the EN–FR Annotated Dataset \nWe ﬁrst analysed the distribution of male and fe- male sentence in our data. In the 10 different "}
{"page": 2, "image_path": "doc_images/D18-1334_2.jpg", "ocr_text": "Languages # sents Languages # sents\nEN-BG 306,380 EN-IT 1,297,635\nEN-CS 491,848 EN-LT 481,570\nEN-DA 1,421,197 | EN-LV 487,287\nEN-DE 1,296,843 | EN-NL 1,419,359\nEN-EL 921,540 EN-PL 478,008\nEN-ES 1,419,507 | EN-PT 1,426,043\nEN-ET 494,645 EN-RO 303,396\nEN-FI 1,393,572 | EN-SK 488,351\nEN-FR 1,440,620 | EN-SL 479,313\nEN-HU 251,833 EN-SV 1,349,472\n\nTable 1: Overview of annotated parallel sentences per lan-\nguage pair\n\ndatasets we experimented with, the percentage of\nsentences uttered by female speakers is very sim-\nilar, ranging between 32% and 33%. This simi-\nlarity can be explained by the fact that Europarl\nis largely a multilingual corpus with a big overlap\nbetween the different language pairs.\n\nWe conducted a more focused analysis on one\nof the subcorpora (EN-FR) with respect to the\npercentage of sentences uttered by males/females\nfor various age groups to obtain a better grasp of\nwhat kind of data we are using for training. As\ncan be seen from Figure 1, with the exception of\nthe youngest age group (20-30), which represents\nonly a very small percentage of the total amount\nof sentences (0.71%), more male data is available\nin all age groups. Furthermore, when looking at\nthe entire dataset, 67.39% of the sentences are pro-\nduced by male speakers. Moreover, almost half of\nthe total number of sentences are uttered by the\n50-60 age group (43.76%).\n\n100%\n90%\n80%\n70%\n60%\n50%\n40%\n30%\n20%\n10%\n\n0%\n\n20-30 30-40 40-50 50-60 60-70 70-80 80-90\n\n= Male\nm@ Female\n\n‘Age groups\n\nFigure 1: Percentage of female and male speakers per age\ngroup\n\nThe analysis shows that indeed, there is a gen-\nder unbalance in the Europar! dataset, which will\nbe reflected in the translations that MT systems\ntrained on this data produce.\n\n4 Experimental Setup\n4.1 Datasets\n\nWe carried out a set of experiments on 10 lan-\nguage pairs (the ones for which we compiled more\nthan 500k annotated Europarl parallel sentences):\nEN-DE, EN-FR, EN-ES, EN-EL, EN-PT, EN—\nFI, EN-IT, EN-SV, EN-NL and EN-DA. We aug-\nmented every sentence with a tag on the English\nsource side, identifying the gender of the speaker,\nas illustrated in (1). This approach for encoding\nsentence-specific information for NMT has been\nsuccessfully exploited to tackle other types of is-\nsues, multilingual NMT systems (e.g., Zero Shot\nTranslation (Johnson et al., 2017)), domain adap-\ntation (Sennrich et al., 2016), etc.\n\n(1) “FEMALE Madam President, as a...”\n\nFor each of these language pairs we trained two\nNMT systems: a baseline and a tagged one. We\nevaluated the performance of all our systems on a\nrandomly selected 2K general test set. Moreover,\nwe further evaluated the EN-FR systems on 2K\nmale-only and female-only test sets to have a look\nat the system performance with respect to gender-\nrelated issues. We also looked at two additional\nmale and female test sets in which the first person\nsingular pronoun appeared.\n\n4.2. Description of the NMT Systems\n\nWe used the OpenNMT-py toolkit (Klein et al.,\n2017) to train the NMT models. The models\nare sequence-to-sequence encoder-decoders with\nLSTMs as the recurrent unit (Bahdanau et al.,\n2014; Cho et al., 2014; Sutskever et al., 2014)\ntrained with the default parameters. In order to by-\npass the OOV problem and reduce the number of\ndictionary entries, we use word-segmentation with\nBPE (Sennrich, 2015). We ran the BPE algorithm\nwith 89,500 operations (Sennrich, 2015). All sys-\ntems are trained for 13 epochs and the best model\nis selected for evaluation.\n\n5 Results\n\nIn this section we discuss some of the results ob-\ntained. We hypothesized that the male/female\ntags would be particularly helpful for French, Por-\ntuguese, Italian, Spanish and Greek, where adjec-\ntives and even verb forms can be marked by the\ngender of the speaker. Since, according to the\nliterature, women and men also make use of dif-\nferent syntactic constructions and make different\n\n3005\n", "vlm_text": "The table shows pairs of languages and the corresponding number of sentences available for each pair. The language pairs are listed alongside the number of sentences:\n\n- EN–BG: 306,380\n- EN–CS: 491,848\n- EN–DA: 1,421,197\n- EN–DE: 1,296,843\n- EN–EL: 921,540\n- EN–ES: 1,419,507\n- EN–ET: 494,645\n- EN–FI: 1,393,572\n- EN–FR: 1,440,620\n- EN–HU: 251,833\n\n- EN–IT: 1,297,635\n- EN–LT: 481,570\n- EN–LV: 487,287\n- EN–NL: 1,419,359\n- EN–PL: 478,008\n- EN–PT: 1,426,043\n- EN–RO: 303,396\n- EN–SK: 488,351\n- EN–SL: 479,313\n- EN–SV: 1,349,472\ndatasets we experimented with, the percentage of sentences uttered by female speakers is very sim- ilar, ranging between   $32\\%$   and   $33\\%$  . This simi- larity can be explained by the fact that Europarl is largely a multilingual corpus with a big overlap between the different language pairs. \nWe conducted a more focused analysis on one of the subcorpora (EN–FR) with respect to the percentage of sentences uttered by males/females for various age groups to obtain a better grasp of what kind of data we are using for training. As can be seen from Figure  1 , with the exception of the youngest age group (20–30), which represents only a very small percentage of the total amount of sentences   $(0.71\\%)$  , more male data is available in all age groups. Furthermore, when looking at the entire dataset,   $67.39\\%$   of the sentences are pro- duced by male speakers. Moreover, almost half of the total number of sentences are uttered by the 50–60 age group   $(43.76\\%)$  . \nThe image is a stacked bar chart showing the percentage of male and female speakers across different age groups. The age groups are divided into segments: 20-30, 30-40, 40-50, 50-60, 60-70, 70-80, and 80-90. \n\n- The red segments represent male speakers, while the blue segments represent female speakers. \n- For most age groups, male speakers are in the majority, especially evident in the 20-30 and 80-90 age groups.\n- The female presence seems relatively low in most groups, with slight variations across different ages.\nThe analysis shows that indeed, there is a gen- der unbalance in the Europarl dataset, which will be reﬂected in the translations that MT systems trained on this data produce. \n4 Experimental Setup \n4.1 Datasets \nWe carried out a set of experiments on 10 lan- guage pairs (the ones for which we compiled more than   $500\\mathrm{k}$   annotated Europarl parallel sentences): EN–DE, EN–FR, EN–ES, EN–EL, EN–PT, EN– FI, EN–IT, EN–SV, EN–NL and EN–DA. We aug- mented every sentence with a tag on the English source side, identifying the gender of the speaker, as illustrated in ( 1 ). This approach for encoding sentence-speciﬁc information for NMT has been successfully exploited to tackle other types of is- sues, multilingual NMT systems (e.g., Zero Shot Translation ( Johnson et al. ,  2017 )), domain adap- tation ( Sennrich et al. ,  2016 ), etc. \n(1) “FEMALE Madam President, as a...” \nFor each of these language pairs we trained two NMT systems: a baseline and a tagged one. We evaluated the performance of all our systems on a randomly selected 2K general test set. Moreover, we further evaluated the EN–FR systems on 2K male-only and female-only test sets to have a look at the system performance with respect to gender- related issues. We also looked at two additional male and female test sets in which the ﬁrst person singular pronoun appeared. \n4.2 Description of the NMT Systems \nWe used the OpenNMT-py toolkit ( Klein et al. , 2017 ) to train the NMT models. The models are sequence-to-sequence encoder-decoders with LSTMs as the recurrent unit ( Bahdanau et al. , 2014 ;  Cho et al. ,  2014 ;  Sutskever et al. ,  2014 ) trained with the default parameters. In order to by- pass the OOV problem and reduce the number of dictionary entries, we use word-segmentation with BPE ( Sennrich ,  2015 ). We ran the BPE algorithm with 89,500 operations ( Sennrich ,  2015 ). All sys- tems are trained for 13 epochs and the best model is selected for evaluation. \n5 Results \nIn this section we discuss some of the results ob- tained. We hypothesized that the male/female tags would be particularly helpful for French, Por- tuguese, Italian, Spanish and Greek, where adjec- tives and even verb forms can be marked by the gender of the speaker. Since, according to the literature, women and men also make use of dif- ferent syntactic constructions and make different word choices, we also tested the approach on other languages that do not have morphological agree- ment with the gender of the speaker such as Dan- ish (DA), Dutch (NL), Finnish (FI), German (DE) and Swedish (SV). "}
{"page": 3, "image_path": "doc_images/D18-1334_3.jpg", "ocr_text": "word choices, we also tested the approach on other\nlanguages that do not have morphological agree-\nment with the gender of the speaker such as Dan-\nish (DA), Dutch (NL), Finnish (FI), German (DE)\nand Swedish (SV).\n\nFirst, we wanted to see how our tagged systems\nperformed on the general test set compared to the\nbaseline. In Table 2, the BLEU scores for 10 base-\nline and 10 gender-enhanced NMT systems are\npresented.\n\nSystems EN EN-TAG\n\nFR 37.82 39.26*\n\nES 42.47 42.28\n\nEL 31.38 31.54\n\nIT 31.46 31.75*\n\nPT 36.11 36.33\n\nDA 36.69 37.00*\n\nDE 28.28 28.05\n\nFI 21.82 21.35*\n\nSV 35.42 35.19\n\nNL 28.35 28.22\nTable 2: BLEU scores for the 10 baseline (denoted with\nEN) and the 10 gender-enhanced NMT (denoted with EN-\nTAG) systems. Entries labeled with * present statistically\nsignificant differences (p < 0.05). Statistical significance was\ncomputed with the MultEval tool (Clark et al., 2011).\n\nWhile most of the BLEU-scores (Papineni et al.,\n2002) in Table 2 are consistent with our hy-\npothesis, showing (significant) improvements for\nthe NMT systems enriched with a gender tag\n(EN-TAG) over the baseline systems (EN) for\nFrench, Italian, Portuguese and Greek, the Span-\nish enriched system surprisingly does not (-0.19\nBLEU). As hypothesized, the Dutch, German,\nFinnish and Swedish systems do not improve.\nHowever, the Danish (EN—DA) enriched NMT\nsystem does achieve a significant +0.31 BLEU im-\nprovement.\n\nWe expected to see the strongest improvements\nin sentences uttered by female speakers as, accord-\ning to our initial analysis, the male data was over-\nrepresented in the training. To test this hypothe-\nsis, we evaluated all systems on a male-only and\nfemale-only test set. Furthermore, we also experi-\nmented on test sets containing the pronoun of the\nfirst person singular as this form is used when a\nspeaker refers to himself/herself. The results on\nthe specific test set for the EN—-FR dataset are pre-\nsented in Table 3. As hypothesized, the biggest\nBLEU score improvement is observed on the fe-\nmale test set, particularly, the test sets containing\nfirst person singular pronouns (F1).\n\nWe had a closer look at some of the transla-\n\nTest Sets EN EN-TAG\nFR (M) 37.58 | 38.71*\nFR (F) 37.75 | 38.97*\nFR (M1) | 39.00 | 39.66*\nFR (F1) | 37.32 | 38.57*\n\nTable 3: BLEU-scores on EN-FR comparing the baseline\n(EN) and the tagged systems (EN-TAG) on 4 different test\nsets: a test set containing only male data (M), only female\ndata (F), lst person male data (M1) and first person female\ndata (F1). All the improvements of the EN-TAG system are\nstatistically significant (p < 0.5), as indicated by *.\n\nions.> There are cases where the gender-informed\n(TAG) system improves over the baseline (BASE)\ndue to better agreement. Interestingly, in (2)\nhe French female form of vice-president (vice-\nprésidente) appears in the translation produced by\nhe BASE system while the male form is the cor-\nrect one. The gender-informed system does make\nhe correct agreement by using the female variant.\nIn (3) the speaker is female but the baseline sys-\nem outputs a male form of the adjective ‘happy’\n(‘heureux’).\n\n(Ref) En tant que vice-président...\n(2) (BASE) _ En tant que vice-présidente...\n(TAG) En tant que vice-président...\n(Ref) ... Je suis heureuse que...\n(3) (BASE) __... je suis heureux que...\n(TAG) ... Je suis heureuse que...\n\nHowever, we also encountered cases where the\ngender-informed system fails to produce the cor-\nrect agreement, as in (4), where both the BASE\nand the TAG system produce a male form (‘em-\nbarassé’) instead of the correct female one (‘em-\nbarassée’ or ‘génée’).\n\n(Ref) je suis génée que...\n(4) (BASE) _ je suis embarassé que...\n(TAG) je suis embarassé que...\n\nFor some language pairs the gender-informed\nsystem leads to a significant improvement even\non a general test set. This implies that the im-\nprovement is not merely because of better mor-\nphological agreement, as these kinds of improve-\nments are very hard to measure with BLEU, espe-\ncially given the fact that Europarl consists of for-\nmal spoken language and does not contain many\nsentences using the first person singular pronoun.\nFrom our analysis, we observe that in many cases\nthe gender-informed systems have a higher BLEU\n\n3We used the tool provided by Tilde https: //www.\nletsmt.eu/Bleu.aspx to see where the BLEU score\nbetween the baseline and our tagged systems varied the most.\n\n3006\n", "vlm_text": "\nFirst, we wanted to see how our tagged systems performed on the general test set compared to the baseline. In Table  2 , the BLEU scores for 10 base- line and 10 gender-enhanced NMT systems are presented. \nThe table presents a comparison of two systems, labeled \"EN\" and \"EN-TAG\", across different languages or categories. The first column lists the systems/languages as FR, ES, EL, IT, PT, DA, DE, FI, SV, and NL. The two subsequent columns provide numerical values for each language under the \"EN\" and \"EN-TAG\" systems, respectively.\n\nHere's a summary of the values in the table:\n\n- FR: EN: 37.82, EN-TAG: 39.26*\n- ES: EN: 42.47, EN-TAG: 42.28\n- EL: EN: 31.38, EN-TAG: 31.54\n- IT: EN: 31.46, EN-TAG: 31.75*\n- PT: EN: 36.11, EN-TAG: 36.33\n- DA: EN: 36.69, EN-TAG: 37.00*\n- DE: EN: 28.28, EN-TAG: 28.05\n- FI: EN: 21.82, EN-TAG: 21.35*\n- SV: EN: 35.42, EN-TAG: 35.19\n- NL: EN: 28.35, EN-TAG: 28.22\n\nThe asterisks (*) next to some values under the \"EN-TAG\" column likely indicate that these values are noteworthy or statistically significant in some way.\nWhile most of the BLEU-scores ( Papineni et al. , 2002 ) in Table  2  are consistent with our hy- pothesis, showing (signiﬁcant) improvements for the NMT systems enriched with a gender tag (EN-TAG) over the baseline systems (EN) for French, Italian, Portuguese and Greek, the Span- ish enriched system surprisingly does not   $(-0.19\\$  BLEU). As hypothesized, the Dutch, German, Finnish and Swedish systems do not improve. However, the Danish (EN–DA) enriched NMT system does achieve a signiﬁcant  $+0.31$   BLEU im- provement. \nWe expected to see the strongest improvements in sentences uttered by female speakers as, accord- ing to our initial analysis, the male data was over- represented in the training. To test this hypothe- sis, we evaluated all systems on a male-only and female-only test set. Furthermore, we also experi- mented on test sets containing the pronoun of the ﬁrst person singular as this form is used when a speaker refers to himself/herself. The results on the speciﬁc test set for the EN–FR dataset are pre- sented in Table  3 . As hypothesized, the biggest BLEU score improvement is observed on the fe- male test set, particularly, the test sets containing ﬁrst person singular pronouns (F1). \nWe had a closer look at some of the transla- \nThe table presents data comparing two different test conditions labeled as \"EN\" and \"EN-TAG\" across four types of test sets. Here is a detailed breakdown:\n\n- **Test Sets**: There are four test sets.\n  - \"FR (M)\" which scores 37.58 in \"EN\" and 38.71 (marked with an asterisk) in \"EN-TAG\".\n  - \"FR (F)\" which scores 37.75 in \"EN\" and 38.97 (marked with an asterisk) in \"EN-TAG\".\n  - \"FR (M1)\" which scores 39.00 in \"EN\" and 39.66 (marked with an asterisk) in \"EN-TAG\".\n  - \"FR (F1)\" which scores 37.32 in \"EN\" and 38.57 (marked with an asterisk) in \"EN-TAG\".\n\n- **EN**: This column represents scores under a condition labeled \"EN\". The scores range from 37.32 to 39.00.\n\n- **EN-TAG**: This column represents scores under a condition labeled \"EN-TAG\". The scores are slightly higher than those in the \"EN\" column, ranging from 38.57 to 39.66, and each score is marked with an asterisk, possibly indicating statistical significance or emphasis.\n\nOverall, the test sets labeled FR (M), FR (F), FR (M1), and FR (F1) achieve higher scores in the \"EN-TAG\" condition compared to the \"EN\" condition, suggesting that the \"EN-TAG\" method or condition may be more effective or improved in some manner.\nTable 3 :  BLEU-scores on EN–FR comparing the baseline (EN) and the tagged systems (EN–TAG) on 4 different test sets: a test set containing only male data (M), only female data (F), 1st person male data (M1) and ﬁrst person female data (F1). All the improvements of the EN-TAG system are statistically signiﬁcant   $({\\tt p}<0.5)$  , as indicated by \\*. \ntions.   There are cases where the gender-informed (TAG) system improves over the baseline (BASE) due to better agreement. Interestingly, in ( 2 ) the French female form of vice-president (vice- pr´ esidente) appears in the translation produced by the BASE system while the male form is the cor- rect one. The gender-informed system does make the correct agreement by using the female variant. In ( 3 ) the speaker is female but the baseline sys- tem outputs a male form of the adjective ‘happy’\n\n (‘heureux’). \n(Ref) En tant que  vice-pr´ esident ...\n\n (2) (BASE) En tant que  vice-pr´ esidente ... (TAG) En tant que  vice-pr´ esident ... \nHowever, we also encountered cases where the gender-informed system fails to produce the cor- rect agreement, as in ( 4 ), where both the BASE and the TAG system produce a male form (‘em- barass´ e’) instead of the correct female one (‘em- barass´ ee’ or ‘gˆ en´ ee’). \nFor some language pairs the gender-informed system leads to a signiﬁcant improvement even on a general test set. This implies that the im- provement is not merely because of better mor- phological agreement, as these kinds of improve- ments are very hard to measure with BLEU, espe- cially given the fact that Europarl consists of for- mal spoken language and does not contain many sentences using the ﬁrst person singular pronoun. From our analysis, we observe that in many cases the gender-informed systems have a higher BLEU score than the baseline system due to differences in word choices as in ( 5 ) and ( 6 ), where both trans- lations are correct, but the gender-informed sys- tem picks the preferred variant. "}
{"page": 4, "image_path": "doc_images/D18-1334_4.jpg", "ocr_text": "score than the baseline system due to differences\nin word choices as in (5) and (6), where both trans-\nlations are correct, but the gender-informed sys-\ntem picks the preferred variant.\n\nThe observations with respect to differences in\nword preferences between male and female speak-\ners are in accordance with corpus linguistic stud-\nies, which have shown that gender does not only\nhave an effect on morphological agreement, but\nalso manifests itself in other ways as males and\nfemales have different preferences when it comes\nto different types of constructions, word choices\netc. (Newman et al., 2008; Coates, 2015). This\nalso implies that, even for languages that do not\nmark gender overtly (ie. grammatically), it can\nstill be beneficial to take the gender of the au-\nthor/speaker into account.\n\n(Ref) Je pense que ...\n(5) (BASE) _ Je crois que...\n(TAG) Je pense que...\n\nAlthough more research is required in order\nto draw general conclusions on this matter, from\nother linguistic studies, it appears that it is indeed\nthe case that there is a relation between the use\nof the word “pense” (“think”’) / “crois” (“believe”)\nand the gender of the speaker. To see whether\nthere is a difference in word choice and whether\nthis is reflected in our data, we compiled a list\nof the most frequent French words for the male\ndata and the female data. Our analysis reveals that\n“crois” is, in general, used more by males (hav-\ning position 303 in the most frequent words for\nmales, but only position 373 for females), while\n“pense” is found at a similar position in both lists\n(position 151 and 153). These findings are in ac-\ncordance with other linguistic corpus studies on\nlanguage and gender stating that women use less\nassertive speech (Newman et al., 2008). “Croire”\nand “penser” are both verbs of cognition but there\nis a difference in the degree of confidence in the\ntruth value predicated: the verb “croire” denotes\nmore confidence in the truth of the complement\nclause than the verb “penser” does. In the future,\nwe would like to perform a more detailed analy-\nsis of other specific differences in lexical choices\nbetween males and females on multiple language\npairs.\n\n(Ref) J’ ai plusieurs remarques...\n(6) (BASE) J’ ai un nombre de commentaires...\n(TAG) J’ ai plusieurs remarques...\n\n6 Conclusions and Future Work\n\nIn this work, we experimented with the incorpora-\nion of speaker-gender tags during the training of\nNMT systems in order to improve morphological\nagreement. We focused particularly on language\npairs that express grammatical gender but included\nother language pairs as well, as linguistic studies\nhave shown that the style and syntax of language\nused by males and females differs (Coates, 2015).\n\nFrom the experiments, we see that informing\nhe NMT system by providing tags indicating the\ngender of the speaker can indeed lead to signif-\nicant improvements over state-of-the-art baseline\nsystems, especially for those languages expressing\ngrammatical gender agreement. However, while\nanalyzing the EN-FR translations, we observed\nthat the improvements are not always consistent\nand that, apart from morphological agreement, the\ngender-aware NMT system differs from the base-\nline in terms of word choices.\n\nIn the future, we would like to conduct fur-\nther manual evaluation on the translations to fur-\nther analyze the differences with the baseline sys-\ntem. Furthermore, we aim to experiment with\nother ways of integrating speaker information. We\nenvisage working on gender classification tech-\nniques in order to work on other types (more in-\nformal) of corpora that are more likely to express\nspeaker characteristics.\n\nAcknowledgements\n\nThis work has been supported by COST action\n1S1312, the Dublin City University Faculty of En-\ngineering & Computing under the Daniel O’ Hare\nResearch Scholarship scheme and by the ADAPT\nCentre for Digital Content Technology, which\nis funded under the SFI Research Centres Pro-\ngramme (Grant 13/RC/2106). Christian Hard-\nmeier was supported by the Swedish Research\nCouncil under grant 2017-930.\n\nWe would also like to thank the anonymous re-\nviewers for their insightful comments and feed-\nback.\n\nReferences\n\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-\ngio. 2014. Neural Machine Translation by Jointly\nLearning to Align and Translate. In International\nConference on Learning Representations, Banff,\nCanada.\n\n3007\n", "vlm_text": "\nThe observations with respect to differences in word preferences between male and female speak- ers are in accordance with corpus linguistic stud- ies, which have shown that gender does not only have an effect on morphological agreement, but also manifests itself in other ways as males and females have different preferences when it comes to different types of constructions, word choices etc. ( Newman et al. ,  2008 ;  Coates ,  2015 ). This also implies that, even for languages that do not mark gender overtly (i.e. grammatically), it can still be beneﬁcial to take the gender of the au- thor/speaker into account. \n(Ref) Je pense que ... (5) (BASE) Je crois que... (TAG) Je pense que... \nAlthough more research is required in order to draw general conclusions on this matter, from other linguistic studies, it appears that it is indeed the case that there is a relation between the use of the word “pense” (“think”) / “crois” (“believe”) and the gender of the speaker. To see whether there is a difference in word choice and whether this is reﬂected in our data, we compiled a list of the most frequent French words for the male data and the female data. Our analysis reveals that “crois” is, in general, used more by males (hav- ing position 303 in the most frequent words for males, but only position 373 for females), while\n\n “pense” is found at a similar position in both lists\n\n (position 151 and 153). These ﬁndings are in ac- cordance with other linguistic corpus studies on language and gender stating that women use less assertive speech ( Newman et al. ,  2008 ). “Croire” and “penser” are both verbs of cognition but there is a difference in the degree of conﬁdence in the truth value predicated: the verb “croire” denotes more conﬁdence in the truth of the complement clause than the verb “penser” does. In the future, we would like to perform a more detailed analy- sis of other speciﬁc differences in lexical choices between males and females on multiple language pairs. \n(Ref) J’ ai plusieurs remarques... (6) (BASE) J’ ai un nombre de commentaires... (TAG) J’ ai plusieurs remarques... \n6 Conclusions and Future Work \nIn this work, we experimented with the incorpora- tion of speaker-gender tags during the training of NMT systems in order to improve morphological agreement. We focused particularly on language pairs that express grammatical gender but included other language pairs as well, as linguistic studies have shown that the style and syntax of language used by males and females differs ( Coates ,  2015 ). \nFrom the experiments, we see that informing the NMT system by providing tags indicating the gender of the speaker can indeed lead to signif- icant improvements over state-of-the-art baseline systems, especially for those languages expressing grammatical gender agreement. However, while analyzing the EN–FR translations, we observed that the improvements are not always consistent and that, apart from morphological agreement, the gender-aware NMT system differs from the base- line in terms of word choices. \nIn the future, we would like to conduct fur- ther manual evaluation on the translations to fur- ther analyze the differences with the baseline sys- tem. Furthermore, we aim to experiment with other ways of integrating speaker information. We envisage working on gender classiﬁcation tech- niques in order to work on other types (more in- formal) of corpora that are more likely to express speaker characteristics. \nAcknowledgements \nThis work has been supported by COST action IS1312, the Dublin City University Faculty of En- gineering & Computing under the Daniel O’Hare Research Scholarship scheme and by the ADAPT Centre for Digital Content Technology, which is funded under the SFI Research Centres Pro- gramme (Grant 13/RC/2106). Christian Hard- meier was supported by the Swedish Research Council under grant 2017-930. \nWe would also like to thank the anonymous re- viewers for their insightful comments and feed- back. \nReferences \nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2014. Neural Machine Translation by Jointly Learning to Align and Translate. In  International Conference on Learning Representations , Banff, Canada. "}
{"page": 5, "image_path": "doc_images/D18-1334_5.jpg", "ocr_text": "Kyunghyun Cho, Bart van Merriénboer, Calar\nGiilgehre, Dzmitry Bahdanau, Fethi Bougares, Hol-\nger Schwenk, and Yoshua Bengio. 2014. Learn-\ning Phrase Representations using RNN Encoder—\nDecoder for Statistical Machine Translation. In Pro-\nceedings of EMNLP 2014, pages 1724-1734, Doha,\nQatar.\n\nJonathan H Clark, Chris Dyer, Alon Lavie, and Noah A\nSmith. 2011. Better Hypothesis Testing for Statisti-\ncal Machine Translation: Controlling for Optimizer\nInstability. In Proceedings of the 49th Annual Meet-\ning of the Association for Computational Linguis-\ntics: Human Language Technologies: short papers-\nVolume 2, pages 176-181. Association for Compu-\ntational Linguistics.\n\nJennifer Coates. 2015. Women, Men and Language:\nA Sociolinguistic Account of Gender Differences in\nLanguage. Routledge, London.\n\nMelvin Johnson, Mike Schuster, Quoc V Le, Maxim\nKrikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat,\nFernanda Viégas, Martin Wattenberg, Greg Corrado,\net al. 2017. Google’s Multilingual Neural Machine\nTranslation System: Enabling Zero-Shot Transla-\ntion. Transactions of the Association of Computa-\ntional Linguistics, 5(1):339-351.\n\nGuillaume Klein, Yoon Kim, Yuntian Deng, Jean\nSenellart, and Alexander M. Rush. 2017. Open-\nNMT: Open-Source Toolkit for Neural Machine\nTranslation. In Proceeding of ACL, Vancouver,\nCanada.\n\nPhilipp Koehn. 2005. Europarl: A Parallel Corpus for\nStatistical Machine Translation. In MT Summit, vol-\nume 5, pages 79-86, Phuket, Thailand.\n\nTatiana Litvinova, Pavel Seredin, Olga Litvinova,\nOlga Zagorovskaya, Aleksandr Sboev, Dmitry Gu-\ndovskih, Ivan Moloshnikov, and Roman Rybka.\n2016. Gender Prediction for Authors of Russian\nTexts Using Regression And Classification Tech-\nniques. In Proceedings of the Third Workshop on\nConcept Discovery in Unstructured Data co-located\nwith the 13th International Conference on Concept\nLattices and Their Applications (CDUD@ CLA),\npages 44-53, Moscow, Russia.\n\nShachar Mirkin, Scott Nowson, Caroline Brun, and\nJulien Perez. 2015. Motivating Personality-Aware\nMachine Translation. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1102-1108, Lisbon, Portu-\ngal.\n\nMatthew L Newman, Carla J Groom, Lori D Handel-\nman, and James W Pennebaker. 2008. Gender Dif-\nferences in Language Use: An Analysis of 14,000\nText Samples. Discourse Processes, 45(3):211-236.\n\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. BLEU: A Method for Automatic\nEvaluation of Machine Translation. In Proceedings\n\nof the 40th annual meeting on association for com-\nputational linguistics, pages 311-318.\n\nJames W. Pennebaker, Matthias R. Mehl, and Kate G.\nNiederhoffer. 2003. Psychological Aspects of Natu-\nral Language Use: Our words, Our Selves. Annual\nreview of psychology, 54(1):547-577.\n\nElla Rabinovich, Raj Nath Patel, Shachar Mirkin, Lu-\ncia Specia, and Shuly Wintner. 2017. Personalized\nMachine Translation: Preserving Original Author\nTraits. In Proceedings of the 15th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics: Volume 1, Long Papers, pages\n1074-1084, Valencia, Spain.\n\nFrancisco Rangel, Paolo Rosso, Moshe Koppel, Ef-\nstathios Stamatatos, and Giacomo Inches. 2013.\nOverview of The Author Profiling Task at PAN\n2013. In CLEF Conference on Multilingual and\nMultimodal Information Access Evaluation, pages\n352-365.\n\nK Santosh, Romil Bansal, Mihir Shekhar, and Va-\nsudeva Varma. 2013. Author profiling: Predicting\nage and gender from blogs. Notebook for PAN at\nCLEF, pages 119-124.\n\nEdward Sapir. 1921. Language: An Introduction to\nthe Study of Speech. NewYork: Harcourt Brace &\nCompany.\n\nRico Sennrich. 2015. Modelling and Optimizing on\nSyntactic N-grams for Statistical Machine Transla-\ntion. Transactions of the Association for Computa-\ntional Linguistics, 3:169-182.\n\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Controlling Politeness in Neural Machine\nTranslation via Side Constraints. In Proceedings of\nthe 2016 Conference of the North American Chap-\nter of the Association for Computational Linguis-\ntics: Human Language Technologies, pages 35-40,\nBerlin, Germany.\n\nDan I. Slobin. 1996. From Thought and Language to\nThinking for Speaking. In J. Gumperz and S. Levin-\nson, editors, Rethinking Linguistic Relativity, pages\n70-96. Cambridge University Press, Cambridge.\n\nIlya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.\nSequence to Sequence Learning with Neural Net-\nworks. In Advances in Neural Information Pro-\ncessing Systems 27: Annual Conference on Neural\nInformation Processing Systems, pages 3104-3112,\nMontreal, Quebec, Canada.\n\nDeborah Tannen. 1991. You Just Don’t Understand.\nBallantine Books, New York, USA.\n\nEva Vanmassenhove and Christian Hardmeier. 2018.\nEuroparl Datasets with Demographic Speaker Infor-\nmation. In EAMT, Alicante, Spain.\n\n3008\n", "vlm_text": "Kyunghyun Cho, Bart van Merri¨ enboer, ¸ alar G¨ ulc ¸ehre, Dzmitry Bahdanau, Fethi Bougares, Hol- ger Schwenk, and Yoshua Bengio. 2014. Learn- ing Phrase Representations using RNN Encoder– Decoder for Statistical Machine Translation. In  Pro- ceedings of EMNLP 2014 , pages 1724–1734, Doha, Qatar. \nJonathan H Clark, Chris Dyer, Alon Lavie, and Noah A Smith. 2011. Better Hypothesis Testing for Statisti- cal Machine Translation: Controlling for Optimizer Instability. In  Proceedings of the 49th Annual Meet- ing of the Association for Computational Linguis- tics: Human Language Technologies: short papers- Volume 2 , pages 176–181. Association for Compu- tational Linguistics. \nJennifer Coates. 2015.  Women, Men and Language: A Sociolinguistic Account of Gender Differences in Language . Routledge, London. \nMelvin Johnson, Mike Schuster, Quoc V Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Vi´ egas, Martin Wattenberg, Greg Corrado, et al. 2017. Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Transla- tion.  Transactions of the Association of Computa- tional Linguistics , 5(1):339–351. \nGuillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, and Alexander M. Rush. 2017. Open- NMT: Open-Source Toolkit for Neural Machine Translation. In  Proceeding of ACL, Vancouver, Canada . \nPhilipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In  MT Summit , vol- ume 5, pages 79–86, Phuket, Thailand. \nTatiana Litvinova, Pavel Seredin, Olga Litvinova, Olga Zagorovskaya, Aleksandr Sboev, Dmitry Gu- dovskih, Ivan Moloshnikov, and Roman Rybka. 2016. Gender Prediction for Authors of Russian Texts Using Regression And Classiﬁcation Tech- niques. In  Proceedings of the Third Workshop on Concept Discovery in Unstructured Data co-located with the 13th International Conference on Concept Lattices and Their Applications (CDUD@ CLA) , pages 44–53, Moscow, Russia. \nShachar Mirkin, Scott Nowson, Caroline Brun, and Julien Perez. 2015. Motivating Personality-Aware Machine Translation. In  Proceedings of the 2015 Conference on Empirical Methods in Natural Lan- guage Processing , pages 1102–1108, Lisbon, Portu- gal. \nMatthew L Newman, Carla J Groom, Lori D Handel- man, and James W Pennebaker. 2008. Gender Dif- ferences in Language Use: An Analysis of 14,000 Text Samples.  Discourse Processes , 45(3):211–236. \nof the 40th annual meeting on association for com- \nputational linguistics , pages 311–318. James W. Pennebaker, Matthias R. Mehl, and Kate G. Niederhoffer. 2003. Psychological Aspects of Natu- ral Language Use: Our words, Our Selves.  Annual review of psychology , 54(1):547–577. Ella Rabinovich, Raj Nath Patel, Shachar Mirkin, Lu- cia Specia, and Shuly Wintner. 2017. Personalized Machine Translation: Preserving Original Author Traits. In  Proceedings of the 15th Conference of the European Chapter of the Association for Compu- tational Linguistics: Volume 1, Long Papers , pages 1074–1084, Valencia, Spain. Francisco Rangel, Paolo Rosso, Moshe Koppel, Ef- stathios Stamatatos, and Giacomo Inches. 2013. Overview of The Author Proﬁling Task at PAN 2013. In  CLEF Conference on Multilingual and Multimodal Information Access Evaluation , pages 352–365. K Santosh, Romil Bansal, Mihir Shekhar, and Va- sudeva Varma. 2013. Author proﬁling: Predicting age and gender from blogs.  Notebook for PAN at CLEF , pages 119–124. Edward Sapir. 1921. Language: An Introduction to the Study of Speech.  NewYork: Harcourt Brace & Company . Rico Sennrich. 2015. Modelling and Optimizing on Syntactic N-grams for Statistical Machine Transla- tion.  Transactions of the Association for Computa- tional Linguistics , 3:169–182. Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Controlling Politeness in Neural Machine Translation via Side Constraints. In  Proceedings of the 2016 Conference of the North American Chap- ter of the Association for Computational Linguis- tics: Human Language Technologies , pages 35–40, Berlin, Germany. Dan I. Slobin. 1996. From Thought and Language to Thinking for Speaking. In J. Gumperz and S. Levin- son, editors,  Rethinking Linguistic Relativity , pages 70–96. Cambridge University Press, Cambridge. Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to Sequence Learning with Neural Net- works. In  Advances in Neural Information Pro- cessing Systems 27: Annual Conference on Neural Information Processing Systems , pages 3104–3112, Montreal, Quebec, Canada. Deborah Tannen. 1991. You Just Don’t Understand . Ballantine Books, New York, USA. Eva Vanmassenhove and Christian Hardmeier. 2018. Europarl Datasets with Demographic Speaker Infor- mation. In  EAMT , Alicante, Spain. \nKishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. BLEU: A Method for Automatic Evaluation of Machine Translation. In  Proceedings "}
