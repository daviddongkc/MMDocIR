{"page": 0, "image_path": "doc_images/2303.05039v2_0.jpg", "ocr_text": "23\n\narXiv:2303.05039v2 [cs.IR] 21 Mar 20\n\nImproving Recommendation Systems with User Personality\nInferred from Product Reviews\n\nXinyuan Lu?\n\nMin-Yen Kan?\n\nIntegrative Sciences and Engineering Programme (ISEP), NUS Graduate School\nSchool of Computing, National University of Singapore, Singapore\n\nluxinyuan@u.nus.edu\n\nABSTRACT\n\nPersonality is a psychological factor that reflects people’s pref-\nerences, which in turn influences their decision-making. We hy-\npothesize that accurate modeling of users’ personalities improves\nrecommendation systems’ performance. However, acquiring such\npersonality profiles is both sensitive and expensive. We address this\nproblem by introducing a novel method to automatically extract\npersonality profiles from public product review text. We then de-\nsign and assess three context-aware recommendation architectures\nthat leverage the profiles to test our hypothesis.\n\nExperiments on our two newly contributed personality datasets\n— Amazon-beauty and Amazon-music — validate our hypothesis,\nshowing performance boosts of 3-28%. Our analysis uncovers that\nvarying personality types contribute differently to recommendation\nperformance: open and extroverted personalities are most helpful in\nmusic recommendation, while a conscientious personality is most\nhelpful in beauty product recommendation.\n\nCCS CONCEPTS\n\n+ Information systems — Recommender systems; « Applied\ncomputing — Psychology.\n\nKEYWORDS\nRecommendation Systems, Psychology, Personality, Review Texts\n\nACM Reference Format:\n\nXinyuan Lu? Min-Yen Kan’, ‘Integrative Sciences\nand Engineering Programme (ISEP), NUS Graduate School, ?School of Com-\nputing, National University of Singapore, Singapore, luxinyuan@u.nus.edu\nkanmy@comp.nus.edu.sg, . 2023. Improving Recommendation Systems\nwith User Personality Inferred from Product Reviews. In Workshop on Inter-\nactive Recommender Systems of the 16th ACM International Conference on\nWeb Search and Data Mining (IRS@WSDM’ 23), February 27-March 3, 2023,\nSingapore. ACM, New York, NY, USA, 9 pages. https://doi.org/XXXXXXX.\nXXXXXXX\n\n1 INTRODUCTION\n\nOnline recommendation systems are algorithms that help users to\nfind their favorite items. In recommendation systems, the user’s\n\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\n\nIRS@WSDM ‘23, February 27-March 3, 2023, Singapore\n\n© 2023 Association for Computing Machinery.\n\nACM ISBN 978-1-4503-XXXX-X/18/06...$15.00\nhttps://doi.org/XXXXXXX.XXXXXXX\n\nkanmy@comp.nus.edu.sg\n\nprofile is important as people with different ages, educational back-\ngrounds exhibit different preferences. Besides static attributes such\nas gender, the user’s psychological factors, especially personality,\ncan be viewed as a user’s dynamic profile are also vital in recom-\nmendations.\n\nPeople with similar personalities are more likely to have similar\ninterests and preferences [23]. Therefore, accurate modeling of the\nuser’s personality plays a vital role in recommendation systems.\nFor example, in movie recommendation, an outgoing person may\nfavour watching comedic movies over romantic ones [23]. Other\nstudies [11] have shown that in music recommendation, a user’s\ndegree of openness strongly determines their preference for ener-\ngetic music genres. These examples show that personality traits\ncan influence users’ preferences.\n\nWhile we can see that personality traits motivate users’ prefer-\nences, there are challenges that need to be solved before one can\nutilize the traits in the recommendation. First, collecting personality\ndata is time-consuming. The current best practice for collecting\npersonality data requires conducting a user study via an ethically-\ncleared questionnaire with informed consent. Subsequent training\nof assessors is also needed. The entire collection process can take\nmonths [19] and also be an expensive process in terms of effort.\n\nSecond, processing personality data raises sensitivity and pri-\nvacy concerns. If handled incorrectly, such data can be misused by\nusers intentionally, resulting in a violation of privacy protection\npolicies and biased performance of the recommendation systems.\nFor example, a scandal emerged when a Facebook app illegally col-\nlected 87 million users’ personality information to manipulate their\nvoting choices in the U.S. presidential election in March 2018 [9].\nSuch risks make the balance between collecting and utilizing users’\npersonality information challenging. This issue has stalled progress\nin this emerging field of research.\n\nDue to the problem above, the third challenge is a lack of personality-\n\ngrounded datasets in the existing work. One notable exception is\nthe website myPersonality!, which contained personality data and\nthe likes of Facebook users. However, in 2018, myPersonality’s\nfounders decided to discontinue the project as “complying with\nvarious regulations [had] become too burdensome”. To the best of\nour knowledge, there are thus few datasets suitable for testing the\neffect of personality factors in recommendation systems research.\n\nIn this study, we explore methods to overcome these challenges\ndiscussed above and contribute to personality-based recommen-\ndation research. We identify a new source for inferring a user’s\npersonality traits: user-generated content, specifically e-commerce\nreview texts. Studies show that review texts can reflect a user’s\npersonality since individuals manifest their personality through\n\n‘https://sites.google.com/michalkosinski.com/mypersonality\n", "vlm_text": "Improving Recommendation Systems with User Personality Inferred from Product Reviews \nXinyuan Lu 1 , Min-Yen Kan 2 1 Integrative Sciences and Engineering Programme (ISEP), NUS Graduate School 2 School of Computing, National University of Singapore, Singapore luxinyuan@u.nus.edu kanmy@comp.nus.edu.sg \nABSTRACT \nPersonality is a psychological factor that reflects people’s pref- erences, which in turn influences their decision-making. We hy- pothesize that accurate modeling of users’ personalities improves recommendation systems’ performance. However, acquiring such personality profiles is both sensitive and expensive. We address this problem by introducing a novel method to automatically extract personality profiles from public product review text. We then de- sign and assess three context-aware recommendation architectures that leverage the profiles to test our hypothesis. \nExperiments on our two newly contributed personality datasets —  Amazon-beauty  and  Amazon-music  — validate our hypothesis, showing performance boosts of   $3{-}28\\%$  . Our analysis uncovers that varying personality types contribute differently to recommendation performance:  open  and  extroverted  personalities are most helpful in music recommendation, while a  conscientious  personality is most helpful in beauty product recommendation. \nCCS CONCEPTS \n•  Informati  systems  $\\rightarrow$  Recommend er systems ;  $\\bullet$   Applied computing  → Psychology . \nKEYWORDS \nRecommendation Systems, Psychology, Personality, Review Texts \nACM Reference Format: \nXinyuan  $\\mathrm{{Nu}}^{1,2}$  Min-Yen Kan 2 ,   1 Integrative Sciences and Engineering Programme (ISEP), NUS Graduate School,   2 School of Com- puting, National University of Singapore, Singapore,  luxinyuan@u.nus.edu kanmy@comp.nus.edu.sg , . 2023. Improving Recommendation Systems with User Personality Inferred from Product Reviews. In  Workshop on Inter- active Recommend er Systems of the 16th ACM International Conference on Web Search and Data Mining (IRS@WSDM’ 23), February 27-March 3, 2023, Singapore.  ACM, New York, NY, USA, 9 pages. https://doi.org/XXXXXXX. XXXXXXX \n1 INTRODUCTION \nOnline recommendation systems are algorithms that help users to find their favorite items. In recommendation systems, the user’s profile is important as people with different ages, educational back- grounds exhibit different preferences. Besides static attributes such as gender, the user’s psychological factors, especially personality, can be viewed as a user’s dynamic profile are also vital in recom- mendations. \n\nPeople with similar personalities are more likely to have similar interests and preferences [ 23 ]. Therefore, accurate modeling of the user’s personality plays a vital role in recommendation systems. For example, in movie recommendation, an outgoing person may favour watching comedic movies over romantic ones [ 23 ]. Other studies [ 11 ] have shown that in music recommendation, a user’s degree of openness strongly determines their preference for ener- getic music genres. These examples show that personality traits can influence users’ preferences. \nWhile we can see that personality traits motivate users’ prefer- ences, there are challenges that need to be solved before one can utilize the traits in the recommendation. First, collecting personality data is time-consuming. The current best practice for collecting personality data requires conducting a user study via an ethically- cleared questionnaire with informed consent. Subsequent training of assessors is also needed. The entire collection process can take months [19] and also be an expensive process in terms of effort. \nSecond, processing personality data raises sensitivity and pri- vacy concerns. If handled incorrectly, such data can be misused by users intentionally, resulting in a violation of privacy protection policies and biased performance of the recommendation systems. For example, a scandal emerged when a Facebook app illegally col- lected 87 million users’ personality information to manipulate their voting choices in the U.S. presidential election in March 2018 [ 9 ]. Such risks make the balance between collecting and utilizing users’ personality information challenging. This issue has stalled progress in this emerging field of research. \nDue to the problem above, the third challenge is a lack of personality- grounded datasets in the existing work. One notable exception is the website  my Personality 1 , which contained personality data and the likes of Facebook users. However, in 2018,  my Personality ’s founders decided to discontinue the project as “complying with various regulations [had] become too burdensome”. To the best of our knowledge, there are thus few datasets suitable for testing the effect of personality factors in recommendation systems research. \nIn this study, we explore methods to overcome these challenges discussed above and contribute to personality-based recommen- dation research. We identify a new source for inferring a user’s personality traits: user-generated content, specifically e-commerce review texts. Studies show that review texts can reflect a user’s personality since individuals manifest their personality through their choice of words [ 17 ]. For example, when showing their dis- likes on the same shampoo, an agreeable person may comment    $^{*}\\!{\\cal I}$  bought this shampoo for my husband. The smell is not good.” , while a neurotic and aggressive person might comment  “Arrived opened and leaking all over the box. Tried shampoo but didn’t help at all. Still so itchy!!!” . In addition, review text is easy to obtain and made publicly available by users in full disclosure on online commercial websites, which helps to solve both time and privacy issues. "}
{"page": 1, "image_path": "doc_images/2303.05039v2_1.jpg", "ocr_text": "IRS@WSDM °23, February 27~March 3, 2023, Singapore\n\ntheir choice of words [17]. For example, when showing their dis-\nlikes on the same shampoo, an agreeable person may comment “I\nbought this shampoo for my husband. The smell is not good.”, while\na neurotic and aggressive person might comment “Arrived opened\nand leaking all over the box. Tried shampoo but didn’t help at all.\nStill so itchy!!!”. In addition, review text is easy to obtain and made\npublicly available by users in full disclosure on online commercial\nwebsites, which helps to solve both time and privacy issues.\n\nIn our experiments, we explore the possibility of automatically\ninferring users’ personality traits from their review texts and then\nuse this information to help recommendations. We do this by lever-\naging an Application Programming Interface (API) to automati-\ncally analyze the user’s personality. There already exist deployed,\nproduction-level APIs for automatic personality detection, such\nas IBM Personality Insights”, Humantic AI’, and Receptiviti* that\npurport to yield personality profiles. In our work here, we use the\nReceptiviti API, because it is a widely-validated and widely-used\npsychology-based language analysis platform for understanding\nhuman emotion, personality, motivation, and psychology from lan-\nguage. Receptiviti’s API outputs scores for the commonly-used\nOCEAN personality model: five values, one for each of the five\npersonality aspects of Openness, Conscientiousness, Extroversion,\nAgreeableness, and Neuroticism (each corresponding to one letter\nof “OCEAN?”). Finally, this inferred personality is fed as input to\na recommendation system, to test whether it can improve recom-\nmendation performance.\n\nTo conduct our study, we first construct two new datasets ex-\ntending from an existing Amazon review dataset, in the beauty and\nmusic domains. We first extract the user reviews that are between\n30 to 80 words. Afterward, we concatenate all the valid review texts\nof each user and input their concatenation to the Receptiviti API to\noutput each user’s inferred personality scores. As a quality check,\nwe evaluate the accuracy of personality detection, by plotting the\npersonality distribution for each dataset. We observe the users with\nextremely high/low personality scores and find that these are reli-\nable indicators of personality, and use the such confidently labeled\noutput as ground truth (silver data).\n\nWe incorporate these personality scores into the recommenda-\ntion process and investigate their effect on current neural-based\nrecommendation systems. We observe consistent improvements\n\non the performance of such recommendation systems. When we\nconsider different personality groups, we find that extroversion and\nagreeableness benefit the recommendation performances across all\nthe domains. However, we lack an in-depth understanding of how\n\nthese personalities affect recommendations and users’ behavior.\n\nThis points to future directions in utilizing other auxiliary informa-\n\ntion to infer users’ personality traits, e.g., users’ browsing histories.\nIn summary, our contributions are:\n\ne We construct two new datasets in the music and beauty\ndomains that combine users’ public product reviews along-\nside automatically inferred personality scores. This directly\n\n2https://cloud.ibm.com/docs/personality- insights\nShttps://humantic.ai\n“https://www.receptiviti.com/\n\nLu and Kan\n\naddresses the lack of personality-based datasets for recom-\nmendation, while avoiding privacy issues by using public\ndata.\n\ne We conduct empirical experiments over these datasets, find-\ning that leveraging personality information indeed improves\nthe recommendation performance, from 3% to 28%.\n\ne We analyze the influence of personality traits in these do-\nmains and find the personality traits of extroversion and\nagreeableness improve the recommendation performance\nacross all domains.\n\n2 RELATED WORK\n\nThe current study investigates how to extract personality traits from\ntexts and how personality traits can be utilized in recommenda-\ntion systems. Therefore, the review below focuses on the literature\nthat discusses personality detection and personality-based recom-\nmendation systems. We first give an introduction of the OCEAN\npersonality models (Section 2.1) before reviewing two topics related\nto our work: personality detection (Section 2.2) and personality-\nbased recommendation systems (Section 2.3).\n\n2.1 The OCEAN Model\n\nPersonality involves a pattern of behavior that is not likely to\nchange over a short period of time [1]. It can be detected either\nexplicitly by a questionnaire or implicitly by observing user behav-\niors [12]. The most commonly-used model describing personality\ntraits is the OCEAN model [12], which we use to model a user’s\npersonality traits. The five fundamental personality dimensions\ndefined by OCEAN are:\n\n(1) Openness to Experience (O), which describes the breadth\n\nand depth of people’s life, including the originality and com-\n\nplexity of their experiences. Individuals with high openness\ntend to be knowledgeable, analytical, and more investigative.\n\n(2) Conscientiousness (C) This trait involves how individu-\nals control, regulate and direct their impulses. For example,\nhighly conscientious people are usually cautious.\n\n(3) Extroversion (E) Extroversion indicates how much people\nare in touch with the outside world. Extroverts are more\nwilling to talk to others about their thoughts.\n\n(4) Agreeableness (A) This trait reflects individual differences\nand social harmony in cooperation. Highly agreeable peo-\nple are more willing to share tasks than to complete tasks\nindependently.\n\n(5) Neuroticism (N) This refers to the tendency of experiencing\nnegative emotions. People with high neuroticism are often\nin a bad mood, therefore they prefer to respond emotionally.\n\n2.2 Personality Detection\n\nThere are two common ways to measure a person’s personality\ntraits using a personality model: personality assessment question-\nnaires and automatic personality detection.\n\n2.2.1. Personality Assessment Questionnaires. Self-reporting\npersonality questionnaires are commonly used to reveal personality\ndifferences among individuals. Responses to questions usually take\nthe form of a five-point Likert scale (strongly agree, agree, disagree,\n", "vlm_text": "\nIn our experiments, we explore the possibility of automatically inferring users’ personality traits from their review texts and then use this information to help recommendations. We do this by lever- aging an Application Programming Interface (API) to automati- cally analyze the user’s personality. There already exist deployed, production-level APIs for automatic personality detection, such as IBM Personality Insights 2 , Humantic  $\\mathrm{Al^{3}}$  , and Recep ti viti 4   that purport to yield personality profiles. In our work here, we use the Recep ti viti API, because it is a widely-validated and widely-used psychology-based language analysis platform for understanding human emotion, personality, motivation, and psychology from lan- guage. Recep ti viti’s API outputs scores for the commonly-used OCEAN personality model: five values, one for each of the five personality aspects of Openness, Conscientiousness, Extroversion, Agreeable ness, and Neurotic is m (each corresponding to one letter of “OCEAN”). Finally, this inferred personality is fed as input to a recommendation system, to test whether it can improve recom- mendation performance. \nTo conduct our study, we first construct two new datasets ex- tending from an existing Amazon review dataset, in the beauty and music domains. We first extract the user reviews that are between 30 to 80 words. Afterward, we concatenate all the valid review texts of each user and input their concatenation to the Recep ti viti API to output each user’s inferred personality scores. As a quality check, we evaluate the accuracy of personality detection, by plotting the personality distribution for each dataset. We observe the users with extremely high/low personality scores and find that these are reli- able indicators of personality, and use the such confidently labeled output as ground truth (silver data). \nWe incorporate these personality scores into the recommenda- tion process and investigate their effect on current neural-based recommendation systems. We observe consistent improvements on the performance of such recommendation systems. When we consider different personality groups, we find that  extroversion  and agreeable ness  benefit the recommendation performances across all the domains. However, we lack an in-depth understanding of how these personalities affect recommendations and users’ behavior. This points to future directions in utilizing other auxiliary informa- tion to infer users’ personality traits,  e.g. , users’ browsing histories. In summary, our contributions are: \n We construct two new datasets in the music and beauty • domains that combine users’ public product reviews along- side automatically inferred personality scores. This directly \naddresses the lack of personality-based datasets for recom- mendation, while avoiding privacy issues by using public data.  We conduct empirical experiments over these datasets, find- • ing that leveraging personality information indeed improves the recommendation performance, from  $3\\%$   to  $28\\%$  .  We analyze the influence of personality traits in these do- • mains and find the personality traits of extroversion and agreeable ness improve the recommendation performance across all domains. \n2 RELATED WORK \nThe current study investigates how to extract personality traits from texts and how personality traits can be utilized in recommenda- tion systems. Therefore, the review below focuses on the literature that discusses personality detection and personality-based recom- mendation systems. We first give an introduction of the OCEAN personality models (Section 2.1) before reviewing two topics related to our work: personality detection (Section 2.2) and personality- based recommendation systems (Section 2.3). \n2.1 The OCEAN Model \nPersonality involves a pattern of behavior that is not likely to change over a short period of time [ 1 ]. It can be detected either explicitly by a questionnaire or implicitly by observing user behav- iors [ 12 ]. The most commonly-used model describing personality traits is the OCEAN model [ 12 ], which we use to model a user’s personality traits. The five fundamental personality dimensions defined by OCEAN are: \n(1)  Openness to Experience (O) , which describes the breadth and depth of people’s life, including the originality and com- plexity of their experiences. Individuals with high openness tend to be knowledgeable, analytical, and more investigative. (2)  Conscientiousness (C)  This trait involves how individu- als control, regulate and direct their impulses. For example, highly conscientious people are usually cautious. (3)  Extroversion (E)  Extroversion indicates how much people are in touch with the outside world. Extroverts are more willing to talk to others about their thoughts. (4)  Agreeable ness (A)  This trait reflects individual differences and social harmony in cooperation. Highly agreeable peo- ple are more willing to share tasks than to complete tasks independently. (5)  Neurotic is m (N)  This refers to the tendency of experiencing negative emotions. People with high neurotic is m are often in a bad mood, therefore they prefer to respond emotionally. \n2.2 Personality Detection \nThere are two common ways to measure a person’s personality traits using a personality model: personality assessment question- naires and automatic personality detection. \n2.2.1 Personality Assessment Questionnaires .  Self-reporting personality questionnaires are commonly used to reveal personality differences among individuals. Responses to questions usually take the form of a five-point Likert scale ( strongly agree ,  agree ,  disagree , and  strongly disagree ). Such personality inventories differ with respect to the number and content of their questions. Common long questionnaires include the NEO Five-Factor Inventory (60 items) [ 2 ], NEO-Personality-Inventory Revised (240 items) [ 6 ], and the Big- Five Inventory (BFI, 44 items) [ 18 ]. Practitioners prefer using shorter instruments, such as the BFI-10 and Ten-Item Personality Inventory (TIPI) [7, 20], as they are time-saving and easier to fill out. "}
{"page": 2, "image_path": "doc_images/2303.05039v2_2.jpg", "ocr_text": "Improving Recommendation Systems with User Personality Inferred from Product Reviews\n\nand strongly disagree). Such personality inventories differ with\nrespect to the number and content of their questions. Common long\nquestionnaires include the NEO Five-Factor Inventory (60 items) [2],\nNEO-Personality-Inventory Revised (240 items) [6], and the Big-\nFive Inventory (BFI, 44 items) [18]. Practitioners prefer using shorter\ninstruments, such as the BFI-10 and Ten-Item Personality Inventory\n(TIPI) [7, 20], as they are time-saving and easier to fill out.\nHowever, using questionnaires for self-report has two major\ndrawbacks. First, questions that assess personality are often quite\nsubjective such as “Do you easily get nervous?”. Answers for such\nquestions are easily affected by a self-bias [16] or reference-group\neffects [24]. For example, an introverted engineer might think he is\nan extrovert if he/she is working with a group of individuals that\nmay be more introverted. Consequently, the results of question-\nnaires are often hard to reproduce. Second, assessing a personality\nby questionnaires can be inconvenient, as the subjects are necessary\nto participate in the studies.\n\n2.2.2 Automatic Personality Detection. To make personality\ndetection more convenient and reproducible, practitioners prefer\nautomated personality detection, which infers a personality type\nbased on user data. Such methods are less accurate than personality\nquestionnaires — as it relies on the input user data manifesting\npersonality traits — but has the advantage of not requiring inputs\nto be answers to questionnaires. For example, social media posts\nthat exhibit opinions and viewpoints are a prime source of text data\nuseful for personality detection. Individuals have different language\nuse behaviors that reveal personality traits [10]. Automatic, text-\nbased personality detection infer users’ personalities by analyzing\nusers’ word choice (lexical selection) and sentence structure (gram-\nmatical selection). Such technology has been sufficiently proven,\nmaking them commonplace and deployed at scale in production,\nand available as a service through cloud-based application APIs.\n\nWe study whether knowing users’ personality information can\nlead to better recommendations, and also, how users’ personality\ninformation be best modeled in recommendation systems to im-\nprove performance. While large-scale recommendation datasets\nexist, they universally lack users’ personality information. It is in-\nfeasible to ask to obtain this information via questionnaires since\nthe identity of users is usually confidential. Therefore, we utilize\nautomatic personality detection to infer personality from product\nreviews written by users. Product reviews are ideal: they are widely\navailable on online commercial websites, they often demonstrate\npersonality traits, and they are public (the texts are meant to be read\nby others). Hence, they can serve as a good source for automatically\ndetecting personality in an economic but accurate way.\n\n2.3. Personality-based Recommendation\nSystems\n\nSince personality traits are characteristics that do not change sharply\nover time and do not depend on a certain context or stimulus, they\nare more easily used to create personalized recommendation sys-\ntems. Earlier work by Winoto and Tang [21] [4] focused on extend-\ning Matrix Factorization by adding a personality latent factor. Their\nmodel used implicit feedback data, such as user—item interactions,\nbeyond just ratings. They only considered the OCEAN scores as one\nattribute, so the effects that are attributable just to personality are\n\nIRS@WSDM °23, February 27-March 3, 2023, Singapore\n\nnot clear. Besides, personality traits have been used to determine a\nneighborhood of similar users by calculating personality similarity.\nThus, for example, Asabere et al. [3] proposed a recommendation\nsystem for attendees of conferences that integrates personality\ntraits and social bonds of attendees.\n\nIn their work, user similarity was equated as personality similar-\nity, calculated by Pearson’s correlation between two users’ OCEAN\nscores. They demonstrated that the system accuracy improves with\na larger user base, due to the higher likelihood of finding other\nusers with similar personalities (high correlation).\n\nResearchers have also associated user personality scores with\nitems. Yang and Huang [23] attributed items (here, computer games)\nwith a personality that is an average of its users. This latent rep-\nresentation can then be used to recommend items to users with\na similar personality as that of the other users of that item. This\nmay make sense when certain items are used primarily by certain\nersonality types (as in computer games) but are less compelling\nfor items that may be used by many personality types. Lastly, in so-\ncial media recommendations, Wu et al. [22] proposed an approach\nfor recommending interest groups by integrating personality. The\n\nersonality-based similarity was defined as the Euclidean distance\ntween two users’ personality scores. However, it combines the\nersonality signal linearly in the recommendation process, which\nwe feel may be limiting.\nIn summary, compared with other context attributes (e.g., pur-\nchase history), personality information helps to capture the users’\notential interests rather than recommending a similar purchased\nitem. However, the previous works used the OCEAN personality as\na linear similar score which lacks the capability of capturing more\nnuanced information latent in personality scores. Different from\nthe methods above, we propose two novel ways of adding person-\nality features into the recommendation system: 1) taking the most\nsalient personality trait as a learnable vector and 2) calculating a\nuser’s personality embedding as a weighted sum of a user’s OCEAN\nersonality features, which is a learnable embedding within the\nrecommendation system.\n\n3 DATASET CONSTRUCTION\n\nWe construct two new datasets, as extensions of the existing, well-\nnown Amazon review dataset. We first automatically infer users’\nersonality traits from users’ review texts as review texts can re-\nflect the personality through word usage. They are also publicly-\navailable text on online commercial websites, allowing researchers\nto have legal access to textual data where experimentation can\ne replicated. Based upon the parent Amazon review dataset, we\nconstruct two new domain-specific datasets: an Amazon-beauty\nand an Amazon-music dataset. These contain Amazon reviews of\nroducts in the beauty and music domains, alongside their posting\nusers’ inferred personality scores.\n\n3.1 Data Source\n\nThe Amazon dataset? [15] is widely used for training and evaluat-\ning recommendation systems. It contains a large number of item\ndescriptions, ratings, and product reviews collected from the Ama-\nzon online commercial website. The Amazon dataset is divided\n\nShttps://nijianmo.github.io/amazon/index.html\n", "vlm_text": "\nHowever, using questionnaires for self-report has two major drawbacks. First, questions that assess personality are often quite subjective such as “Do you easily get nervous?”. Answers for such questions are easily affected by a self-bias [ 16 ] or reference-group effects [ 24 ]. For example, an introverted engineer might think he is an extrovert if he/she is working with a group of individuals that may be more introverted. Consequently, the results of question- naires are often hard to reproduce. Second, assessing a personality by questionnaires can be inconvenient, as the subjects are necessary to participate in the studies. \n2.2.2 Automatic Personality Detection .  To make personality detection more convenient and reproducible, practitioners prefer automated personality detection, which infers a personality type based on user data. Such methods are less accurate than personality questionnaires — as it relies on the input user data manifesting personality traits — but has the advantage of not requiring inputs to be answers to questionnaires. For example, social media posts that exhibit opinions and viewpoints are a prime source of text data useful for personality detection. Individuals have different language use behaviors that reveal personality traits [ 10 ]. Automatic, text- based personality detection infer users’ personalities by analyzing users’ word choice (lexical selection) and sentence structure (gram- matical selection). Such technology has been sufficiently proven, making them commonplace and deployed at scale in production, and available as a service through cloud-based application APIs. \nWe study whether knowing users’ personality information can lead to better recommendations, and also, how users’ personality information be best modeled in recommendation systems to im- prove performance. While large-scale recommendation datasets exist, they universally lack users’ personality information. It is in- feasible to ask to obtain this information via questionnaires since the identity of users is usually confidential. Therefore, we utilize automatic personality detection to infer personality from product reviews written by users. Product reviews are ideal: they are widely available on online commercial websites, they often demonstrate personality traits, and they are public (the texts are meant to be read by others). Hence, they can serve as a good source for automatically detecting personality in an economic but accurate way. \n2.3 Personality-based Recommendation Systems \nSince personality traits are characteristics that do not change sharply over time and do not depend on a certain context or stimulus, they are more easily used to create personalized recommendation sys- tems. Earlier work by Winoto and Tang [ 21 ] [ 4 ] focused on extend- ing Matrix Factorization by adding a personality latent factor. Their model used implicit feedback data, such as user–item interactions, beyond just ratings. They only considered the OCEAN scores as one attribute, so the effects that are attributable just to personality are not clear. Besides, personality traits have been used to determine a neighborhood of similar users by calculating personality similarity. Thus, for example, Asabere  et al.  [ 3 ] proposed a recommendation system for attendees of conferences that integrates personality traits and social bonds of attendees. \n\nIn their work, user similarity was equated as personality similar- ity, calculated by Pearson’s correlation between two users’ OCEAN scores. They demonstrated that the system accuracy improves with a larger user base, due to the higher likelihood of finding other users with similar personalities (high correlation). \nResearchers have also associated user personality scores with items. Yang and Huang [ 23 ] attributed items (here, computer games) with a personality that is an average of its users. This latent rep- resent ation can then be used to recommend items to users with a similar personality as that of the other users of that item. This may make sense when certain items are used primarily by certain personality types (as in computer games) but are less compelling for items that may be used by many personality types. Lastly, in so- cial media recommendations, Wu  et al.  [ 22 ] proposed an approach for recommending interest groups by integrating personality. The personality-based similarity was defined as the Euclidean distance between two users’ personality scores. However, it combines the personality signal linearly in the recommendation process, which we feel may be limiting. \nIn summary, compared with other context attributes (e.g., pur- chase history), personality information helps to capture the users’ potential interests rather than recommending a similar purchased item. However, the previous works used the OCEAN personality as a linear similar score which lacks the capability of capturing more nuanced information latent in personality scores. Different from the methods above, we propose two novel ways of adding person- ality features into the recommendation system: 1) taking the most salient personality trait as a learnable vector and 2) calculating a user’s personality embedding as a weighted sum of a user’s OCEAN personality features, which is a learnable embedding within the recommendation system. \n3 DATASET CONSTRUCTION \nWe construct two new datasets, as extensions of the existing, well- known Amazon review dataset. We first automatically infer users’ personality traits from users’ review texts as review texts can re- flect the personality through word usage. They are also publicly- available text on online commercial websites, allowing researchers to have legal access to textual data where experimentation can be replicated. Based upon the parent Amazon review dataset, we construct two new domain-specific datasets: an  Amazon-beauty and an  Amazon-music  dataset. These contain Amazon reviews of products in the beauty and music domains, alongside their posting users’ inferred personality scores. \n3.1 Data Source \nThe Amazon dataset 5   [ 15 ] is widely used for training and evaluat- ing recommendation systems. It contains a large number of item descriptions, ratings, and product reviews collected from the Ama- zon online commercial website. The Amazon dataset is divided according to the domain. In our study, we choose two domains: beauty  and  music . We construct datasets separately for these two domains since we want to study whether personality has differ- ent influences on users’ behaviours for different domains. Studies have shown that people with different personalities prefer differ- ent kinds of music [ 11 ]. For example, people with a high degree of openness like to listen to rock music, while neurotic people like jazz. Therefore, we choose  music  as one of the domains to be studied. In order to study the role of personality in different domains, we randomly select  beauty  for comparison. Table 1 shows a sample of the original Amazon dataset, which contains the user ( review- erID ,  reviewer Name ), the product’s Amazon Standard Identification Number ( asin ), the review text for the product ( reviewText ), and the overall rating given to the product ( overall ). "}
{"page": 3, "image_path": "doc_images/2303.05039v2_3.jpg", "ocr_text": "IRS@WSDM °23, February 27~March 3, 2023, Singapore\n\naccording to the domain. In our study, we choose two domains:\nbeauty and music. We construct datasets separately for these two\ndomains since we want to study whether personality has differ-\nent influences on users’ behaviours for different domains. Studies\nhave shown that people with different personalities prefer differ-\nent kinds of music [11]. For example, people with a high degree of\nopenness like to listen to rock music, while neurotic people like jazz.\nTherefore, we choose music as one of the domains to be studied.\nIn order to study the role of personality in different domains, we\nrandomly select beauty for comparison. Table 1 shows a sample\nof the original Amazon dataset, which contains the user (review-\nerID, reviewerName), the product’s Amazon Standard Identification\nNumber (asin), the review text for the product (reviewText), and the\noverall rating given to the product (overall).\n\nreviewerID A2SUAMIJ3GNN3S\nasin 0000013714\nreviewerName J.McDonald\nvote 5\nstyle Format:Hardcover\nTbought this for my husband who plays the piano. He is\nhaving a wonderful time playing these old hymns. The\nreviewText | music is at times hard to read because we think the book\nwas published for singing from more than playing form.\nGreate purchase though!\noverall 5.0\n\nTable 1: An example of Receptiviti score for a specific,\nanonymized user.\n\n3.2 Dataset Construction\n\nSince we do not know the personality for each user in the Amazon\ndataset, we need to infer them. We first retrieve each user’s review\ntexts and then use the Receptiviti API°, a computational language\npsychology platform for understanding human behavior, to infer a\npersonality. The API can take a long piece of human-written text\n(more than 300 words), and output a faceted personality score with\n35 factors, including OCEAN scores.\n\nFor each user that wrote reviews in either of the two domains,\nwe collect all his/her review texts and concatenate them together\ninto a single document. Afterward, we send the concatenated text\nto Receptiviti to infer a personality. We select the personality scores\ncorresponding to the five-dimensional personality traits defined in\nthe OCEAN model [12] (Table 2). Each personality score is normal-\nized to a range from 1 to 100. The higher the score, the more overt\nthe personality trait. Note that each of the five OCEAN scores is\nindependent of the other.\n\nUser ID AGR | CON | NEU | EXT | OPEN\n| A2GBIFL43U1LKJ 54.05 | 34.87 | 25.96 | 54.39 | 42.71\n\nTable 2: An example of Receptiviti score for a specific,\nanonymized user.\n\nShttps://www.receptiviti.com/\n\nLu and Kan\n\nTo improve the personality prediction process, we only analyze\nthe personality traits for active users who bought many products\nand wrote a sufficient number of product reviews. To be specific, we\nselect users that 1) wrote product reviews for at least 10 different\nitems they purchased, and where 2) each product review contains\nbetween 30 to 80 words. Table 3 shows the statistics after the fil-\ntration. For example, using these criteria, 1,791 active users are\nselected for the Amazon-music dataset. Each user in the Amazon-\nmusic dataset has an average of 990.48 review words over all of\nhis/her reviews, averaging 51.01 words for each review.\n\n3.3 Dataset Statistics\n\nAside from our constructed Amazon-beauty and Amazon-music\ndataset, we also include an existing dataset Personality 2018 in\nour study. Personality 20187 [14] is a version of the MovieLens\ndataset that includes each user’s personality information obtained\nthrough questionnaires. It contains 21,776 movies, 339,000 ratings,\nand 678 users with the OCEAN personality questionnaire scores\nfrom 1 to 7. This dataset is included to study the difference between\nquestionnaire-based personality trait scores with our review-based\nautomatic personality trait detection scores.\n\nTable 3 shows the final statistics of the datasets used in our\nstudy. We can observe that the Amazon-beauty / Amazon-music\ndataset has the largest / smallest percentage of interactions. The\nPersonality2018 dataset contains the largest number of items and\nthe smallest number of users. We can see that these datasets differ\nin domains, number of users, items, and interactions, which facili-\ntates the study of personality-based recommendation across a wide\nspectrum of settings.\n\nDataset Amazon-beauty | Amazon-music | Personality’18\n# of items 85 8,895 21,776\n# of users 991 1,791 678\n# of ratings 5,269 28,399 339,000\n# of interactions 6.26% 0.18% 2.30%\n‘Avg. words/user 990.48 466.43 -\nAvg. words/review 51.01 51.18 -\n\nTable 3: Statistics of the three datasets used in our study.\n\n4 METHODS\n\nBased on our constructed dataset, we conduct experiments to study\nwhether the recommendation system can benefit from incorporat-\ning personality traits. We choose the Neural Collaborative Filtering\n(NCF) [8] as the foundation model of our study because it is the fun-\ndamental neural-based model for the recommendation. Specifically,\nwe design a personality-enhanced version of NCF [8] to compare\nwith the vanilla NCF, alongside several other baselines.\n\n4.1 Neural Collaborative Filtering (NCF)\n\nNCF [8] is the first deep-learning-based recommendation algo-\nrithm. Different from traditional collaborative filtering algorithms,\nthe model encodes the user and item into latent vectors and then\n\nThttps://grouplens.org/datasets/personality-2018/\n", "vlm_text": "\nThe table contains a review of a book. Here's the information included:\n\n- **reviewerID**: A2SUAM1J3GNN38\n- **asin**: 0000013714\n- **reviewerName**: J. McDonald\n- **vote**: 5\n- **style**: Format: Hardcover\n- **reviewText**: A positive review about purchasing a book for a husband who plays piano. The reviewer notes that while the music is a bit hard to read, the purchase was great overall.\n- **overall**: 5.0\n3.2 Dataset Construction \nSince we do not know the personality for each user in the Amazon dataset, we need to infer them. We first retrieve each user’s review texts and then use the Recep ti viti  $\\mathrm{API^{6}}$  , a computational language psychology platform for understanding human behavior, to infer a personality. The API can take a long piece of human-written text (more than 300 words), and output a faceted personality score with 35 factors, including OCEAN scores. \nFor each user that wrote reviews in either of the two domains, we collect all his/her review texts and concatenate them together into a single document. Afterward, we send the concatenated text to Recep ti viti to infer a personality. We select the personality scores corresponding to the five-dimensional personality traits defined in the OCEAN model [ 12 ] (Table 2). Each personality score is normal- ized to a range from 1 to 100. The higher the score, the more overt the personality trait. Note that each of the five OCEAN scores is independent of the other. \nThe table contains data for a user with the ID \"A2GBIFL43U1LKJ.\" It includes the following personality scores:\n\n- AGR (Agreeableness): 54.05\n- CON (Conscientiousness): 34.87\n- NEU (Neuroticism): 25.96\n- EXT (Extraversion): 54.39\n- OPEN (Openness): 42.71\nTo improve the personality prediction process, we only analyze the personality traits for  active  users who bought many products and wrote a sufficient number of product reviews. To be specific, we select users that 1) wrote product reviews for at least 10 different items they purchased, and where 2) each product review contains between 30 to 80 words. Table 3 shows the statistics after the fil- tration. For example, using these criteria, 1,791  active  users are selected for the  Amazon-music  dataset. Each user in the  Amazon- music  dataset has an average of 990.48 review words over all of his/her reviews, averaging 51.01 words for each review. \n3.3 Dataset Statistics \nAside from our constructed  Amazon-beauty  and  Amazon-music dataset , we also include an existing dataset  Personality 2018  in our study. Personality  $2018^{7}$    [ 14 ] is a version of the MovieLens dataset that includes each user’s personality information obtained through questionnaires. It contains 21,776 movies, 339,000 ratings, and 678 users with the OCEAN personality questionnaire scores from 1 to 7. This dataset is included to study the difference between questionnaire-based personality trait scores with our review-based automatic personality trait detection scores. \nTable 3 shows the final statistics of the datasets used in our study. We can observe that the  Amazon-beauty  /  Amazon-music dataset has the largest / smallest percentage of interactions. The Personality 2018  dataset contains the largest number of items and the smallest number of users. We can see that these datasets differ in domains, number of users, items, and interactions, which facili- tates the study of personality-based recommendation across a wide spectrum of settings. \nThe table compares three datasets: Amazon-beauty, Amazon-music, and Personality’18. Here are the details provided for each dataset:\n\n1. **Amazon-beauty**:\n   - # of items: 85\n   - # of users: 991\n   - # of ratings: 5,269\n   - # of interactions: 6.26%\n   - Avg. words/user: 990.48\n   - Avg. words/review: 51.01\n\n2. **Amazon-music**:\n   - # of items: 8,895\n   - # of users: 1,791\n   - # of ratings: 28,399\n   - # of interactions: 0.18%\n   - Avg. words/user: 466.43\n   - Avg. words/review: 51.18\n\n3. **Personality’18**:\n   - # of items: 21,776\n   - # of users: 678\n   - # of ratings: 339,000\n   - # of interactions: 2.30%\n   - Avg. words/user: Not provided\n   - Avg. words/review: Not provided\n\nThe table outlines the number of items, users, ratings, and interactions, along with average words per user and review where applicable.\n4 METHODS \nBased on our constructed dataset, we conduct experiments to study whether the recommendation system can benefit from incorporat- ing personality traits. We choose the Neural Collaborative Filtering (NCF) [ 8 ] as the foundation model of our study because it is the fun- damental neural-based model for the recommendation. Specifically, we design a personality-enhanced version of NCF [ 8 ] to compare with the vanilla NCF, alongside several other baselines. \n4.1 Neural Collaborative Filtering (NCF) \nNCF [ 8 ] is the first deep-learning-based recommendation algo- rithm. Different from traditional collaborative filtering algorithms, the model encodes the user and item into latent vectors and then projects them through a Multi-layer Perceptron (MLP) to predict a probability score, representing the probability that a user would buy a target item. In our implementation, we use a 4-layer MLP and a 16-dimensional user and item embedding. "}
{"page": 4, "image_path": "doc_images/2303.05039v2_4.jpg", "ocr_text": "Improving Recommendation Systems with User Personality Inferred from Product Reviews\n\nprojects them through a Multi-layer Perceptron (MLP) to predict\na probability score, representing the probability that a user would\nbuy a target item. In our implementation, we use a 4-layer MLP\nand a 16-dimensional user and item embedding.\n\n4.2 Personality-enhanced NCF\n\nWe then propose three different ways to incorporate the personality\ninformation into the NCF model, as shown in Fig. 1. We first design\nNCF+Most salient Personality model by adding the most salient per-\nsonality trait as input into NCF. We also design NCF + Soft-labeled\nPersonality and NCF + Hard-coded Personality to incorporate all the\nfive personality traits of OCEAN. The difference between the two\nlatter versions is that the personality vector in NCF + Soft-labeled\nPersonality is learnable, while in NCF + Hard-coded Personality, the\nvector is predetermined and fixed.\n\nMethod 1: Most salient personality\nPersonality embedding vector\n\nMethod 2: Soft-tabeled personality\na:\nE\nA\n\nPersonali\n30 0.15)\n70 0.35,\n50 0.25;\n30/] Softmax Jo 15)\nN loo. o1\n\nPersonality score\n\nOpenness\no\n\nJ\n\noven ware wou | = ‘neuosing | oan waves\n\nConscientiousness\n\n+\n\n@® teraveion\n\n‘Agreeableness\n\nNeuroticism\n\nNo gradient\n\nMethod 3: Hard-coded personality\n\n>| Scaling\n\nFigure 1: The overall structure of our model. In this ex-\nample, the user’s OCEAN score is {30,70,50,30,20}. TheNCF\n+ Most salient personality selects the personality with the\nhighest score, i.e., conscientiousness as the personality em-\nbedding vector. NCF + Soft-labeled personality takes all five\nOCEAN scores as a personality embedding matrix. NCF +\nHard-coded personality predetermines and fixes the person-\nality vector as {0.3,0.7,0.5,0.3,0.2}\n\n1. NCF + Most Salient Personality. In this model, we introduce\na 4-dimensional personality vector for each of the five types of\npersonalities, which are learned during training. We treat the most\nsalient personality as the user’s personality label and concatenate\nthe corresponding personality vector with the user’s latent vector.\n\n2. NCF + Soft-labeled Personality. In this model, we make\nfull use of all five personality trait scores. We first apply a Softmax\nfunction to map the personality scores into a probability distribution\nof personality. Afterward, the probability distribution is used as\nthe weight to calculate the weighted sum of the five personality\nvectors. The output vector is then concatenated with the user’s\nlatent vector as the input of the MLP.\n\n3. NCF + Hard-coded Personality. This model also considers\nall the user’s five personality traits information. However, instead\nof introducing learnable personality vectors, we directly scale each\n\n1B score\n\nIRS@WSDM °23, February 27-March 3, 2023, Singapore\n\npersonality score to sum to a unit value (here, 100) to get a hard-\ncoded 5-dimensional vector to represent the user’s personality in-\nformation. This vector is concatenated with the user’s latent vector,\nbut is fixed during training.\n\n5 EXPERIMENTS\n\nWe evaluate our proposed method on our three datasets by an-\nswering the following four research questions. We first evaluate\nwhether we can accurately detect personality from texts (RQ1, Sec-\ntion 5.1). Afterward, we analyze the distribution of personality in\nreview texts (RQ2, Section 5.2). Then, we explore whether adding\npersonality information can improve recommendation performance\n(RQ3, Section 5.3). Finally, we analyze the influence of personality\ninformation on different domains (RQ4, Section 5.4).\n\n5.1 Can we accurately detect personality from\ntexts? (RQ1)\n\nTo evaluate whether we can accurately detect personality traits\nfrom texts, we analyze the personality scores inferred by the Recep-\ntiviti API for each user. Since there are over 2,500 users in total in\nour two constructed datasets, it is time-consuming to manually eval-\nuate them all. As a compromise, we choose to manually examine\nthe users that receive extremely high scores for certain personal-\nity traits. We believe those examples are more easily evaluated by\nhumans. Specifically, for each personality trait, we select the users\nthat receive the top 10 highest scores on this type. We analyze both\nthe Amazon-beauty and the Amazon-music datasets, resulting in a\ntotal of 100 samples. These samples are evaluated by two gradu-\nate students. Both were trained with a detailed explanation of the\nOCEAN personality model. We ask them to choose whether the\nsampled review texts accurately match their inferred personality,\nchoosing between three options of yes, no, or not sure. We then\ncalculate the accuracy of the samples and the inter-annotator agree-\nment between the two annotators using Cohen’s Kappa [5]. We\nfind that the inferred personality matches with the review text in\n81% of the Amazon-beauty samples, and 79% of the samples from\nAmazon-music. The average Cohen’s Kappa is 0.70. We take this to\nindicate that the Receptiviti API can indeed infer users’ personality\ntraits from review texts with generally high accuracy.\n\nTable 4 shows examples of review texts with their inferred per-\nsonality scores. We observe that people with different personalities\nhave different language habits. For example, extroverts tend to use\nthe words “love” and exclamation marks because they are character-\nized by a strong tendency to express their affection. People who are\nagreeable are usually bought items for other people, e.g., “my kids”\nand “my wife”, perhaps due to their inclusiveness. Conscientious\npeople usually talk about their own experience and feelings before\nrecommending the items to others, e.g., “I have had this shower gel\nonce before” or “Don’t just take my word for it”. This is perhaps\nbecause they are usually cautious.\n\n5.2 What is the distribution of users’\npersonalities? (RQ2)\n\nWe further analyze the personality distribution for all users by plot-\n\nting the score histograms for each personality trait in the Amazon-\n\nbeauty dataset and the Amazon-music dataset in Fig. 2.\n", "vlm_text": "\n4.2 Personality-enhanced NCF \nWe then propose three different ways to incorporate the personality information into the NCF model, as shown in Fig. 1. We first design NCF+Most salient Personality  model by adding the most salient per- sonality trait as input into NCF. We also design    $N C F+$  Soft-labeled Personality  and  $N C F+$  Hard-coded Personality  to incorporate all the five personality traits of OCEAN. The difference between the two latter versions is that the personality vector in    $N C F+$  Soft-labeled Personality  is learnable, while in  $N C F+$  Hard-coded Personality , the vector is predetermined and fixed. \nThe image is a diagram illustrating a model that uses different methods to integrate personality trait scores represented by the OCEAN model, which includes Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. In this example, a user has an OCEAN score of {30, 70, 50, 30, 20}. The diagram presents three methods for incorporating these scores into the model:\n\n1. **Method 1: Most Salient Personality** - This method selects the personality trait with the highest score (Conscientiousness in this case, with a score of 70) to create a personality embedding vector. This vector is then used along with a user latent vector and item latent vector in a Multi-Layer Perceptron (MLP) to generate a score.\n\n2. **Method 2: Soft-labeled Personality** - This method applies a softmax function to the OCEAN scores to generate probabilities, which are then used to weight the personality embedding matrix. This matrix encompasses all five OCEAN traits, and each trait is represented as a vector. The weighted sum of these vectors acts as the personality embedding.\n\n3. **Method 3: Hard-coded Personality** - This method scales the raw OCEAN scores and fixes them as a personality vector {0.3, 0.7, 0.5, 0.3, 0.2}, which won't change during training as no gradient is applied to it. Like the other methods, this personality vector is combined with other latent vectors in the MLP to produce a score.\n\nThe outputs from these methods, serving as personality embeddings, are combined with a user latent vector and an item latent vector in an MLP to generate a final score. Each method represents a different approach to incorporating personality data into a machine learning model.\n1.  NCF   $^+$   Most Salient Personality.  In this model, we introduce a 4-dimensional  personality vector  for each of the five types of personalities, which are learned during training. We treat the most salient personality as the user’s personality label and concatenate the corresponding personality vector with the user’s latent vector. \n2.  NCF  $^+$   Soft-labeled Personality.  In this model, we make full use of all five personality trait scores. We first apply a  Softmax function to map the personality scores into a probability distribution of personality. Afterward, the probability distribution is used as the weight to calculate the weighted sum of the five personality vectors. The output vector is then concatenated with the user’s latent vector as the input of the MLP. \n3.  NCF  $^+$   Hard-coded Personality.  This model also considers all the user’s five personality traits information. However, instead of introducing learnable personality vectors, we directly scale each personality score to sum to a unit value (here, 100) to get a hard- coded 5-dimensional vector to represent the user’s personality in- formation. This vector is concatenated with the user’s latent vector, but is fixed during training. \n\n5 EXPERIMENTS \nWe evaluate our proposed method on our three datasets by an- swering the following four research questions. We first evaluate whether we can accurately detect personality from texts (RQ1, Sec- tion 5.1). Afterward, we analyze the distribution of personality in review texts (RQ2, Section 5.2). Then, we explore whether adding personality information can improve recommendation performance (RQ3, Section 5.3). Finally, we analyze the influence of personality information on different domains (RQ4, Section 5.4). \n5.1 Can we accurately detect personality from texts? (RQ1) \nTo evaluate whether we can accurately detect personality traits from texts, we analyze the personality scores inferred by the Recep- tiviti API for each user. Since there are over 2,500 users in total in our two constructed datasets, it is time-consuming to manually eval- uate them all. As a compromise, we choose to manually examine the users that receive extremely high scores for certain personal- ity traits. We believe those examples are more easily evaluated by humans. Specifically, for each personality trait, we select the users that receive the top 10 highest scores on this type. We analyze both the  Amazon-beauty  and the  Amazon-music  datasets, resulting in a total of 100 samples. These samples are evaluated by two gradu- ate students. Both were trained with a detailed explanation of the OCEAN personality model. We ask them to choose whether the sampled review texts accurately match their inferred personality, choosing between three options of  yes ,  no , or  not sure . We then calculate the accuracy of the samples and the inter-annotator agree- ment between the two annotators using Cohen’s Kappa [ 5 ]. We find that the inferred personality matches with the review text in  $81\\%$   of the  Amazon-beauty  samples, and  $79\\%$   of the samples from Amazon-music . The average Cohen’s Kappa is 0.70. We take this to indicate that the Recep ti viti API can indeed infer users’ personality traits from review texts with generally high accuracy. \nTable 4 shows examples of review texts with their inferred per- sonality scores. We observe that people with different personalities have different language habits. For example, extroverts tend to use the words “love” and exclamation marks because they are character- ized by a strong tendency to express their affection. People who are agreeable are usually bought items for other people,  e.g.,  “my kids” and “my wife”, perhaps due to their inclusive ness. Conscientious people usually talk about their own experience and feelings before recommending the items to others,  e.g.,  “I have had this shower gel once before” or “Don’t just take my word for it”. This is perhaps because they are usually cautious. \n5.2 What is the distribution of users’ personalities? (RQ2) \nWe further analyze the personality distribution for all users by plot- ting the score histograms for each personality trait in the  Amazon- beauty  dataset and the  Amazon-music  dataset in Fig. 2. "}
{"page": 5, "image_path": "doc_images/2303.05039v2_5.jpg", "ocr_text": "IRS@WSDM °23, February 27~March 3, 2023, Singapore Lu and Kan\n\nPersonality label\n\nPersonality\nScore\n\nReview Texts\n\nOpenness\n\n63.07\n\nNear perfect exfoliating gloves my only complaint is a matter of preference rather than product\ndefect.\n\nI prefer the harder surface area to use on round areas of the body or potentially harder like the feet,\nelbows, etc.\n\nOpenness\n\n62.62\n\nAzur is always my favorite in the Thymes collection because of its clean, fresh scent.\nI like that my skin feels moisturized when using this product in the shower.\n\nConscientiousness\n\n75.38\n\nIhave had this shower gel once before, and it’s amazing. Hard to find, too.\nOne of The Body Shop’s best scents, and it’s usually only available seasonally!\nwish they sold it in bigger bottles, but I was happy to find it.\n\nConscientiousness\n\n71.02\n\nDon’t just take my word for it, you must try it.\n\nA dear friend got me this from Italy 12 years ago and has been using it since,\nvery hard to find it in the US.\nThis shower cream will transform your shower experience.\n\nExtroversion\n\n75.06\n\nLove this shampoo! Recommended by a friend! The color really lasts!!!\n\nExtroversion\n\n72.90\n\nLooked all over to find where to purchase this product and we are very happy to\nbe able to finally find it.\nhe PRELL Conditioner is by far the best you can buy. We love it!!\n\nAgreeableness\n\n80.06\n\nreat product - my wife loves it\n\nAgreeableness\n\n78.18\n\nought a box of them years ago and we still have some left!!!\nreat deal and leaves my kids smelling awesome!\n\nTl\n\nG\n\nGreat deal and leaves my kids smelling awesome!\nI\n\nG\n\nNeuroticism\n\n67.81\n\nToo expensive for such poor quality.\n\nThere was no improvement and I am starting to think my scalp is worse off than it was before\nI started using this product.\n\nI do agree with other reviews that it feels watered.\n\nNeuroticism\n\n62.28\n\nNope. It smells like artificial bananas, and this smell does linger.\n\nIt’s pure liquid, there is no thickness to it at all, it’s like pouring banana water on your head\nthat lathers.\n\nIt does not help with an itchy scalp either.\n\nTable 4: The data sample of extreme personality cases to the annotators. Each data sample contains the user’s personality\nlabels, personality scores, and review texts.\n\nof users\n\n‘Amazon-beauty\n\nHof users\n\nAmazon-music\n\nFigure 2: Distribution of personality traits in Amazon-beauty and Amazon-music datasets. The x-axis represents the score for\neach trait; the y-axis represents the number of users. The red line represents the median for each trait.\n\nWe observe a similar trend in both domains: agreeable people median score. A possible reason is that neurotic people are more\nhave the highest median score, and neurotic people have the lowest\n", "vlm_text": "The table contains three columns:\n1. **Personality Label** - Indicates the trait being evaluated (e.g., Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism).\n2. **Personality Score** - The score associated with the personality trait.\n3. **Review Texts** - Comments or feedback related to different products, seemingly aligned with the respective personality traits.\nThe image shows histograms depicting the distribution of personality traits in two datasets: Amazon-beauty and Amazon-music. \n\nEach row corresponds to one dataset, with the top row showing Amazon-beauty and the bottom row showing Amazon-music. The columns represent different personality traits: Openness (OPEN), Conscientiousness (CON), Extraversion (EXT), Agreeableness (AGR), and Neuroticism (NEU).\n\n- The x-axis indicates the score for each trait.\n- The y-axis indicates the number of users.\n- The red line represents the median score for each trait.\n\nThe histograms display how each personality trait score is distributed among users in the respective datasets.\nWe observe a similar trend in both domains: agreeable people median score. A possible reason is that neurotic people are more have the highest median score, and neurotic people have the lowest "}
{"page": 6, "image_path": "doc_images/2303.05039v2_6.jpg", "ocr_text": "Improving Recommendation Systems with User Personality Inferred from Product Reviews\n\nintroverted and are less likely to publish their opinions publicly,\nwhile agreeable people are more willing to share their thoughts.\nAnother observation is that the personalities of each dataset are\ngenerally bell-curved. This indicates that each personality trait is\nnormally distributed.\n\nWe also examine the difference in personality distributions be-\ntween the two domains. In the Amazon-music dataset, the average\nscores of extroversion and openness are higher than those in the\nAmazon-beauty dataset. This indicates that the personality char-\nacteristics of extroverts and open people are more obvious in the\nmusic domain than in the beauty domain.\n\nFrom the above figures, we draw the following conclusions. First,\nthe personality traits of users are not evenly distributed. There are\nmore instances of people with certain personality traits (e.g., agree-\nableness) than others (e.g., neuroticism). A possible reason is that\n\npeople with certain personalities are more willing to write product\nreviews. 2) The distributions for the two domains are generally\nthe same, with higher agreeable scores and lower neurotic scores.\nHowever, there is a slight difference. For example, the scores of\n\nextroverts in music are generally higher than that in the beauty\ndomain. This could be explained by the possibility that people who\nare passionate about music may be more emotional.\n\n5.3 Does incorporating personality improve\nrecommendation performance? (RQ3)\n\nNext, we want to explore whether adding the induced user person-\nality benefits the recommendation quality. To this end, we compare\nthe personality-enhanced NCF with the following two baseline\nmodels that do not utilize personality information.\n\n1. NCF with random personality (NCF + Random). We ran-\ndomly assign each user with a random personality label, regardless\nof his/her original, inferred personality scores.\n\n2. NCF with same personality (NCF + Same). We assign each\nuser to a single personality trait. To be specific, we assume every\nuser is “open” and assign the corresponding personality vector\nto NCF. Although the personality vector does not provide any\nadditional signal to the model in this case, it can serve as a place-\nholder to keep the network structure identical to the personality-\nenhanced model, resulting in a fair comparison.\n\nEvaluation Metrics. We use two metrics to measure the per-\nformance of our proposed recommendation models: Hit Rate (HR)\n@ K and Normalized Discounted Cumulative Gain (NDCG) @ K (K\n= 3, 5, 10). Larger HR and NDCG demonstrate better accuracy.\n\nExperiment Results. Table 5 shows the experimental results\nin the Amazon-beauty and the Amazon-music, and Personality2018\ndatasets, respectively. In Amazon-beauty and Amazon-music, we\nfind that the three personality-enhanced NCF models outperform\nthe two baseline models, in terms of both NDCG and HR. Especially,\nthe first three rows show that the NCF with the most salient person-\nality label outperforms NCF with the same or random personality\nlabel. This indicates that adding personality information into NCF\nimproves recommendation performance. From the last three rows,\nwe further find that NCF + Soft-labeled/Hard-coded outperforms\nNCF + Most salient personality in terms of NDCG. This shows that\nutilizing all five personality traits is better than using the most\nsalient personality trait in NCF.\n\nIRS@WSDM °23, February 27-March 3, 2023, Singapore\n\nIn the Personality 2018 dataset, the trend in the Amazon-beauty\nand Amazon-music also holds for it. For example, the NCF + Soft-\nlabeled model outperforms the other models, showing that adding\npersonality information improves performance. However, the im-\nprovement in the Personality 2018 is less obvious than that in the\nAmazon-beauty dataset. We hypothesize the reason might be due\nto the difference in the sizes of the datasets. Since Amazon-beauty\nis a small dataset, adding personality information may better help\nto address the data sparsity problem, therefore exhibiting a better\nperformance gain.\n\n5.4 How does personality information improve\nthe performance of recommendation\nsystem? (RQ4)\n\nTo gain a better understanding of the improvement brought by in-\n\ncorporating personality, we separately evaluate the HR and NDCG\n\nfor the five personality traits, as shown in Table 6 . “+” represents\nthe NCF+Soft-labeled model (with personality information), and “-”\nrepresents the NCF+Same model (without personality information).\n\nWe make two major observations.\n\nFirst, the improvement brought by adding personality is promi-\nnent for the Amazon-beauty dataset, over all five personality traits.\nIn particular, the trait of conscientiousness (CON) has the highest\ngain in terms of both HR (+21%) and NDCG (+57%). However, in\nthe Amazon-music dataset, openness (+27%), agreeableness (+10%),\nextroversion (+5%) improve while neuroticism (-18%) and conscien-\ntiousness (-12%) decreases.\n\nSecond, for the Personality2018 dataset, the improvement brought\nby adding personality is not obvious: only conscientiousness, extro-\nversion, and agreeableness have shown minor performance gain.\nFrom the above breakdown analysis, we find that adding person-\nality information can benefit certain personality traits better than\nothers. However, the personality trait that improves the most dif-\nfers greatly across the three datasets. This indicates that although\nimprovements are observed in terms of empirical results, the mech-\nanism of how personality influences the recommendation still de-\nserves more in-depth investigation.\n\n6 DISCUSSION\n\nIn this work, we make a preliminary attempt to explore how to au-\ntomatically infer users’ personality traits from product reviews and\nhow the inferred traits can benefit the state-of-the-art automated\nrecommendation processes. Although we observe that recommen-\ndation performance is indeed boosted by incorporating personality\ninformation, we believe there are several limitations. In the follow-\ning, we discuss these limitations with potential future directions.\nFirst, we believe capturing personality from the review texts\nmay lead to selective bias. Introverts are less likely to share their\nthoughts online while extroverts are more likely to share expe-\nriences. This results in an imbalanced personality distribution in\nour collected data. As shown in the analysis in RQ2 (Section 5.2),\nextroversion is the most common personality trait of users in our\ndatasets. To address this, in future works, we could utilize other\ncontext information to infer users’ personalities such as a user’s\npurchase history. Such user behaviours can also reflect personality;\n", "vlm_text": "introverted and are less likely to publish their opinions publicly, while agreeable people are more willing to share their thoughts. Another observation is that the personalities of each dataset are generally bell-curved. This indicates that each personality trait is normally distributed. \nWe also examine the difference in personality distributions be- tween the two domains. In the  Amazon-music  dataset, the average scores of extroversion and openness are higher than those in the Amazon-beauty  dataset. This indicates that the personality char- act eris tics of extroverts and open people are more obvious in the music domain than in the beauty domain. \nFrom the above figures, we draw the following conclusions. First, the personality traits of users are not evenly distributed. There are more instances of people with certain personality traits ( e.g.,  agree- ableness) than others ( e.g.,  neurotic is m). A possible reason is that people with certain personalities are more willing to write product reviews. 2) The distributions for the two domains are generally the same, with higher agreeable scores and lower neurotic scores. However, there is a slight difference. For example, the scores of extroverts in music are generally higher than that in the beauty domain. This could be explained by the possibility that people who are passionate about music may be more emotional. \n5.3 Does incorporating personality improve recommendation performance? (RQ3) \nNext, we want to explore whether adding the induced user person- ality benefits the recommendation quality. To this end, we compare the personality-enhanced NCF with the following two baseline models that do not utilize personality information. \n1.  NCF with random personality (NCF  $^+$   Random).  We ran- domly assign each user with a random personality label, regardless of his/her original, inferred personality scores. \n2.  NCF with same personality   $(\\mathbf{NCF+Same})$  ).  We assign each user to a single personality trait. To be specific, we assume every user is “open” and assign the corresponding personality vector to NCF. Although the personality vector does not provide any additional signal to the model in this case, it can serve as a place- holder to keep the network structure identical to the personality- enhanced model, resulting in a fair comparison. \nEvaluation Metrics.  We use two metrics to measure the per- formance of our proposed recommendation models:  Hit Rate (HR)\n\n  $\\varpi\\,K$   and  Normalized Discounted Cumulative Gain (NDCG)   $\\varpi\\,K\\,(K\n\n$   $=3,\\,5,\\,10)$  . Larger HR and NDCG demonstrate better accuracy. \nExperiment Results.  Table 5 shows the experimental results in the  Amazon-beauty  and the  Amazon-music , and  Personality 2018 datasets, respectively. In  Amazon-beauty  and  Amazon-music , we find that the three personality-enhanced NCF models outperform the two baseline models, in terms of both NDCG and HR. Especially, the first three rows show that the NCF with the most salient person- ality label outperforms NCF with the same or random personality label. This indicates that adding personality information into NCF improves recommendation performance. From the last three rows, we further find that  $\\mathrm{NCF+}$  Soft-labeled/Hard-coded outperforms  $\\mathrm{NCF+Mosst}$   salient personality in terms of NDCG. This shows that utilizing all five personality traits is better than using the most salient personality trait in NCF. \nIn the  Personality 2018  dataset, the trend in the  Amazon-beauty and  Amazon-music  also holds for it. For example, the NCF  $^+$   Soft- labeled model outperforms the other models, showing that adding personality information improves performance. However, the im- provement in the  Personality 2018  is less obvious than that in the Amazon-beauty  dataset. We hypothesize the reason might be due to the difference in the sizes of the datasets. Since  Amazon-beauty is a small dataset, adding personality information may better help to address the data sparsity problem, therefore exhibiting a better performance gain. \n5.4 How does personality information improve the performance of recommendation system? (RQ4) \nTo gain a better understanding of the improvement brought by in- corpora ting personality, we separately evaluate the HR and NDCG for the five personality traits, as shown in Table 6 .  $^{\\alpha}{+}^{\\ast}$   represents the  $\\mathsf{N C F}\\!+\\!\\mathsf{S}$  Soft-labeled model (with personality information), and “-” represents the  $\\mathsf{N C F}+\\ldots$  Same model (without personality information). We make two major observations. \nFirst, the improvement brought by adding personality is promi- nent for the  Amazon-beauty  dataset, over all five personality traits. In particular, the trait of conscientiousness (CON) has the highest gain in terms of both HR  $(+21\\%)$   and NDCG   $(+57\\%)$  ). However, in the  Amazon-music  dataset,  openness    $(+27\\%)$  ,  agreeable ness    $(+10\\%)$  , extroversion  $(+5\\%)$   improve while  neurotic is m  $(-18\\%)$   and  conscien- tiousness    $(-12\\%)$   decreases. \nSecond, for the  Personality 2018  dataset, the improvement brought by adding personality is not obvious: only  conscientiousness ,  extro- version , and  agreeable ness  have shown minor performance gain. From the above breakdown analysis, we find that adding person- ality information can benefit certain personality traits better than others. However, the personality trait that improves the most dif- fers greatly across the three datasets. This indicates that although improvements are observed in terms of empirical results, the mech- anism of how personality influences the recommendation still de- serves more in-depth investigation. \n6 DISCUSSION \nIn this work, we make a preliminary attempt to explore how to au- to mati call y infer users’ personality traits from product reviews and how the inferred traits can benefit the state-of-the-art automated recommendation processes. Although we observe that recommen- dation performance is indeed boosted by incorporating personality information, we believe there are several limitations. In the follow- ing, we discuss these limitations with potential future directions. \nFirst, we believe capturing personality from the review texts may lead to selective bias. Introverts are less likely to share their thoughts online while extroverts are more likely to share expe- riences. This results in an imbalanced personality distribution in our collected data. As shown in the analysis in RQ2 (Section 5.2), extroversion is the most common personality trait of users in our datasets. To address this, in future works, we could utilize other context information to infer users’ personalities such as a user’s purchase history. Such user behaviours can also reflect personality; "}
{"page": 7, "image_path": "doc_images/2303.05039v2_7.jpg", "ocr_text": "IRS@WSDM \"23, February 27-March 3, 2023, Singapore Lu and Kan\nAlgorithms Amazon-beauty ‘Amazon-music Personality2018\nRating H@3 | H@S5 | H@10 | N@3 | N@5 | N@10 | H@3 | H@5 | H@10 | N@3 | N@5 | N@10 | H@3 | H@5 | H@10 | N@3 | N@5 | N@10\nNCF+Random | 0.923 | 0.965 | 0.975 | 0.675 | 0.605 | 0.660 | 0.159 | 0.224 | 0.339 | 0.117 | 0.143 | 0.171 | 0.510 | 0.628 | 0.777 | 0.406 | 0454 | 0.504\nNCF+Same 0.918 | 0.967 [0.975 | 0.683 | 0.630 | 0.662 | 0.160 0.340 | 0.122 [0.149 [0.167 | 0511 | 0.622 | 0.777 | 0.403 | 0.454 | 0.502\nNCF+Most-Salient | 0.939 | 0.969 | 0.977 | 0.714 | 0.676 | 0.707 | 0.156 0.343 | 0.164 | 0.145 | 0.174 | 0.516 | 0.631 | 0.795 | 0.415 | 0.463 | 0.511\nNCF+Soft-labeled | 0.936 | 0.965 | 0.973 | 0.810 | 0.867 | 0.831 | 0.156 0.348 | 0.113 | 0.141 | 0.175 | 0.528 | 0.656 | 0.805 | 0.421 | 0.471 | 0.511\nNCF+Hard-Coded | 0.948 | 0.961 | 0.977 _| 0.849 | 0.826 | 0.848 | 0.175 0.345 | 0.147 | 0.160 | 0.189 | 0.503 | 0.622 | 0.758 | 0.398 | 0.447 | 0.498\n\nTable 5: Hit Rate(H) and NDCG(N) @K in the Amazon-beauty, Amazon-music, and Personality 2018 datasets. The best perfor-\n\nmance is bolded.\n\nAmazon-beauty | Amazon-music | Personality2018\n\nTrait HR NDCG HR NDCG HR NDCG\nO + | 0.833 0.729 0.330 0.205 0.535 0.420\nPEN | 0.750 0.545 0.313 0.161 0.547 0.422\nCON + | 0.883 0.769 0.228 0.132 0.475 0.358\n- | 0.727 0.490 0.279 0.150 0.441 0.361\n\nEXT + | 0.970 0.882 0.319 0.181 0.611 0.412\n- | 0.872 0.600 0.317 0.169 0.556 0.411\n\nACR + | 0.968 0.878 0.332 0.198 0.621 0.512\n- | 0.864 0.593 0.308 0.185 0.552 0.430\n\nNEU + | 0.933 0.835 0.397 0.230 0.489 0.390\n- | 0.833 0.536 0.397 0.254 0.511 0.415\n\nTable 6: HR and NDCG results group by 5 personality traits\nin Amazon-beauty, Amazon-music, and Personality2018\ndatasets. “+” represents the NCF+Soft-labeled model (with\npersonality information), and “-” represents the NCF+Same\nmodel (without personality information).The best perfor-\nmance is in bold.\n\nfor example, open people are more likely to follow popular trends\nwhich can be reflected in their purchase history.\n\nSecond, we only conduct experiments on a single basic model,\nNCF, which may loss of generalization. More advanced models\ngraph recommendation models can be used in the future. Third, we\nconduct empirical experiments on whether personality information\nbenefits recommendation. However, more in-depth investigation is\nnecessary on how personality affects recommendation and users’\nbehavior. In the future, we could conduct a user study to find the\ncausal relationship between personality and recommendation. To\nbe specific, we can develop different marketing strategies for users\nwith different personalities. By observing the effects of different\nstrategies on users’ behavior, we can gain a better understanding of\nhow personality affects recommendation. Fourth, we find that the\nopenness, conscientiousness and neuroticism features do not have a\nnoticeable impact on the recommendation performance. A possi-\nble reason is that OCEAN only contains five types of personality,\nwhich might be insufficient to provide enough useful signals to\nrecommendations. A possible solution is to use a more fine-grained\npersonality model than OCEAN; e.g., the MBTI personality model\nwhich has a richer, 16-facet personality profile.\n\nLast, the five personalities are encoded independently of each\nother in our model. But there is a correlation between these person-\nality traits in real life; e.g., a majority of extroverts are also open.\nIn the future, we can make use of the relationship between person-\nalities, perhaps by defining a hierarchical structure of personality\ntraits and employing graph-based neural networks to encode them.\n\n7 CONCLUSION AND FUTURE WORKS\n\nIn this work, we explore a new way of automatically extracting\npersonality information from review texts and applying it to recom-\nmendation systems. We first construct two new datasets based on\nthe Amazon dataset in the beauty and music domains and include\nOCEAN personality scores automatically inferred by the Receptiviti\nAPI, a commercial service. We then analyze the accuracy of using\ntexts to obtain personality profiles and output personality score\ndistributions. To explore the effectiveness of using personality in\ncurrent recommendation systems, we conduct a few experiments\nwith the standard neural collaborative filtering (NCF) recommenda-\ntion algorithm and our variants, finding that incorporating person-\nality information improves recommendation performance by 3% to\n28%. In terms of the relationship between personality and domain,\nwe find that openness, extroversion, and agreeableness are helpful in\nmusic recommendation, while conscientiousness is most helpful in\nthe beauty recommendation.\n\nIn the future, more advanced models graph recommendation\nmodels can be used in the experiments. In addition, collecting more\ninformation beyond review texts (e.g., purchase history, browsing\nhistory) is a potential direction. Moreover, except for the accuracy-\nbased performance, it is possible to improve the fairness by using\nthe OCEAN model [13]. To explore the inner relationship between\npersonality and recommendation systems, doing a user study is\nalso a possible way to further validate the findings.\n\nACKNOWLEDGEMENT\n\nWe sincerely appreciate Dr. Liangming Pan’s efforts in his help in\nproofreading this work.\n\nREFERENCES\n\n1] GW. Allport. 1961. Pattern and Growth in Personality. Holt, Rinehart and Winston.\nhttps://books.google.com.sg/books?id=GVRAAAAAIAAJ\n\n2] Anton Aluja, Oscar Garcia, Jerome Rossier, and Luis F. Garcia. 2005. Comparison\nof the NEO-FFI, the NEO-FFI-R and an alternative short version of the NEO-PI-R\n(NEO-60) in Swiss and Spanish samples. Personality and Individual Differences\n38, 3 (2005), 591-604. https://doi.org/10.1016/j.paid.2004.05.014\n\n3] Nana Yaw Asabere, Amevi Acakpovi, and Mathias Bennet Michael. 2018. Improv-\ning Socially-Aware Recommendation Accuracy Through Personality. IEEE Trans.\nAffect. Comput. 9, 3 (2018), 351-361. https://doi.org/10.1109/TAFFC.2017.2695605\n4] Deger Ayata, Yusuf Yaslan, and Mustafa E Kamasak. 2018. Emotion based music\nrecommendation system using wearable physiological sensors. IEEE transactions\non consumer electronics 64, 2 (2018), 196-203.\n\n5] J. Cohen. 1968. Weighted kappa: nominal scale agreement with provision for\nscaled disagreement or partial credit. Psychological bulletin 70 4 (1968), 213-20.\n6] Paul T Costa Jr and Robert R McCrae. 2008. The Revised Neo Personality Inventory\n(neo-pi-r). Sage Publications, Inc.\n\n7] Samuel D Gosling, Peter J Rentfrow, and William B Swann Jr. 2003. A very brief\nmeasure of the Big-Five personality domains. Journal of Research in personality\n37, 6 (2003), 504-528.\n\n8] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng\nChua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International\nConference on World Wide Web, WWW 2017, Perth, Australia, April 3-7, 2017, Rick\n\n", "vlm_text": "The table presents performance metrics for different algorithms across three datasets: Amazon-beauty, Amazon-music, and Personality2018. The metrics used are Hit rate (H@k) and Normalized Discounted Cumulative Gain (N@k) for k values of 3, 5, and 10. \n\n- The algorithms listed in the table are:\n  1. NCF+Random\n  2. NCF+Same\n  3. NCF+Most-Salient\n  4. NCF+Soft-labeled\n  5. NCF+Hard-Coded\n\nThese algorithms are evaluated on each dataset, with the corresponding performance metrics provided. The bold numbers in the table indicate the highest metric value for each metric type and dataset.\nThis table compares the performance of different traits across three datasets: Amazon-beauty, Amazon-music, and Personality2018. The traits listed are OPEN, CON (Conscientiousness), EXT (Extraversion), AGR (Agreeableness), and NEU (Neuroticism). For each trait, two conditions are considered: \"+\" and \"-\". \n\nThe table includes two evaluation metrics: HR (Hit Rate) and NDCG (Normalized Discounted Cumulative Gain). The values for these metrics are provided under each dataset. The bolded values represent the higher performance results for each condition and trait. \n\nHere's a breakdown of the columns:\n- Trait: Personality trait evaluated.\n- Amazon-beauty: Hit Rate (HR) and NDCG values for Amazon's beauty category.\n- Amazon-music: Hit Rate (HR) and NDCG values for Amazon's music category.\n- Personality2018: Hit Rate (HR) and NDCG values for the Personality2018 dataset.\n\nThe \"+\" and \"-\" indicate different conditions or scenarios under which these traits were evaluated, and the values are indicative of how well each trait performs under these scenarios on the specified metrics across the datasets.\nfor example, open people are more likely to follow popular trends which can be reflected in their purchase history. \nSecond, we only conduct experiments on a single basic model, NCF, which may loss of generalization. More advanced models graph recommendation models can be used in the future. Third, we conduct empirical experiments on whether personality information benefits recommendation. However, more in-depth investigation is necessary on how personality affects recommendation and users’ behavior. In the future, we could conduct a user study to find the causal relationship between personality and recommendation. To be specific, we can develop different marketing strategies for users with different personalities. By observing the effects of different strategies on users’ behavior, we can gain a better understanding of how personality affects recommendation. Fourth, we find that the openness ,  conscientiousness  and  neurotic is m  features do not have a noticeable impact on the recommendation performance. A possi- ble reason is that OCEAN only contains five types of personality, which might be insufficient to provide enough useful signals to recommendations. A possible solution is to use a more fine-grained personality model than OCEAN;  e.g.,  the MBTI personality model which has a richer, 16-facet personality profile. \nLast, the five personalities are encoded independently of each other in our model. But there is a correlation between these person- ality traits in real life;  e.g.,  a majority of extroverts are also open. In the future, we can make use of the relationship between person- alities, perhaps by defining a hierarchical structure of personality traits and employing graph-based neural networks to encode them. \n7 CONCLUSION AND FUTURE WORKS \nIn this work, we explore a new way of automatically extracting personality information from review texts and applying it to recom- mendation systems. We first construct two new datasets based on the Amazon dataset in the beauty and music domains and include OCEAN personality scores automatically inferred by the Recep ti viti API, a commercial service. We then analyze the accuracy of using texts to obtain personality profiles and output personality score distributions. To explore the effectiveness of using personality in current recommendation systems, we conduct a few experiments with the standard neural collaborative filtering (NCF) recommenda- tion algorithm and our variants, finding that incorporating person- ality information improves recommendation performance by   $3\\%$   to  $28\\%$  . In terms of the relationship between personality and domain, we find that  openness ,  extroversion , and  agreeable ness  are helpful in music recommendation, while  conscientiousness  is most helpful in the beauty recommendation. \nIn the future, more advanced models graph recommendation models can be used in the experiments. In addition, collecting more information beyond review texts ( e.g.,  purchase history, browsing history) is a potential direction. Moreover, except for the accuracy- based performance, it is possible to improve the fairness by using the OCEAN model [ 13 ]. To explore the inner relationship between personality and recommendation systems, doing a user study is also a possible way to further validate the findings. \nACKNOWLEDGEMENT \nWe sincerely appreciate Dr. Liangming Pan’s efforts in his help in proofreading this work.\n\n \nREFERENCES \n[1]  G.W. Allport. 1961.  Pattern and Growth in Personality . Holt, Rinehart and Winston. https://books.google.com.sg/books?id=G VR A AAAA I A A J\n\n [2]  Anton Aluja, Oscar Garcia, Jerome Rossier, and Luis F. Garcia. 2005. Comparison of the NEO-FFI, the NEO-FFI-R and an alternative short version of the NEO-PI-R (NEO-60) in Swiss and Spanish samples.  Personality and Individual Differences 38, 3 (2005), 591–604. https://doi.org/10.1016/j.paid.2004.05.014\n\n [3]  Nana Yaw Asabere, Amevi Acakpovi, and Mathias Bennet Michael. 2018. Improv- ing Socially-Aware Recommendation Accuracy Through Personality.  IEEE Trans. Affect. Comput.  9, 3 (2018), 351–361. https://doi.org/10.1109/TAFFC.2017.2695605\n\n [4]  Deger Ayata, Yusuf Yaslan, and Mustafa E Kamasak. 2018. Emotion based music recommendation system using wearable physiological sensors.  IEEE transactions on consumer electronics  64, 2 (2018), 196–203.\n\n [5]  J. Cohen. 1968. Weighted kappa: nominal scale agreement with provision for scaled disagreement or partial credit.  Psychological bulletin  70 4 (1968), 213–20.\n\n [6]  Paul T Costa Jr and Robert R McCrae. 2008.  The Revised Neo Personality Inventory (neo-pi-r).  Sage Publications, Inc.\n\n [7]  Samuel D Gosling, Peter J Rentfrow, and William B Swann Jr. 2003. A very brief measure of the Big-Five personality domains.  Journal of Research in personality 37, 6 (2003), 504–528.\n\n [8]  Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In  Proceedings of the 26th International Conference on World Wide Web, WWW 2017, Perth, Australia, April 3-7, 2017 , Rick "}
{"page": 8, "image_path": "doc_images/2303.05039v2_8.jpg", "ocr_text": "Improving Recommendation Systems with User Personality Inferred from Product Reviews\n\nBarrett, Rick Cummings, Eugene Agichtein, and Evgeniy Gabrilovich (Eds.). ACM,\n173-182. https://doi.org/10.1145/3038912.3052569\n\nJoanne Hinds, Emma J. Williams, and AdamN. Joinson. 2020. \"It wouldn’t happen\nto me’: Privacy concerns and perspectives following the Cambridge Analytica\nscandal. Int. J. Hum. Comput. Stud. 143 (2020), 102498. https://doi.org/10.1016/j.\nijhes.2020.102498\n\nJacob B Hirsh and Jordan B Peterson. 2009. Personality and language use in\nself-narratives. Journal of research in personality 43, 3 (2009), 524-527.\n\nMahesh Babu Mariappan, Myunghoon Suk, and Balakrishnan Prabhakaran. 2012.\nFaceFetch: A User Emotion Driven Multimedia Content Recommendation System\nBased on Facial Expression Recognition. In 2012 IEEE International Symposium\non Multimedia, ISM 2012, Irvine, CA, USA, December 10-12, 2012. IEEE Computer\nSociety, 84-87. https://doi.org/10.1109/ISM.2012.24\n\nRobert R McCrae and Oliver P John. 1992. An introduction to the five-factor\nmodel and its applications. Journal of personality 60, 2 (1992), 175-215.\nAlessandro B Melchiorre, Eva Zangerle, and Markus Schedl. 2020. Personality\nbias of music recommendation algorithms. In Fourteenth ACM conference on\nrecommender systems. 533-538.\n\nTien T. Nguyen, F. Maxwell Harper, Loren Terveen, and Joseph A. Konstan. 2018.\nUser Personality and User Satisfaction with Recommender Systems. Inf. Syst.\nFrontiers 20, 6 (2018), 1173-1189. https://doi.org/10.1007/s10796-017-9782-y\nJianmo Ni, Jiacheng Li, and Julian J. McAuley. 2019. Justifying Recommendations\nusing Distantly-Labeled Reviews and Fine-Grained Aspects. In Proceedings of the\n2019 Conference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing, EMNLP-IJCNLP\n2019, Hong Kong, China, November 3-7, 2019, Kentaro Inui, Jing Jiang, Vincent\nNg, and Xiaojun Wan (Eds.). Association for Computational Linguistics, 188-197.\nhttps://doi.org/10.18653/v1/D19- 1018\n\nCynthia A. Pedregon, Roberta L. Farley, Allison Davis, James M. Wood, and\nRussell D. Clark. 2012. Social desirability, personality questionnaires, and the\n“better than average” effect. Personality and Individual Differences 52, 2 (2012),\n\n20.\n\n21\n\n22,\n\n23,\n\n24\n\nIRS@WSDM °23, February 27-March 3, 2023, Singapore\n\n213-217. https://doi.org/10.1016/j-paid.2011.10.022\n\nJames W Pennebaker and Laura A King. 1999. Linguistic styles: language use as\nan individual difference. Journal of personality and social psychology 77, 6 (1999),\n1296.\n\nBeatrice Rammstedt and Oliver P John. 2007. Measuring personality in one\nminute or less: A 10-item short version of the Big Five Inventory in English and\nGerman. Journal of research in Personality 41, 1 (2007), 203-212.\n\nSanja Stajner and Seren Yenikent. 2020. A Survey of Automatic Personality\nDetection from Texts. In Proceedings of the 28th International Conference on\nComputational Linguistics, COLING 2020, Barcelona, Spain (Online), December\n8-13, 2020, Donia Scott, Nuria Bel, and Chengqing Zong (Eds.). International\nCommittee on Computational Linguistics, 6284-6295. https://doi-org/10.18653/\nv1/2020.coling-main.553\n\nEwa Topolewska, Ewa Skimina, WLODZIMIERZ Strus, Jan Cieciuch, and Tomasz\nRowitiski. 2014. The short IPIP-BFM-20 questionnaire for measuring the Big Five.\nRoczniki Psychologiczne 17, 2 (2014), 385-402.\n\nPinata Winoto and Tiffany Ya Tang. 2010. The role of user mood in movie\nrecommendations. Expert Syst. Appl. 37, 8 (2010), 6086-6092. https://doi.org/10.\n1016/j.eswa.2010.02.117\n\nWen Wu, Li Chen, and Yu Zhao. 2018. Personalizing recommendation diversity\nbased on user personality. User Model. User Adapt. Interact. 28, 3 (2018), 237-276.\nhttps://doi.org/10.1007/s11257-018-9205-x\n\nHsin-Chang Yang and Zi-Rui Huang. 2019. Mining personality traits from social\nmessages for game recommender systems. Knowl. Based Syst. 165 (2019), 157-168.\nhttps://doi.org/10.1016/j-knosys.2018.11.025\n\nWu Youyou, David Stillwell, H. Andrew Schwartz, and Michal Kosinski. 2017.\nBirds of a Feather Do Flock Together: Behavior-Based Personality-Assessment\nMethod Reveals Personality Similarity Among Couples and Friends. Psycho-\nlogical Science 28, 3 (2017), 276-284. https://doi.org/10.1177/0956797616678187\narXiv:https://doi.org/10.1177/0956797616678187 PMID: 28059682.\n", "vlm_text": "Barrett, Rick Cummings, Eugene Agichtein, and Evgeniy Ga br ilo vich (Eds.). ACM, 173–182. https://doi.org/10.1145/3038912.3052569\n\n [9]  Joanne Hinds, Emma J. Williams, and Adam N. Joinson. 2020. \"It wouldn’t happen to me\": Privacy concerns and perspectives following the Cambridge Analytica scandal.  Int. J. Hum. Comput. Stud.  143 (2020), 102498. https://doi.org/10.1016/j. ijhcs.2020.102498\n\n [10]  Jacob B Hirsh and Jordan B Peterson. 2009. Personality and language use in self-narratives.  Journal of research in personality  43, 3 (2009), 524–527.\n\n [11]  Mahesh Babu Mariappan, Myunghoon Suk, and Balakrishnan Prabhakaran. 2012. FaceFetch: A User Emotion Driven Multimedia Content Recommendation System Based on Facial Expression Recognition. In  2012 IEEE International Symposium on Multimedia, ISM 2012, Irvine, CA, USA, December 10-12, 2012 . IEEE Computer Society, 84–87. https://doi.org/10.1109/ISM.2012.24\n\n [12]  Robert R McCrae and Oliver P John. 1992. An introduction to the five-factor model and its applications.  Journal of personality  60, 2 (1992), 175–215.\n\n [13]  Alessandro B Melchiorre, Eva Zangerle, and Markus Schedl. 2020. Personality bias of music recommendation algorithms. In  Fourteenth ACM conference on recommend er systems . 533–538.\n\n [14]  Tien T. Nguyen, F. Maxwell Harper, Loren Terveen, and Joseph A. Konstan. 2018. User Personality and User Satisfaction with Recommend er Systems.  Inf. Syst. Frontiers  20, 6 (2018), 1173–1189. https://doi.org/10.1007/s10796-017-9782-y\n\n [15]  Jianmo Ni, Jiacheng Li, and Julian J. McAuley. 2019. Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects. In  Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019 , Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (Eds.). Association for Computational Linguistics, 188–197. https://doi.org/10.18653/v1/D19-1018\n\n [16]  Cynthia A. Pedregon, Roberta L. Farley, Allison Davis, James M. Wood, and Russell D. Clark. 2012. Social desirability, personality questionnaires, and the “better than average” effect.  Personality and Individual Differences  52, 2 (2012), 213–217. https://doi.org/10.1016/j.paid.2011.10.022\n\n \n[17]  James W Pennebaker and Laura A King. 1999. Linguistic styles: language use as an individual difference.  Journal of personality and social psychology  77, 6 (1999), 1296.\n\n [18]  Beatrice Rammstedt and Oliver P John. 2007. Measuring personality in one minute or less: A 10-item short version of the Big Five Inventory in English and German.  Journal of research in Personality  41, 1 (2007), 203–212.\n\n [19]  Sanja Stajner and Seren Yenikent. 2020. A Survey of Automatic Personality Detection from Texts. In  Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13, 2020 , Donia Scott, Núria Bel, and Chengqing Zong (Eds.). International Committee on Computational Linguistics, 6284–6295. https://doi.org/10.18653/ v1/2020.coling-main.553\n\n [20]  Ewa Topolewska, Ewa Skimina, W OD ZI MIE RZ Strus, Jan Cieciuch, and Tomasz Rowiński. 2014. The short IPIP-BFM-20 questionnaire for measuring the Big Five. Roczniki Psycho logic z ne  17, 2 (2014), 385–402.\n\n [21]  Pinata Winoto and Tiffany Ya Tang. 2010. The role of user mood in movie recommendations.  Expert Syst. Appl.  37, 8 (2010), 6086–6092. https://doi.org/10. 1016/j.eswa.2010.02.117\n\n [22]  Wen Wu, Li Chen, and Yu Zhao. 2018. Personalizing recommendation diversity based on user personality.  User Model. User Adapt. Interact.  28, 3 (2018), 237–276. https://doi.org/10.1007/s11257-018-9205-x\n\n [23]  Hsin-Chang Yang and Zi-Rui Huang. 2019. Mining personality traits from social messages for game recommend er systems.  Knowl. Based Syst.  165 (2019), 157–168. https://doi.org/10.1016/j.knosys.2018.11.025\n\n [24]  Wu Youyou, David Stillwell, H. Andrew Schwartz, and Michal Kosinski. 2017. Birds of a Feather Do Flock Together: Behavior-Based Personality-Assessment Method Reveals Personality Similarity Among Couples and Friends.  Psycho- logical Science  28, 3 (2017), 276–284. https://doi.org/10.1177/0956797616678187 arXiv:https://doi.org/10.1177/0956797616678187 PMID: 28059682. "}
