{"layout": 0, "type": "text", "text": "", "text_level": 1, "page_idx": 0, "bbox": [77, 242, 526, 330], "page_size": [612.0, 792.0]}
{"layout": 1, "type": "text", "text": "  ", "page_idx": 0, "bbox": [186.64999389648438, 385.1416015625, 189.13999938964844, 396.43414306640625], "page_size": [612.0, 792.0]}
{"layout": 2, "type": "text", "text": "BY  Aaron Smith  ", "page_idx": 0, "bbox": [77.42400360107422, 410.9064025878906, 157.3629608154297, 423.45037841796875], "page_size": [612.0, 792.0]}
{"layout": 3, "type": "text", "text": "About Pew Research Center   ", "text_level": 1, "page_idx": 1, "bbox": [66, 103, 288, 121], "page_size": [612.0, 792.0]}
{"layout": 4, "type": "text", "text": "Pew Research Center is a nonpartisan fact tank that informs the public about the issues, attitudes  and trends shaping America and the world. It does not take policy positions. It conducts public  opinion polling, demographic research, content analysis and other data-driven social science  research. The Center studies U.S. politics and policy; journalism and media; internet, science and  technology; religion and public life; Hispanic trends; global attitudes and trends; and U.S. social  and demographic trends. All of the Center’s reports are available at www.pew research.org. Pew  Research Center is a subsidiary of The Pew Charitable Trusts, its primary funder.   ", "page_idx": 1, "bbox": [65, 135.2164306640625, 540, 243.79039001464844], "page_size": [612.0, 792.0]}
{"layout": 5, "type": "text", "text": " $\\copyright$   Pew Research Center 2018  ", "page_idx": 1, "bbox": [65, 263, 211.75296020507812, 275.8303527832031], "page_size": [612.0, 792.0]}
{"layout": 6, "type": "text", "text": "", "text_level": 1, "page_idx": 2, "bbox": [65, 90, 426, 138], "page_size": [612.0, 792.0]}
{"layout": 7, "type": "text", "text": "", "page_idx": 2, "bbox": [65, 141, 464, 200], "page_size": [612.0, 792.0]}
{"layout": 8, "type": "text", "text": "Algorithms are all around us, utilizing massive stores of data  and complex analytics to make decisions with often significant  impacts on humans. They recommend books and movies for us  to read and watch, surface news stories they think we might find  relevant, estimate the likelihood that a tumor is cancerous and  predict whether someone might be a criminal or a worthwhile  credit risk. But despite the growing presence of algorithms in  many aspects of daily life, a Pew Research Center survey of U.S.  adults finds that the public is frequently skeptical of these tools  when used in various real-life situations.   ", "page_idx": 2, "bbox": [66, 212.76641845703125, 381, 369.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 9, "type": "text", "text": "This skepticism spans several dimensions. At a broad level,  $58\\%$    of Americans feel that computer programs will always reflect  some level of human bias – although  $40\\%$   think these programs  can be designed in a way that is bias-free. And in various  contexts, the public worries that these tools might violate  privacy, fail to capture the nuance of complex situations, or  simply put the people they are evaluating in an unfair situation.  Public perceptions of algorithmic decision-making are also  often highly contextual. The survey shows that otherwise similar  technologies can be viewed with support or suspicion depending  on the circumstances or on the tasks they are assigned to do.  ", "page_idx": 2, "bbox": [66, 388, 381, 561.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 10, "type": "text", "text": "To gauge the opinions of everyday Americans on this relatively  complex and technical subject, the survey presented  respondents with four different scenarios in which computers  ", "page_idx": 2, "bbox": [66, 580.8563842773438, 381, 625.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 11, "type": "text", "text": "Real-world examples of the  scenarios in this survey  ", "text_level": 1, "page_idx": 2, "bbox": [406, 204, 551, 234], "page_size": [612.0, 792.0]}
{"layout": 12, "type": "text", "text": "All four of the concepts discussed in the  survey are based on real-life applications  of algorithmic decision-making and  artificial intelligence (AI):  ", "page_idx": 2, "bbox": [407, 250.0016326904297, 581, 303.4141540527344], "page_size": [612.0, 792.0]}
{"layout": 13, "type": "text", "text": "Numerous firms now offer  non traditional credit scores  that build  their ratings using thousands of data  points about customers’ activities and  behaviors, under the premise that “all  data is credit data.”  ", "page_idx": 2, "bbox": [407, 316.0016174316406, 574, 397.3941650390625], "page_size": [612.0, 792.0]}
{"layout": 14, "type": "text", "text": "States across the country use  criminal  risk assessments  to estimate the  likelihood that someone convicted of a  crime will reoffend in the future.  ", "page_idx": 2, "bbox": [407, 410.10162353515625, 574, 463.3941650390625], "page_size": [612.0, 792.0]}
{"layout": 15, "type": "text", "text": "Several multinational companies are  currently using AI-based systems  during  job interviews  to evaluate the honesty,  emotional state and overall personality  of applicants.  ", "page_idx": 2, "bbox": [407, 476.10162353515625, 581, 543.4641723632812], "page_size": [612.0, 792.0]}
{"layout": 16, "type": "text", "text": "Computerized resume screening is a  longstanding and common HR practice  for eliminating candidates who do not  meet the requirements for a job posting.  ", "page_idx": 2, "bbox": [407, 556.0516357421875, 581, 609.4641723632812], "page_size": [612.0, 792.0]}
{"layout": 17, "type": "text", "text": "make decisions by collecting and analyzing large quantities of public and private data. Each of  these scenarios were based on real-world examples of algorithmic decision-making (see  accompanying sidebar) and included: a personal finance score used to offer consumers deals or  discounts; a criminal risk assessment of people up for parole; an automated resume screening  ", "page_idx": 2, "bbox": [66, 628.8563842773438, 530.4581909179688, 689.42041015625], "page_size": [612.0, 792.0]}
{"layout": 18, "type": "text", "text": "program for job applicants; and a computer-based analysis of job interviews. The survey also  included questions about the content that users are exposed to on social media platforms as a way  to gauge opinions of more consumer-facing algorithms.  ", "page_idx": 3, "bbox": [66, 92.73638916015625, 542.7916870117188, 137.32041931152344], "page_size": [612.0, 792.0]}
{"layout": 19, "type": "text", "text": "The following are among the major findings.  ", "page_idx": 3, "bbox": [66, 156.6964111328125, 284.59295654296875, 169.2404022216797], "page_size": [612.0, 792.0]}
{"layout": 20, "type": "text", "text": "The public expresses broad concerns about the fairness and acceptability of using  computers for decision-making in situations with important real-world consequences  ", "text_level": 1, "page_idx": 3, "bbox": [65, 188, 512, 218], "page_size": [612.0, 792.0]}
{"layout": 21, "type": "text", "text": "By and large, the public views these examples of algorithmic decision-making as unfair to the  ", "page_idx": 3, "bbox": [66, 226.806396484375, 519, 239.3503875732422], "page_size": [612.0, 792.0]}
{"layout": 22, "type": "text", "text": "people the computer-based  systems are evaluating. Most  notably, only around one-third  of Americans think that the  video job interview and  personal finance score  algorithms would be fair to job  applicants and consumers.  When asked directly whether  they think the use of these  algorithms is acceptable, a  majority of the public says that  they are not acceptable. Two- thirds of Americans   $(68\\%)$    find the personal finance score  algorithm unacceptable, and   $67\\%$   say the computer-aided  video job analysis algorithm is  unacceptable.   ", "page_idx": 3, "bbox": [65, 242.76641845703125, 219, 543.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 23, "type": "text", "text": "Majorities of Americans find it unacceptable to use  algorithms to make decisions with real-world  consequences for humans  ", "text_level": 1, "page_idx": 3, "bbox": [230, 257, 523, 303], "page_size": [612.0, 792.0]}
{"layout": 24, "type": "text", "text": " $\\%$   of U.S. adults who say the following examples of algorithmic decision- making are …  ", "page_idx": 3, "bbox": [230, 307, 523.5662231445312, 330.22314453125], "page_size": [612.0, 792.0]}
{"layout": 25, "type": "image", "page_idx": 3, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_0.jpg", "bbox": [230, 335, 541, 492], "page_size": [612.0, 792.0], "ocr_text": "Unacceptable Acceptable\n\nCriminal risk assessment\nfor people up for parole\n\nAutomated resume screening\nof job applicants\n\nAutomated video analysis\nof job interviews\n\nPersonal finance score\nusing many types of\nconsumer data\n\n", "vlm_text": "The image is a chart depicting people's opinions on the acceptability of different automated processes. For each process, there are two percentages: one indicating the proportion of people who find the process unacceptable and another for those who find it acceptable. The four automated processes assessed are:\n\n1. Criminal risk assessment for people up for parole: 56% find it unacceptable, and 42% find it acceptable.\n2. Automated resume screening of job applicants: 57% find it unacceptable, and 41% find it acceptable.\n3. Automated video analysis of job interviews: 67% find it unacceptable, and 32% find it acceptable.\n4. Personal finance score using many types of consumer data: 68% find it unacceptable, and 31% find it acceptable. \n\nEach section has a relevant icon and is presented with green indicating the \"Unacceptable\" percentage and blue for the \"Acceptable\" percentage."}
{"layout": 26, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 3, "bbox": [230, 533.811279296875, 319.1199951171875, 542.9269409179688], "page_size": [612.0, 792.0]}
{"layout": 27, "type": "text", "text": "There are several themes  driving concern among those who find these programs to be unacceptable. Some of the more  prominent concerns mentioned in response to open-ended questions include the following:  ", "page_idx": 3, "bbox": [66, 562.8563842773438, 519, 607.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 28, "type": "text", "text": "▪   They violate privacy.  This is the top concern of those who find the personal finance score  unacceptable, mentioned by  $_{26\\%}$   of such respondents.  ", "page_idx": 3, "bbox": [66, 625.072021484375, 519, 655.3403930664062], "page_size": [612.0, 792.0]}
{"layout": 29, "type": "text", "text": "▪   They are unfair.  Those who worry about the personal finance score scenario, the job interview  vignette and the automated screening of job applicants often cited concerns about the fairness  of those processes in expressing their worries.  \n\n ▪   They remove the human element from important decisions.  This is the top concern of those  who find the automated resume screening concept unacceptable (  ${\\it\\Delta}36\\%$   mention this), and it is a  prominent concern among those who are worried about the use of video job interview analysis   $({\\bf16\\%})$  . \n\n ▪   Humans are complex, and these systems are incapable of capturing nuance.  This is a  relatively consistent theme, mentioned across several of these concepts as something about  which people worry when they consider these scenarios. This concern is especially prominent  among those who find the use of criminal risk scores unacceptable. Roughly half of these  respondents mention concerns related to the fact that all individuals are different, or that a  system such as this leaves no room for personal growth or development.  ", "page_idx": 4, "bbox": [66, 90.99198913574219, 547.3428955078125, 297.3103942871094], "page_size": [612.0, 792.0]}
{"layout": 30, "type": "text", "text": "Attitudes toward algorithmic decision-making can depend heavily on context  ", "text_level": 1, "page_idx": 4, "bbox": [66, 316, 470, 329], "page_size": [612.0, 792.0]}
{"layout": 31, "type": "text", "text": "Despite the consistencies in some of these responses, the survey also highlights the ways in which  Americans’ attitudes toward algorithmic decision-making can depend heavily on the context of  those decisions and the characteristics of the people who might be affected.   ", "page_idx": 4, "bbox": [66, 338.76641845703125, 543, 383.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 32, "type": "text", "text": "This context dependence is especially notable in the public’s contrasting attitudes toward the  criminal risk score and personal finance score concepts. Similar shares of the population think  these programs would be effective at doing the job they are supposed to do, with  $54\\%$   thinking the  personal finance score algorithm would do a good job at identifying people who would be good  customers and  $49\\%$   thinking the criminal risk score would be effective at identifying people who  are deserving of parole. But a larger share of Americans think the criminal risk score would be fair  to those it is analyzing. Half   $\\left(50\\%\\right)$   think this type of algorithm would be fair to people who are up  for parole, but just  $32\\%$   think the personal finance score concept would be fair to consumers.  ", "page_idx": 4, "bbox": [66, 402.74639892578125, 543, 527.400390625], "page_size": [612.0, 792.0]}
{"layout": 33, "type": "text", "text": "When it comes to the algorithms that underpin the social media environment, users’ comfort level  with sharing their personal information also depends heavily on how and why their data are being  used. A   $75\\%$   majority of social media users say they would be comfortable sharing their data with  those sites if it were used to recommend events they might like to attend. But that share falls to  just  $37\\%$   if their data are being used to deliver messages from political campaigns.   ", "page_idx": 4, "bbox": [66, 546.7764282226562, 543, 624], "page_size": [612.0, 792.0]}
{"layout": 34, "type": "text", "text": "In other instances, different  types of users offer divergent  views about the collection and  use of their personal data. For  instance, about two-thirds of  social media users younger than  50 find it acceptable for social  media platforms to use their  personal data to recommend  connecting with people they  might want to know. But that  view is shared by fewer than  half of users ages 65 and older.  ", "page_idx": 5, "bbox": [66, 92.73638916015625, 218, 297.3103942871094], "page_size": [612.0, 792.0]}
{"layout": 35, "type": "text", "text": "Social media users are  exposed to a mix of positive  and negative content on  these sites  ", "text_level": 1, "page_idx": 5, "bbox": [65, 316, 214, 378], "page_size": [612.0, 792.0]}
{"layout": 36, "type": "text", "text": "Across age groups, social media users are comfortable  with their data being used to recommend events – but  wary of that data being used for political messaging  ", "text_level": 1, "page_idx": 5, "bbox": [230, 105, 543, 150], "page_size": [612.0, 792.0]}
{"layout": 37, "type": "text", "text": "% of social media users who say it is acceptable for social media sites to use  data about them and their online activities to …  ", "page_idx": 5, "bbox": [231, 154.72705078125, 536.8557739257812, 176.953125], "page_size": [612.0, 792.0]}
{"layout": 38, "type": "image", "page_idx": 5, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_1.jpg", "bbox": [229, 186, 544, 380], "page_size": [612.0, 792.0], "ocr_text": "Recommend events Ages 65+ 50-64 18-29 30-49\n\nin their area f O-O-@\n67% 72 78 80\n\nRecommend someone\n\nthey might want to t <> e-@\nknow 36 53 6667\nShow them ads for } O—@®-@\nproducts and services 39 5154 60\nShow them messages } OS®\n\nfrom political campaigns 31 35 3840\n\nNote: Includes those saying it is “very” or “somewhat” acceptable for social media sites to do\nthis. Respondents who did not give an answer or gave other answers are not shown.\n\nSource: Survey of U.S. adults conducted May 29-June 11, 2018.\n\n“Public Attitudes Toward Computer Algorithms”\n", "vlm_text": "The image is a chart showing the percentage of people within different age groups who find certain actions by social media sites acceptable. The actions are:\n\n1. **Recommend events in their area**\n   - Ages 65+: 67%\n   - Ages 50-64: 72%\n   - Ages 18-29: 78%\n   - Ages 30-49: 80%\n\n2. **Recommend someone they might want to know**\n   - Ages 65+: 36%\n   - Ages 50-64: 53%\n   - Ages 18-29: 66%\n   - Ages 30-49: 67%\n\n3. **Show them ads for products and services**\n   - Ages 65+: 39%\n   - Ages 50-64: 51%\n   - Ages 18-29: 54%\n   - Ages 30-49: 60%\n\n4. **Show them messages from political campaigns**\n   - Ages 65+: 31%\n   - Ages 50-64: 35%\n   - Ages 18-29: 38%\n   - Ages 30-49: 40%\n\nThe chart draws from a survey of U.S. adults conducted from May 29 to June 11, 2018, titled \"Public Attitudes Toward Computer Algorithms.\" The note specifies that these percentages reflect those who said it is \"very\" or \"somewhat\" acceptable for social media platforms to do these activities."}
{"layout": 39, "type": "text", "text": "Algorithms shape the modern  social media landscape in  ", "page_idx": 5, "bbox": [66, 386.7864074707031, 213.79824829101562, 415.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 40, "type": "text", "text": "profound and ubiquitous ways. By determining the specific types of content that might be most  appealing to any individual user based on his or her behaviors, they influence the media diets of  millions of Americans. This has  led to concerns  that these sites are steering huge numbers of  people toward content that is “engaging” simply because it makes them angry, inflames their  emotions or otherwise serves as intellectual junk food.  ", "page_idx": 5, "bbox": [66, 418.826416015625, 532, 495.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 41, "type": "text", "text": "On this front, the survey provides ample evidence that social media users are regularly exposed to  potentially problematic or troubling content on these sites. Notably,  $71\\%$   of social media users say  they ever see content there that makes them angry – with   $25\\%$   saying they see this sort of content  frequently. By the same token, roughly six-in-ten users say they frequently encounter posts that  are overly exaggerated   $(58\\%)$   or posts where people are making accusations or starting arguments  without waiting until they have all the facts   $\\left(59\\%\\right)$  .  ", "page_idx": 5, "bbox": [66, 514.8563842773438, 543, 607.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 42, "type": "text", "text": "But as is often true of users’ experiences on social media more broadly, these negative encounters  are accompanied by more positive interactions. Although  $25\\%$   of these users say they frequently  encounter content that makes them feel angry, a comparable share   $\\left(\\boldsymbol{\\it{21\\%}}\\right)$   says they frequently   ", "page_idx": 5, "bbox": [66, 626.81640625, 543, 671.42041015625], "page_size": [612.0, 792.0]}
{"layout": 43, "type": "text", "text": "encounter content that makes them feel connected to others. And an even larger share   $(44\\%)$    reports frequently seeing content that makes them amused.  ", "page_idx": 6, "bbox": [66, 92, 518.5777587890625, 121.24039459228516], "page_size": [612.0, 792.0]}
{"layout": 44, "type": "text", "text": "Similarly, social media users  tend to be exposed to a mix of  positive and negative behaviors  from other users on these sites.  Around half of users   $\\left(54\\%\\right)$   say  they see an equal mix of people  being mean or bullying and  people being kind and  supportive. The remaining  users are split between those  who see more meanness   $\\left(\\boldsymbol{\\it{21\\%}}\\right)$    and kindness   $({\\it24\\%})$   on these  sites. And a majority of users   $(63\\%)$   say they see an equal mix  of people trying to be deceptive  and people trying to point out  inaccurate information – with  the remainder being evenly  split between those who see  more people spreading  inaccuracies   $(\\mathbf{1}8\\%)$   and more  people trying to correct that  behavior   $(17\\%)$  .  ", "page_idx": 6, "bbox": [65, 140.73638916015625, 222, 505.32037353515625], "page_size": [612.0, 792.0]}
{"layout": 45, "type": "text", "text": "Amusement, anger, connected ness top the emotions  users frequently feel when using social media  ", "text_level": 1, "page_idx": 6, "bbox": [230, 152, 533, 183], "page_size": [612.0, 792.0]}
{"layout": 46, "type": "text", "text": " $\\%$   of social media users in each age group who say they frequently see  content on social media that makes them feel …  ", "page_idx": 6, "bbox": [230, 187, 515.408935546875, 210.55316162109375], "page_size": [612.0, 792.0]}
{"layout": 47, "type": "image", "page_idx": 6, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_2.jpg", "bbox": [230, 225, 541, 443], "page_size": [612.0, 792.0], "ocr_text": "Ages 65+ 50-64 30-49 18-29\n\nAmused O—@ ee\n30% 39 51 54\n\nAngry @\n23 24 25 27\nConnected Oo C@\n15 2023 25\n\nInspired oO @\n\n9 161719\nDepressed @ r }\n1112 17\nLonely O}@ ©\n\n257 15\n", "vlm_text": "The image is a chart comparing emotional responses across different age groups (65+, 50-64, 30-49, 18-29) for various emotions. Each emotion is represented by a horizontal line with dots corresponding to percentages for each age group. \n\nHere are the emotions and percentages shown:\n\n- **Amused**: \n  - Ages 65+: 30%\n  - 50-64: 39%\n  - 30-49: 51%\n  - 18-29: 54%\n\n- **Angry**: \n  - Ages 65+: 23%\n  - 50-64: 24%\n  - 30-49: 25%\n  - 18-29: 27%\n\n- **Connected**: \n  - Ages 65+: 15%\n  - 50-64: 20%\n  - 30-49: 23%\n  - 18-29: 25%\n\n- **Inspired**: \n  - Ages 65+: 9%\n  - 50-64: 16%\n  - 30-49: 17%\n  - 18-29: 19%\n\n- **Depressed**: \n  - Ages 65+: 11%\n  - 50-64: 12%\n  - 30-49: 12%\n  - 18-29: 17%\n\n- **Lonely**: \n  - Ages 65+: 2%\n  - 50-64: 5%\n  - 30-49: 7%\n  - 18-29: 15%"}
{"layout": 48, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 6, "bbox": [230, 478.5813293457031, 319.1199951171875, 487.6969909667969], "page_size": [612.0, 792.0]}
{"layout": 49, "type": "text", "text": "Other key findings from this survey of 4,594 U.S. adults conducted May 29-June 11, 2018, include: \n\n ", "page_idx": 6, "bbox": [66, 524.81640625, 545.4229736328125, 537.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 50, "type": "text", "text": "▪   Public attitudes toward algorithmic decision-making can vary by factors related to race and  ethnicity. Just   $25\\%$   of whites think the personal finance score concept would be fair to  consumers, but that share rises to  $45\\%$   among blacks. By the same token,  $61\\%$   of blacks think  the criminal risk score concept is  not  fair to people up for parole, but that share falls to   $49\\%$    among whites. \n\n ▪   Roughly three-quarters of the public   $\\left(74\\%\\right)$   thinks the content people post on social media is  not reflective of how society more broadly feels about important issues – although  $25\\%$   think  that social media does paint an accurate portrait of society.  ", "page_idx": 6, "bbox": [66, 555.1119995117188, 537, 681.3804321289062], "page_size": [612.0, 792.0]}
{"layout": 51, "type": "text", "text": "▪   Younger adults are twice as likely to say they frequently see content on social media that makes  them feel amused   $\\left(54\\%\\right)$   as they are content that makes them feel angry   $\\left(27\\%\\right)$  . But users ages  65 and older encounter these two types of content with more comparable frequency. The  survey finds that  $30\\%$   of older users frequently see content on social media that makes them  feel amused, while   $24\\%$   frequently see content that makes them feel angry.  ", "page_idx": 7, "bbox": [66.6240005493164, 90.99198913574219, 547.3320922851562, 169.2404022216797], "page_size": [612.0, 792.0]}
{"layout": 52, "type": "text", "text": "1. Attitudes toward algorithmic decision-making   ", "text_level": 1, "page_idx": 8, "bbox": [64, 90, 449, 110], "page_size": [612.0, 792.0]}
{"layout": 53, "type": "text", "text": "Today, many decisions that could be made by human beings – from interpreting medical images to  recommending books or movies – can now be made by computer algorithms with advanced  analytic capabilities and access to huge stores of data. The growing prevalence of these algorithms  has led to widespread concerns about their impact on those who are affected by decisions they  make. To proponents, these systems promise to increase accuracy and reduce human bias in  important decisions. But others worry that many of these systems amount to “ weapons of math  destruction ” that simply reinforce existing biases and disparities under the guise of algorithmic  neutrality.  ", "page_idx": 8, "bbox": [66, 122.73638916015625, 548.1671142578125, 247.27037048339844], "page_size": [612.0, 792.0]}
{"layout": 54, "type": "text", "text": "This survey finds that the public is more broadly  inclined to share the latter, more skeptical view.  Roughly six-in-ten Americans   $(58\\%)$   feel that  computer programs will always reflect the biases  of the people who designed them, while  $40\\%$   feel  it is possible for computer programs to make  decisions that are free from human bias.  Notably, younger Americans are more  supportive of the notion that computer programs  can be developed that are free from bias. Half of  18- to 29-year-olds and   $43\\%$   of those ages 30 to  49 hold this view, but that share falls to   $34\\%$    among those ages 50 and older.  ", "page_idx": 8, "bbox": [66, 266.76641845703125, 307, 471.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 55, "type": "text", "text": "This general concern about computer programs  making important decisions is also reflected in  public attitudes about the use of algorithms and  big data in several real-life contexts.  ", "page_idx": 8, "bbox": [66, 490.8564147949219, 307, 551.400390625], "page_size": [612.0, 792.0]}
{"layout": 56, "type": "text", "text": "Majority of Americans say computer  programs will always reflect human  bias; young adults are more split  ", "text_level": 1, "page_idx": 8, "bbox": [312, 275, 522, 323], "page_size": [612.0, 792.0]}
{"layout": 57, "type": "text", "text": " $\\%$   of U.S. adults who say that …  It is possible for computer  Computer programs  ", "page_idx": 8, "bbox": [313, 327, 444.5909118652344, 337.78314208984375], "page_size": [612.0, 792.0]}
{"layout": 58, "type": "text", "text": "", "page_idx": 8, "bbox": [344.6400146484375, 349.20947265625, 540, 359.4407958984375], "page_size": [612.0, 792.0]}
{"layout": 59, "type": "image", "page_idx": 8, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_3.jpg", "bbox": [328, 370.25, 538, 479], "page_size": [612.0, 792.0], "ocr_text": "programs to make decisions\nwithout human bias\n\nTotal 40 | |\nel\n30-49 43 7\n50+ 34 ||\n\nwill always reflect\nbias of designers\n\n58\n48\n56\n\n63\n", "vlm_text": "The image is a bar chart comparing perceptions of different age groups on whether programs can make decisions without human bias versus whether they will always reflect the bias of designers. Here are the details:\n\n- **Total**: 40% believe programs can make decisions without human bias, while 58% think they will always reflect designer bias.\n- **Ages 18-29**: 50% believe decisions can be made without bias, and 48% think bias is inevitable.\n- **Ages 30-49**: 43% believe in unbiased decisions, versus 56% seeing inevitable bias.\n- **Ages 50+**: 34% think decisions can be unbiased, while 63% expect bias.\n\nThe chart shows a general trend of older age groups being more skeptical about the unbiased capability of programs."}
{"layout": 60, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 8, "bbox": [313, 530.331298828125, 402.6400146484375, 539.4469604492188], "page_size": [612.0, 792.0]}
{"layout": 61, "type": "text", "text": "To gain a deeper understanding of the public’s views of algorithms, the survey asked respondents  about their opinions of four examples in which computers use various personal and public data to  make decisions with real-world impact for humans. They include examples of decisions being  made by both public and private entities. They also include a mix of personal situations with direct  relevance to a large share of Americans (such as being evaluated for a job) and those that might be  more distant from many people’s lived experiences (like being evaluated for parole). And all four  are based on real-life examples of technologies that are currently in use in various fields.  ", "page_idx": 8, "bbox": [66, 570.7764282226562, 546, 679.3403930664062], "page_size": [612.0, 792.0]}
{"layout": 62, "type": "text", "text": "The specific scenarios in the survey include the following: \n\n ", "page_idx": 9, "bbox": [66, 92.73638916015625, 347.97296142578125, 105.2803726196289], "page_size": [612.0, 792.0]}
{"layout": 63, "type": "text", "text": "▪   An automated  personal finance score  that collects and analyzes data from many different  sources about people’s behaviors and personal characteristics (not just their financial  behaviors) to help businesses decide whether to offer them loans, special offers or other  services. \n\n ▪   A  criminal risk assessment  that collects data about people who are up for parole, compares  that data with that of others who have been convicted of crimes, and assigns a score that helps  decide whether they should be released from prison. \n\n ▪   A program that  analyzes videos of job interviews , compares interviewees’ characteristics,  behavior and answers to other successful employees, and gives them a score that can help  businesses decide whether job candidates would be a good hire or not. \n\n ▪   A  computerized resume screening  program that evaluates the contents of submitted resumes  and only forwards those meeting a certain threshold score to a hiring manager for further  review about reaching the next stage of the hiring process.   ", "page_idx": 9, "bbox": [66, 123.03202819824219, 542, 329.3503723144531], "page_size": [612.0, 792.0]}
{"layout": 64, "type": "text", "text": "For each scenario, respondents were asked to indicate whether they think the program would be  fair to the people being evaluated; if it would be effective at doing the job it is designed to do; and  whether they think it is generally acceptable for companies or other entities to use these tools for  the purposes outlined.  ", "page_idx": 9, "bbox": [66, 348.74639892578125, 542, 409.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 65, "type": "text", "text": "Sizable shares of Americans  view each of these scenarios  as unfair to those being  evaluated  ", "text_level": 1, "page_idx": 9, "bbox": [65, 427, 219, 490], "page_size": [612.0, 792.0]}
{"layout": 66, "type": "text", "text": "Americans are largely skeptical  about the fairness of these  programs: None is viewed as  fair by a clear majority of the  public. Especially small shares  think the “personal finance  score” and “video job interview  analysis” concepts would be fair  to consumers or job applicants   $(32\\%$   and  $33\\%$  , respectively).  The automated criminal risk  score concept is viewed as fair  ", "page_idx": 9, "bbox": [66, 498.7763977050781, 222, 687.3804321289062], "page_size": [612.0, 792.0]}
{"layout": 67, "type": "text", "text": "Broad public concern about the fairness of these  examples of algorithmic decision-making  ", "text_level": 1, "page_idx": 9, "bbox": [231, 421, 509, 453], "page_size": [612.0, 792.0]}
{"layout": 68, "type": "text", "text": " $\\%$   of U.S. adults who think the following types of computer programs would  be ___ to the people being evaluated  ", "page_idx": 9, "bbox": [230, 456, 539, 479.28314208984375], "page_size": [612.0, 792.0]}
{"layout": 69, "type": "image", "page_idx": 9, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_4.jpg", "bbox": [237, 491, 525, 623], "page_size": [612.0, 792.0], "ocr_text": "Not fair Notvery Somewhat Very\n\nat all fair fair fair\n\nAutomated scoring of people 47\nup for parole\n\nAutomated resume screening 23\n\nof job applicants\n\nAutomated video analysis of 27\njob interviews\n\nAutomated personal 33\nfinance score\n", "vlm_text": "The image is a bar chart comparing perceptions of fairness regarding automated decision-making systems in four scenarios:\n\n1. **Automated scoring of people up for parole:**\n   - Not fair at all: 17%\n   - Not very fair: 32%\n   - Somewhat fair: 41%\n   - Very fair: 10%\n\n2. **Automated resume screening of job applicants:**\n   - Not fair at all: 23%\n   - Not very fair: 34%\n   - Somewhat fair: 35%\n   - Very fair: 8%\n\n3. **Automated video analysis of job interviews:**\n   - Not fair at all: 27%\n   - Not very fair: 39%\n   - Somewhat fair: 27%\n   - Very fair: 6%\n\n4. **Automated personal finance score:**\n   - Not fair at all: 33%\n   - Not very fair: 33%\n   - Somewhat fair: 27%\n   - Very fair: 6%\n\nThe chart uses varying shades of blue to represent different levels of perceived fairness."}
{"layout": 70, "type": "text", "text": "by the largest share of Americans. Even so, only around half the public finds this concept fair –  and just one-in-ten think this type of program would be  very  fair to people in parole hearings.  ", "page_idx": 10, "bbox": [66, 92.73638916015625, 528, 121.24039459228516], "page_size": [612.0, 792.0]}
{"layout": 71, "type": "text", "text": "Demographic differences are relatively modest on the question of whether these systems are fair,  although there is some notable at t it udin al variation related to race and ethnicity. Blacks and  Hispanics are more likely than whites to find the consumer finance score concept fair to  consumers. Just   $25\\%$   of whites think this type of program would be fair to consumers, but that  share rises to  $45\\%$   among blacks and   $47\\%$   among Hispanics. By contrast, blacks express much  more concern about a parole scoring algorithm than do either whites or Hispanics. Roughly six-in- ten blacks   $(61\\%)$   think this type of program would  not  be fair to people up for parole, significantly  higher than the share of either whites   $(49\\%)$   or Hispanics   $(38\\%)$   who say the same.  ", "page_idx": 10, "bbox": [66, 140.73638916015625, 543, 265.2703552246094], "page_size": [612.0, 792.0]}
{"layout": 72, "type": "text", "text": "The public is mostly divided on whether these programs would be effective or not  ", "text_level": 1, "page_idx": 10, "bbox": [66, 284, 492, 298], "page_size": [612.0, 792.0]}
{"layout": 73, "type": "text", "text": "The public is relatively split on whether these  programs would be effective at doing the job they  are designed to do. Some  $54\\%$   think the personal  finance score program would be effective at  identifying good customers, while around half  think the parole rating  $(49\\%)$   and resume  screening   $(47\\%)$   algorithms would be effective.  Meanwhile,  $39\\%$   think the video job interview  concept would be a good way to identify  successful hires.   ", "page_idx": 10, "bbox": [66, 306.7264099121094, 305, 463.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 74, "type": "text", "text": "For the most part, people’s views of the fairness  and effectiveness of these programs go hand in  hand. Similar shares of the public view these  concepts as fair to those being judged, as say  they would be effective at producing good  decisions. But the personal finance score concept  is a notable exception to this overall trend. Some  ", "page_idx": 10, "bbox": [66, 482.7864074707031, 305, 591.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 75, "type": "text", "text": " $\\pmb{54\\%}$   of Americans think automated  finance scores would be effective – but  just  $\\pmb{\\mathscr{\\textbf{s2}}}\\%$   think they would be fair  ", "text_level": 1, "page_idx": 10, "bbox": [312, 318, 539, 365], "page_size": [612.0, 792.0]}
{"layout": 76, "type": "text", "text": " $\\%$   of U.S. adults who say the following types of computer  programs would be very/somewhat …  ", "page_idx": 10, "bbox": [313, 369, 544, 391.8031311035156], "page_size": [612.0, 792.0]}
{"layout": 77, "type": "table", "page_idx": 10, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_5.jpg", "table_footnote": "Note: Respondents who did not give an answer or gave other  answers are not shown.  Source: Survey of U.S. adults conducted May 29-June 11, 2018.  “Public Attitudes Toward Computer Algorithms”  ", "bbox": [313, 397, 543, 560], "page_size": [612.0, 792.0], "ocr_text": "Automated personal finance\nscore\n\nAutomated video analysis of\njob interviews\nAutomated resume\nscreening of job applicants\n\nAutomated scoring of\npeople up for parole\n\nEffective\n54%\n\n39\n\n47\n\n49\n\nFair\n32%\n\n33\n\n43\n\n50\n\nEffective-\nfair\ndifference\n\n+22\n\n+6\n\n+4\n", "vlm_text": "This table compares the perceived effectiveness and fairness of different automated systems:\n\n1. **Automated personal finance score**\n   - Effective: 54%\n   - Fair: 32%\n   - Effective-fair difference: +22\n\n2. **Automated video analysis of job interviews**\n   - Effective: 39%\n   - Fair: 33%\n   - Effective-fair difference: +6\n\n3. **Automated resume screening of job applicants**\n   - Effective: 47%\n   - Fair: 43%\n   - Effective-fair difference: +4\n\n4. **Automated scoring of people up for parole**\n   - Effective: 49%\n   - Fair: 50%\n   - Effective-fair difference: -1\n\nThe \"Effective-fair difference\" indicates the difference between the percentage of people who find each system effective versus fair."}
{"layout": 78, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 10, "bbox": [313, 564.4113159179688, 401.9200134277344, 573.5269775390625], "page_size": [612.0, 792.0]}
{"layout": 79, "type": "text", "text": " $54\\%$   of Americans think this type of program would do a good job at helping businesses find new  customers, but just  $32\\%$   think it is fair for consumers to be judged in this way. That 22-percentage- point difference is by far the largest among the four different scenarios.  ", "page_idx": 10, "bbox": [65, 594, 545.44921875, 639.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 80, "type": "text", "text": "Majorities of Americans think the use of these programs is unacceptable; concerns about  data privacy, fairness and overall effectiveness highlight their list of worries  ", "text_level": 1, "page_idx": 11, "bbox": [66, 92, 537, 122], "page_size": [612.0, 792.0]}
{"layout": 81, "type": "text", "text": "Majorities of the public think it is  not  acceptable for companies or other entities to use the  concepts described in this survey. Most prominently,  $68\\%$   of Americans think using the personal  finance score concept is unacceptable, and  $67\\%$   think it is unacceptable for companies to conduct  computer-aided video analysis of interviews when hiring job candidates.  ", "page_idx": 11, "bbox": [66, 130.77642822265625, 545, 191.32041931152344], "page_size": [612.0, 792.0]}
{"layout": 82, "type": "text", "text": "The survey asked respondents to describe in their own words why they feel these programs are  acceptable or not, and certain themes emerged in these responses. Those who think these  programs are acceptable often focus on the fact that they would be effective at doing the job they  purport to do. Additionally, some argue in the case of private sector examples that the concepts  simply represent the company’s prerogative or the free market at work.  ", "page_idx": 11, "bbox": [66, 210.72637939453125, 545, 287.3503723144531], "page_size": [612.0, 792.0]}
{"layout": 83, "type": "text", "text": "Meanwhile, those who find the use of these programs to be unacceptable often worry that they will  not do as good a job as advertised. They also express concerns about the fairness of these  programs and in some cases worry about the privacy implications of the data being collected and  shared. The public reaction to each of these concepts is discussed in more detail below.  ", "page_idx": 11, "bbox": [66, 306.7264099121094, 545, 367.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 84, "type": "text", "text": "Automated personal finance score  ", "page_idx": 11, "bbox": [66, 386.7864074707031, 237.43296813964844, 399.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 85, "type": "text", "text": "Among the  $31\\%$   of Americans who think it would be acceptable for companies to use this type of  program, the largest share of respondents   $\\left(31\\%\\right)$   feel it would be effective at helping companies  find good customers. Smaller shares say customers have no right to complain about this practice  since they are willingly putting their data out in public with their online activities   $\\left(\\mathbf{1}2\\%\\right)$  , or that  companies can do what they want and/or that this is simply the free market at work  $(6\\%)$  .   ", "page_idx": 11, "bbox": [66, 408, 545, 485.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 86, "type": "text", "text": "Here are some samples of these responses: \n\n ", "page_idx": 11, "bbox": [66, 504.77642822265625, 276.552978515625, 517.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 87, "type": "text", "text": "▪   “I believe that companies should be able to use an updated, modern effort to judge someone’s  fiscal responsibility in ways other than if they pay their bills on time.”  Man, 28  \n\n ▪   “Finances and financial situations are so complex now. A person might have a bad credit score  due to a rough patch but doesn't spend frivolously, pays bills, etc. This person might benefit  from an overall look at their trends. Alternately, a person who sides on trends in the opposite  direction but has limited credit/good credit might not be a great choice for a company as their  trends may indicate that they will default later.”  Woman, 32  \n\n ▪   “[It’s] simple economics – if people want to put their info out there....well, sucks to be them.”  Man, 29   ", "page_idx": 11, "bbox": [66, 535.072021484375, 545, 677.42041015625], "page_size": [612.0, 792.0]}
{"layout": 88, "type": "text", "text": "▪   “It sounds exactly like a  credit card score, which,  while not very fair, is  considered acceptable.”  Woman, 25  \n\n ▪   “Because it’s efficient and  effective at bringing  businesses information  that they can use to  connect their services and  products (loans) to  customers. This is a good  thing. To streamline the  process and make it  cheaper and more targeted  means less waste of  resources in advertising  such things.”  Man, 33    ", "page_idx": 12, "bbox": [65, 90.99198913574219, 214, 377.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 89, "type": "text", "text": "The  $68\\%$   of Americans who  think it is unacceptable for  companies to use this type of  program cite three primary  concerns. Around one-quarter   $(26\\%)$   argue that collecting  this data violates people’s  privacy. One-in-five say that  someone’s online data does  not accurately represent them  ", "page_idx": 12, "bbox": [65, 396, 214, 553.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 90, "type": "text", "text": "Concerns over automated personal finance scores  focus on privacy, discrimination, failure to represent  people accurately  ", "text_level": 1, "page_idx": 12, "bbox": [230, 103, 529, 148], "page_size": [612.0, 792.0]}
{"layout": 91, "type": "image", "page_idx": 12, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_6.jpg", "bbox": [229, 153, 538, 461], "page_size": [612.0, 792.0], "ocr_text": "% of U.S. adults\nwho say itis__\nfor companies to\nuse automated\npersonal finance\nscores\n\nEE) Acceptable\n\nNot\n(3:47) acceptable\n\n| Among those who say acceptable,\n% who give these as the main reasons\n\nWould be effective 31%\nConsumers willingly make info public | 12 |\nFree market at work | 6\nOK if info can be corrected i 4\n\nSame as traditional credit score I 3\n\nAmong those who say NOT acceptable,\n% who give these as the main reasons\n\nViolates privacy 26%\n\nDoesn't represent person accurately\n\nUnfair/discriminatory\nDoesn't reflect creditworthiness | 9]\n\nNo way to change score i 5\n\n", "vlm_text": "The image is a bar chart illustrating the percentage of U.S. adults who find it acceptable or not acceptable for companies to use automated personal finance scores.\n\n- **31% Acceptable:**  \n  - Reasons include:\n    - Would be effective (31%)\n    - Consumers willingly make info public (12%)\n    - Free market at work (6%)\n    - OK if info can be corrected (4%)\n    - Same as traditional credit score (3%)\n\n- **68% Not Acceptable:**  \n  - Reasons include:\n    - Violates privacy (26%)\n    - Doesn’t represent person accurately (20%)\n    - Unfair/discriminatory (15%)\n    - Doesn’t reflect creditworthiness (9%)\n    - No way to change score (5%)"}
{"layout": 92, "type": "text", "text": "PEW RESEARCH CENTER  as a person, while  $9\\%$   make the related point that people’s online habits and behaviors have  nothing to do with their overall credit worthiness. And   $15\\%$   feel that it is potentially unfair or  discriminatory to rely on this type of score.   ", "page_idx": 12, "bbox": [231.52999877929688, 519.1713256835938, 319.1199951171875, 528.2869873046875], "page_size": [612.0, 792.0]}
{"layout": 93, "type": "text", "text": "", "page_idx": 12, "bbox": [66, 556.8563842773438, 515, 601.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 94, "type": "text", "text": "Here are some samples of these responses:  ", "page_idx": 12, "bbox": [66, 620.81640625, 276.552978515625, 633.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 95, "type": "text", "text": "▪   “Opaque algorithms can introduce biases even without intending to. This is more of an issue  with criminal sentencing algorithms, but it can still lead to redlining and biases against  minority communities. If they were improved to eliminate this I’d be more inclined to accept  their use.”  Man, 46   \n\n ", "page_idx": 12, "bbox": [66, 651.1320190429688, 533.358154296875, 681.3804321289062], "page_size": [612.0, 792.0]}
{"layout": 96, "type": "text", "text": "", "page_idx": 13, "bbox": [84, 92.73638916015625, 543, 121.24039459228516], "page_size": [612.0, 792.0]}
{"layout": 97, "type": "text", "text": "▪   “It encroaches on someone’s ability to freely engage in activities online. It makes one want to  hide what they are buying – whether it is a present for a friend or a book to read. Why should  anyone have that kind of access to know my buying habits and take advantage of it in some  way? That kind of monitoring just seems very archaic. I can understand why this would be  done, from their point of view it helps to show what I as a customer would be interested in  buying. But I feel that there should be a line of some kind, and this crosses that line.”  Woman,  27   \n\n ▪   “I don’t think it is fair for companies to use my info without my permission, even if it would be  a special offer that would interest me. It is like spying, not acceptable. It would also exclude  people from receiving special offers that can’t or don’t use social media, including those from  lower socioeconomic levels.”  Woman, 63  \n\n ▪   “Algorithms are biased programs adhering to the views and beliefs of whomever is ordering  and controlling the algorithm ... Someone has made a decision about the relevance of certain  data and once embedded in a reviewing program becomes irrefutable gospel, whether it is a  good indicator or not.”  Man, 80   ", "page_idx": 13, "bbox": [66, 123.03202819824219, 543, 361.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 98, "type": "text", "text": "Automated criminal risk score  ", "page_idx": 13, "bbox": [66, 380.7864074707031, 219.07296752929688, 393.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 99, "type": "text", "text": "The  $42\\%$   of Americans who think the use of this type of program is acceptable mention a range of  reasons for feeling this way, with no single factor standing out from the others. Some  $16\\%$   of these  respondents think this type of program is acceptable because it would be effective or because it’s  helpful for the justice system to have more information when making these decisions. A similar  share   $(13\\%)$   thinks this type of program would be acceptable if it is just one part of the decision- making process, while one-in-ten think it would be fairer and less biased than the current system.  ", "page_idx": 13, "bbox": [66, 402, 543, 495.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 100, "type": "text", "text": "In some cases, respondents use very different arguments to support the same outcome. For  instance,  $9\\%$   of these respondents think this type of program is acceptable because it offers  prisoners a second chance at being a productive member of society. But   $6\\%$   support it because they  think it would help protect the public by keeping potentially dangerous individuals in jail who  might otherwise go free.  ", "page_idx": 13, "bbox": [66, 514.8563842773438, 548.167724609375, 591.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 101, "type": "text", "text": "Some examples:  ", "page_idx": 13, "bbox": [66, 610.8563842773438, 148.1229705810547, 623.400390625], "page_size": [612.0, 792.0]}
{"layout": 102, "type": "text", "text": "▪   “Prison and law enforcement officials have been doing this for hundreds of years already. It is  common sense. Now that it has been identified and called a program or a process [that] does  not change anything.”  Man, 71   ", "page_idx": 13, "bbox": [66, 641.052001953125, 543, 687.3804321289062], "page_size": [612.0, 792.0]}
{"layout": 103, "type": "text", "text": "▪   “Because the other  option is to rely  entirely upon human  decisions, which are  themselves flawed and  biased. Both human  intelligence and data  should be used.”  Man,  56  \n\n ▪   “Right now, I think  many of these  decisions are made  subjectively. If we can  quantify risk by  objective criteria that  have shown validity in  the real world, we  should use it. Many  black men are in  prison, it is probable  that with more  objective criteria they  would be eligible for  parole. Similarly, other  racial/ethnic groups  may be getting an  undeserved break  because of subjective  bias. We need to be as  fair as possible to all  individuals, and this may help.”  ", "page_idx": 14, "bbox": [67, 90.99198913574219, 196, 585.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 104, "type": "text", "text": "Concerns over criminal risk scores focus on lack of  individual focus, people’s ability to change  ", "text_level": 1, "page_idx": 14, "bbox": [204, 103, 496, 134], "page_size": [612.0, 792.0]}
{"layout": 105, "type": "image", "page_idx": 14, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_7.jpg", "bbox": [205, 137, 507, 479], "page_size": [612.0, 792.0], "ocr_text": "% of U.S. adults\nwho say it is__\nfor the criminal\njustice system to\n\nuse automated Would be effective\ncriminal risk Should be one-but only one--factor } 13]\nscores Would be more fair/unbiased\nPeople deserve a second chance\nNeed to identify repeat offenders\n\nPeople can change in future | 2\n\nAmong those who say acceptable,\n% who give these as the main reasons\n\nvbi7 Acceptable\nNeed a human involved in the process | 4\n\nUnfair/could result in bias or profiling | a\n\nAmong those who say NOT acceptable,\n% who give these as the main reasons\n\nNot\nj-)/5, acceptable\n\nEvery individual/circumstance is diff.\n\nPeople can change\nNeed a human involved in the process\nUnfair/could result in bias or profiling\nViolates privacy [fj 4\nShould be one--but only one-factor jj 2\n\nWould be fair/unbiased | 1\n", "vlm_text": "The image is a chart showing the opinions of U.S. adults on the use of automated criminal risk scores by the criminal justice system. \n\n- 42% find it acceptable, while 56% find it not acceptable.\n  \nFor those who say it's acceptable, reasons include:\n- Would be effective (16%)\n- Should be one of several factors (13%)\n- Would be more fair/unbiased (10%)\n- People deserve a second chance (9%)\n- Need to identify repeat offenders (6%)\n- People can change in future (2%)\n- Need human involvement (1%)\n- Unfair/could result in bias/profiling (1%)\n\nFor those who say it's not acceptable, reasons include:\n- Every individual/circumstance is different (26%)\n- People can change (25%)\n- Need human involvement (12%)\n- Unfair/could result in bias/profiling (9%)\n- Violates privacy (4%)\n- Should be one of several factors (2%)\n- Would be fair/unbiased (1%)"}
{"layout": 106, "type": "text", "text": "PEW RESEARCH CENTER  ▪   “While such a program would have its flaws, the current alternative of letting people decide is  far more flawed.”  Man, 42  \n\n ", "page_idx": 14, "bbox": [206.69000244140625, 539.331298828125, 294.2799987792969, 548.4469604492188], "page_size": [612.0, 792.0]}
{"layout": 107, "type": "text", "text": "", "page_idx": 14, "bbox": [66, 587.0320434570312, 539, 617.400390625], "page_size": [612.0, 792.0]}
{"layout": 108, "type": "text", "text": "▪   “As long as they have OTHER useful info to make their decisions then it would be acceptable.  They need to use whatever they have available that is truthful and informative to make such an  important decision!”  Woman, 63   ", "page_idx": 14, "bbox": [66, 619.072021484375, 545.6077880859375, 665.42041015625], "page_size": [612.0, 792.0]}
{"layout": 109, "type": "text", "text": "The  $56\\%$   of Americans who think this type of program is not acceptable tend to focus on the  efficacy of judging people in this manner. Some   $26\\%$   of these responses argue that every individual  or circumstance is different and that a computer program would have a hard time capturing these  nuances. A similar share   $(25\\%)$   argues that this type of system precludes the possibility of personal  growth or worries that the program might not have the best information about someone when  making its assessment. And around one-in-ten worry about the lack of human involvement in the  process   $\\left(\\mathbf{1}2\\%\\right)$   or express concern that this system might result in unfair bias or profiling   $(9\\%)$  .  ", "page_idx": 15, "bbox": [66, 92, 547, 201.28038024902344], "page_size": [612.0, 792.0]}
{"layout": 110, "type": "text", "text": "Some examples: \n\n ", "page_idx": 15, "bbox": [66, 220.806396484375, 148, 233.3503875732422], "page_size": [612.0, 792.0]}
{"layout": 111, "type": "text", "text": "▪   “People should be looked at and judged as an individual, not based on some compilation of  many others. We are all very different from one another even if we have the same interests or  ideas or beliefs – we are an individual within the whole.”  Woman, 71  \n\n ▪   “Two reasons: People can change, and data analysis can be wrong.”  Woman, 63  \n\n ▪   “Because it seems like you’re determining a person’s future based on another person’s  choices.”  Woman, 46  \n\n ▪   “Information about populations are not transferable to individuals. Take BMI [body mass  index] for instance. This measure was designed to predict heart disease in large populations  but has been incorrectly applied for individuals. So, a 6-foot-tall bodybuilder who weighs 240  lbs is classified as morbidly obese because the measure is inaccurate. Therefore, information  about recidivism of populations cannot be used to judge individual offenders.”  Woman, 54  \n\n ▪   “Data collection is often flawed and difficult to correct. Algorithms do not reflect the soul. As a  data scientist, I also know how often these are just wrong.”  Man, 36   ", "page_idx": 15, "bbox": [66, 250.9819793701172, 547, 457.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 112, "type": "text", "text": "Video analysis of job candidates  ", "page_idx": 15, "bbox": [66, 476.7864074707031, 227.59295654296875, 489.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 113, "type": "text", "text": "Two themes stand out in the responses of the  $32\\%$   of Americans who think it is acceptable to use  this tool when hiring job candidates. Some  $17\\%$   of these respondents think companies should have  the right to hire however they see fit, while  $16\\%$   think it is acceptable because it’s just one data  point among many in the interview process. Another  $9\\%$   think this type of analysis would be more  objective than a traditional person-to-person interview.  ", "page_idx": 15, "bbox": [66, 498.7763977050781, 547, 575.400390625], "page_size": [612.0, 792.0]}
{"layout": 114, "type": "text", "text": "Some examples: \n\n ", "page_idx": 15, "bbox": [66, 594.7764282226562, 148, 607.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 115, "type": "text", "text": "▪   “All’s fair in commonly accepted business practices.”  Man, 76  \n\n ▪   “They are analyzing your traits. I don’t have a problem with that.”  Woman, 38  \n\n ▪   “Again, in this fast-paced world, with our mobile society and labor market, a semi-scientific  tool bag is essential to stay competitive.”  Man, 71   ", "page_idx": 15, "bbox": [66, 625.072021484375, 531, 687.3804321289062], "page_size": [612.0, 792.0]}
{"layout": 116, "type": "text", "text": "▪   “As long as the job  candidate agrees to this  format, I think it’s  acceptable. Hiring  someone entails a huge  financial investment and  this might be a useful  tool.”  Woman, 61  \n\n ▪   “I think it’s acceptable to  use the product during the  interview. However, to use  it as the deciding factor is  ludicrous. Interviews are  tough and make  candidates nervous,  therefore I think that using  this is acceptable but poor  if used for final selection.”  Man, 23   ", "page_idx": 16, "bbox": [66, 90.99198913574219, 217, 393.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 117, "type": "text", "text": "Respondents who think this  type of process is unacceptable  tend to focus on whether it  would work as intended. One- in-five argue that this type of  analysis simply won’t work or  is flawed in some general way.  A slightly smaller share   $\\left(16\\%\\right)$    ", "page_idx": 16, "bbox": [66, 412.826416015625, 217, 537.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 118, "type": "text", "text": "Concerns over automated job interview analysis focus  on fairness, effectiveness, lack of human involvement  ", "text_level": 1, "page_idx": 16, "bbox": [229, 103, 539, 133], "page_size": [612.0, 792.0]}
{"layout": 119, "type": "image", "page_idx": 16, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_8.jpg", "bbox": [229, 139, 535, 449], "page_size": [612.0, 792.0], "ocr_text": "% of U.S. adults\nwho say it is__\nfor companies to\nuse video analysis\nwhen hiring job Companies can hire however they want\ncandidates Just one data pt. in the process\nWould be more objective\nAcceptable with candidate knowledge | | 4\n\nAmong those who say acceptable,\n% who give these as the main reasons\n\nKyla Acceptable —— Humans should evaluate humans J2\nWould not work/is flawed |2\nIs not fair |4\n\nAmong those who say NOT acceptable,\n% who give these as the main reasons\n\nNot Would not work/is flawed | 20%\nzed) acceptable Humans should evaluate humans | 16]\n\nIs not fair\n\nNot everyone interviews well HE)\nAcceptable with candidate knowledge | i\n\nIs weird/uncomfortable | ull\n\n", "vlm_text": "The image is an infographic representing the opinions of U.S. adults on the acceptability of companies using video analysis when hiring job candidates. \n\nKey points include:\n\n- 32% find it acceptable, while 67% do not.\n- Among those who say it's acceptable, the main reasons given are: \n  - \"Companies can hire however they want\" (17%),\n  - \"Just one data point in the process\" (16%),\n  - \"Would be more objective\" (9%),\n  - \"Acceptable with candidate knowledge\" (4%),\n  - \"Humans should evaluate humans\" (2%),\n  - \"Would not work/is flawed\" (1%),\n  - \"Is not fair\" (1%).\n  \n- Among those who say it's not acceptable, the main reasons are:\n  - \"Would not work/is flawed\" (20%),\n  - \"Humans should evaluate humans\" (16%),\n  - \"Is not fair\" (14%),\n  - \"Not everyone interviews well\" (13%),\n  - \"Acceptable with candidate knowledge\" (1%),\n  - \"Is weird/uncomfortable\" (1%)."}
{"layout": 120, "type": "text", "text": "PEW RESEARCH CENTER  makes the case that humans should interview other humans, while  $14\\%$   feel that this process is  just not fair to the people being evaluated. And   $13\\%$   feel that not everyone interviews well and that  this scoring system might overlook otherwise talented candidates.  ", "page_idx": 16, "bbox": [231.52999877929688, 505.6112976074219, 319.1199951171875, 514.7269287109375], "page_size": [612.0, 792.0]}
{"layout": 121, "type": "text", "text": "", "page_idx": 16, "bbox": [66, 540, 544.4247436523438, 585.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 122, "type": "text", "text": "Some examples: \n\n ", "page_idx": 16, "bbox": [66, 604.8563842773438, 148.1229705810547, 617.400390625], "page_size": [612.0, 792.0]}
{"layout": 123, "type": "text", "text": "▪   “I don’t think that characteristics obtained in this manner would be reliable. Great employees  can come in all packages.”  Woman, 68  \n\n ", "page_idx": 16, "bbox": [66, 635.052001953125, 538.8118896484375, 665.42041015625], "page_size": [612.0, 792.0]}
{"layout": 124, "type": "text", "text": "▪   “Individuals may have attributes and strengths that are not evident through this kind of  analysis and they would be screened out based on the algorithm.”  Woman, 57    ", "page_idx": 16, "bbox": [66, 667.092041015625, 511.24517822265625, 697.3403930664062], "page_size": [612.0, 792.0]}
{"layout": 125, "type": "text", "text": "▪   “A person could be great in person but freeze during such an interview (on camera). Hire a  person not a robot if you are wanting a person doing a job. Interviews as described should only  be used for persons that live far away and can’t come in and then only to narrow down the  candidates for the job, then the last interview should require them to have a person to person  interview.”  Woman, 61   \n\n ▪   “Some people do not interview well, and a computer cannot evaluate a person’s personality  and how they relate to other people.”  Man, 75    ", "page_idx": 17, "bbox": [66, 90.99198913574219, 545.2925415039062, 201.28038024902344], "page_size": [612.0, 792.0]}
{"layout": 126, "type": "text", "text": "Automated resume screening  ", "page_idx": 17, "bbox": [66, 220.806396484375, 213.31295776367188, 233.3503875732422], "page_size": [612.0, 792.0]}
{"layout": 127, "type": "text", "text": "The  $41\\%$   of Americans who think it is acceptable for companies to use this type of program give  three major reasons for feeling this way. Around one-in-five   $(19\\%)$   find it acceptable because the  company using the process would save a great deal of time and money. An identical share thinks it  would be more accurate than screening resumes by hand, and   $16\\%$   feel that companies can hire  however they want to hire.  ", "page_idx": 18, "bbox": [66, 114, 544.7960815429688, 191.32041931152344], "page_size": [612.0, 792.0]}
{"layout": 128, "type": "text", "text": "Some examples: \n\n ", "page_idx": 18, "bbox": [66, 210.72637939453125, 148, 223.27037048339844], "page_size": [612.0, 792.0]}
{"layout": 129, "type": "text", "text": "▪   “Have you ever tried to  sort through hundreds of  applications? A program  provides a non-partial  means of evaluating  applicants. It may not be  perfect, but it is efficient.”  Woman, 65   \n\n ▪   “While I wouldn’t do this  for my company, I simply  think it’s acceptable  because private companies  should be able to use  whatever methods they  want as long as they don’t  illegally discriminate. I  happen to think some  potentially good  candidates would be  passed over using this  method, but I wouldn’t say  an organization shouldn’t  be allowed to do it this  way.”  Man, 50   \n\n ▪   “If it eliminates resumes  that don’t meet criteria, it  allows the hiring process  ", "page_idx": 18, "bbox": [66, 241.0220184326172, 216, 671.42041015625], "page_size": [612.0, 792.0]}
{"layout": 130, "type": "text", "text": "Concerns over automated resume screening focus on  fairness, lack of human involvement  ", "text_level": 1, "page_idx": 18, "bbox": [230, 199, 535, 229], "page_size": [612.0, 792.0]}
{"layout": 131, "type": "image", "page_idx": 18, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_9.jpg", "bbox": [230, 237, 542, 590], "page_size": [612.0, 792.0], "ocr_text": "% of U.S. adults\nwho say it is__\nfor companies to\nuse automated\nresume\nscreening when\nhiring job\ncandidates\n\nU&E Acceptable —\n\nNot\nyay, acceptable —\n\nAmong those who say acceptable,\n% who give these as the main reasons\n\nSaves time/money\nWould be more accurate\n\nCompanies can hire however they want | 16]\nRemoves human element from process\nWould remove bias\nOK as long as it’s not the whole process\nIs not fair/may not get best person\n\nResumes are bad/system can be gamed Iz\n\nAmong those who say NOT acceptable,\n% who give these as the main reasons\n\nRemoves human element from process\n\nResumes are bad/system can be gamed | 16]\n\nWould be more accurate | 1\n\nIs not fair/may not get best person\n", "vlm_text": "The image is a bar chart showing the percentage of U.S. adults who find it acceptable or not acceptable for companies to use automated resume screening when hiring job candidates. \n\n- 41% of respondents say it is acceptable, and among those:\n  - 19% find it acceptable because it saves time/money.\n  - 19% think it would be more accurate.\n  - 16% believe companies can hire however they want.\n  - 6% note it removes the human element from the process.\n  - 5% say it would remove bias.\n  - 5% are okay with it as long as it’s not the whole process.\n  - 4% consider it is not fair/may not get the best person.\n  - 2% think resumes are bad/system can be gamed.\n\n- 57% say it is not acceptable, and among those:\n  - 36% say it removes the human element from the process.\n  - 23% believe it is not fair/may not get the best person.\n  - 16% say resumes are bad/system can be gamed.\n  - 1% think it would be more accurate."}
{"layout": 132, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 18, "bbox": [231.52999877929688, 652.6312866210938, 319.1199951171875, 661.7469482421875], "page_size": [612.0, 792.0]}
{"layout": 133, "type": "text", "text": "to be more efficient.”  Woman, 43 ", "page_idx": 19, "bbox": [84, 92.73638916015625, 246.02099609375, 105.2803726196289], "page_size": [612.0, 792.0]}
{"layout": 134, "type": "text", "text": "Those who find the process unacceptable similarly focus on three major themes. Around one-third \n\n  $(36\\%)$   worry that this type of process takes the human element out of hiring. Roughly one-quarter \n\n  $({\\it23\\%})$   feel that this system is not fair or would not always get the best person for the job. And  $16\\%$    worry that resumes are simply not a good way to choose job candidates and that people could  game the system by putting in keywords that appeal to the algorithm.  ", "page_idx": 19, "bbox": [65, 124.77642822265625, 545, 201.28038024902344], "page_size": [612.0, 792.0]}
{"layout": 135, "type": "text", "text": "Here are some samples of these responses: \n\n ", "page_idx": 19, "bbox": [65, 220.806396484375, 276.552978515625, 233.3503875732422], "page_size": [612.0, 792.0]}
{"layout": 136, "type": "text", "text": "▪   “Again, you are taking away the human component. What if a very qualified person couldn’t  afford to have a professional resume writer do his/her resume? The computer would kick it  out.”  Woman, 72   \n\n ▪   “Companies will get only employees who use certain words, phrases, or whatever the  parameters of the search are. They will miss good candidates and homogenize their  workforce.”  Woman, 48   \n\n ▪   “The likelihood that a program kicks a resume, and the human associated with it, for minor  quirks in terminology grows. The best way to evaluate humans is with humans.”  Man, 54   \n\n ▪   “It’s just like taking standardized school tests, such as the SAT, ACT, etc. There are teaching  programs to help students learn how to take the exams and how to ‘practice’ with various  examples. Therefore, the results are not really comparing the potential of all test takers, but  rather gives a positive bias to those who spend the time and money learning how to take the  test.”  Man, 64   ", "page_idx": 19, "bbox": [65, 250.9819793701172, 531, 457.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 137, "type": "text", "text": "2. Algorithms in action: The content people see on social  media  ", "text_level": 1, "page_idx": 20, "bbox": [65, 91, 513, 129], "page_size": [612.0, 792.0]}
{"layout": 138, "type": "text", "text": "The social media environment is another prominent example of algorithmic decision-making in  Americans’ daily lives. Nearly all the content people see on social media is chosen not by human  editors but rather by computer programs using massive quantities of data about each user to  deliver content that he or she might find relevant or engaging. This has led to widespread concerns  that these sites are promoting content that is attention-grabbing but ultimately harmful to users –  such as misinformation, sensationalism or “hate clicks.”  ", "page_idx": 20, "bbox": [66, 142.77642822265625, 547.0426635742188, 235.27037048339844], "page_size": [612.0, 792.0]}
{"layout": 139, "type": "text", "text": "To more broadly understand public attitudes toward algorithms  in this context, the survey asked respondents a series of questions  about the content they see on social media, the emotions that  content arouses, and their overall comfort level with these sites  using their data to serve them different types of information. And  like the questions around the impact of algorithms discussed in  the preceding chapter, this portion of the survey led with a broad  question about whether the public thinks social media reflects  overall public sentiment.  ", "page_idx": 20, "bbox": [66, 254.76641845703125, 390, 395.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 140, "type": "text", "text": "On this score, a majority of Americans   $\\left(74\\%\\right)$   think the content  people post on social media does  not  provide an accurate picture  of how society feels about important issues, while one-quarter say  it does. Certain groups of Americans are more likely than others  to think that social media paints an accurate picture of society  writ large. Notably, blacks   $\\left(37\\%\\right)$   and Hispanics   $\\left(35\\%\\right)$  ) are more  likely than whites   $\\left(\\boldsymbol{20\\%}\\right)$   to say this is the case. And the same is  true of younger adults compared with their elders:   $35\\%$   of  ${\\bf18-}$   to  29-year-olds think that social media paints an accurate portrait of  society, but that share drops to  $19\\%$   among those ages 65 and  older. Still, despite these differences, a majority of Americans  across a wide range of demographic groups feel that social media is  ", "page_idx": 20, "bbox": [66, 414.74639892578125, 390, 603.3604125976562], "page_size": [612.0, 792.0]}
{"layout": 141, "type": "text", "text": "Most think social media  does not accurately  reflect society  ", "text_level": 1, "page_idx": 20, "bbox": [395, 269, 534, 314], "page_size": [612.0, 792.0]}
{"layout": 142, "type": "text", "text": " $\\%$   of U.S. adults who say the content  on social media ___ provide an  accurate picture of how society feels  about important issues  ", "page_idx": 20, "bbox": [396, 318, 544, 365.7631530761719], "page_size": [612.0, 792.0]}
{"layout": 143, "type": "image", "page_idx": 20, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_10.jpg", "bbox": [399, 381, 534, 509], "page_size": [612.0, 792.0], "ocr_text": "Does not\n74%\n\nNo\nanswer\n\n", "vlm_text": "The image is a pie chart that shows the distribution of responses among three categories. The sections are labeled as follows:\n- \"Does\": This section represents 25% and is shown in a lighter blue color.\n- \"Does not\": This section represents 74% and is shown in a darker blue color.\n- \"No answer\": This section represents 1% and is depicted as a narrow gray slice."}
{"layout": 144, "type": "text", "text": "Source: Survey of U.S. adults conducted  May 29-June 11, 2018.  “Public Attitudes Toward Computer  Algorithms”  ", "page_idx": 20, "bbox": [396, 513.7713012695312, 533.7335815429688, 553.0069580078125], "page_size": [612.0, 792.0]}
{"layout": 145, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 20, "bbox": [396, 558.4113159179688, 484.75, 567.5269775390625], "page_size": [612.0, 792.0]}
{"layout": 146, "type": "text", "text": "opinion more broadly.  ", "page_idx": 20, "bbox": [66.6240005493164, 606.7764282226562, 177.67295837402344, 619.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 147, "type": "text", "text": "Social media users frequently  encounter content that  sparks feelings of  amusement but also see  material that angers them  ", "text_level": 1, "page_idx": 21, "bbox": [65, 91, 222, 170], "page_size": [612.0, 792.0]}
{"layout": 148, "type": "text", "text": "When asked about six different  emotions that they might  experience due to the content  they see on social media, the  largest share of users (  $88\\%$   in  total) say they see content on  these sites that makes them feel  amused. Amusement is also the  emotion that the largest share  of users   $(44\\%)$    frequently   experience on these sites.   ", "page_idx": 21, "bbox": [66, 178.77642822265625, 222, 351.3103942871094], "page_size": [612.0, 792.0]}
{"layout": 149, "type": "text", "text": "Social media users experience a mix of positive,  negative emotions while using these platforms  ", "text_level": 1, "page_idx": 21, "bbox": [230, 104, 506, 135], "page_size": [612.0, 792.0]}
{"layout": 150, "type": "text", "text": " $\\%$   of social media users who say they ___ see content on social media that  makes them feel …  ", "page_idx": 21, "bbox": [230, 139, 531, 161.953125], "page_size": [612.0, 792.0]}
{"layout": 151, "type": "image", "page_idx": 21, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_11.jpg", "bbox": [245, 174, 526, 325], "page_size": [612.0, 792.0], "ocr_text": "Amused\nAngry\nConnected\nInspired\nDepressed\n\nLonely\n\nFrequently\n\n44\n\n1\n1\n\n3\n\nea\nBR\n2 i)\nNO\nol\n\nSometimes\n\nNET\n\n88\n\n71\n\n71\n\n69\n\n49\n\n31\n", "vlm_text": "The image is a bar chart showing the frequency of different emotions experienced. Each emotion is split into \"Frequently\" and \"Sometimes\", with a total \"NET\" score. \n\n- **Amused**: Frequently 44, Sometimes 44, NET 88\n- **Angry**: Frequently 25, Sometimes 47, NET 71\n- **Connected**: Frequently 21, Sometimes 49, NET 71\n- **Inspired**: Frequently 16, Sometimes 53, NET 69\n- **Depressed**: Frequently 13, Sometimes 36, NET 49\n- **Lonely**: Frequently 7, Sometimes 24, NET 31"}
{"layout": 152, "type": "text", "text": "Social media also leads many  users to feel anger. A total of  ", "page_idx": 21, "bbox": [65, 370.826416015625, 210.55296325683594, 399.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 153, "type": "text", "text": " $71\\%$   of social media users report encountering content that makes them angry, and one-quarter  see this type of content frequently. Similar shares say they encounter content that makes them feel  connected   $(71\\%)$   or inspired   $(69\\%)$  . Meanwhile, around half   $(49\\%)$   say they encounter content that  makes them feel depressed, and  $31\\%$   indicate that they at least sometimes see content that makes  them feel lonely.  ", "page_idx": 21, "bbox": [65, 402, 547, 479.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 154, "type": "text", "text": "Identical shares of users across a range of age groups say they frequently encounter content on  social media that makes them feel angry. But other emotions exhibit more variation based on age.  Notably, younger adults are more likely than older adults to say they frequently encounter content  on social media that makes them feel lonely. Some  $15\\%$   of social media users ages 18 to 29 say this,  compared with  $7\\%$   of those ages 30 to 49 and just  $4\\%$   of those 50 and older. Conversely, a  relatively small share of older adults are frequently amused by content they see on social media. In  fact, similar shares of social media users ages 65 and older say they frequently see content on these  platforms that makes them feel amused   $\\left(30\\%\\right)$   and angry   $({\\it24\\%})$  .  ", "page_idx": 21, "bbox": [65, 498.7763977050781, 547, 623.400390625], "page_size": [612.0, 792.0]}
{"layout": 155, "type": "text", "text": "A recent Pew Research Center  analysis  of congressional  Facebook pages found that the  “anger” emoticon is now the  most common reaction to posts  by members of Congress. And  although this survey did not ask  about the specific types of  content that might make people  angry, it does find a modest  correlation between the  frequency with which users see  content that makes them angry  and their overall political  affiliation. Some   $31\\%$   of  conservative Republicans say  they frequently feel angry due  to things they see on social  media (compared with  $19\\%$   of  moderate or liberal  Republicans), as do   $27\\%$   of  liberal Democrats (compared  with  $19\\%$   of moderate or  conservative Democrats).  ", "page_idx": 22, "bbox": [66, 92.73638916015625, 223, 473.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 156, "type": "text", "text": "Larger share of young social media users say these  platforms frequently make them feel amused – but  also lonely and depressed  ", "text_level": 1, "page_idx": 22, "bbox": [231, 99, 523, 143], "page_size": [612.0, 792.0]}
{"layout": 157, "type": "text", "text": " $\\%$   of social media users in each age group who say they frequently see  content on social media that makes them feel…  ", "page_idx": 22, "bbox": [231, 148, 516.12890625, 170.953125], "page_size": [612.0, 792.0]}
{"layout": 158, "type": "image", "page_idx": 22, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_12.jpg", "bbox": [232, 185, 543, 402], "page_size": [612.0, 792.0], "ocr_text": "Ages 65+ 50-64 30-49 18-29\n\nAmused O—® ry)\n30% 39 51 54\n\nAngry @e\n23'2425:27\nConnected Oo C@\n15 2023 25\n\nInspired O—@e\n\n9 161719\nDepressed @ @\nPOs Le\nLonely O@ ©\n\n257 15\n", "vlm_text": "The image is a horizontal dot plot displaying survey data about the emotional responses of different age groups to humorous or amusing content. The age groups are coded by color: blue for Ages 65+, light blue for 50-64, dark blue for 30-49, and green for 18-29. Each emotional response (Amused, Angry, Connected, Inspired, Depressed, and Lonely) is plotted with dots representing the percentage of people in each age group who experienced that emotion.\n\nHere is a breakdown of the emotional responses by age group:\n- **Amused:** 30% (65+), 39% (50-64), 51% (30-49), 54% (18-29)\n- **Angry:** 23% (65+), 24% (50-64), 25% (30-49), 27% (18-29)\n- **Connected:** 15% (65+), 20% (50-64), 23% (30-49), 25% (18-29)\n- **Inspired:** 9% (65+), 16% (50-64), 17% (30-49), 19% (18-29)\n- **Depressed:** 11% (65+), 12% (50-64), 12% (30-49), 17% (18-29)\n- **Lonely:** 2% (65+), 5% (50-64), 7% (30-49), 15% (18-29)\n\nThe chart depicts how different age groups react emotionally, particularly highlighting that younger people (18-29) tend to report stronger emotions across all categories compared to older age groups."}
{"layout": 159, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 22, "bbox": [231, 438.9813232421875, 319.8399963378906, 448.09698486328125], "page_size": [612.0, 792.0]}
{"layout": 160, "type": "text", "text": "Social media users frequently encounter people being overly dramatic or starting  arguments before waiting for all the facts to emerge  ", "text_level": 1, "page_idx": 22, "bbox": [66, 492, 493, 522], "page_size": [612.0, 792.0]}
{"layout": 161, "type": "text", "text": "Along with asking about the emotions social media platforms inspire in users, the survey also  included a series of questions about how often social media users encounter certain types of  behaviors and content. These findings indicate that users see two types of content especially  frequently: posts that are overly dramatic or exaggerated (  $58\\%$   of users say they see this type of  content frequently) and people making accusations or starting arguments without waiting until  they have all the facts   $(59\\%$   see this frequently).  ", "page_idx": 22, "bbox": [66, 530.81640625, 529, 624], "page_size": [612.0, 792.0]}
{"layout": 162, "type": "text", "text": "A majority of social media users also say they at least sometimes encounter posts that appear to be  about one thing but turn out to be about something else, as well as posts that teach them   ", "page_idx": 22, "bbox": [66, 642.79638671875, 545.2318115234375, 671.42041015625], "page_size": [612.0, 792.0]}
{"layout": 163, "type": "text", "text": "something useful they hadn’t  known before. But in each  instance, fewer than half say  they see these sorts of posts  frequently.   ", "page_idx": 23, "bbox": [65, 92.73638916015625, 215, 169.2404022216797], "page_size": [612.0, 792.0]}
{"layout": 164, "type": "text", "text": "Beyond the emotions they feel  while browsing social media,  users are exposed to a mix of  positive and negative behaviors  from others. Around half   $\\left(54\\%\\right)$    of social media users say they  typically see an equal mix of  people being kind or supportive  and people being mean or  bullying. Around one-in-five   $\\left(\\boldsymbol{\\it{21\\%}}\\right)$   say they more often see  people being kind and  supportive on these sites, while  a comparable share   $\\left({\\it24\\%}\\right)$   says  ", "page_idx": 23, "bbox": [65, 188.73638916015625, 222, 409.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 165, "type": "text", "text": "Majorities of social media users frequently see people  engaging in drama and exaggeration, jumping into  arguments without having all the facts  ", "text_level": 1, "page_idx": 23, "bbox": [230, 103, 539, 149], "page_size": [612.0, 792.0]}
{"layout": 166, "type": "text", "text": "% of social media users who say they ___ see the following types of content  on social media  ", "page_idx": 23, "bbox": [231, 154.007080078125, 537.4234619140625, 176.233154296875], "page_size": [612.0, 792.0]}
{"layout": 167, "type": "image", "page_idx": 23, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_13.jpg", "bbox": [241, 182, 529, 333], "page_size": [612.0, 792.0], "ocr_text": "Posts that are overly dramatic\nor exaggerated\n\nPeople making accusations or\nstarting arguments without\nhaving all the facts\n\nPosts that teach you something\nuseful you hadn't known before\n\nPosts that appear to be about\none thing but turn out to be\nabout something else\n\nFrequently Sometimes\n\n8\n\n59\n\nZEA\n\n3\n\n.\nol\n\nNET\n\n88\n\n87\n\n79\n\n78\n", "vlm_text": "The image is a bar chart that displays how frequently certain types of posts occur, based on survey responses. There are four categories of posts, and for each category, participants indicated whether they encounter these posts \"Frequently\" or \"Sometimes.\" The NET column represents the combined percentage of \"Frequently\" and \"Sometimes\" responses for each type.\n\n1. Posts that are overly dramatic or exaggerated:\n   - Frequently: 58%\n   - Sometimes: 31%\n   - NET: 88%\n\n2. People making accusations or starting arguments without having all the facts:\n   - Frequently: 59%\n   - Sometimes: 28%\n   - NET: 87%\n\n3. Posts that teach you something useful you hadn't known before:\n   - Frequently: 21%\n   - Sometimes: 57%\n   - NET: 79%\n\n4. Posts that appear to be about one thing but turn out to be about something else:\n   - Frequently: 33%\n   - Sometimes: 45%\n   - NET: 78%"}
{"layout": 168, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 23, "bbox": [231, 373.8213195800781, 319.1199951171875, 382.9369812011719], "page_size": [612.0, 792.0]}
{"layout": 169, "type": "text", "text": "they more often see people being mean or bullying.  ", "page_idx": 23, "bbox": [66.6240005493164, 412.826416015625, 316.4129638671875, 425.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 170, "type": "text", "text": "Previous  surveys by the Center   have found that men are  slightly more likely than women  to encounter any sort of  harassing or abusive behavior  online. And in this instance, a  slightly larger share of men   $(29\\%)$   than women   $({\\bf19\\%})$   say  they more often see people  being mean or bullying content  on social media platforms than  see kind behavior. Women, on  the other hand, are slightly  more likely than men to say  that they more often see people  being kind or supportive. But  the largest shares of both men   $\\left(52\\%\\right)$   and women   $(56\\%)$   say  that they typically see an equal  mix of supportive and bullying  behavior on social media.  ", "page_idx": 24, "bbox": [65, 92.73638916015625, 221, 425.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 171, "type": "text", "text": "Men somewhat more likely than women to see people  being bullying, deceptive on social media  ", "text_level": 1, "page_idx": 24, "bbox": [231, 107, 539, 137], "page_size": [612.0, 792.0]}
{"layout": 172, "type": "text", "text": " $\\%$   of social media users who say they more often see ___when using these  sites  ", "page_idx": 24, "bbox": [231, 141, 532.1675415039062, 164.233154296875], "page_size": [612.0, 792.0]}
{"layout": 173, "type": "image", "page_idx": 24, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_14.jpg", "bbox": [233, 166, 537, 366], "page_size": [612.0, 792.0], "ocr_text": "People being\nPeople being kind or\nmean or bullying supportive Equal mix of both\n\nTotal\n\nPeople trying\nPeople trying to to point out\nbe deceptive inaccurate info Equal mix of both\n\nTotal 17\n\nBER\na\n\n", "vlm_text": "The image presents two sets of bar graphs comparing perceptions of online behavior between men and women. The first set evaluates perceptions of people being mean or bullying, being kind or supportive, and an equal mix of both. The second set looks at people trying to be deceptive, trying to point out inaccurate information, and an equal mix of both.\n\n1. **People being mean or bullying**:\n   - Total: 24%\n   - Men: 29%\n   - Women: 19%\n\n2. **People being kind or supportive**:\n   - Total: 21%\n   - Men: 17%\n   - Women: 24%\n\n3. **Equal mix of both (mean/kind)**:\n   - Total: 54%\n   - Men: 52%\n   - Women: 56%\n\n4. **People trying to be deceptive**:\n   - Total: 18%\n   - Men: 24%\n   - Women: 13%\n\n5. **People trying to point out inaccurate info**:\n   - Total: 17%\n   - Men: 17%\n   - Women: 17%\n\n6. **Equal mix of both (deceptive/pointing out inaccuracies)**:\n   - Total: 63%\n   - Men: 58%\n   - Women: 67%\n\nThe data suggests differences in perceptions between men and women regarding these online behaviors."}
{"layout": 174, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 24, "bbox": [231, 406.9413146972656, 319.8399963378906, 416.0569763183594], "page_size": [612.0, 792.0]}
{"layout": 175, "type": "text", "text": "When asked about the efforts they see other users making to spread – or correct – misinformation,  around two-thirds of users   $(63\\%)$   say they generally see an even mix of people trying to be  deceptive and people trying to point out inaccurate information. Similar shares more often see one  of these behaviors than others, with  $18\\%$   of users saying they more often see people trying to be  deceptive and   $17\\%$   saying they more often see people trying to point out inaccurate information.  Men are around twice as likely as women to say they more often seeing people being deceptive on  social media (  $\\mathbf{\\tilde{2}}4\\%$   vs.  $13\\%$  ). But majorities of both men   $(58\\%)$   and women  $(67\\%)$   see an equal mix  of deceptiveness and attempts to correct misinformation.  ", "page_idx": 24, "bbox": [66, 444.74639892578125, 547, 569.400390625], "page_size": [612.0, 792.0]}
{"layout": 176, "type": "text", "text": "Users’ comfort level with  social media companies  using their personal data  depends on how their data  are used  ", "text_level": 1, "page_idx": 25, "bbox": [65, 91, 207, 169], "page_size": [612.0, 792.0]}
{"layout": 177, "type": "text", "text": "The vast quantities of data that  social media companies possess  about their users – including  behaviors, likes, clicks and  other information users provide  about themselves – are  ultimately what allows these  platforms to deliver  individually targeted content in  an automated fashion. And this  survey finds that users’ comfort  level with this behavior is  heavily context-dependent.  ", "page_idx": 25, "bbox": [66, 178.77642822265625, 223, 383.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 178, "type": "text", "text": "Users are relatively comfortable with social platforms  using their data for some purposes, but not others  ", "text_level": 1, "page_idx": 25, "bbox": [230, 104, 536, 134], "page_size": [612.0, 792.0]}
{"layout": 179, "type": "text", "text": "% of social media users who say it is ___ for social media sites to use data  about them and their online activities to …  ", "page_idx": 25, "bbox": [231, 139.007080078125, 532.0595703125, 161.233154296875], "page_size": [612.0, 792.0]}
{"layout": 180, "type": "image", "page_idx": 25, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_15.jpg", "bbox": [236, 168, 544, 321], "page_size": [612.0, 792.0], "ocr_text": "Not at all Not very Somewhat Very\nacceptable acceptable acceptable acceptable\n\nRecommend events in\ntheir area 141 50 25\nRecommend someone they\nmight want to know a9 os i\nShow them ads for products\nor services aa 41 ta\nTf\n\nShow them messages from\npolitical campaigns\n\n34 30\n\n", "vlm_text": "This image is a bar chart showing the acceptability of different online recommendations. The categories are:\n\n1. **Recommend events in their area**:\n   - Not at all acceptable: 11%\n   - Not very acceptable: 14%\n   - Somewhat acceptable: 50%\n   - Very acceptable: 25%\n\n2. **Recommend someone they might want to know**:\n   - Not at all acceptable: 19%\n   - Not very acceptable: 24%\n   - Somewhat acceptable: 43%\n   - Very acceptable: 14%\n\n3. **Show them ads for products or services**:\n   - Not at all acceptable: 21%\n   - Not very acceptable: 26%\n   - Somewhat acceptable: 41%\n   - Very acceptable: 11%\n\n4. **Show them messages from political campaigns**:\n   - Not at all acceptable: 31%\n   - Not very acceptable: 31%\n   - Somewhat acceptable: 30%\n   - Very acceptable: 7%"}
{"layout": 181, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 25, "bbox": [231, 361.8213195800781, 319.1199951171875, 370.9369812011719], "page_size": [612.0, 792.0]}
{"layout": 182, "type": "text", "text": "They are relatively accepting of their data being used for certain types of messages, but much less  comfortable when it is used for other purposes.  ", "page_idx": 25, "bbox": [65, 386.7864074707031, 541, 415.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 183, "type": "text", "text": "Three-quarters of social media users find it acceptable for those platforms to use data about them  and their online behavior to recommend events in their area that they might be interested in, while  a smaller majority  $\\left(57\\%\\right)$   thinks it is acceptable if their data are used to recommend other people  they might want to be friends with.  ", "page_idx": 25, "bbox": [65, 434.7864074707031, 547, 495.33038330078125], "page_size": [612.0, 792.0]}
{"layout": 184, "type": "text", "text": "On the other hand, users are somewhat less comfortable with these sites using their data to show  advertisements for products or services. Around half  $\\left(52\\%\\right)$   think this behavior is acceptable, but a  similar share   $(47\\%)$   finds it to be not acceptable – and the share that finds it  not at all  acceptable   $\\left(\\boldsymbol{\\it{21\\%}}\\right)$   is roughly double the share who finds it  very  acceptable   $\\left(\\mathbf{11}\\%\\right)$  . Meanwhile, a substantial  majority of users think it is  not  acceptable for social media platforms to use their data to deliver  messages from political campaigns – and  $31\\%$   say this is not acceptable at all.  ", "page_idx": 25, "bbox": [65, 514.8563842773438, 547, 607.3204345703125], "page_size": [612.0, 792.0]}
{"layout": 185, "type": "text", "text": "Relatively sizable majorities of users across a range of age groups think it is acceptable for social  media sites to use their data to show them events happening in their area. And majorities of users  across a range of age categories feel it is  not  acceptable for social platforms to use their data to  serve them ads from political campaigns.   ", "page_idx": 25, "bbox": [65, 626.81640625, 541, 687.3804321289062], "page_size": [612.0, 792.0]}
{"layout": 186, "type": "text", "text": "But outside of these specific  similarities, older users are  much less accepting of social  media sites using their data for  other reasons. This is most  pronounced when it comes to  using that data to recommend  other people they might know.  By a two-to-one margin (  ${}^{66\\%}$   to   $33\\%$  , social media users ages  18 to 49 think this is an  acceptable use of their data. But  by a similar  $63\\%$   to  $36\\%$    margin, users ages 65 and older  say this is  not  acceptable.  Similarly, nearly six-in-ten  users ages 18 to 49 think it is  acceptable for these sites to use  their data to show them  advertisements for products or  ", "page_idx": 26, "bbox": [65, 92.73638916015625, 223, 409.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 187, "type": "text", "text": "Social media users from a range of age groups are  wary of their data being used to deliver political  messages  ", "text_level": 1, "page_idx": 26, "bbox": [231, 101, 519, 146], "page_size": [612.0, 792.0]}
{"layout": 188, "type": "text", "text": " $\\%$   of social media users who say it is acceptable for social media sites to use  data about them and their online activities to …  ", "page_idx": 26, "bbox": [231, 150, 537.5226440429688, 173.233154296875], "page_size": [612.0, 792.0]}
{"layout": 189, "type": "image", "page_idx": 26, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_16.jpg", "bbox": [232, 182, 545, 335], "page_size": [612.0, 792.0], "ocr_text": "Recommend events\nin their area\n\nRecommend someone\nthey might want to\nknow\n\nShow them ads for\nproducts and services\n\nShow them messages\n\nfrom political campaigns\n\nAges 65+ 50-64 18-29 30-49\n\nO-0-@\n67% 72 78 80\n\nO e—e\n36 53 6667\n\nO—€8-©\n39 5154 60\n\nOS®\n31 35 38 40\n", "vlm_text": "This image is a chart comparing how different age groups feel about certain types of recommendations and advertisements they receive. The age groups are color-coded as follows:\n\n- Ages 65+ (light blue)\n- Ages 50-64 (dark blue)\n- Ages 18-29 (green)\n- Ages 30-49 (blue-green)\n\nFor each of the four categories listed, dots represent the percentage of people in each age group that approves:\n\n1. **Recommend events in their area:** \n   - 67% of Ages 65+\n   - 72% of Ages 50-64\n   - 78% of Ages 18-29\n   - 80% of Ages 30-49\n\n2. **Recommend someone they might want to know:**\n   - 36% of Ages 65+\n   - 53% of Ages 50-64\n   - 66% of Ages 18-29\n   - 67% of Ages 30-49\n\n3. **Show them ads for products and services:**\n   - 39% of Ages 65+\n   - 51% of Ages 50-64\n   - 54% of Ages 18-29\n   - 60% of Ages 30-49\n\n4. **Show them messages from political campaigns:**\n   - 31% of Ages 65+\n   - 35% of Ages 50-64\n   - 38% of Ages 18-29\n   - 40% of Ages 30-49\n\nEach line has dots indicating the percentage for each age group."}
{"layout": 190, "type": "text", "text": "PEW RESEARCH CENTER  ", "page_idx": 26, "bbox": [231, 380.78131103515625, 319.8399963378906, 389.89697265625], "page_size": [612.0, 792.0]}
{"layout": 191, "type": "text", "text": "services, but that share falls to  $39\\%$   among those 65 and older.  ", "page_idx": 26, "bbox": [64, 412.826416015625, 371.3729553222656, 426], "page_size": [612.0, 792.0]}
{"layout": 192, "type": "text", "text": "Beyond using their personal data in these specific ways, social media users express consistent and  pronounced opposition to these platforms changing their sites in certain ways for some users but  not others. Roughly eight-in-ten social media users think it is unacceptable for these platforms to  do things like remind some users but not others to vote on election day   $(82\\%)$  , or to show some  users more of their friends’ happy posts and fewer of their sad posts   $(78\\%)$  . And even the standard   $\\mathbf{A}/\\mathbf{B}$   testing that most platforms engage in on a continuous basis is viewed with much suspicion by  users:  $78\\%$   of users think it is unacceptable for social platforms to change the look and feel of their  site for some users but not others.  ", "page_idx": 26, "bbox": [64, 444.74639892578125, 545, 569.400390625], "page_size": [612.0, 792.0]}
{"layout": 193, "type": "text", "text": "Older users are overwhelmingly opposed to these interventions. But even among younger users,  large shares find them problematic even in their most common forms. For instance,  $71\\%$   of social  media users ages 18 to 29 say it is unacceptable for these sites to change the look and feel for some  users but not others.  ", "page_idx": 26, "bbox": [64, 588.7764282226562, 545, 649.3403930664062], "page_size": [612.0, 792.0]}
{"layout": 194, "type": "text", "text": "Acknowledgements  ", "text_level": 1, "page_idx": 27, "bbox": [65, 91, 225, 110], "page_size": [612.0, 792.0]}
{"layout": 195, "type": "text", "text": "This report is a collaborative effort based on the input and analysis of the following individuals.  Find related reports online at  pew research.org/internet .  ", "page_idx": 27, "bbox": [66, 122.73638916015625, 530.0633544921875, 151.2404022216797], "page_size": [612.0, 792.0]}
{"layout": 196, "type": "text", "text": "Primary researchers  ", "text_level": 1, "page_idx": 27, "bbox": [66, 170, 173, 183], "page_size": [612.0, 792.0]}
{"layout": 197, "type": "text", "text": "Aaron Smith,  Associate Director, Research  ", "page_idx": 27, "bbox": [66, 192.6964111328125, 278.35296630859375, 205.2404022216797], "page_size": [612.0, 792.0]}
{"layout": 198, "type": "text", "text": "Research team  ", "text_level": 1, "page_idx": 27, "bbox": [66, 224, 147, 237], "page_size": [612.0, 792.0]}
{"layout": 199, "type": "text", "text": "Lee Rainie,  Director, Internet and Technology Research Kenneth Olmstead,  Research Associate   Jingjing Jiang,  Research Analyst  Andrew Perrin , Research Analyst  Paul Hitlin , Senior Researcher  Meg Hefferon,  Research Analyst   ", "page_idx": 27, "bbox": [66, 246.72637939453125, 341, 339.3103942871094], "page_size": [612.0, 792.0]}
{"layout": 200, "type": "text", "text": "Editorial and graphic design  ", "text_level": 1, "page_idx": 27, "bbox": [65, 358, 215, 372], "page_size": [612.0, 792.0]}
{"layout": 201, "type": "text", "text": "Margaret Porteus,  Information Graphics Designer Travis Mitchell,  Copy Editor   ", "page_idx": 27, "bbox": [66, 380.7864074707031, 312.74371337890625, 409.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 202, "type": "text", "text": "Communications and web publishing  ", "text_level": 1, "page_idx": 27, "bbox": [66, 428, 261, 441], "page_size": [612.0, 792.0]}
{"layout": 203, "type": "text", "text": "Haley Nolan,  Communications Assistant  Sara Atske,  Assistant Digital Producer  ", "page_idx": 27, "bbox": [66, 450.74639892578125, 267.4329528808594, 479.3703918457031], "page_size": [612.0, 792.0]}
{"layout": 204, "type": "text", "text": "The American Trends Panel Survey Methodology  ", "text_level": 1, "page_idx": 28, "bbox": [66, 90, 446, 110], "page_size": [612.0, 792.0]}
{"layout": 205, "type": "text", "text": "The American Trends Panel (ATP), created by Pew Research Center, is a nationally representative  panel of randomly selected U.S. adults recruited from landline and cellphone random-digit-dial  (RDD) surveys. Panelists participate via monthly self-administered web surveys. Panelists who do  not have internet access are provided with a tablet and wireless internet connection. The panel is  being managed by GfK.  ", "page_idx": 28, "bbox": [66, 122.73638916015625, 544, 199.2404022216797], "page_size": [612.0, 792.0]}
{"layout": 206, "type": "text", "text": "Data in this report are drawn from the panel wave conducted May 29-June 11, 2018, among 4,594  respondents. The margin of sampling error for the full sample of 4,594 respondents is plus or  minus 2.4 percentage points.   ", "page_idx": 28, "bbox": [66, 218.76641845703125, 544, 263.3503723144531], "page_size": [612.0, 792.0]}
{"layout": 207, "type": "text", "text": "Members of the American Trends Panel were recruited from several large, national landline and  cellphone RDD surveys conducted in English and Spanish. At the end of each survey, respondents  were invited to join the panel. The first group of panelists was recruited from the 2014 Political  Polarization and Typology Survey, conducted Jan. 23 to March 16, 2014. Of the 10,013 adults  interviewed, 9,809 were invited to take part in the panel and a total of 5,338 agreed to participate. The second group of panelists was recruited from the 2015 Pew Research Center Survey on  Government, conducted Aug. 27 to Oct. 4, 2015. Of the 6,004 adults interviewed, all were invited  to join the panel, and 2,976 agreed to participate.  The third group of panelists was recruited from  a survey conducted April 25 to June 4, 2017. Of the 5,012 adults interviewed in the survey or  pretest, 3,905 were invited to take part in the panel and a total of 1,628 agreed to participate.   ", "page_idx": 28, "bbox": [66, 282.7264099121094, 544, 439.2903747558594], "page_size": [612.0, 792.0]}
{"layout": 208, "type": "text", "text": "The ATP data were weighted in a multistep process that begins with a base weight incorporating  the respondents’ original survey selection probability and the fact that in 2014 some panelists were  subsampled for invitation to the panel. Next, an adjustment was made for the fact that the  propensity to join the panel and remain an active panelist varied across different groups in the  sample. The final step in the weighting uses an iterative technique that aligns the sample to  population benchmarks on a number of dimensions. Gender, age, education, race, Hispanic origin  and region parameters come from the U.S. Census Bureau’s 2016 American Community Survey.  The county-level population density parameter (deciles) comes from the 2010 U.S. decennial  census. The telephone service benchmark comes from the July-December 2016 National Health  ", "page_idx": 28, "bbox": [66, 458.7864074707031, 547.4103393554688, 599.400390625], "page_size": [612.0, 792.0]}
{"layout": 209, "type": "text", "text": "Interview Survey and is projected to 2017. The volunteer is m benchmark comes from the 2015  Current Population Survey Volunteer Supplement. The party affiliation benchmark is the average  of the three most recent Pew Research Center general public telephone surveys. The internet  access benchmark comes from the 2017 ATP Panel Refresh Survey. Respondents who did not  previously have internet access are treated as not having internet access for weighting purposes.  Sampling errors and statistical tests of significance take into account the effect of weighting.  Interviews are conducted in both English and Spanish, but the Hispanic sample in the ATP is  predominantly native born and English speaking.   ", "page_idx": 29, "bbox": [65, 92.73638916015625, 540, 217.27037048339844], "page_size": [612.0, 792.0]}
{"layout": 210, "type": "table", "page_idx": 29, "img_path": "layout_images/PI_2018.11.19_algorithms_FINAL_17.jpg", "table_caption": "The following table shows the unweighted sample sizes and the error attributable to sampling that  would be expected at the  $95\\%$   level of confidence for different groups in the survey:  ", "bbox": [65, 235, 542, 388], "page_size": [612.0, 792.0], "ocr_text": "Group\nTotal sample\n\n18-29\n30-49\n50-64\n65+\n\nUnweighted\nsample size\n\n4,594\n\n469\n1,343\n1,451\n1,326\n\nPlus or minus ...\n2.4 percentage points\n\n7.5 percentage points\n4.4 percentage points\n4.3 percentage points\n4.5 percentage points\n\n", "vlm_text": "The table provides information about sample sizes and margins of error for different age groups in a study or survey:\n\n- **Total sample**: \n  - Unweighted sample size: 4,594\n  - Margin of error: ±2.4 percentage points\n\n- **Age group 18-29**: \n  - Unweighted sample size: 469\n  - Margin of error: ±7.5 percentage points\n\n- **Age group 30-49**: \n  - Unweighted sample size: 1,343\n  - Margin of error: ±4.4 percentage points\n\n- **Age group 50-64**: \n  - Unweighted sample size: 1,451\n  - Margin of error: ±4.3 percentage points\n\n- **Age group 65+**: \n  - Unweighted sample size: 1,326\n  - Margin of error: ±4.5 percentage points"}
{"layout": 211, "type": "text", "text": "Sample sizes and sampling errors for other subgroups are available upon request.  ", "page_idx": 29, "bbox": [65, 402.62640380859375, 463.5629577636719, 415.1703796386719], "page_size": [612.0, 792.0]}
{"layout": 212, "type": "text", "text": "In addition to sampling error, one should bear in mind that question wording and practical  difficulties in conducting surveys can introduce error or bias into the findings of opinion polls.  ", "page_idx": 29, "bbox": [65, 434.6664123535156, 525, 463.1703796386719], "page_size": [612.0, 792.0]}
{"layout": 213, "type": "text", "text": "The May 2018 wave had a response rate of   $84\\,\\%$   (4,594 responses among 5,486 individuals in the  panel). Taking account of the combined, weighted response rate for the recruitment surveys   $\\left(10.0\\%\\right)$   and attrition from panel members who were removed at their request or for inactivity, the  cumulative response rate for the wave is  $2.4\\%.4$    ", "page_idx": 29, "bbox": [65, 482, 545.1690063476562, 543.2404174804688], "page_size": [612.0, 792.0]}
{"layout": 214, "type": "text", "text": " $\\copyright$   Pew Research Center, 2018  ", "page_idx": 29, "bbox": [65, 562, 214.63296508789062, 575.2803955078125], "page_size": [612.0, 792.0]}
