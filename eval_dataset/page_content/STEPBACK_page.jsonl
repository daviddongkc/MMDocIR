{"page": 0, "image_path": "doc_images/STEPBACK_0.jpg", "ocr_text": "arXiv:2310.06117v1 [cs.LG] 9 Oct 2023\n\n© Google DeepMind\n\nTAKE A STEP BACK: EVOKING REASONING VIA AB-\nSTRACTION IN LARGE LANGUAGE MODELS\n\nHuaixiu Steven Zheng* Swaroop Mishra* Xinyun Chen Heng-Tze Cheng\nEd H.Chi Quoc VLe Denny Zhou\n\nGoogle DeepMind\n\nABSTRACT\n\nWe present STEP-BACK PROMPTING, a simple prompting technique that enables\nLLMs to do abstractions to derive high-level concepts and first principles from\ninstances containing specific details. Using the concepts and principles to guide the\nreasoning steps, LLMs significantly improve their abilities in following a correct\nreasoning path towards the solution. We conduct experiments of STEP-BACK\nPROMPTING with PaLM-2L models and observe substantial performance gains on\na wide range of challenging reasoning-intensive tasks including STEM, Knowl-\nedge QA, and Multi-Hop Reasoning. For instance, STEP- BACK PROMPTING\nimproves PaLM-2L performance on MMLU Physics and Chemistry by 7% and\n11%, TimeQA by 27%, and MuSiQue by 7%.\n\nThe purpose of abstraction is not to be vague, but to create a new semantic level in which one can be\nabsolutely precise. — Edsger W. Dijkstra\n\n1 INTRODUCTION\n\nThe field of natural language processing (NLP) is witnessing a ground-breaking revolution because\nof the Transformer-based (Vaswani et al., 2017) large language models (LLMs) (Devlin et al., 2018;\nRaffel et al., 2020; Brown et al., 2020; Anil et al., 2023). Scaling up the model size and pre-training\ncorpus (Hoffmann et al., 2022; Chowdhery et al., 2022) has brought remarkable improvement in model\ncapabilities and sample efficiency with insights from the scaling law (Kaplan et al., 2020; Hoffmann\net al., 2022), as well as emergent abilities (Wei et al., 2022a) such as multi-step reasoning (Wei et al.,\n2022b; Zhou et al., 2022) and instruction following (Mishra et al., 2022b; Wei et al., 2021).\n\n= GPT-4 = PaLM-2L = PaLM-2L + CoT = PaLM-2L + Step-Back Prompting\n\n08\n\n0.\n\n0.2 i\n\n0.\nMMLU Physics MMLU Chemistry TimeQA SituatedQA MuSiQue StrategyQA\n\no\n\nz\n\nFigure 1: Strong Performance of STEP-BACK PROMPTING: our proposed Abstraction-and-Reasoning\nscheme leads to a substantial improvement in a wide range of challenging tasks in STEM, Knowledge\nQA and Multi-Hop Reasoning requiring complex (often multi-hop) reasoning.\n\n*Equal Contribution\n", "vlm_text": "T AKE A  S TEP  B ACK : E VOKING  R EASONING VIA  A B - STRACTION IN  L ARGE  L ANGUAGE  M ODELS \nHuaixiu Steven Zheng ∗ Swaroop Mishra ∗ Xinyun Chen Heng-Tze Cheng Ed H. Chi Quoc V Le Denny Zhou \nGoogle DeepMind \nA BSTRACT \nWe present S TEP -B ACK  P ROMPTING , a simple prompting technique that enables LLMs to do abstractions to derive high-level concepts and first principles from instances containing specific details. Using the concepts and principles to guide the reasoning steps, LLMs significantly improve their abilities in following a correct reasoning path towards the solution. We conduct experiments of S TEP -B ACK P ROMPTING  with PaLM-2L models and observe substantial performance gains on a wide range of challenging reasoning-intensive tasks including STEM, Knowl- edge QA, and Multi-Hop Reasoning. For instance, S TEP -B ACK  P ROMPTING improves PaLM-2L performance on MMLU Physics and Chemistry by  $7\\%$   and  $11\\%$  , TimeQA by  $27\\%$  , and MuSiQue by  $7\\%$  . \nThe purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise. — Edsger W. Dijkstra \n1 I N TRO DUCT ION \nThe field of natural language processing (NLP) is witnessing a ground-breaking revolution because of the Transformer-based (Vaswani et al., 2017) large language models (LLMs) (Devlin et al., 2018; Raffel et al., 2020; Brown et al., 2020; Anil et al., 2023). Scaling up the model size and pre-training corpus (Hoffmann et al., 2022; Chowdhery et al., 2022) has brought remarkable improvement in model capabilities and sample efficiency with insights from the scaling law (Kaplan et al., 2020; Hoffmann et al., 2022), as well as emergent abilities (Wei et al., 2022a) such as multi-step reasoning (Wei et al., 2022b; Zhou et al., 2022) and instruction following (Mishra et al., 2022b; Wei et al., 2021). \nThe image is a bar chart comparing the performance of different models across various tasks. Here’s what it shows:\n\n1. **Models Compared**:\n   - GPT-4 (blue)\n   - PaLM-2L (red)\n   - PaLM-2L + CoT (yellow)\n   - PaLM-2L + Step-Back Prompting (green)\n\n2. **Tasks Evaluated**:\n   - MMLU Physics\n   - MMLU Chemistry\n   - TimeQA\n   - SituatedQA\n   - MuSiQue\n   - StrategyQA\n\n3. **Performance Scores**:\n   - Each task features bars of different colors representing the models.\n   - The y-axis indicates performance scores, ranging from 0.0 to 1.0.\n   - The highest performance score in each task varies across different models.\n\nThe image visually demonstrates how different prompting techniques and models perform across specific evaluation tasks.\nFigure 1: Strong Performance of S TEP -B ACK  P ROMPTING : our proposed Abstraction-and-Reasoning scheme leads to a substantial improvement in a wide range of challenging tasks in STEM, Knowledge QA and Multi-Hop Reasoning requiring complex (often multi-hop) reasoning. "}
{"page": 1, "image_path": "doc_images/STEPBACK_1.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nDespite the great advancements, complex multi-step reasoning remains challenging for even the state-\nof-the-art LLMs. Lightman et al. (2023) show that process-supervision with step-by-step verification\nis a promising remedy to improve the correctness of intermediate reasoning steps. Techniques such\nas Chain-of-Thought prompting (Wei et al., 2022b) were introduced to produce a coherent series of\nintermediate reasoning steps to increase the success rate of following the right decoding path. Inspired\nby the fact that when faced with challenging tasks humans often step back and do abstractions to arrive\nat high-level concepts and principles to guide the process, we propose STEP-BACK PROMPTING to\nground reasoning on abstractions to reduce the chance of making errors in the intermediate reasoning\nsteps.\n\nStep-Back Prompting\n\nSiepback Question _} Stepback Answer}\n\nWhat are the physics Ideal gas law: PV = nRT, where P is the pressure, V\nprinciples behind this is the volume, n is the number of moles, R is the gas\nquestion? constant, and T is the temperature.\n\n...If the temperature is increased by a\nfactor of 2 and the volume is increased by\na factor of 8, we can rewrite the ideal gas\nlaw as: 2P\" (8V) = nR(2T), where P*\nrepresents the new pressure.\n\nStep 2: Reasoning\n\nSimplifying the equation, we get: 16P'V =\n2nRT or P’ = (2nRT) / (16V)\n\nStep 1: Abstaction ‘Apply Ideal gas law to find out the pressure.\nSince n, R, and V are constants, we can \\\n\nwrite this as: P' = (1/8) * (nRT/V)\n\nIf the temperature is increased by a factor of 2, then T\nbecomes 2T. If the volume is increased by a factor of 8,\nthen V becomes 8V.\n\nWhat happens to the\npressure, P, of an ideal gas if\nthe temperature is increased\nby a factor of 2 and the\nvolume is increased by a\nfactor of 8 ?\n\nSince nRT/V is the original pressure P, we\nhave: P' = (1/8) * P This means the new\n\n\\eee P' is 1/8 of the original pressure\nP..\n\nIf the temperature is increased by a factor of 2\nand the volume is increased by a factor of 8,\nthen the pressure will decrease by a factor of\n16.\n\nSubstituting these values into the ideal gas law, we get:\nP(8V) = nR(2T)\n\nDividing both sides by 8V, we get:\nP= nR(2T)/8V\n\nWe can see that the pressure has decreased by a “y)\nof 4.\n\nStep-Back Prompting\nStepback Answer}\nB.S. in Botany, University of Wisconsin, Madison, 1948 |\n\nX\n\n... After that, she pursued graduate studies\nat the University of California, Berkeley,\nearning her master's degree in 1950 and her\n\n‘Stepback Question _}\n\nWhat was Estella Leopold's\n\n‘ yas Es M.S. in Botany, University of California, Berkeley, 1950\nPh.D. in 1956, education histo yor\nConsidering this timeline, it is highly likely me Ph.D. in Botany, Yale University, 1955\nthat Estella Leopold was attending the\nUniversity of California, Berkeley, between Step 1: Abstaction Step 2: Reasoning\nAugust 1954 and November 1954... __ _\n\nx/ Original Question } Final Answer)\n\nEstella Leopold went to which\nschool between Aug 1954\nand Nov 1954?\n\nEstella Leopold attended the University of\nWisconsin-Madison between August 1954\nand November 1954 x\n\nfrom 1951 to 1955. Therefore, Estella Leopold was most\nlikely attending Yale University between August 1954 ay\n\nNovember 1954. ~)\n\nFigure 2: Illustration of STEP-BACK PROMPTING with two steps of Abstraction and Reasoning\nguided by concepts and principles. Top: an example of MMLU high-school physics (Hendrycks et al.,\n2020) where the first principle of Ideal Gas Law is retrieved via abstraction. Bottom: an example\nfrom TimeQA (Chen et al., 2021) where the high-level concept of education history is a result of the\nabstraction. Left: PaLM-2L (Anil et al., 2023) fails to answer the original question. Chain-of-Thought\nprompting (Wei et al., 2022b; Kojima et al., 2022) ran into errors during intermediate reasoning\nsteps (highlighted as red). Right: PaLM-2L (Anil et al., 2023) successfully answers the question via\nSTEP-BACK PROMPTING.\n\nShe was enrolled in the Ph.D. program in Botany at Yale |\n\nAmong many of the cognitive skills, abstraction (Lachmy et al., 2022) is ubiquitous to humans’ ability\nto process vast amount of information and derive general rules, and principles. For example, Kepler\ncompressed thousands of measurements into Kepler’s three laws of planetary motion which precisely\ndescribe the orbits of planets around the Sun (Russell, 1964). In critical decision making, humans\nfind abstraction to be helpful since it provides a broader view of the environment. This work explores\nhow LLMs can tackle complex tasks involving many low-level details through a two-step process\nof abstraction-and-reasoning. The first step is to teach LLMs to step back, and derive high-level\nabstractions such as concepts and first principles from the specific example. The second step is to\nleverage the reasoning ability to ground the solution on the high-level concepts and first principles.\nWe use few-shot exemplar demonstrations to execute STEP- BACK PROMPTING on LLMs.\n\nWe experiment across a range of tasks involving domain specific reasoning such as Physics and Chem-\nistry, knowledge-intensive question answering requiring factual knowledge, multi-hop commonsense\nreasoning. We observe significant performance improvements (up to 27%) in PaLM-2L (Anil et al.,\n", "vlm_text": "Despite the great advancements, complex multi-step reasoning remains challenging for even the state- of-the-art LLMs. Lightman et al. (2023) show that process-supervision with step-by-step verification is a promising remedy to improve the correctness of intermediate reasoning steps. Techniques such as Chain-of-Thought prompting (Wei et al., 2022b) were introduced to produce a coherent series of intermediate reasoning steps to increase the success rate of following the right decoding path. Inspired by the fact that when faced with challenging tasks humans often step back and do abstractions to arrive at high-level concepts and principles to guide the process, we propose S TEP -B ACK  P ROMPTING  to ground reasoning on abstractions to reduce the chance of making errors in the intermediate reasoning steps. \nThe image is a comparison of two problem-solving methods: Chain-of-Thought and Step-Back Prompting.\n\n1. **First Problem: Ideal Gas Law**\n   - **Chain-of-Thought**: The pressure decreases by a factor of 8, leading to an incorrect answer of decrease by a factor of 16.\n   - **Step-Back Prompting**: Breaks down using the ideal gas law (PV = nRT), correctly concludes the pressure decreases by a factor of 4.\n\n2. **Second Problem: Estella Leopold’s Education**\n   - **Chain-of-Thought**: Incorrectly states Estella attended the University of Wisconsin-Madison between August 1954 and November 1954.\n   - **Step-Back Prompting**: Provides Estella’s educational history and correctly concludes she likely attended Yale University during that period.\n\nThe image highlights how Step-Back Prompting offers a more structured and accurate approach to problem-solving compared to the Chain-of-Thought method.\nFigure 2: Illustration of S TEP -B ACK  P ROMPTING  with two steps of Abstraction and Reasoning guided by concepts and principles.  Top : an example of MMLU high-school physics (Hendrycks et al., 2020) where the first principle of Ideal Gas Law is retrieved via abstraction.  Bottom : an example from TimeQA (Chen et al., 2021) where the high-level concept of education history is a result of the abstraction.  Left : PaLM-2L (Anil et al., 2023) fails to answer the original question. Chain-of-Thought prompting (Wei et al., 2022b; Kojima et al., 2022) ran into errors during intermediate reasoning steps (highlighted as red).  Right : PaLM-2L (Anil et al., 2023) successfully answers the question via S TEP -B ACK  P ROMPTING . \nAmong many of the cognitive skills, abstraction (Lachmy et al., 2022) is ubiquitous to humans’ ability to process vast amount of information and derive general rules, and principles. For example, Kepler compressed thousands of measurements into Kepler’s three laws of planetary motion which precisely describe the orbits of planets around the Sun (Russell, 1964). In critical decision making, humans find abstraction to be helpful since it provides a broader view of the environment. This work explores how LLMs can tackle complex tasks involving many low-level details through a two-step process of abstraction-and-reasoning. The first step is to teach LLMs to step back, and derive high-level abstractions such as concepts and first principles from the specific example. The second step is to leverage the reasoning ability to ground the solution on the high-level concepts and first principles. We use few-shot exemplar demonstrations to execute S TEP -B ACK  P ROMPTING  on LLMs. \nWe experiment across a range of tasks involving domain specific reasoning such as Physics and Chem- istry, knowledge-intensive question answering requiring factual knowledge, multi-hop commonsense reasoning. We observe significant performance improvements (up to  $27\\%$  ) in PaLM-2L (Anil et al., 2023) demonstrating the efficacy of S TEP -B ACK  P ROMPTING  in tackling complex tasks which are otherwise challenging due to the amount of details involved to reason through. Figure 1 shows a summary of all the key results presented in this paper. Some the tasks are very challenging: both PaLM-2L and GPT-4 achieve only    $\\sim40\\%$   accuracy on TimeQA and MuSiQue. Chain-of-Thought prompting leads to a minor improvement on a few tasks, while S TEP -B ACK  P ROMPTING  improves the performance of PaLM-2L across the board:  $7\\%$   and    $11\\%$   on MMLU Physics and Chemistry,    $27\\%$  on TimeQA, and  $7\\%$   on MuSiQue. "}
{"page": 2, "image_path": "doc_images/STEPBACK_2.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\n2023) demonstrating the efficacy of STEP-BACK PROMPTING in tackling complex tasks which are\notherwise challenging due to the amount of details involved to reason through. Figure 1 shows a\nsummary of all the key results presented in this paper. Some the tasks are very challenging: both\nPaLM-2L and GPT-4 achieve only ~ 40% accuracy on TimeQA and MuSiQue. Chain-of-Thought\nprompting leads to a minor improvement on a few tasks, while STEP-BACK PROMPTING improves\nthe performance of PaLM-2L across the board: 7% and 11% on MMLU Physics and Chemistry, 27%\non TimeQA, and 7% on MuSiQue.\n\nWe conduct a variety of analysis and find that STEP-BACK PROMPTING has strong performance\nimprovements (up to 36%) over chain of thought (CoT) prompting (Wei et al., 2022b) and take a\ndeep breathe (TDB) prompting (Yang et al., 2023). We perform a qualitative evaluation where we\nfind that Step-Back fixes a large portion of errors of the base model (up to ~ 40%) while introducing\na small portion of new errors (max ~ 12%). We also conduct an error analysis and find that majority\nof the errors made by STEP-BACK PROMPTING is attributed to the intrinsic limitations of reasoning\ncapabilities of LLMs while abstraction skills are relatively easy to teach LLMs, pointing out the\ndirection for future improvements of methods alike STEP-BACK PROMPTING.\n\n2  STEP-BACK PROMPTING\n\nSTEP-BACK PROMPTING is motivated by the observation that many tasks contain a lot of details,\nand are hard for LLMs to retrieve relevant facts to tackle the task. As shown in the first example\n\n(top) in Figure 2, for a Physics question of “What happens to the pressure, P, of an ideal gas if the\ntemperature is increased by a factor of 2 and the volume is increased by a factor of 8 ?”, the LLM can\ndeviate from the first principle of Ideal Gas Law when reasoning directly on the question. Similarly, a\nquestion of “Estella Leopold went to which school between Aug 1954 and Nov 1954?” is very hard to\naddress directly given the detailed time range constraint. In both cases, taking a step back and asking\na step-back question helps model to solve the problem effectively.\n\nWe define a step-back question as a derived question from the original question at a higher-level of\nabstraction. For instance, instead of directly asking “which school Estella Leopold went to during a\nspecific period”, a step-back question (Figure 2 bottom) would ask about the “education history’,\nwhich is a high-level concept encompasses the original question. Answering the step-back question\nof “Estella Leopold’s education history” in this case will provide all the necessary information to\nreason about “which school Estella Leopold went to during a specific period”. The premise is that\nmore often the step-back question is much easier to address than the original question. Grounding the\nreasoning on top of such abstractions helps to avoid reasoning errors in the intermediate steps such as\nthe example shown in Figure 2 (left) from Chain-of-Thought. In short, STEP-BACK PROMPTING\nconsists two simple steps:\n\nIn the following sections, we present an empirical study of STEP-BACK PROMPTING on a range of\nchallenging tasks covering STEM, Knowledge QA and Multi-Hop Reasoning involving complex\nreasoning.\n\n3. EXPERIMENTAL SETUP\n\nHere we define the tasks and models we experiment with. We also describe our evaluation metric and\nthe baselines we consider.\n\n3.1 TASKS\n\nWe experiment with the following diverse tasks: (a) STEM, (b) Knowledge QA and (c) Multi-Hop\nReasoning. We describe below the datasets we consider (see Appendix B for more details).\n", "vlm_text": "\nWe conduct a variety of analysis and find that S TEP -B ACK  P ROMPTING  has strong performance improvements (up to  $36\\%$  ) over chain of thought (CoT) prompting (Wei et al., 2022b) and take a deep breathe (TDB) prompting (Yang et al., 2023). We perform a qualitative evaluation where we find that Step-Back fixes a large po  errors of the base model (up to  $\\sim40\\%$  ) while introducing a small portion of new errors (max  ∼  $\\sim12\\%$  ). We also conduct an error analysis and find that majority of the errors made by S TEP -B ACK ROMPTING  is attributed to the intrinsic limitations of reasoning capabilities of LLMs while abstraction skills are relatively easy to teach LLMs, pointing out the direction for future improvements of methods alike S TEP -B ACK  P ROMPTING . \n2 S TEP -B ACK  P ROMPTING \nS TEP -B ACK  P ROMPTING  is motivated by the observation that many tasks contain a lot of details, and are hard for LLMs to retrieve relevant facts to tackle the task. As shown in the first example (top) in Figure 2, for a Physics question of “ What happens to the pressure, P, of an ideal gas if the temperature is increased by a factor of 2 and the volume is increased by a factor of 8 ? ”, the LLM can deviate from the first principle of Ideal Gas Law when reasoning directly on the question. Similarly, a question of “ Estella Leopold went to which school between Aug 1954 and Nov 1954? ” is very hard to address directly given the detailed time range constraint. In both cases, taking a step back and asking a step-back question helps model to solve the problem effectively. \nWe define a step-back question as a derived question from the original question at a higher-level of abstraction. For instance, instead of directly asking “ which school Estella Leopold went to during a specific period ”, a step-back question (Figure 2 bottom) would ask about the “ education history ”, which is a high-level concept encompasses the original question. Answering the step-back question of “ Estella Leopold’s education history ” in this case will provide all the necessary information to reason about “ which school Estella Leopold went to during a specific period ”. The premise is that more often the step-back question is much easier to address than the original question. Grounding the reasoning on top of such abstractions helps to avoid reasoning errors in the intermediate steps such as the example shown in Figure 2 (left) from Chain-of-Thought. In short, S TEP -B ACK  P ROMPTING consists two simple steps: \n Abstraction : Instead of addressing the question directly, we first prompt the LLM to ask a generic step-back question about a higher-level concept or principles, and retrieve relevant facts about the high-level concept or principles.  Reasoning : Grounded on the facts regarding high-level concept or principles, the LLM can reason about the solution to the original question. We term this  Abstraction-grounded Reasoning . \nIn the following sections, we present an empirical study of S TEP -B ACK  P ROMPTING  on a range of challenging tasks covering STEM, Knowledge QA and Multi-Hop Reasoning involving complex reasoning. \n3 E X PERI MENTAL  S ETUP \nHere we define the tasks and models we experiment with. We also describe our evaluation metric and the baselines we consider. \n3.1 T ASKS \nWe experiment with the following diverse tasks: (a) STEM, (b) Knowledge QA and (c) Multi-Hop Reasoning. We describe below the datasets we consider (see Appendix B for more details). "}
{"page": 3, "image_path": "doc_images/STEPBACK_3.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\n¢ STEM: MMLU (Hendrycks et al., 2020) contains a series of benchmarks across diverse\ndomains to evaluate model’s language understanding. We consider the high school physics\nand chemistry portions of MMLU because of the deep reasoning involved.\n\n* Knowledge QA: We consider TimeQA (Chen et al., 2021) since it contains complex\nqueries that requires challenging time-sensitive knowledge. We also experiment with\nSituatedQA (Zhang & Choi, 2021), another challenging open-retrieval QA dataset requiring\nmodel to answer questions given temporal or geographical contexts.\n\n¢ Multi-Hop Reasoning: We experiment with MuSiQue (Trivedi et al., 2022), a hard multihop\nreasoning dataset created via composable pairs of single-hop questions, and StrategyQA\n(Geva et al., 2021) with open-domain questions that demands some strategy to solve.\n\n3.2 MODELS\n\nWe use the following state of the art LLMs: PaLM-2L (Anil et al., 2023) and GPT-4 (OpenAI, 2023).\nWe experiment with a variety of baselines with an instruction-tuned PaLM-2L model.\n\n3.3. EVALUATION\n\nConventional evaluation metric such as accuracy, F1 score has limitations specifically for evaluating\nthe generations of state of the art LLMs since these models often generate long form answers which\nare hard to capture. We instead conduct evaluation using the PaLM2-L model where we few-shot\nprompt the model to identify equivalence between target answers and the model predictions. Few\nshot examples, prompts and other details we use for this evaluation are in Appendix C.\n\n3.4 BASELINE METHODS\n\n¢ PaLM-2L, PaLM-2L 1-shot: PaLM-2L is either queried directly with the question or has a\nsingle demonstration exemplar of question-answer included in the prompt.\n\n¢ PaLM-2L + CoT, PaLM-2L + CoT 1-shot: PaLM-2L model is queried with zero-shot CoT\nprompting (Kojima et al., 2022): “Let’s think step by step” is appended to the question. For\n1-shot, One demonstration example of a question and answer pair is provided in the prompt,\nwhere the answer is in the style of CoT (Wei et al., 2022b) with intermediate reasoning\nsteps.\n\n¢ PaLM-2L + TDB: Zero-shot prompting with “Take a deep breath and work on this problem\nstep-by-step.” (Yang et al., 2023) prepended to the question.\n\n¢ PaLM-2L + RAG: For Sections 5 and 6, we use retrieval-augmented generation (RAG)\nwhere the relevant passage retrieved is used as context by the LLM.\n\n* GPT-4: GPT-4 API is directly queried.\n\nWe do not use RAG for MMLU, because of the inherent reasoning nature of this benchmark contrary\nto the other fact-seeking datasets. All inferences are done using greedy decoding.\n\n4 STEM\n\nWe evaluate STEP-BACK PROMPTING on STEM tasks (Hendrycks et al., 2020) to gauge the efficacy\nof our method on reasoning in highly-specialized domains. We explain below our experimental setup,\nresult and analysis of applying STEP- BACK PROMPTING on the MMLU high-school Physics and\nChemistry benchmarks.\n\n4.1 STEP-BACK PROMPTING\n\nQuestions in the MMLU benchmarks require deeper reasoning. Furthermore, they also require\nunderstanding and application of formulae which are often physics and chemistry principles and\nconcepts. In this case, we first teach the model to do abstraction in the form of concepts and first\nprinciples such as Newton’s first law of motion, Doppler effect, and Gibbs free energy etc. The implicit\nstep-back question here is “what are the physics or chemistry principles and concepts involved in\n", "vlm_text": "•  STEM : MMLU (Hendrycks et al., 2020) contains a series of benchmarks across diverse domains to evaluate model’s language understanding. We consider the high school physics and chemistry portions of MMLU because of the deep reasoning involved. •  Knowledge QA : We consider TimeQA (Chen et al., 2021) since it contains complex queries that requires challenging time-sensitive knowledge. We also experiment with SituatedQA (Zhang & Choi, 2021), another challenging open-retrieval QA dataset requiring model to answer questions given temporal or geographical contexts. •  Multi-Hop Reasoning : We experiment with MuSiQue (Trivedi et al., 2022), a hard multihop reasoning dataset created via composable pairs of single-hop questions, and StrategyQA (Geva et al., 2021) with open-domain questions that demands some strategy to solve. \n3.2 M ODELS \nWe use the following state of the art LLMs: PaLM-2L (Anil et al., 2023) and GPT-4 (OpenAI, 2023). We experiment with a variety of baselines with an instruction-tuned PaLM-2L model. \n3.3 E VALUATION \nConventional evaluation metric such as accuracy, F1 score has limitations specifically for evaluating the generations of state of the art LLMs since these models often generate long form answers which are hard to capture. We instead conduct evaluation using the PaLM2-L model where we few-shot prompt the model to identify equivalence between target answers and the model predictions. Few shot examples, prompts and other details we use for this evaluation are in Appendix C. \n3.4BASELINE METHODS\n•  PaLM-2L, PaLM-2L 1-shot : PaLM-2L is either queried directly with the question or has a single demonstration exemplar of question-answer included in the prompt. •    $\\mathbf{PaLM-}2\\mathbf{L}+\\mathbf{CoT}_{\\mathrm{i}}$  , PaLM-2L  $^+$   CoT 1-shot : PaLM-2L model is queried with zero-shot CoT prompting (Kojima et al., 2022): “ Let’s think step by step ” is appended to the question. For 1-shot, One demonstration example of a question and answer pair is provided in the prompt, where the answer is in the style of CoT (Wei et al., 2022b) with intermediate reasoning steps. •  PaLM-2L  $^+$   TDB : Zero-shot prompting with “ Take a deep breath and work on this problem step-by-step. ” (Yang et al., 2023) prepended to the question. •  PaLM  $\\mathbf{\\nabla}\\!\\cdot\\!\\mathbf{2L}+\\mathbf{RAC}$  : For Sections 5 and 6, we use retrieval-augmented generation (RAG) where the relevant passage retrieved is used as context by the LLM. •  GPT-4 : GPT-4 API is directly queried. \nWe do not use RAG for MMLU, because of the inherent reasoning nature of this benchmark contrary to the other fact-seeking datasets. All inferences are done using greedy decoding. \n4 STEM \nWe evaluate S TEP -B ACK  P ROMPTING  on STEM tasks (Hendrycks et al., 2020) to gauge the efficacy of our method on reasoning in highly-specialized domains. We explain below our experimental setup, result and analysis of applying S TEP -B ACK  P ROMPTING  on the MMLU high-school Physics and Chemistry benchmarks. \n4.1 S TEP -B ACK  P ROMPTING \nQuestions in the MMLU benchmarks require deeper reasoning. Furthermore, they also require understanding and application of formulae which are often physics and chemistry principles and concepts. In this case, we first teach the model to do abstraction in the form of concepts and first principles such as  Newton’s first law of motion ,  Doppler effect , and  Gibbs free energy  etc. The implicit step-back question here is “ what are the physics or chemistry principles and concepts involved in Table 1: Strong performance of S TEP -B ACK  P ROMPTING  on STEM tasks achieving state-of-the-art surpassing GPT-4. CoT: zero-shot Chain of Thought prompting (Kojima et al., 2022), TDB: Take a Deep Breathe prompting (Yang et al., 2023). The Table reports the average accuracy over 5 evaluation runs, with standard deviations in the parentheses. "}
{"page": 4, "image_path": "doc_images/STEPBACK_4.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nTable 1: Strong performance of STEP-BACK PROMPTING on STEM tasks achieving state-of-the-art\nsurpassing GPT-4. CoT: zero-shot Chain of Thought prompting (Kojima et al., 2022), TDB: Take a\nDeep Breathe prompting (Yang et al., 2023). The Table reports the average accuracy over 5 evaluation\nruns, with standard deviations in the parentheses.\n\nMethod | MMLU Physics | MMLU Chemistry\nPaLM-2L 66.4% (0.8%) 70.9% (0.9%)\nPaLM-2L 1-shot 64% (1.6%) 75.6% (0.4%)\nPaLM-2L + CoT 65% (2%) 75.3% (1.5%)\nPaLM-2L + CoT I-shot 61.5% (1.8%) 716.6% (1%)\nPaLM-2L + TDB 65.7% (0.7%) 73.8% (1.1%)\nPaLM-2L + Step-Back (ours) | 73.2% (1.9%) 81.8% (1.4%)\nGPT-4 | 70.3% (2.3%) | 79.9% (1.0%)\n\nsolving this task?”. We provide demonstrations to teach the model to recite from its own knowledge\nrelevant principles for solving the task (see Appendix D.1 for few-shot exemplars).\n\n4.2 RESULTS\n\nTable 1 illustrates model performance across accuracy\nvarious setup. PaLM-2L baseline performance is 9 75,\n66.4% and 70.9% on Physics and Chemistry, re- 074\n\nspectively. We find that CoT and TDB zero-shot .\n\nprompting do not significantly increase model 078 ON\nperformance which could be due to inherent °”2\nhardness and deep reasoning associated with °71\nthese tasks. In addition PaLM-2L 1-shot and 0.70\nPaLM-2L + CoT 1-shot do not improve against\n\nthe baseline much, highlighting the challenge of\ndemonstrating the reasoning steps to the model.\n\nIn contrast, STEP-BACK PROMPTING signifi- _ ;\ncantly improves model performance: +7% and Figure 3: Ablation study of STEP-BACK PROMPT-\n+11% compared to PaLM-2L, achieving state- ING accuracy on MMLU high-school Physics\n\nof-the-art performance surpassing GPT-4. against number of few shot exemplars: robust per-\nformance with respect to varying number of shots.\n\n1 2 3 4 5\n\nNumber of Shots\n\n4.3 ABLATION AND ANALYSIS\n\nFew-shot Ablation: First, in Figure 3 we ob-\n\nserve that STEP-BACK PROMPTING is robust against number of few-shot exemplars of (question,\nprinciples) pairs used as demonstrations. Adding more demonstration examples beyond a single\nexample is not helpful any more. This indicates that the task of retrieving the relevant principles and\nconcepts is relatively easy to learn and a single demonstration suffices.\n\nError Analysis: Figure 4 (left) shows the error analysis of the predictions of STEP-BACK PROMPT-\nING compared to the baseline PaLM-2L model for MMLU high-school Physics: STEP-BACK\nPROMPTING corrects 20.5% errors from the baseline while introducing 11.9% errors.\n\nTo further understand where the errors come from in STEP-BACK PROMPTING, we annotate all the\nwrong predictions of STEP-BACK PROMPTING in the test set, and category them into 5 classes (see\nAppendix E.1 for examples in each class):\n\n¢ Principle Error: The error happens at the step of Abstraction, where the first principles generated\nby models are wrong or incomplete.\n¢ Factual Error: There is at least one factual error when the model recites its own factual knowledge.\n\n¢ Math Error: There is at least one math error in the intermediate steps when math calculations are\ninvolved in deriving the final answer.\n", "vlm_text": "\nThe table presents performance metrics for different methods on two datasets: MMLU Physics and MMLU Chemistry. The methods include variations of PaLM-2L and GPT-4. Here's a breakdown:\n\n### Methods:\n1. **PaLM-2L**\n2. **PaLM-2L 1-shot**\n3. **PaLM-2L + CoT**\n4. **PaLM-2L + CoT 1-shot**\n5. **PaLM-2L + TDB**\n6. **PaLM-2L + Step-Back (ours)**\n7. **GPT-4**\n\n### Performance:\n- The performance is given in percentages, representing accuracy, with a percentage in parentheses indicating some measure of variance or error (possibly standard deviation).\n\n#### MMLU Physics:\n- **PaLM-2L**: 66.4% (0.8%)\n- **PaLM-2L 1-shot**: 64% (1.6%)\n- **PaLM-2L + CoT**: 65% (2%)\n- **PaLM-2L + CoT 1-shot**: 61.5% (1.8%)\n- **PaLM-2L + TDB**: 65.7% (0.7%)\n- **PaLM-2L + Step-Back (ours)**: 73.2% (1.9%)\n- **GPT-4**: 70.3% (2.3%)\n\n#### MMLU Chemistry:\n- **PaLM-2L**: 70.9% (0.9%)\n- **PaLM-2L 1-shot**: 75.6% (0.4%)\n- **PaLM-2L + CoT**: 75.3% (1.5%)\n- **PaLM-2L + CoT 1-shot**: 76.6% (1%)\n- **PaLM-2L + TDB**: 73.8% (1.1%)\n- **PaLM-2L + Step-Back (ours)**: 81.8% (1.4%)\n- **GPT-4**: 79.9% (1.0%)\n\n#### Observations:\n- **PaLM-2L + Step-Back (ours)** method shows the highest performance on both datasets.\n- **GPT-4** performs well, especially on MMLU Chemistry.\nsolving this task? ”. We provide demonstrations to teach the model to recite from its own knowledge relevant principles for solving the task (see Appendix D.1 for few-shot exemplars). \n4.2 R ESULTS \nTable 1 illustrates model performance across various setup. PaLM-2L baseline performance is  $66.4\\%$   and  $70.9\\%$   on Physics and Chemistry, re- spectively. We find that CoT and TDB zero-shot prompting do not significantly increase model performance which could be due to inherent hardness and deep reasoning associated with these tasks. In addition PaLM-2L 1-shot and PaLM-  $2\\mathrm{L}+\\mathrm{CoT}$  1-shot do not improve against the baseline much, highlighting the challenge of demonstrating the reasoning steps to the model. In contrast, S TEP -B ACK  P ROMPTING  signifi- cantly improves model performance:  $+7\\%$   and  $+11\\%$   compared to PaLM-2L, achieving state- of-the-art performance surpassing GPT-4. \nThe image is a line graph titled \"Accuracy.\" The x-axis is labeled with numbers from 1 to 5, which are described in the caption as the \"Number of Shots.\" The y-axis ranges from 0.70 to 0.75. The line connects five data points, showing fluctuations in accuracy across the five shots. The peak accuracy occurs at the third shot, while the lowest is on the fourth shot.\n4.3 A BLATION AND  A NALYSIS \nFew-shot Ablation : First, in Figure 3 we ob- serve that S TEP -B ACK  P ROMPTING  is robust against number of few-shot exemplars of (question, principles) pairs used as demonstrations. Adding more demonstration examples beyond a single example is not helpful any more. This indicates that the task of retrieving the relevant principles and concepts is relatively easy to learn and a single demonstration suffices. \nError Analysis : Figure 4 (left) shows the error analysis of the predictions of S TEP -B ACK  P ROMPT - ING  compared to the baseline PaLM-2L model for MMLU high-school Physics: S TEP -B ACK P ROMPTING  corrects  $20.5\\%$   errors from the baseline while introducing  $11.9\\%$   errors. \nTo further understand where the errors come from in S TEP -B ACK  P ROMPTING , we annotate all the wrong predictions of S TEP -B ACK  P ROMPTING  in the test set, and category them into 5 classes (see Appendix E.1 for examples in each class):\n\n \n•  Principle Error : The error happens at the step of Abstraction, where the first principles generated by models are wrong or incomplete.\n\n •  Factual Error : There is at least one factual error when the model recites its own factual knowledge.\n\n •  Math Error : There is at least one math error in the intermediate steps when math calculations are involved in deriving the final answer. "}
{"page": 5, "image_path": "doc_images/STEPBACK_5.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nTable 2: Strong performance of STEP-BACK PROMPTING on Knowledge QA tasks. CoT: Chain of\nThought prompting, TDB: Take a Deep Breathe prompting, RAG: retrieval-augmented generation.\n\nSTEP-BACK PROMPTING results in significant performance improvements.\n\nMethod TimeQA | TQA Easy TQA Hard SituatedQA\nPaLM-2L 41.5% 42.6% 40.4% 54.3% (0.3%)\nPaLM-2L 1-shot 40.7% 41.7% 39.1% 51.8% (0.6%)\nPaLM-2L + CoT 40.8% 41.8% 39.8% 56.4% (0.2%)\nPaLM-2L + CoT 1-shot 38.1% 39.3% 36.8% 54% (0.8%)\nPaLM-2L + TDB 40.9% 42.6% 39.1% 54% (0.5%)\nPaLM-2L + RAG 57.4% 67.8% 46.8% 59.3% (0.4%)\nPaLM-2L + Step-Back (ours) 66% 10.4% 61.6% 57.5% (0.3%)\nPaLM-2L + Step-Back + RAG (ours) | 68.7% 75.2% 62.3% 61% (0.4%)\nGPT-4 45.6% 48.9% 42.6% 63.2% (0.4%)\n\n* Context Loss: There is at least one error when the model response loses context from the question,\nand deviates from addressing the original question.\n\n¢ Reasoning Error: We define Reasoning Error as when the model makes error in the intermediate\nReasoning steps before arriving at the final answer.\n\nAll five types of errors are happening during the Reasoning step except Principle Error which points\nto the failure of the Abstraction step. As shown in Figure 4 (right), Principle Error in fact comprises\nonly a small fraction of the errors the model makes: more than 90% of the errors happen at the\nReasoning step. Among the four error types during Reasoning, Reasoning Error and Math Error are\nthe major loss buckets. This corroborates with the finding in the ablation study above that very few\nexemplars are needed to teach LLMs the Abstraction skill. Reasoning step is still the bottleneck of\nhow well STEP-BACK PROMPTING can perform tasks such as MMLU requiring complex reasoning.\nFor MMLU Physics specifically, the Reasoning and Math skills are critical for solving the problems\nsuccessfully: even if the first principles are retrieved correctly, deep reasoning and math are involved\nto derive a correct final answer through a typical multi-step reasoning process.\n\nStep-Back Wrong\n\n1 0.6\nBoth Wrong\n0.4\nBaseline Wron\n0.2 0.25\n0.04\noo | 0.09 |\nro oh oe ro ro\nBoth Right a are wo 0\" ge\n7 io w SS . ao\n€ oe aK\n\nFigure 4: Error Analysis of STEP-BACK PROMPTING on MMLU high-school Physics. Left: example\ncategories in four buckets regarding whether the baseline or Step-Back prediction is right or wrong.\nRight: five classes of errors Step-Back makes with Reasoning being the dominating class.\n\n5 KNOWLEDGE QA\n\nWe evaluate STEP-BACK PROMPTING on question answering benchmarks requiring intensive factual\nknowledge. Knowledge QA has been challenging for LLMs. In this section, we first describe the\nexperimental setup, followed by results and analysis on STEP-BACK PROMPTING.\n", "vlm_text": "Table 2: Strong performance of S TEP -B ACK  P ROMPTING  on Knowledge QA tasks. CoT: Chain of Thought prompting, TDB: Take a Deep Breathe prompting, RAG: retrieval-augmented generation. S TEP -B ACK  P ROMPTING  results in significant performance improvements.\n\n \nThe table shows the performance of different methods on four benchmarks: TimeQA, TQA Easy, TQA Hard, and SituatedQA. Here's a breakdown:\n\n- **Methods**: Various combinations of the PaLM-2L model with different approaches, such as 1-shot learning, CoT (Chain of Thought), TDB, RAG, and Step-Back, compared to GPT-4.\n- **Columns**: Each method's performance is measured in percentages for each benchmark.\n  - **TimeQA**: \n    - Highest: PaLM-2L + Step-Back + RAG (68.7%)\n  - **TQA Easy**: \n    - Highest: PaLM-2L + Step-Back + RAG (75.2%)\n  - **TQA Hard**: \n    - Highest: PaLM-2L + Step-Back (61.6%)\n  - **SituatedQA**: \n    - Highest: GPT-4 (63.2% with a variation of 0.4%)\n\nThe values in parentheses represent variation percentages for SituatedQA.\n•  Context Loss : There is at least one error when the model response loses context from the question, and deviates from addressing the original question.\n\n •  Reasoning Error : We define Reasoning Error as when the model makes error in the intermediate Reasoning steps before arriving at the final answer. \nAll five types of errors are happening during the Reasoning step except  Principle Error  which points to the failure of the Abstraction step. As shown in Figure 4 (right),  Principle Error  in fact comprises only a small fraction of the errors the model makes: more than  $90\\%$   of the errors happen at the Reasoning step. Among the four error types during Reasoning,  Reasoning Error  and  Math Error  are the major loss buckets. This corroborates with the finding in the ablation study above that very few exemplars are needed to teach LLMs the Abstraction skill. Reasoning step is still the bottleneck of how well S TEP -B ACK  P ROMPTING  can perform tasks such as MMLU requiring complex reasoning. For MMLU Physics specifically, the Reasoning and Math skills are critical for solving the problems successfully: even if the first principles are retrieved correctly, deep reasoning and math are involved to derive a correct final answer through a typical multi-step reasoning process. \nThe image contains two main parts related to error analysis in high-school physics using Step-Back Prompting on the MMLU dataset:\n\n1. **Left: Pie Chart** - This chart shows the distribution of prediction outcomes in four categories:\n   - Both Right: 40.4%\n   - Baseline Wrong: 20.5%\n   - Step-Back Wrong: 11.9%\n   - Both Wrong: 27.2%\n\n2. **Right: Bar Chart** - This chart highlights five classes of errors made by the Step-Back model:\n   - Factual Error: 0.04\n   - Math Error: 0.25\n   - Context Loss: 0.07\n   - Reasoning Error: 0.55 (dominating class)\n   - Principle Error: 0.09\n\nThe analysis suggests that reasoning errors are most frequent when using Step-Back Prompting.\n5 K NOWLEDGE  QA \nWe evaluate S TEP -B ACK  P ROMPTING  on question answering benchmarks requiring intensive factual knowledge. Knowledge QA has been challenging for LLMs. In this section, we first describe the experimental setup, followed by results and analysis on S TEP -B ACK  P ROMPTING . "}
{"page": 6, "image_path": "doc_images/STEPBACK_6.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\n5.1 STEP-BACK PROMPTING\n\nWe evaluate STEP-BACK PROMPTING on TimeQA (Chen et al., 2021) and SituatedQA (Zhang &\nChoi, 2021) in the Knowledge QA category. We first teach the LLMs to do Abstraction. The step-back\nquestion “What was Estella Leopold’s education history” in Figure 2 is generated by the LLM through\nfew-shot demonstrations (see Appendix D.2 for details). Given the knowledge-intensive nature of\nthese queries, we use retrieval augmentation (RAG) in combination with STEP-BACK PROMPTING.\nThe step-back question is used to retrieve relevant facts, which works as additional context (see\nTable 12 for the prompting template) to ground the final reasoning step.\n\n5.2 RESULTS\n\nWe evaluate the models on the test-set of TimeQA. As shown in Table 2, the baseline models of\nGPT-4 and PaLM-2L achieved 45.6% and 41.5%, highlighting the difficulty of the task. Applying\neither CoT or TDB zero-shot (and one-shot) prompting to the baseline model shows no improvement.\nIn contrast, augmenting the baseline model by regular retrieval augmentation (RAG) improves the\naccuracy to 57.4%, highlighting the factual intensive nature of the task. The result of Step-Back\n+ RAG shows the effectiveness of going back to a high-level concept, which enables much more\nreliable retrieval augmentation: the accuracy on TimeQA achieves a remarkable 68.7%.\n\nNext, we segment TimeQA into the Easy and Hard difficulty level provided in the original dataset.\nAs expected, all methods perform worse on the Hard segment. While RAG can improve the Easy\naccuracy from 42.6% to 67.8%, the improvement is much smaller on the Hard accuracy: 40.4% to\n46.8%. This is where STEP-BACK PROMPTING really shines by retrieving facts regarding high-level\nconcepts to ground the final reasoning: Step-Back + RAG further improves the Hard accuracy to\n62.3%, outperforming 42.6% from GPT-4. We hypothesis that facts regarding the high-level concepts\n(such as education history) is much more accessible than the low-level details.\n\nOn the SituatedQA benchmark, we observe a moderate quality gain from 54.3% to our best method\nof Step-Back + RAG 61% with a small gap to GPT-4’s 63.2%. Similar to TimeQA, prompting\ntechniques such as CoT and TDB don’t help significantly for SituatedQA.\n\nAccuracy 06\ne@ All « Easy * Hard\n0.80 0.52\n0.75 = + “ ss + 04 0.45\n0.70 5 . = —° °\n0.65 =\n0.60 t — oe\n0.55\n1 2 3 4 5 0.02 0.01\nNumber of Shots 0.0 —— —\n\nReasoning Error Scoring Error RAG StepBack\n\nFigure 5: Ablation and error analysis of STEP-BACK PROMPTING on TimeQA. Left: ablation against\nnumber of few-shot exemplars. Right: four classes of errors Step-Back makes with Reasoning and\nRAG being the dominating error sources.\n\n5.3. ABLATION AND ANALYSIS\n\nFew-shot Ablation: We observe in Figure 5 (left) that the performance of STEP-BACK PROMPTING\nis robust against the number of exemplars used in demonstration, highlighting again the sample\nefficiency of learning Abstraction skills for models like PaLM-2L.\n\nError Analysis: Figure 5 (right) shows the breakdown of the all the remaining errors made by\nSTEP-BACK PROMPTING predictions. Similar to Section 4.3, we categorize the errors:\n\n¢ StepBack: The step-back question generated is not helpful in solving the task.\n\n¢ RAG: RAG fails to retrieval relevant information despite that the step-back question is on target.\n¢ Scoring Error: The evaluation by the judge model made a mistake.\n", "vlm_text": "5.1 S TEP -B ACK  P ROMPTING \nWe evaluate S TEP -B ACK  P ROMPTING  on TimeQA (Chen et al., 2021) and SituatedQA (Zhang & Choi, 2021) in the Knowledge QA category. We first teach the LLMs to do Abstraction. The step-back question “ What was Estella Leopold’s education history ” in Figure 2 is generated by the LLM through few-shot demonstrations (see Appendix D.2 for details). Given the knowledge-intensive nature of these queries, we use retrieval augmentation (RAG) in combination with S TEP -B ACK  P ROMPTING . The step-back question is used to retrieve relevant facts, which works as additional context (see Table 12 for the prompting template) to ground the final reasoning step. \n5.2 R ESULTS \nWe evaluate the models on the test-set of TimeQA. As shown in Table 2, the baseline models of GPT-4 and PaLM-2L achieved    $45.6\\%$   and  $41.5\\%$  , highlighting the difficulty of the task. Applying either CoT or TDB zero-shot (and one-shot) prompting to the baseline model shows no improvement. In contrast, augmenting the baseline model by regular retrieval augmentation (RAG) improves the accuracy to  $57.4\\%$  , highlighting the factual intensive nature of the task. The result of Step-Back  $+\\;\\mathbf{R}\\mathbf{A}\\mathbf{G}$   shows the effectiveness of going back to a high-level concept, which enables much more reliable retrieval augmentation: the accuracy on TimeQA achieves a remarkable  $68.7\\%$  . \nNext, we segment TimeQA into the Easy and Hard difficulty level provided in the original dataset. As expected, all methods perform worse on the Hard segment. While RAG can improve the Easy accuracy from  $42.6\\%$   to  $67.8\\%$  , the improvement is much smaller on the Hard accuracy:  $40.4\\%$   to  $46.8\\%$  . This is where S TEP -B ACK  P ROMPTING  really shines by retrieving facts regarding high-level concepts to ground the final reasoning: Step-Back  $^+$   RAG further improves the Hard accuracy to\n\n  $62.3\\%$  , outperforming  $42.6\\%$   from GPT-4. We hypothesis that facts regarding the high-level concepts\n\n (such as  education history ) is much more accessible than the low-level details. \nOn the SituatedQA benchmark, we observe a moderate quality gain from    $54.3\\%$   to our best method of Step-Back  $^+$   RAG    $61\\%$   with a small gap to GPT-4’s    $63.{\\dot{2}}{\\bar{\\%}}$  . Similar to TimeQA, prompting techniques such as CoT and TDB don’t help significantly for SituatedQA. \nThe image consists of two charts:\n\n1. **Line Chart (Left):**\n   - Displays accuracy against the number of shots.\n   - Three categories are shown: All (blue circles), Easy (red triangles), and Hard (yellow stars).\n   - Accuracy remains relatively stable across 1 to 5 shots.\n   - Easy tasks have higher accuracy compared to All and Hard tasks.\n\n2. **Bar Chart (Right):**\n   - Compares different types of errors or methods labeled as Reasoning Error, Scoring Error, RAG, and StepBack.\n   - The values are: Reasoning Error (0.52), Scoring Error (0.02), RAG (0.45), and StepBack (0.01).\n   - Reasoning Error and RAG have higher values compared to Scoring Error and StepBack.\nFigure 5: Ablation and error analysis of S TEP -B ACK  P ROMPTING  on TimeQA.  Left : ablation against number of few-shot exemplars.  Right : four classes of errors Step-Back makes with Reasoning and RAG being the dominating error sources. \n5.3 A BLATION AND  A NALYSIS \nFew-shot Ablation : We observe in Figure 5 (left) that the performance of S TEP -B ACK  P ROMPTING is robust against the number of exemplars used in demonstration, highlighting again the sample efficiency of learning Abstraction skills for models like PaLM-2L. \nError Analysis:  Figure 5 (right) shows the breakdown of the all the remaining errors made by S TEP -B ACK  P ROMPTING  predictions. Similar to Section 4.3, we categorize the errors:\n\n \n•  StepBack : The step-back question generated is not helpful in solving the task.\n\n •  RAG : RAG fails to retrieval relevant information despite that the step-back question is on target.\n\n •  Scoring Error : The evaluation by the judge model made a mistake. "}
{"page": 7, "image_path": "doc_images/STEPBACK_7.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nTable 3: Results of STEP-BACK PROMPTING on Multi-Hop Reasoning. CoT: Chain of Thought\nprompting, TDB: Take a Deep Breathe prompting, RAG: retrieval augmentation generation. Average\n\naccuracy is over 5 evaluation runs with the standard deviations included in the parentheses.\nMethod MuSiQue StrategyQA\nPaLM-2L 35.5% (3%) | 82.8% (0.7%)\nPaLM-2L 1-shot 29.0% (0.5%) | 76.6% (0.5%)\nPaLM-2L + CoT 38.7% (3.2%) | 83.6% (0.4%)\nPaLM-2L + CoT 1-shot 38.5% (2.2%) | 76.8% (1.4%)\nPaLM-2L + TDB 39.0% (2.3%) | 82.7% (0.9%)\nPaLM-2L + RAG 39.6% (2.8%) | 84.2% (0.5%)\nPaLM-2L + Step-Back (ours) 42.6% (3.1%) | 82.7% (0.4%)\nPaLM-2L + Step-Back + RAG (ours) | 42.8% (2.0%) | 86.4% (1%)\nGPT-4 38.5% (0.2%) | 78.3% (1.1%)\n\n¢ Reasoning Error: The retrieved context is relevant, but the model still fails to reason through the\n\ncontext to arrive at the right answer.\n\nStepBack rarely fails. In contrast, we find more than half of the errors are due to reasoning errors.\n45% of errors are due to failure in retrieving the right information despite that Abstraction provided\nby step-back makes it a much easier task. This reflects the difficulty level of the TimeQA task.\nAdditional error analysis of TimeQA is in Appendix A.\n\n6 MULTI-HOP REASONING\n\nWe evaluate STEP-BACK PROMPTING on challenging Multi-Hop reasoning benchmark MuSiQue\n(Trivedi et al., 2022) and StrategyQA (Geva et al., 2021). We follow the same protocol as Section 5\nto implement STEP- BACK PROMPTING.\n\n6.1 RESULTS\n\nTable 3 shows performance of various baselines on the dev set of MuSiQue and StrategyQA. Baseline\nperformance of PaLM-2L and GPT4 are low (35.5% and 38.5% for PaLM-2L and GPT-4 respectively)\nin MuSiQue since it is a hard multihop reasoning behchmark. In contrast, StartegyQA has stronger\nbaselines (82.8% and 78.3% for PaLM-2L and GPT4 respectively) probably because of the binary\nclassification task. CoT and TDB improve model performance a bit in case of MuSiQue (~ 3% and\n3.5% respectively) which can be attributed to the inherent reasoning nature of this task where these\nmethods are shown to be helpful. In case of StrategyQA, there is no signficant performance gain with\nCOT and TDB which could be due to the high baseline performance in this task, with limited scope\nfor these prompting methods to improve performance. Often, 1-shot performance is significantly\nlower than their zero-shot methods which could be attributed to the potential example bias (Zhao\net al., 2021; Parmar et al., 2023). RAG improves model performance (~ 4% and 2% for MuSiQue\nand StrategyQA respectively.). STEP-BACK PROMPTING with the power of abstraction produces\nthe best performance of all methods: 42.8% in MuSiQue and 86.4% in StrategyQA, significantly\noutperforming GPT-4 on both tasks.\n\n6.2 ANALYSIS\n\nSimilar to our observation in previous sections, we find that STEP-BACK PROMPTING with RAG is\nable to turn 15.4% wrong predictions of base model into correct predictions, while leading to 6.1%\nerrors the other way around. Furthermore, Step-Back + RAG fixes 12.7% errors coming from RAG.\nThe errors introduced to RAG by Step-Back is just 4.4%. More detailed analysis is in Appendix A.2.\n", "vlm_text": "Table 3: Results of S TEP -B ACK  P ROMPTING  on Multi-Hop Reasoning. CoT: Chain of Thought prompting, TDB: Take a Deep Breathe prompting, RAG: retrieval augmentation generation. Average accuracy is over 5 evaluation runs with the standard deviations included in the parentheses. \nThe table compares different methods and their performance on two datasets, MuSiQue and StrategyQA. The methods evaluated include variations of PaLM-2L with different techniques and GPT-4. \n\nEach method's performance is presented as a percentage with a margin of error in parentheses. The methods evaluated are:\n\n- PaLM-2L\n- PaLM-2L 1-shot\n- PaLM-2L + CoT\n- PaLM-2L + CoT 1-shot\n- PaLM-2L + TDB\n- PaLM-2L + RAG\n- PaLM-2L + Step-Back (ours)\n- PaLM-2L + Step-Back + RAG (ours)\n- GPT-4\n\nThe highest performance for each dataset is bolded:\n\n- **MuSiQue:** PaLM-2L + Step-Back + RAG (ours) at **42.8% (2.0%)**\n- **StrategyQA:** PaLM-2L + Step-Back + RAG (ours) at **86.4% (1%)**\n•  Reasoning Error : The retrieved context is relevant, but the model still fails to reason through the context to arrive at the right answer. \nStepBack rarely fails. In contrast, we find more than half of the errors are due to reasoning errors.  $45\\%$   of errors are due to failure in retrieving the right information despite that Abstraction provided by step-back makes it a much easier task. This reflects the difficulty level of the TimeQA task. Additional error analysis of TimeQA is in Appendix A. \n6 M ULTI -H OP  R EASONING \nWe evaluate S TEP -B ACK  P ROMPTING  on challenging Multi-Hop reasoning benchmark MuSiQue (Trivedi et al., 2022) and StrategyQA (Geva et al., 2021). We follow the same protocol as Section 5 to implement S TEP -B ACK  P ROMPTING . \n6.1 R ESULTS \nTable 3 shows performance of various baselines on the dev set of MuSiQue and StrategyQA. Baseline performance of PaLM-2L and GPT4 are low   $(35.5\\%$   and  $38.5\\%$   for PaLM-2L and GPT-4 respectively) in MuSiQue since it is a hard multihop reasoning behchmark. In contrast, StartegyQA has stronger baselines   $(82.8\\%$   and  $78.3\\%$   for PaLM-2L and GPT4 respectively) probably because of the binary fication task. CoT and TDB improve model performance a bit in case of MuSiQue (  $\\sim3\\%$   and 3.5% respectively) which can be attributed to the inherent reasoning nature of this task where these methods are shown to be helpful. In case of StrategyQA, there is no signficant performance gain with COT and TDB which could be due to the high baseline performance in this task, with limited scope for these prompting methods to improve performance. Often, 1-shot performance is significantly lower than their zero-shot methods which could be attributed to the potential example bias (Zhao et al., 2021; Parmar et al., 2023). RAG improves model performance (  $\\sim4\\%$   and  $2\\%$   for MuSiQue and StrategyQA respectively.). S TEP -B ACK  P ROMPTING  with the power of abstraction produces the best performance of all methods:    $42.8\\%$   in MuSiQue and    $86.4\\%$   in StrategyQA, significantly outperforming GPT-4 on both tasks. \n6.2 A NALYSIS \nSimilar to our observation in previous sections, we find that S TEP -B ACK  P ROMPTING  with RAG is able to turn    $15.4\\%$   wrong predictions of base model into correct predictions, while leading to  $6.1\\%$  errors the other way around. Furthermore, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   fixes  $12.7\\%$   errors coming from RAG. The errors introduced to RAG by Step-Back is just    $4.4\\%$  . More detailed analysis is in Appendix A.2. "}
{"page": 8, "image_path": "doc_images/STEPBACK_8.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\n7 DISCUSSION\n\nAbstraction helps humans to solve complex tasks by removing irrelevant details and distill the high-\nlevel concepts and principles to guide the problem-solving process. STEP-BACK PROMPTING breaks\ncomplex tasks such as knowledge-intensive QA, multi-hop reasoning and science questions into two\nseparate steps of Abstraction and Reasoning. We demonstrate through empirical experiments that\nAbstraction is an easy skill to teach the LLMs such as PaLM-2L via sample-efficient demonstrations.\nGrounding on the high-level concepts and principles, LLMs can leverage their intrinsic Reasoning\ncapabilities to derive the solution. This reduces the chance of reasoning failures in the intermediate\nsteps, and is shown to improve the performance on a wide range of complex reasoning tasks. Despite\nthe success, through error analysis, we find that Reasoning is still one of the hardest skills for LLMs\nto acquire as it is still the dominating failure mode even after the large chunk of task complexity\nreduction by STEP-BACK PROMPTING.\n\nNevertheless, Abstraction is neither absolutely necessary nor possible in all scenarios. For instance,\nthe task can be as simple as who was the president of the United States in 2000?, in which case\nthere is not such a need to step back and ask a high-level question as the answer to such questions is\nreadily available. Parallelly, questions such as what is the speed of light? point to the first principles\nthemselves. Doing Abstraction in this case would not make a difference.\n\n8 RELATED WORK\n\nSTEP-BACK PROMPTING is related to the literature of prompting and decomposition.\n\n8.1 PROMPTING\n\nFew-shot prompting (Brown et al., 2020; Liu et al., 2023; Mishra et al., 2022a; Wei et al., 2022b)\nhas significantly improved model performance across a range of tasks without requiring to update\nany model parameters. Our work STEP-BACK PROMPTING is in the same category as chain of\nthought prompting (Wei et al., 2022b) and scratchpad (Nye et al., 2021) owing to its simplicity and\ngeneric nature, however, is focused on the key idea of abstraction which is inspired from the fact\nthat often taking a step back and looking at broader level help humans in performing complex tasks.\nOur work is also related to the recitation-augmented language models (Sun et al., 2022), however in\ncontrast to their work, we explicitly perform step-back and abstraction, with optional use of retrieval\naugmentation depending the nature of the task at hand.\n\n8.2 DECOMPOSITION\n\nDecomposing a task into simpler tasks and solving these tasks to solve the original task have been an\neffective way (Zhou et al., 2022; Patel et al., 2022; Khot et al., 2022; Press et al., 2022) to improve\nmodel performance on complex tasks. Several prompting methods have been successful in improving\nmodel performance. Our work STEP-BACK PROMPTING, in contrast, is on making the question more\nabstract and high level, which is different from decomposition that is often low level breakdowns\nof the original question. Furthermore, abstract questions such as what is the employment history of\nperson X? are often generic in nature so have a many-to-one mapping since many questions (e.g.\nwhich employer did X work for in 1990? and which employer did X work for in 2000?) can have the\nsame abstract questions. This is in contrast to decomposition where there is often a one-to-many\nmapping since there are multiple decomposed sub-problems necessary to solve a given question.\n\n9 CONCLUSION\n\nWe introduce STEP-BACK PROMPTING as a simple and generic method to elicit deep reasoning via\nabstraction in large language models. Experimentation on LLMs across fact-seeking, commonsense\nreasoning and domain specific reasoning benchmark shows STEP-BACK PROMPTING significantly\nimprove model performance. We hypothesize that abstraction helps models to hallucinate less and\nreason better, probably reflecting the true nature of the model which are often hidden while responding\nto the original question without abstraction. We hope our work will inspire more human-inspired\napproaches to elicit the hidden potential of large language models.\n", "vlm_text": "7 D ISCUSSION \nAbstraction helps humans to solve complex tasks by removing irrelevant details and distill the high- level concepts and principles to guide the problem-solving process. S TEP -B ACK  P ROMPTING  breaks complex tasks such as knowledge-intensive QA, multi-hop reasoning and science questions into two separate steps of Abstraction and Reasoning. We demonstrate through empirical experiments that Abstraction is an easy skill to teach the LLMs such as PaLM-2L via sample-efficient demonstrations. Grounding on the high-level concepts and principles, LLMs can leverage their intrinsic Reasoning capabilities to derive the solution. This reduces the chance of reasoning failures in the intermediate steps, and is shown to improve the performance on a wide range of complex reasoning tasks. Despite the success, through error analysis, we find that Reasoning is still one of the hardest skills for LLMs to acquire as it is still the dominating failure mode even after the large chunk of task complexity reduction by S TEP -B ACK  P ROMPTING . \nNevertheless, Abstraction is neither absolutely necessary nor possible in all scenarios. For instance, the task can be as simple as  who was the president of the United States in 2000? , in which case there is not such a need to step back and ask a high-level question as the answer to such questions is readily available. Parallelly, questions such as  what is the speed of light?  point to the first principles themselves. Doing Abstraction in this case would not make a difference. \n8 R ELATED  W ORK \nS TEP -B ACK  P ROMPTING  is related to the literature of prompting and decomposition. \n8.1 P ROMPTING \nFew-shot prompting (Brown et al., 2020; Liu et al., 2023; Mishra et al., 2022a; Wei et al., 2022b) has significantly improved model performance across a range of tasks without requiring to update any model parameters. Our work S TEP -B ACK  P ROMPTING  is in the same category as chain of thought prompting (Wei et al., 2022b) and scratchpad (Nye et al., 2021) owing to its simplicity and generic nature, however, is focused on the key idea of abstraction which is inspired from the fact that often taking a step back and looking at broader level help humans in performing complex tasks. Our work is also related to the recitation-augmented language models (Sun et al., 2022), however in contrast to their work, we explicitly perform step-back and abstraction, with optional use of retrieval augmentation depending the nature of the task at hand. \n8.2 D E COMPOSITION \nDecomposing a task into simpler tasks and solving these tasks to solve the original task have been an effective way (Zhou et al., 2022; Patel et al., 2022; Khot et al., 2022; Press et al., 2022) to improve model performance on complex tasks. Several prompting methods have been successful in improving model performance. Our work S TEP -B ACK  P ROMPTING , in contrast, is on making the question more abstract and high level, which is different from decomposition that is often low level breakdowns of the original question. Furthermore, abstract questions such as  what is the employment history of person   $X?$   are often generic in nature so have a many-to-one mapping since many questions (e.g. which employer did X work for in 1990?  and  which employer did X work for in 2000? ) can have the same abstract questions. This is in contrast to decomposition where there is often a one-to-many mapping since there are multiple decomposed sub-problems necessary to solve a given question. \n9 C ONCLUSION \nWe introduce S TEP -B ACK  P ROMPTING  as a simple and generic method to elicit deep reasoning via abstraction in large language models. Experimentation on LLMs across fact-seeking, commonsense reasoning and domain specific reasoning benchmark shows S TEP -B ACK  P ROMPTING  significantly improve model performance. We hypothesize that abstraction helps models to hallucinate less and reason better, probably reflecting the true nature of the model which are often hidden while responding to the original question without abstraction. We hope our work will inspire more human-inspired approaches to elicit the hidden potential of large language models. "}
{"page": 9, "image_path": "doc_images/STEPBACK_9.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nREFERENCES\n\nRohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos,\nSiamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report. arXiv\npreprint arXiv:2305.10403, 2023.\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\nfew-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\nWenhu Chen, Xinyi Wang, and William Yang Wang. A dataset for answering time-sensitive questions.\narXiv preprint arXiv:2108.06314, 2021.\n\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:\nScaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep\nbidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\n\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle\nuse a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of\nthe Association for Computational Linguistics, 9:346-361, 2021.\n\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and\nJacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint\narXiv:2009.03300, 2020.\n\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza\nRutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al.\nTraining compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022.\n\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott\nGray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models.\narXiv preprint arXiv:2001.08361, 2020.\n\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish\nSabharwal. Decomposed prompting: A modular approach for solving complex tasks. arXiv\npreprint arXiv:2210.02406, 2022.\n\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\nlanguage models are zero-shot reasoners. Advances in neural information processing systems, 35:\n\n22199-22213, 2022.\n\nRoyi Lachmy, Valentina Pyatkin, Avshalom Manevich, and Reut Tsarfaty. Draw me a flower:\nProcessing and grounding abstraction in natural language. Transactions of the Association for\nComputational Linguistics, 2022.\n\nHunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan\nLeike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step. arXiv preprint\narXiv:2305.20050, 2023.\n\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig.\nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language\nprocessing. ACM Computing Surveys, 55(9):1-35, 2023.\n\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, and Hannaneh Hajishirzi. Reframing\ninstructional prompts to gptk’s language. In Findings of the Association for Computational\nLinguistics: ACL 2022, pp. 589-612, 2022a.\n\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-task generalization\n\nvia natural language crowdsourcing instructions. In Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers), pp. 3470-3487, 2022b.\n\n10\n", "vlm_text": "R EFERENCES \nRohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report.  arXiv preprint arXiv:2305.10403 , 2023. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neel a kant an, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.  Advances in neural information processing systems , 33:1877–1901, 2020. Wenhu Chen, Xinyi Wang, and William Yang Wang. A dataset for answering time-sensitive questions. arXiv preprint arXiv:2108.06314 , 2021. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways.  arXiv preprint arXiv:2204.02311 , 2022. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding.  arXiv preprint arXiv:1810.04805 , 2018. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies.  Transactions of the Association for Computational Linguistics , 9:346–361, 2021. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buch at s kaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models.  arXiv preprint arXiv:2203.15556 , 2022. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 , 2020. Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks.  arXiv preprint arXiv:2210.02406 , 2022. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners.  Advances in neural information processing systems , 35: 22199–22213, 2022. Royi Lachmy, Valentina Pyatkin, Avshalom Manevich, and Reut Tsarfaty. Draw me a flower: Processing and grounding abstraction in natural language.  Transactions of the Association for Computational Linguistics , 2022. Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step.  arXiv preprint arXiv:2305.20050 , 2023. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.  ACM Computing Surveys , 55(9):1–35, 2023. Swaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, and Hannaneh Hajishirzi. Reframing instructional prompts to gptk’s language. In  Findings of the Association for Computational Linguistics: ACL 2022 , pp. 589–612, 2022a. Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-task generalization via natural language crowd sourcing instructions. In  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 3470–3487, 2022b. "}
{"page": 10, "image_path": "doc_images/STEPBACK_10.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work:\nScratchpads for intermediate computation with language models. arXiv preprint arXiv:2112.00114,\n2021.\n\nOpenAl. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\n\nMihir Parmar, Swaroop Mishra, Mor Geva, and Chitta Baral. Don’t blame the annotator: Bias\nalready starts in the annotation instructions. In Proceedings of the 17th Conference of the European\nChapter of the Association for Computational Linguistics, pp. 1771-1781, 2023.\n\nPruthvi Patel, Swaroop Mishra, Mihir Parmar, and Chitta Baral. Is a question decomposition unit\nall we need? In Proceedings of the 2022 Conference on Empirical Methods in Natural Language\nProcessing, pp. 4553-4569, 2022.\n\nOfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring\nand narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350,\n2022.\n\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text\ntransformer. The Journal of Machine Learning Research, 21(1):5485-5551, 2020.\n\nJohn L Russell. Kepler’s laws of planetary motion: 1609-1666. The British journal for the history of\nscience, 2(1):1-24, 1964.\n\nZhiging Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and Denny Zhou. Recitation-augmented language\nmodels. arXiv preprint arXiv:2210.01296, 2022.\n\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. Musique: Multihop\nquestions via single-hop question composition. Transactions of the Association for Computational\nLinguistics, 10:539-554, 2022.\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz\nKaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing\nsystems, 30, 2017.\n\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,\nAndrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint\narXiv:2109.01652, 2021.\n\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\nMaarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models.\narXiv preprint arXiv:2206.07682, 2022a.\n\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\nZhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in\nNeural Information Processing Systems, 35:24824—24837, 2022b.\n\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen.\nLarge language models as optimizers. arXiv preprint arXiv:2309.03409, 2023.\n\nMichael Zhang and Eunsol Choi. Situatedqa: Incorporating extra-linguistic contexts into qa. In\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp.\n7371-7387, 2021.\n\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving\nfew-shot performance of language models. In Jnternational Conference on Machine Learning, pp.\n12697-12706. PMLR, 2021.\n\nDenny Zhou, Nathanael Schirli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans,\nClaire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning\nin large language models. arXiv preprint arXiv:2205. 10625, 2022.\n\n11\n", "vlm_text": "Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Micha lewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratch pads for intermediate computation with language models.  arXiv preprint arXiv:2112.00114 , 2021. \nOpenAI. Gpt-4 technical report.  arXiv preprint arXiv:2303.08774 , 2023. \nMihir Parmar, Swaroop Mishra, Mor Geva, and Chitta Baral. Don’t blame the annotator: Bias already starts in the annotation instructions. In  Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics , pp. 1771–1781, 2023. Pruthvi Patel, Swaroop Mishra, Mihir Parmar, and Chitta Baral. Is a question decomposition unit all we need? In  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing , pp. 4553–4569, 2022. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring and narrowing the compositional it y gap in language models.  arXiv preprint arXiv:2210.03350 , 2022. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer.  The Journal of Machine Learning Research , 21(1):5485–5551, 2020. John L Russell. Kepler’s laws of planetary motion: 1609–1666.  The British journal for the history of science , 2(1):1–24, 1964. Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and Denny Zhou. Recitation-augmented language models.  arXiv preprint arXiv:2210.01296 , 2022. Harsh Trivedi, Niranjan Bala subramania n, Tushar Khot, and Ashish Sabharwal. Musique: Multihop questions via single-hop question composition.  Transactions of the Association for Computational Linguistics , 10:539–554, 2022. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,  Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need.  Advances in neural information processing systems , 30, 2017. Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners.  arXiv preprint arXiv:2109.01652 , 2021. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 , 2022a. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models.  Advances in Neural Information Processing Systems , 35:24824–24837, 2022b. Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers.  arXiv preprint arXiv:2309.03409 , 2023. Michael Zhang and Eunsol Choi. Situatedqa: Incorporating extra-linguistic contexts into qa. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pp. 7371–7387, 2021. Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving few-shot performance of language models. In  International Conference on Machine Learning , pp. 12697–12706. PMLR, 2021. Denny Zhou, Nathanael Sch arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning in large language models.  arXiv preprint arXiv:2205.10625 , 2022. "}
{"page": 11, "image_path": "doc_images/STEPBACK_11.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nA ADDITIONAL ERROR ANALYSIS\n\nA.1 TIMEQA ERROR ANALYSIS\n\nWe conduct error analysis to understand where STEP-BACK PROMPTING fixes the errors the baseline\nmodels make. Figure 6 shows that compared to the predictions of baseline PaLM-2L, STEP-BACK\nPROMPTING is able to fix 39.9% of the predictions where the baseline prediction is wrong, while\ncausing 5.6% errors. Furthermore, Step-Back + RAG fixes 21.6% errors coming from RAG. The %\nof errors introduced by STEP-BACK PROMPTING to RAG is still relatively low (6.3%). Together,\nthis shows that the STEP-BACK PROMPTING is helpful most of the time, signifying the need and\neffectiveness of doing Abstraction before directly addressing the original question.\n\nStep-Back + RAG Wrong_ Step-Back + RAG Wrong _\n\nae Both Wrong 5% Both Wrong\nRAG Wrong\nBaseline Wrong\n39.99\nBoth Right Both Right\n27.9 on 46.2\n\nFigure 6: Error Analysis of Step-Back Prompting on TimeQA. Left: Step-Back + RAG vs Baseline\npredictions. Right: Step-Back RAG vs RAG predictions. Step-Back + RAG is able to fix 39.9%\nof the predictions where the baseline prediction is wrong, while causing 5.6% errors. Furthermore,\nStep-Back + RAG fixes 21.6% errors coming from RAG. The % of errors introduced by STEP-BACK\nPROMPTING to RAG is still relatively low (6.3%).\n\nA.2. STRATEGYQA ERROR ANALYSIS\n\nFigure 7 shows the error analysis of StrategyQA on the predictions of Step-Back + RAG against the\nbaseline model and the raw retrieval augmentation variant of PaLM-2L. Compared to the baseline,\nStep-Back + RAG is able to turn 15.4% wrong predictions into correct predictions, while leading to\n6.1% errors the other way around. Furthermore, Step-Back + RAG fixes 12.7% errors coming from\nRAG. The errors introduced to RAG by Step-Back is just 4.4%.\n\nBoth Right\n74.6%\n\nBoth Wrong Both Wrong\n3.9% 5.7%\nBaseline Wrong RAG Wrong\n15.4% 12.7%\nStep-Back + RAG Wrong ack + RAG Wrong\n6.1% 4.4%\n\nBoth Right\n\n77.2%\n\nFigure 7: Error Analysis of Step-Back Prompting on StrategyQA. Left: Step-Back + RAG vs Baseline\npredictions. Right: Step-Back + RAG vs RAG predictions. Step-Back + RAG is able to turn\n15.4% wrong predictions into correct predictions, while leading to 6.1% errors the other way around.\nFurthermore, Step-Back + RAG fixes 12.7% errors coming from RAG. The errors introduced to RAG\nby Step-Back is just 4.4%.\n\n12\n", "vlm_text": "A A DDITIONAL  E RROR  A NALYSIS \nA.1 T IME QA E RROR  A NALYSIS \nWe conduct error analysis to understand where S TEP -B ACK  P ROMPTING  fixes the errors the baseline models make. Figure 6 shows that compared to the predictions of baseline PaLM-2L, S TEP -B ACK P ROMPTING  is able to fix  $39.9\\%$   of the predictions where the baseline prediction is wrong, while causing    $5.6\\%$   errors. Furthermore, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   fixes    $21.6\\%$   errors coming from RAG. The    $\\%$  of errors introduced by S TEP -B ACK  P ROMPTING  to RAG is still relatively low   $(6.3\\%)$  . Together, this shows that the S TEP -B ACK  P ROMPTING  is helpful most of the time, signifying the need and effectiveness of doing Abstraction before directly addressing the original question. \nThe image contains two pie charts.\n\nThe chart on the left shows:\n- Baseline Wrong: 39.9%\n- Both Wrong: 26.5%\n- Both Right: 27.9%\n- Step-Back + RAG Wrong: 5.6%\n\nThe chart on the right shows:\n- Both Right: 46.2%\n- Both Wrong: 25.8%\n- RAG Wrong: 21.6%\n- Step-Back + RAG Wrong: 6.3%\n\nEach segment is represented with different colors.\nFigure 6: Error Analysis of Step-Back Prompting on TimeQA.  Left : Step-  $\\mathrm{back}+\\mathrm{RAG}$   vs Baseline predictions.  Right : Step-Back RAG vs RAG predictions. Step-Back  $+\\;\\mathbf{R}\\mathbf{A}\\mathbf{G}$   is able to fix    $39.9\\%$  of the predictions where the baseline prediction is wrong, while causing  $5.6\\%$   errors. Furthermore, Step-Back  $^+$  RAG fixes  $21.6\\%$   errors coming from RAG. The    $\\%$   of errors introduced by S TEP -B ACK P ROMPTING  to RAG is still relatively low   $(6.3\\%)$  . \nA.2 S TRATEGY QA E RROR  A NALYSIS \nFigure 7 shows the error analysis of StrategyQA on the predictions of Step-Back  $^+$   RAG against the baseline model and the raw retrieval augmentation variant of PaLM-2L. Compared to the baseline, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   is able to turn    $15.4\\%$   wrong predictions into correct predictions, while leading to  $6.1\\%$   errors the other way around. Furthermore, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   fixes    $12.7\\%$   errors coming from RAG. The errors introduced to RAG by Step-Back is just    $4.4\\%$  . \nThe image shows two pie charts comparing the accuracy of two systems. \n\n- **Left Pie Chart:**\n  - Both Right: 74.6% (green)\n  - Baseline Wrong: 15.4% (red)\n  - Step-Back + RAG Wrong: 6.1% (yellow)\n  - Both Wrong: 3.9% (blue)\n\n- **Right Pie Chart:**\n  - Both Right: 77.2% (green)\n  - RAG Wrong: 12.7% (red)\n  - Step-Back + RAG Wrong: 4.4% (yellow)\n  - Both Wrong: 5.7% (blue)\n\nThese charts likely represent the performance comparison between different methods or configurations, showing the percentage of correct and incorrect results for each scenario.\nFigure 7: Error Analysis of Step-Back Prompting on StrategyQA.  Left : Step-Back  $^+$  RAG vs Baseline predictions.  Right : Step-Back  $^+$   RAG vs RAG predictions. Step-Back  $+$   RAG is able to turn  $\\bar{1}5.4\\%$   wrong predictions into correct predictions, while leading to  $6.{\\bar{1}}\\%$   errors the other way around. Furthermore, Step-Back  $^+$   RAG fixes  $12.7\\%$   errors coming from RAG. The errors introduced to RAG by Step-Back is just  $4.4\\%$  . "}
{"page": 12, "image_path": "doc_images/STEPBACK_12.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nTable 4: Stats of the evaluation datasets used in this paper.\n\nDomain Dataset Split | Number of Examples\nSTEM MMLU high-school Physics Test 151\nMMLU high-school Chemistry | Test 203\nKnowledge QA TimeQA Test 5226\nTimeQA Easy Test 2613\nTimeQA Hard Test 2613\nSituatedQA Test 2901\nMulti-hop Reasoning MuSiQue Dev 2417\nStrategyQA Dev 229\n\nAre the following two answers to the given question equivalent? Do not\nconsider whether the answers are right or wrong, but only whether they\nare equivalent. Directly state ’ Yes” or No”.\n\nQuestion: Which title was conferred to Anna Muzychuk in 2007?\nAnswer 1: Anna Muzychuk was conferred the title of International\nMaster (IM) in 2007. She earned the title by scoring three norms in rapid\nchess tournaments.\n\nAnswer 2: International Master\n\nAnswer 1 (short): International Master\n\nAnswer 2 (short): International Master\n\nAre the two answers equivalent? Yes\n\nQuestion: What state is Seattle located in?\n\nAnswer 1: Seattle is in Washington State.\n\nAnswer 2: The answer is George Washington.\n\nAnswer 1 (short): Washington State\n\nAnswer 2 (short): George Washington\n\nAre the two answers equivalent? No\n\nQuestion: <Question>\n\nAnswer 1: <Model Output>\n\nAnswer 2: <Target Label>\n\nTable 5: Illustration of few shot evaluation with the PaLM-2L model.\n\nB_ DATASET DETAILS\n\nTable 4 shows the split and number of examples used for evaluations in TimeQA, StrategyQA and\nMMLU high-school Physics.\n\nC_ EVALUATION DETAILS\n\nC.1 FEW-SHOT EXAMPLES FOR EVALUATION WITH PALM2-L\n\nGiven the model free-form outputs and the target label, we use one positive and one negative outputs\nas few-shot examples to teach the scoring model how to score the output. Table 5 illustrates the\nprompt we used for the scoring model. We parse out the “Yes” or “No” answer from the scoring\nmodel output as TRUE or FALSE score of the model output.\n\nC.2 HYPER-PARAMETERS FOR EVALUATION WITH PALM2-L\nWe use PaLM-2L as the scoring model for evaluation. We experiment with different sampling\n\ntemperatures, and find that T’ = 1 gives us a highly-accurate evaluating. For example, we sampled\n100 test examples and the model predictions, and manually rated the correctness of the model scoring.\n\n13\n", "vlm_text": "The table contains the following information:\n\n**Columns:**\n1. **Domain**: Categories of datasets.\n2. **Dataset**: Specific datasets within each domain.\n3. **Split**: Type of data division (Test or Dev).\n4. **Number of Examples**: The count of examples in each dataset.\n\n**Data:**\n\n- **STEM:**\n  - *Dataset*: MMLU high-school Physics, MMLU high-school Chemistry\n  - *Split*: Test\n  - *Number of Examples*: 151, 203 respectively\n\n- **Knowledge QA:**\n  - *Dataset*: TimeQA, TimeQA Easy, TimeQA Hard, SituatedQA\n  - *Split*: Test\n  - *Number of Examples*: 5226, 2613, 2613, 2901 respectively\n\n- **Multi-hop Reasoning:**\n  - *Dataset*: MuSiQue, StrategyQA\n  - *Split*: Dev\n  - *Number of Examples*: 2417, 229 respectively\nAre the following two answers to the given question equivalent? Do not consider whether the answers are right or wrong, but only whether they are equivalent. Directly state ”Yes” or ”No”. Question : Which title was conferred to Anna Muzychuk in 2007? Answer 1 : Anna Muzychuk was conferred the title of International Master (IM) in 2007. She earned the title by scoring three norms in rapid chess tournaments. Answer 2 : International Master Answer 1 (short) : International Master Answer 2 (short) : International Master Are the two answers equivalent?  Yes Question : What state is Seattle located in? Answer 1 : Seattle is in Washington State. Answer 2 : The answer is George Washington. Answer 1 (short) : Washington State Answer 2 (short) : George Washington Are the two answers equivalent?  No Question :    $<$  Question > Answer 1 :  < Model Output > Answer 2 :  < Target Label > \nB D ATASET  D ETAILS \nTable 4 shows the split and number of examples used for evaluations in TimeQA, StrategyQA and MMLU high-school Physics. \nC E VALUATION  D ETAILS \nC.1 F EW - SHOT  E XAMPLES FOR  E VALUATION WITH  P A LM2-L \nGiven the model free-form outputs and the target label, we use one positive and one negative outputs as few-shot examples to teach the scoring model how to score the output. Table 5 illustrates the prompt we used for the scoring model. We parse out the “Yes” or “No” answer from the scoring model output as TRUE or FALSE score of the model output. \nC.2 H YPER - PARAMETERS FOR  E VALUATION WITH  P A LM2-L \nWe use PaLM-2L as the scoring model for evaluation. We experiment with different sampling temperatures, and find that    $T=1$   gives us a highly-accurate evaluating. For example, we sampled 100  test examples and the model predictions, and manually rated the correctness of the model scoring. "}
{"page": 13, "image_path": "doc_images/STEPBACK_13.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nMMLU Physics/Chemistry First-Principle Prompt\n\nYou are an expert at Physics/Chemistry. You are given\na Physics/Chemistry problem. Your task is to extract the\nPhysics/Chemistry concepts and principles involved in solving\nthe problem. Here are a few examples:\n\nQuestion: <Question Example1>\nPrinciples Involved: <Principles Example1>\n\nQuestion: <Question Example5>\n\nPrinciples Involved: <Principles ExampleS>\nQuestion: <Question>\n\nPrinciples Involved:\n\nTable 6: Prompt of extracting the underlying principles involved in MMLU physics and chemistry\nquestions.\n\nMMLU Physics/Chemistry Final Answer Prompt\n\nYou are an expert at Physics/Chemistry. You are given a\nPhysics/Chemistry problem and a set of principles involved in\nsolving the problem. Solve the problem step by step by following the\nprinciples. Here are a few examples:\n\nQuestion: <Question Example1>\nPrinciples: <Principles Example1>\nAnswer: <Answer Examplel >\n\nQuestion: <Question Example5>\nPrinciples: <Principles Example5>\nAnswer: <Answer Example5>\nQuestion: <Question>\n\nPrinciples: <Principles>\n\nAnswer:\n\nTable 7: Prompt of querying the model for final answer with first principles behind the question in\nMMLU high-school Physics and Chemistry.\n\nWe found that out of 4 trials, the model scoring agrees with human ratings 97%, 98%, 99% and 99%\nof the time.\n\nD_ PROMPTS AND FEW SHOT EXAMPLES\n\nD.1 STEM\n\nFor MMLU high-school Physics and Chemistry, we first prompt the model to generate the first\nprinciples behind the question. Using the generated first principles, we further prompt the model to\ngenerate the final answer through few-shot demonstrations The prompt generating first principles is\nshown in Table 6 for MMLU high-school Physics and Chemistry.\n\nAfter extracting the first principles of solving a particular question, we formulate the prompt in\nTable 7 to query the model for the final answer.\n\nTables 8-9 show one demonstration exemplar of Question-Principles-Answer triplets for MMLU\nhigh-school Physics and Chemistry, respectively.\n\n14\n", "vlm_text": "This table is a prompt template for a Physics/Chemistry task. It instructs the user to extract the Physics or Chemistry concepts and principles involved in solving given problems. The template provides examples labeled as \"Question Example1\" to \"Question Example5\" with corresponding \"Principles Example1\" to \"Principles Example5.\" After the examples, there is a placeholder for a new question and its involved principles.\nThe table contains a prompt titled \"MMLU Physics/Chemistry Final Answer Prompt.\" It provides instructions for solving Physics/Chemistry problems by following a set of principles. The text is organized in the following format:\n\n- Introduction: You are given a Physics/Chemistry problem and a set of principles for solving it.\n- A prompt to solve the problem step by step using the provided principles.\n- Examples showcasing how to approach the problem:\n  - Example 1 to Example 5 with placeholders for:\n    - Question: `<Question ExampleX>`\n    - Principles: `<Principles ExampleX>`\n    - Answer: `<Answer ExampleX>`\n- A blank template for a new question:\n  - Question: `<Question>`\n  - Principles: `<Principles>`\n  - Answer: \n\nThe table provides a structured way to approach and solve problems in a Physics/Chemistry context.\nTable 7: Prompt of querying the model for final answer with first principles behind the question in MMLU high-school Physics and Chemistry. \nWe found that out of 4 trials, the model scoring agrees with human ratings    $97\\%$  ,  $98\\%$  ,  $99\\%$   and    $99\\%$  of the time. \nD P ROMPTS AND  F EW SHOT  E XAMPLES \nD.1 STEM \nFor MMLU high-school Physics and Chemistry, we first prompt the model to generate the first principles behind the question. Using the generated first principles, we further prompt the model to generate the final answer through few-shot demonstrations The prompt generating first principles is shown in Table 6 for MMLU high-school Physics and Chemistry. \nAfter extracting the first principles of solving a particular question, we formulate the prompt in Table 7 to query the model for the final answer. \nTables 8-9 show one demonstration exemplar of Question-Principles-Answer triplets for MMLU high-school Physics and Chemistry, respectively. "}
{"page": 14, "image_path": "doc_images/STEPBACK_14.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nQuestion\n\nA spherical conductor carries a net charge. How is this charge distributed on\nthe sphere?\n\n0) The charge is evenly distributed on the surface.\n\n1) The charge resides on the surface only; the distribution of charge on the\nsurface depends on what other charged objects are near the sphere.\n\n2) The charge moves continually within the sphere.\n\n3) The charge is distributed uniformly throughout the sphere.\n\nPrinciples\n\nCoulomb’s Law: the force between two charged particles is proportional to the\nproduct of their charges and inversely proportional to the square of the distance\nbetween them, F =k * ql * q2/r, where F is the electric force, k is a constant,\nql and q2 are the charges the particles carry, and r is the distance between them.\n\nAnswer\n\nUsing the Principles of Coulomb’s Law, we can solve the problem as following:\nStep 1: Apply Coulomb’s Law to find out how charges are distributed on the\nsurface.\n\nIn the case of a spherical conductor, the charges on the surface will repel each\nother. The further apart the charges are, the less force they will exert on each\nother. Therefore, the charges will distribute themselves evenly on the surface\nof the sphere, as this is the configuration that minimizes the repulsive force\nbetween them.\n\nStep 2: Apply Coulomb’s Law to find out what happens if there are other\ncharges present.\n\nThe distribution of charge on the surface may also be affected by the presence\nof other charged objects near the sphere. For example, if a negatively charged\nobject is brought near a positively charged sphere, the negative charges on the\nsphere will be repelled and will move to the opposite side of the sphere. This\nwill result in a non-uniform distribution of charge on the surface of the sphere.\n\nTherefore, the correct answer is 1) The charge resides on the surface only; the\ndistribution of charge on the surface depends on what other charged objects are\nnear the sphere.\n\nTable 8: Few-shot demonstration exemplar for MMLU high-school Physics.\n\n15\n", "vlm_text": "The table contains the following information:\n\n- **Question**: How is the charge distributed on a spherical conductor carrying a net charge?\n  - Options:\n    0) Evenly distributed on the surface.\n    1) Surface only; depends on other nearby charged objects.\n    2) Moves continually within the sphere.\n    3) Uniformly distributed throughout the sphere.\n\n- **Principles**: Explanation of Coulomb’s Law, which describes the force between two charged particles as proportional to the product of their charges and inversely proportional to the square of the distance between them.\n\n- **Answer**: \n  - Application of Coulomb’s Law to determine charge distribution.\n  - Step 1: Charges on a spherical conductor repel and distribute evenly on the surface to minimize repulsive force.\n  - Step 2: Presence of other charged objects affects surface charge distribution, leading to non-uniform distribution if influenced by nearby charges.\n  - Correct answer: 1) The charge resides on the surface only, and its distribution depends on nearby charged objects.\nTable 8: Few-shot demonstration exemplar for MMLU high-school Physics. "}
{"page": 15, "image_path": "doc_images/STEPBACK_15.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nQuestion\n\nA sample of an unknown chloride compound was dissolved in water, and\nthen titrated with excess Pb(NO3)2 to create a precipitate. After drying, it is\ndetermined there are 0.0050 mol of precipitate present. What mass of chloride\nis present in the original sample?\n\n0) 0.177 g\n\n1) 0.355 g\n\n2) 0.522 g\n\n3) 0.710 g\n\nPrinciples\n\nAnswer\n\nPrecipitation reactions: Precipitation reactions occur when two soluble salts are\nmixed and form an insoluble product, called a precipitate. The precipitate can\nbe separated from the solution by filtration or centrifugation.\n\nMolar mass: The molar mass of a substance is the mass of one mole of that\nsubstance. The molar mass is expressed in grams per mole (g/mol).\n\nLimiting reactant: The limiting reactant is the reactant that is completely con-\nsumed in a chemical reaction. The amount of product formed is determined by\nthe amount of limiting reactant.\n\nAssuming the unknown chloride compound is MCI, where M represents the\nmetal cation, the balanced chemical equation for the precipitation reaction is:\nPb(NO3)2(aq) + 2MCl(aq) —> PbCl2(s) + 2M NO3(aq)\n\nSince Pb(NO3)o is in excess, MCI is the limiting reactant. The stoichiometry\nof the reaction indicates that 2 moles of MCI produce 1 mole of PbClz\nprecipitate. Therefore, 0.0050 mol of PbClz corresponds to 0.010 mol of MCL.\n\nThe mass of chloride in the original sample can be calculated using the molar\nmass of chloride (35.45 g/mol):\n0.010 mol Cl x 35.45 g/mol = 0.355 g Cl\n\nThe correct answer is 1) 0.355 g.\n\nTable 9: Few-shot demonstration exemplar for MMLU high-school Chemistry.\n\n16\n", "vlm_text": "The table contains three sections: \n\n1. **Question**: \n   - A sample of an unknown chloride compound is dissolved in water and titrated with excess Pb(NO3)2 to form a precipitate. After drying, 0.0050 mol of precipitate is obtained. The task is to determine the mass of chloride in the original sample, with options: \n     - 0) 0.177 g \n     - 1) 0.355 g \n     - 2) 0.522 g \n     - 3) 0.710 g\n\n2. **Principles**: \n   - Explanation of precipitation reactions, molar mass, and limiting reactants:\n     - Precipitation reactions occur when two soluble salts form an insoluble product (precipitate).\n     - Molar mass is the mass of one mole of a substance.\n     - The limiting reactant is fully consumed in a reaction, determining the product amount.\n\n3. **Answer**: \n   - Assuming the compound is MCl (where M is a metal cation), the reaction is:\n     - Pb(NO3)2(aq) + 2MCl(aq) → PbCl2(s) + 2MNO3(aq)\n   - MCl is the limiting reactant. Based on stoichiometry, 2 moles of MCl produce 1 mole of PbCl2. Thus, 0.0050 mol of PbCl2 corresponds to 0.010 mol of MCl.\n   - Calculating mass using the molar mass of chloride (35.45 g/mol):\n     - 0.010 mol Cl × 35.45 g/mol = 0.355 g Cl\n   - The correct answer is 1) 0.355 g.\nTable 9: Few-shot demonstration exemplar for MMLU high-school Chemistry. "}
{"page": 16, "image_path": "doc_images/STEPBACK_16.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nKnowledge QA Step-Back Prompt\n\nYou are an expert at world knowledge. Your task is to step back and\nparaphrase a question to a more generic step-back question, which is\neasier to answer. Here are a few examples:\n\nOriginal Question: <Original Question Examplel >\nStepback Question: <Stepback Question Example1>\n\nOriginal Question: <Original Question Example5>\nStepback Question: <Stepback Question Example5>\nOriginal Question: <Original Question>\n\nStepback Question:\n\nTable 10: Prompt of asking step-back question in Knowledge QA tasks.\n\ndataset Original Question Step-back Question\n\nTimeQA Which position did Knox Cunningham Which positions have Knox Cunning-\nhold from May 1955 to Apr 1956? ham held in his career?\n\nTimeQA Who was the spouse of Anna Karina Who were the spouses of Anna Karina?\nfrom 1968 to 1974?\n\nTimeQA Which team did Thierry Audel play for Which teams did Thierry Audel play for\nfrom 2007 to 2008? in his career?\n\nTimeQA What was the operator of GCR Class | What were the operators of GCR Class\n11E from 1913 to Dec 1922? 11E in history?\n\nTimeQA Which country did Sokolovsko belong Which countries did Sokolovsko belong\nto from 1392 to 1525? to in history?\n\nSituatedQA when was the last time a team from which years did a team from canada\ncanada won the stanley cup as of 2002 _ won the stanley cup as of 2002\n\nSituatedQA when did england last get to the semi _ which years did england get to the semi\nfinal in a world cup as of 2019 final in a world cup as of 2019?\n\nSituatedQA what is the biggest hotel in las vegas nv _ what is the size of the hotels in las vegas\nas of November 28, 1993 nv as of November 28, 1993\n\nSituatedQA who has scored most runs in t20 What are the runs of players in t20\nmatches as of 2017 matches as of 2017\n\nSituatedQA who is the highest paid player in the nba ___ what is the salary of the high paid play-\n\nthis season as of 2017\n\ners in the nba this season as of 2017\n\nTable 11: Few-shot demonstration exemplars for asking step-back questions in TimeQA and Situat-\n\nedQA.\n\nD.2 KNOWLEDGE QA\n\nWe use the following prompting in Table 10 to teach the LLM to ask a step-back question for\nTimeQA and SituatedQA including up to 5 exemplar demonstrations of pairs of Original Question\nand Step-back Question.\n\nTable 11 shows 5 exemplars from the Train split of TimeQA and SituatedQA as demonstrations of\nasking step-back questions.\n\nThe step-back question is extracted from the model output using the prompt. Using the step-back\nquestion, we do retrieval augmentation. Using both the retrieval augmentations from the original\nquestion and the step-back question, we formulate the final prompt to query the model for the final\nanswer, as shown in Table 12.\n\n17\n", "vlm_text": "The table is titled \"Knowledge QA Step-Back Prompt.\" It provides instructions for creating more generic, paraphrased questions to make them easier to answer. The table includes placeholders for examples of original questions and their corresponding step-back questions, ultimately illustrating the task of simplifying queries.\nThe table includes three columns labeled \"dataset,\" \"Original Question,\" and \"Step-back Question.\"\n\n1. **dataset**: Indicates the source of the questions, either \"TimeQA\" or \"SituatedQA.\"\n2. **Original Question**: Lists specific questions with time constraints, such as historical facts or statistics as of a certain year.\n3. **Step-back Question**: Reframes the original questions to focus on broader or more general information, often removing specific time constraints.\nD.2 K NOWLEDGE  QA \nWe use the following prompting in Table 10 to teach the LLM to ask a step-back question for TimeQA and SituatedQA including up to 5 exemplar demonstrations of pairs of Original Question and Step-back Question. \nTable 11 shows 5 exemplars from the Train split of TimeQA and SituatedQA as demonstrations of asking step-back questions. \nThe step-back question is extracted from the model output using the prompt. Using the step-back question, we do retrieval augmentation. Using both the retrieval augmentations from the original question and the step-back question, we formulate the final prompt to query the model for the final answer, as shown in Table 12. "}
{"page": 17, "image_path": "doc_images/STEPBACK_17.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nKnowledge QA Final-Answer Prompt\n\nYou are an expert of world knowledge. I am going to ask you a question.\nYour response should be comprehensive and not contradicted with the\nfollowing context if they are relevant. Otherwise, ignore them if they are\nnot relevant.\n\n<Passage from original retrieval augmentation>\n<Passage from step-back retrieval augmentation>\n\nOriginal Question: <Original Question>\nAnswer:\n\nTable 12: Prompt of querying the model for final answer with additional contexts from original and\n\nstep-back retrieval augmentations in TimeQA and SituatedQA\n\ndataset Original Question Step-back Question\n\nMuSiQue at year saw the creation of the region _ which region is the county of Hert-\nwhere the county of Hertfordshire is  fordshire located?\nlocated?\n\nMuSiQue Jan Sindel’s was born in what coun- what is Jan Sindel’s personal his-\ntry? tory?\n\nMuSiQue When was the abolishment of the — which studio distributed The Game?\nstudio that distributed The Game?\n\nMuSiQue What city is the person who broad-_ who broadened the doctrine of phi-\nened the doctrine of philosophy of losophy of language\nlanguage from?\n\nMuSiQue When was the baseball team win- which baseball team won the world\nning the world series in 2015 base- _ series in 2015 baseball?\nball created?\n\nStrategyQA Could the members of The Police what can the members of The Police\nperform lawful arrests? do?\n\nStrategyQA Would a Monoamine Oxidase candy What are the effects of Monoamine\nbar cheer up a depressed friend? Oxidase?\n\nStrategyQA Would a dog respond to bell before Would a dog respond to bell before\nGrey seal? Grey seal?\n\nStrategyQA Is shrimp scampi definitely free of | what is shrimp scampi made of?\nplastic?\n\nStrategyQA Do the anchors on Rede Globo What languages do the anchors on\n\nspeak Chinese?\n\nRede Globo speak?\n\nTable 13: Few-shot demonstration exemplars for asking step-back questions in MuSiQue and Strate-\ngyQA.\n\nD.3. MULTI-HOP REASONING\n\nFor Multi-Hop Reasoning, we use the same prompting template as in Knowledge QA to ask the\nstep-back question, and query for the final answer given the retrieval augmentations. Table 13 shows\n5 demonstration exemplars for asking step-back questions from the Train split of MuSiQue and\nStrategyQA.\n\n18\n", "vlm_text": "The table contains a prompt for a knowledge QA (Question-Answer) task. It outlines instructions for generating a comprehensive response to a question based on provided contextual passages. The structure includes:\n\n1. **Prompt Description**: Instructs the responder to use relevant contextual information without contradiction.\n2. **Placeholders**:\n   - `<Passage from original retrieval augmentation>`: Placeholder for a text passage.\n   - `<Passage from step-back retrieval augmentation>`: Another placeholder for additional context.\n   - `<Original Question>`: Placeholder for the original question asked.\n3. **Answer**: Space for the final answer to be formulated.\nThe table compares two datasets, MuSiQue and StrategyQA, by presenting pairs of questions from each dataset:\n\n1. The first column lists the dataset name.\n2. The second column contains the original question from each dataset.\n3. The third column shows the \"Step-back Question,\" which rephrases or contextualizes the original question.\n\nEach row represents a question pair from either MuSiQue or StrategyQA.\nD.3 M ULTI -H OP  R EASONING \nFor Multi-Hop Reasoning, we use the same prompting template as in Knowledge QA to ask the step-back question, and query for the final answer given the retrieval augmentations. Table 13 shows 5 demonstration exemplars for asking step-back questions from the Train split of MuSiQue and StrategyQA. "}
{"page": 18, "image_path": "doc_images/STEPBACK_18.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nBaseline few-shot Prompt\n\nYou are an expert of world knowledge and physics. Your task is to solve\nthe following question. Here are a few examples:\n\nQuestion: <Question Example>\nAnswer: <Answer Example>\n\nQuestion: <Question>\nAnswer:\n\nTable 14: Prompt of querying the baseline model for final answer with few-shot demonstration\nexemplars.\n\nD.4_ BASELINE PROMPTS\nFor zero-shot baseline, we simply take the question itself and query the model for answers. For\n\nstandard few-shot prompting of the baseline model, we formulate the prompt using the template in\nTable 14 with one exemplar. Table 15 shows the baseline few-shot exemplar exemplars used in this\n\npaper.\nD.5 CHAIN OF THOUGHT (COT)\n\nFor zero-shot CoT prompting, we simply append Let’s think step by step. to the question to query the\nmodel.\n\nFor few-shot CoT prompting, we use the same template as the Baseline prompting in Sec. D.4 by\nreplacing the few-shot examples using CoT responses, as shown in Tables 16, 17, 18, and 19.\n\nD.6 TAKE A DEEP BREATHE (TDB)\n\nWe study the zero-shot Take a Deep Breathe prompting found in Yang et al. (2023): we take Take a\ndeep breath and work on this problem step-by-step., and prepend it to the question.\n\nE EXAMPLES OF ERROR ANALYSIS AND WINS OF STEP-BACK PROMPTING\n\nE.1 MMLU ERROR ANALYSIS\n\nIn Tables 20-24, we show one example for each of the 5 error categories we identified through error\nanalysis on STEP-BACK PROMPTING.\n\nE.2. EXAMPLE WINS FROM STEP-BACK PROMPTING\n\nTables 25-27, 28 29, 30 and 31 illustrate the some successful examples of STEP-BACK PROMPTING\non MMLU-Physics, MMLU-Chemistry, TimeQA, SituatedQA, and StrategyQA respectively.\n\n19\n", "vlm_text": "The table contains a baseline few-shot prompt. It states that you are an expert in world knowledge and physics and are tasked with solving a question. It provides an example format for questions and answers:\n\n- Question: <Question Example>\n- Answer: <Answer Example>\n- Question: <Question>\n- Answer: \n\nThis format is used to demonstrate how to respond to a given question.\nD.4 B ASELINE  P ROMPTS \nFor zero-shot baseline, we simply take the question itself and query the model for answers. For standard few-shot prompting of the baseline model, we formulate the prompt using the template in Table 14 with one exemplar. Table 15 shows the baseline few-shot exemplar exemplars used in this paper. \nD.5CHAIN OF THOUGHT (COT)\nFor zero-shot CoT prompting, we simply append  Let’s think step by step.  to the question to query the model. \nFor few-shot CoT prompting, we use the same template as the Baseline prompting in Sec. D.4 by replacing the few-shot examples using CoT responses, as shown in Tables 16, 17, 18, and 19. \nD.6 T AKE A  D EEP  B REATHE  (TDB) \nWe study the zero-shot Take a Deep Breathe prompting found in Yang et al. (2023): we take  Take a deep breath and work on this problem step-by-step. , and prepend it to the question. \nEEXAMPLES OF ERROR ANALYSIS AND WINS OF STEP-BACK PROMPTING\nE.1 MMLU  ERROR ANALYSIS \nIn Tables 20-24, we show one example for each of the 5 error categories we identified through error analysis on S TEP -B ACK  P ROMPTING . \nE.2EXAMPLE WINS FROM STEP-BACK PROMPTING\nTables 25- 27, 28 29, 30 and 31 illustrate the some successful examples of S TEP -B ACK  P ROMPTING on MMLU-Physics, MMLU-Chemistry, TimeQA, SituatedQA, and StrategyQA respectively. "}
{"page": 19, "image_path": "doc_images/STEPBACK_19.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset Question Answer\nMMLU A point charge, Q1=+1mC,is The work required to move a charge in an\nPhysics fixed at the origin. How much electric field is equal to the change in potential\nwork is required to move another energy of the charge. The potential energy of a\ncharge, Q2 = +8 jC, from the charge in an electric field is given by: U = k *\npoint (0, 4 meters) to the point QI * Q2/r where: k is the Coulomb constant,\n(3 meters, 0)? QI and Q2 are the charges, r is the distance\n0) 3.5 J between the charges. In this case, the initial po-\n1) 6.0J tential energy of Q2 is: U1 =k * QI * Q2/4 meters\n2) 22.5 J\n3) 40 J The final potential energy of Q2 is: U2=k * QI *\nQ2/3 meters\nThe change in potential energy is: AU = U2 - U1\n=k * QI * Q2 * (1/3 meters - 1/4 meters)\nPlugging in the values, we get: AU = (9 x 10°N x\nm?/C?) x (1x 1073C) «(8 x L0-8C) « (1/3m —\n1/4m)\nAU=6J\nTherefore, the work required to move Q2 from (0,\n4 meters) to (3 meters, 0) is 6 J. The answer is 1)\n6.0 J.\nMMLU A sample of an unknown chlo- 0.0050 moles of lead chloride precipitate contain\nChemistry ride compound was dissolved in 0.010 moles of chloride ions due to the 2:1 mole\nwater, and then titrated with ex- ratio between chloride ions and lead chloride.\ncess Pb(NO3)2 to create a pre-\ncipitate. After drying, it is deter- The mass of 0.010 moles of chloride ions is 0.355\nmined there are 0.0050 mol of g.\nprecipitate present. What mass\nof chloride is present in the orig- Therefore, the mass of chloride present in the orig-\ninal sample? inal sample is 0.355 g.\n0) 0.177 g\n1) 0.355 g\n2) 0.522 g\n3) 0.710 g\nTimeQA Who was the spouse of Anna Ka- Anna Karina’s spouse from 1968 to 1974 was\nrina from 1968 to 1974? French actor Pierre Fabre.\nSituatedQA what is the biggest hotel inlas ve- The biggest hotel in Las Vegas, Nevada as of\ngas nv as of November 28, 1993 November 28, 1993 was the Excalibur Hotel &\nCasino.\nMuSiQue What year saw the creation of 1994\nthe region where the county of\nHertfordshire is located?\nStrategyQA Would a Monoamine Oxidase A Monoamine Oxidase (MAO) candy bar would\n\ncandy bar cheer up a depressed\nfriend?\n\nnot cheer up a depressed friend. MAO is an en-\nzyme that breaks down neurotransmitters such as\nserotonin, dopamine, and norepinephrine. These\nneurotransmitters are associated with mood, so in-\nhibiting MAO can lead to an increase in their lev-\nels.\n\nTable 15: Demonstration exemplar for standard prompting.\n\n20\n", "vlm_text": "The table lists various questions from different datasets, providing their answers:\n\n1. **MMLU: Physics**\n   - **Question:** How much work is required to move a charge?\n   - **Answer:** 6.0 J, with an explanation of potential energy change.\n\n2. **MMLU: Chemistry**\n   - **Question:** What mass of chloride is present in the original sample given a known amount of precipitate?\n   - **Answer:** 0.355 g, explaining the mole ratio and calculations.\n\n3. **TimeQA**\n   - **Question:** Who was Anna Karina's spouse from 1968 to 1974?\n   - **Answer:** Pierre Fabre.\n\n4. **SituatedQA**\n   - **Question:** Biggest hotel in Las Vegas as of November 28, 1993?\n   - **Answer:** Excalibur Hotel & Casino.\n\n5. **MuSiQue**\n   - **Question:** Year of creation for Hertfordshire's region?\n   - **Answer:** 1994.\n\n6. **StrategyQA**\n   - **Question:** Effect of a Monoamine Oxidase candy bar on a depressed friend?\n   - **Answer:** It wouldn't cheer up a depressed friend; explanation about MAO enzyme.\n\n"}
{"page": 20, "image_path": "doc_images/STEPBACK_20.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset Question Answer\nMMLU A point charge, Q1=+1mC,is Sure, let’s think step by step.\nPhysics fixed at the origin. How much\n\nwork is required to move another\ncharge, Q2 = +8 pC, from the\npoint (0, 4 meters) to the point\n(3 meters, 0)?\n\n0) 3.5 J\n\n1) 6.0 J\n\n2) 22.5 J\n\n3) 40 J\n\n1. Calculate the electric potential energy of Q2\nat the initial position. The electric potential\nenergy (U) of a point charge Q2 at a distance\nr from another point charge Q1 is given by the\nfollowing equation: U =k * QI * Q2/r, where k\nis Coulomb’s constant.\n\nTherefore, the electric potential energy of Q2 at\nthe initial position is:\n\nUinitiat = (9 x 10° Nm? /C?) « (1 x 1073C) * (8 x\n10~°C) /4m = 18 J\n\n2. Calculate the electric potential energy of Q2 at\nthe final position. The electric potential energy of\nQ2 at the final position is:\n\nUsinat = (9 x 10°Nm?/C?) * (1 x 1073C) « (8 x\n10-°C)/3m = 24 J\n\n3. Calculate the work required to move Q2 from\nthe initial position to the final position. The work\n(W) required to move a charge from one position\nto another is equal to the change in electric\npotential energy (AU) between the two positions.\nW = AU = Usinat - Vinitia = 24 J - 18S = 65\n\nTherefore, the answer is 1) 6.0 J.\n\nTable 16: Demonstration exemplar for CoT prompting for MMLU Physics.\n\n21\n", "vlm_text": "The table shows a physics problem about calculating the work required to move a charge and the solution to that problem. Here's a summary:\n\n**Dataset:** MMLU Physics\n\n**Question:** \n- A point charge, Q1 = +1 mC, is fixed at the origin. How much work is required to move another charge, Q2 = +8 μC, from the point (0, 4 meters) to the point (3 meters, 0)?\n- Options: 0) 3.5 J, 1) 6.0 J, 2) 22.5 J, 3) 40 J\n\n**Answer:**\n1. Calculate the initial electric potential energy of Q2 using Coulomb's law.\n2. Calculate the final electric potential energy of Q2.\n3. Determine the work done, \\( W \\), as the change in electric potential energy: \\( W = U_{\\text{final}} - U_{\\text{initial}} = 6 \\, \\text{J} \\).\n\n**Conclusion:** The work required is 6.0 J."}
{"page": 21, "image_path": "doc_images/STEPBACK_21.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset Question Answer\nMMLU A sample of an unknown chlo- Here’s the step-by-step solution:\nChemistry ride compound was dissolved in Identify the precipitate: The precipitate formed\n\nwater, and then titrated with ex-\ncess Pb(NO3)2 to create a pre-\ncipitate. After drying, it is deter-\nmined there are 0.0050 mol of\nprecipitate present. What mass\nof chloride is present in the orig-\ninal sample?\n\n0) 0.177 g\n\n1) 0.355 g\n\n2) 0.522 g\n\n3) 0.710 g\n\nwhen a chloride compound reacts with lead nitrate\n(Pb(NO3)2) is lead chloride (PbC12).\n\nDetermine the mole ratio: The balanced chemical\nequation for the reaction between a chloride\ncompound (represented as MCI, where M is the\nunknown metal) and lead nitrate is: 2MCl +\nPb(NO3)2 —> 2M NO3 + PbCly\n\nFrom the balanced equation, you can see that 2\nmoles of chloride ions (Cl-) react with 1 mole of\nlead nitrate to produce 1 mole of lead chloride\nprecipitate. Additionally, 1 mole of lead chloride\ncontains 2 moles of chloride ions.\n\nCalculate the moles of chloride ions: Since\n0.0050 moles of lead chloride precipitate\nwere formed, there must have been 2 x 0.0050 =\n0.010 moles of chloride ions in the original sample.\n\nCalculate the mass of chloride ions: The molar\nmass of chlorine (Cl) is 35.45 g/mol. Therefore,\nthe mass of 0.010 moles of chloride ions is:\n\nmass = moles x molar mass = 0.010 mol x 35.45\ng/mol = 0.355 g\n\nTherefore, the mass of chloride present in the origi-\nnal sample is 0.355 g. The correct answer is option\n1.\n\nTable 17: Demonstration exemplar for CoT prompting for MMLU Chemistry.\n\n22\n", "vlm_text": "The table has two columns, \"Question\" and \"Answer,\" related to a chemistry topic. \n\n**Question:**\nA sample of an unknown chloride compound was dissolved in water and titrated with excess Pb(NO3)2, forming a precipitate. It was found that 0.0050 mol of precipitate is present. The challenge is to determine the mass of chloride in the original sample, with options:\n0) 0.177 g\n1) 0.355 g\n2) 0.522 g\n3) 0.710 g\n\n**Answer:**\nA step-by-step solution is given:\n1. Identify the precipitate as lead chloride (PbCl2).\n2. Determine the mole ratio from the balanced equation \\(2MCl + Pb(NO3)2 → 2MNO3 + PbCl2\\), showing 2 moles of Cl- react with 1 mole of Pb(NO3)2.\n3. Calculate moles of chloride ions: 0.0050 mol lead chloride precipitate = 0.010 mol Cl-.\n4. Calculate the mass of chloride ions using the molar mass of Cl (35.45 g/mol): \n   \\(mass = 0.010 \\, \\text{mol} \\times 35.45 \\, \\text{g/mol} = 0.355 \\, \\text{g}\\).\n   \nTherefore, the mass of chloride in the original sample is 0.355 g, option 1."}
{"page": 22, "image_path": "doc_images/STEPBACK_22.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset Question\n\nAnswer\n\nTimeQA Who was the spouse of Anna Ka-\n\nrina from 1968 to 1974?\n\nStep 1: Identify Anna Karina’s spouses:Jean-Luc\nGodard (1961-1965).\n\nPierre Fabre (1968-1974)\n\nDaniel Duval (1978-1981)\n\nDennis Berry (1982-1994)\n\nStep 2: Determine which spouse was married to\nAnna Karina from 1968 to 1974.\n\nJean-Luc Godard was married to Anna Karina\nfrom 1961 to 1965, so he is not the correct answer.\nPierre Fabre was married to Anna Karina from\n1968 to 1974, so he is the correct answer.\n\nDaniel Duval was married to Anna Karina from\n1978 to 1981, so he is not the correct answer.\nDennis Berry was married to Anna Karina from\n1982 to 1994, so he is not the correct answer.\n\nTherefore, Anna Karina’s spouse from 1968 to\n1974 was Pierre Fabre.\n\nSituatedQA what is the biggest hotel in las ve-\ngas nv as of November 28, 1993\n\nSure, let’s think step by step:\n\nWhat were the largest hotels in Las Vegas in 1993?\nAccording to a 1993 article in the Las Vegas\nReview-Journal, the largest hotels in Las Vegas\nat the time were:\n\nMGM Grand (5,005 rooms) Excalibur (4,008\nrooms) The Mirage (3,049 rooms) Flamingo\nHilton (3,565 rooms) Caesars Palace (2,577 rooms)\nWhich of these hotels was the largest on November\n28, 1993? The MGM Grand opened in December\n1993, so it would not have been the largest hotel\non November 28, 1993. The Excalibur opened in\nJune 1990, so it would have been the largest hotel\non November 28, 1993.\n\nTherefore, the largest hotel in Las Vegas on Novem-\nber 28, 1993 was the Excalibur.\n\nTable 18: Demonstration exemplar for CoT prompting for TimeQA and SituatedQA.\n\n23\n", "vlm_text": "The table contains the following information:\n\n1. **Dataset: TimeQA**\n   - **Question:** Who was the spouse of Anna Karina from 1968 to 1974?\n   - **Answer:** The solution involves identifying Anna Karina's spouses and determining that Pierre Fabre was her spouse from 1968 to 1974.\n\n2. **Dataset: SituatedQA**\n   - **Question:** What is the biggest hotel in Las Vegas, NV as of November 28, 1993?\n   - **Answer:** The answer, deduced from a 1993 article, indicates that the Excalibur was the largest hotel on that date. Various hotel sizes are compared, and it is concluded that Excalibur, which opened in June 1990, was the largest at that time."}
{"page": 23, "image_path": "doc_images/STEPBACK_23.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset Question Answer\n\nMuSiQue What year saw the creation of The county of Hertfordshire is in the \"East of Eng-\nthe region where the county of land’ region. The ’East of England’ region was\nHertfordshire is located? created in 1994. So, the answer is 1994.\n\nStrategyQA Would a Monoamine Oxidase No, a Monoamine Oxidase (MAO) candy bar\n\ncandy bar cheer up a depressed\nfriend?\n\nwould not cheer up a depressed friend. In fact,\nit could be dangerous for them to consume. Here’s\na step-by-step explanation:\n\n1. MAO is an enzyme that breaks down neuro-\ntransmitters like serotonin, dopamine, and nore-\npinephrine. These neurotransmitters are important\nfor regulating mood, and low levels of them are\nassociated with depression.\n\n2. MAO inhibitors (MAOIs) are a type of medica-\ntion that blocks the action of MAO, which can in-\ncrease levels of these neurotransmitters in the brain.\nMAOIs are sometimes used to treat depression, but\nthey can have serious side effects, including inter-\nactions with certain foods and medications.\n\n3. A MAO candy bar would not contain enough\nMAOI to have a therapeutic effect on depression.\nIn fact, it is unlikely that a candy bar could contain\nany MAOT at all, as these medications are typically\ntaken in pill form.\n\nIn conclusion, a MAO candy bar would not cheer\nup a depressed friend and could even be dangerous\nfor them to consume.\n\nTable 19: Demonstration exemplar for CoT prompting for MuSiQue and StrategyQA.\n\n24\n", "vlm_text": "The table lists two datasets, questions, and answers:\n\n1. **Dataset:** MuSiQue\n   - **Question:** What year saw the creation of the region where the county of Hertfordshire is located?\n   - **Answer:** The county of Hertfordshire is in the 'East of England' region. The 'East of England' region was created in 1994. So, the answer is 1994.\n\n2. **Dataset:** StrategyQA\n   - **Question:** Would a Monoamine Oxidase candy bar cheer up a depressed friend?\n   - **Answer:** No, a Monoamine Oxidase (MAO) candy bar would not cheer up a depressed friend. In fact, it could be dangerous for them to consume. Here’s a step-by-step explanation:\n     1. MAO is an enzyme that breaks down neurotransmitters like serotonin, dopamine, and norepinephrine. These neurotransmitters are important for regulating mood, and low levels of them are associated with depression.\n     2. MAO inhibitors (MAOIs) are a type of medication that blocks the action of MAO, which can increase levels of these neurotransmitters in the brain. MAOIs are sometimes used to treat depression, but they can have serious side effects, including interactions with certain foods and medications.\n     3. A MAO candy bar would not contain enough MAOI to have a therapeutic effect on depression. In fact, it is unlikely that a candy bar could contain any MAOI at all, as these medications are typically taken in pill form.\n   \n   In conclusion, a MAO candy bar would not cheer up a depressed friend and could even be dangerous for them to consume."}
{"page": 24, "image_path": "doc_images/STEPBACK_24.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nQuestion An alarm whose frequency is 400 Hz is dropped out of a third-floor window. The\nstudent who drops it measures the frequency with a very sensitive oscilloscope.\nThe measured frequency\n0) appears higher than 400 Hz and the frequency increase as it falls\n1) appears higher than 400 Hz and the frequency decreases as it falls\n2) appears lower than 400 Hz and the frequency decreases as it falls\n3) appears lower than 400 Hz and the frequency increases as it falls\n\nPrinciples Doppler Effect: the effect produced by the motion of a wave source, observer, or\nboth that causes a change in wave frequency perceived by an observer relative\nto the frequency produced by the source. The Doppler effect is observed with\nall types of waves, including electromagnetic and acoustic waves. It was named\nafter Austrian physicist Christian Doppler.\n\nAnswer Using the Principles of Doppler Effect, we can solve the problem as following:\n\nStep 1: Apply Doppler Effect to find out the measured frequency.\n\nThe Doppler Effect is the change in frequency of a wave as measured by an\nobserver who is moving relative to the source of the wave. In this case, the\nsource of the wave is the alarm, and the observer is the student who drops it.\n\nAs the alarm falls, the distance between the alarm and the student decreases.\nThis means that the frequency of the wave as measured by the student will\nincrease. Therefore, the measured frequency will appear higher than 400 Hz,\nand the frequency will increase as the alarm falls.\n\nTherefore, the correct answer is 0) appears higher than 400 Hz and the frequency\nincrease as it falls.\n\nTable 20: Error example of STEP-BACK PROMPTING on MMLU high-school Physics in the class of\nFactual Error. In this case, the Factual error leads to the wrong answer despite that the Principle and\nReasoning are all sound.\n\n25\n", "vlm_text": "The table consists of three sections: \n\n1. **Question**: Describes a scenario involving an alarm with a frequency of 400 Hz being dropped out of a window. The student who drops it measures the frequency and must determine how it appears:\n   - 0) Appears higher than 400 Hz and the frequency increases as it falls\n   - 1) Appears higher than 400 Hz and the frequency decreases as it falls\n   - 2) Appears lower than 400 Hz and the frequency decreases as it falls\n   - 3) Appears lower than 400 Hz and the frequency increases as it falls\n\n2. **Principles**: Explains the Doppler Effect, which notes the change in wave frequency perceived by an observer due to the relative motion between the source of the wave and the observer.\n\n3. **Answer**: Steps through applying the Doppler Effect to solve the problem. As the alarm falls, the distance between the alarm and the student decreases, causing the frequency to increase. Thus, the correct choice is 0) the frequency appears higher than 400 Hz and increases as it falls."}
{"page": 25, "image_path": "doc_images/STEPBACK_25.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nQuestion An astronaut lands on a planet whose mass and radius are each twice that of\nEarth. If the astronaut weighs 800 N on Earth, how much will he weigh on this\nplanet?\n\n0) 200 N\n1) 400 N\n2) 800 N\n3) 1600 N\n\nPrinciples Weight: W = m * g, where W is the weight, m is the mass and g is the\nacceleration due to gravity\nAcceleration due to gravity: g = G * m/r?, where G is the gravitational constant,\nm is the mass of the object and r is the radius of the object\n\nAnswer Using the Principles of Newton’s law of universal gravitation and Weight, we\n\ncan solve the problem as following:\n\nStep 1: Apply Newton’s law of universal gravitation to find out the acceleration\ndue to gravity on the planet.\n\nThe acceleration due to gravity on a planet is given by the formula:\ng=G*m/r?, where g is the acceleration due to gravity, G is the gravitational\nconstant, m is the mass of the planet, and r is the radius of the planet.\n\nIn this problem, we are given the following information:\nm=2* mearth\nr=2* rearth\n\nPlugging these values into the formula, we get:\ng=Gt2* Mearth, (2 * Teartn)”\n8=G* Mearth ! earth\n\nThis is the same as the acceleration due to gravity on Earth.\n\nStep 2: Apply Weight to find out the weight of the astronaut on the planet.\nThe weight of an object is given by the formula:\n\nW =m * g, where W is the weight, m is the mass of the object, and g is the\nacceleration due to gravity.\n\nIn this problem, we are given the following information:\nm= 800N/ gearth\n8 = IGearth\n\nPlugging these values into the formula, we get:\nW = 800 N/ gearth * Jearth\nW = 800 N\n\nTherefore, the astronaut will weigh 800 N on the planet. The correct answer is\n2) 800 N.\n\nTable 21: Error example of STEP-BACK PROMPTING on MMLU high-school Physics in the class of\nMath Error. As highlighted, the math error leads to directly a wrong answer with a factor of 2 off.\n\n26\n", "vlm_text": "The table contains a problem related to physics, specifically Newton's law of universal gravitation and the concept of weight. Here's a breakdown of the contents of the table:\n\n- **Question**: The scenario describes an astronaut landing on a planet where both the mass and radius are twice that of Earth. The astronaut weighs 800 N on Earth, and the question asks for his weight on the new planet. The options provided are 200 N, 400 N, 800 N, and 1600 N, with \"400 N\" marked as an option but with no indication that it's correct.\n\n- **Principles**: The table outlines two key equations:\n  - Weight, \\( W = m \\times g \\), where \\( W \\) is weight, \\( m \\) is mass, and \\( g \\) is acceleration due to gravity.\n  - Acceleration due to gravity, \\( g = G \\times m / r^2 \\), where \\( G \\) is the gravitational constant, \\( m \\) is the planet's mass, and \\( r \\) is the planet's radius.\n\n- **Answer**: The solution is presented in a step-by-step format:\n  - **Step 1**: Calculation of the acceleration due to gravity on the new planet, which is found to be the same as on Earth by substituting the conditions \\( m = 2 \\times m_{earth} \\) and \\( r = 2 \\times r_{earth} \\).\n  - **Step 2**: Verification via the weight equation, confirming that since \\( g \\) on the new planet equals \\( g_{earth} \\), the astronaut's weight remains 800 N.\n  - It concludes that the astronaut will weigh 800 N on the planet, identifying option 2 (800 N) as correct.\n\nOverall, the table systematically applies physics principles to identify the correct weight of the astronaut on the new planet.\nTable 21: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Math Error . As highlighted, the math error leads to directly a wrong answer with a factor of 2 off. "}
{"page": 26, "image_path": "doc_images/STEPBACK_26.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nQuestion\n\nPrinciples\n\nAnswer\n\nTwo spheres of net charge +5e and -6e briefly come into contact. Afterward,\nwhich of the following is a possible combination of net charges for the two\nspheres?\n\n0) +3e and -4e\n\n1) +1.5e and -2.5e\n\n2) Both of the above\n\n3) None of the above\n\nLaw of conservation of charge: the total charge in a closed system remains\nconstant.\n\nCoulomb’s Law: the mutual repulsion of like charges demands that the charges\nbe as far apart as possible.\n\nUsing the Principles of Conservation of charge, we can solve the problem as\nfollowing:\n\nStep 1: Apply Conservation of charge to find out the possible combination of\nnet charges for the two spheres.\n\nThe total charge of the two spheres before they come into contact is +5e - 6e =\n-le. After they come into contact, the total charge of the two spheres must still\nbe -le.\n\nStep 2: Find out the possible combination of net charges for the two spheres.\nThe possible combination of net charges for the two spheres are:\n\n(1) +3e and -4e\n\n(2) +1.5e and -2.5e\n\nTherefore, the correct answer is 2) Both of the above.\n\nTable 22: Error example of STEP-BACK PROMPTING on MMLU high-school Physics in the class of\nPrinciple Error. In this case, Coulomb’s Law is not needed for solving this problem. Instead, the\nCharge Quantization Principle is missing from the retrieved principles, and is in fact needed to rule\nout option (2) of fractional charges.\n\n27\n", "vlm_text": "The table contains a question about two spheres with net charges of +5e and -6e coming into contact. It asks for the possible combination of net charges afterward. The options are:\n\n0) +3e and -4e  \n1) +1.5e and -2.5e  \n2) Both of the above  \n3) None of the above  \n\nThe principles discussed are the law of conservation of charge and Coulomb's law regarding the repulsion of like charges.\n\nThe answer is provided as:\n\n1. Using the conservation of charge, the total charge of the two spheres before and after contact must be -1e.\n2. The possible combinations are:\n   - (1) +3e and -4e\n   - (2) +1.5e and -2.5e\n\nTherefore, the correct answer is 2) Both of the above.\nTable 22: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Principle Error . In this case, Coulomb’s Law is not needed for solving this problem. Instead, the Charge Quantization Principle is missing from the retrieved principles, and is in fact needed to rule out option (2) of fractional charges. "}
{"page": 27, "image_path": "doc_images/STEPBACK_27.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nQuestion\n\nPrinciples\n\nAnswer\n\nThe circumference of a helium-filled balloon is measured for three different\nconditions: at room temperature, after being in a warm oven for 30 minutes,\nand after being in a freezer for 30 minutes. A student plotting the circumference\ncubed C® as a function of temperature T, should expect to find which of the\nfollowing?\n\n0) a cubic relationship between C? and T\n\n1) an indirect relationship between C? and T\n\n2) an extrapolated temperature T where C® reaches zero\n\n3) a maximum C® as the temperature T increases\n\nIdeal Gas Law: PV = nRT, where P is the pressure, V is the volume, n is\nthe number of moles of gas, R is the ideal gas constant, T is the absolute\ntemperature.\n\nVolume of a sphere: V = 4/3 * 7 * r, where r is the radius.\n\nAbsolute temperature: Absolute temperature is always written as kelvin.\nAbsolute zero: Absolute zero is the lowest limit of the kelvin scale and is the\nlowest possible temperature (- 273.15 °C).\n\nUsing the Principles of Charles’s Law and Gay-Lussac’s Law, we can solve the\nproblem as following:\n\nStep 1: Apply Charles’s Law to find out the relationship between the volume\nand temperature of the gas. Charles’s Law states that the volume of a fixed\nmass of a gas is directly proportional to the absolute temperature of the gas\nwhen pressure is kept constant. This means that if the temperature of the gas\nincreases, the volume of the gas will also increase.\n\nStep 2: Apply Gay-Lussac’s Law to find out the relationship between the\npressure and temperature of the gas. Gay-Lussac’s Law states that the pressure\nof a fixed mass of a gas is directly proportional to the absolute temperature of\nthe gas when volume is kept constant. This means that if the temperature of the\ngas increases, the pressure of the gas will also increase.\n\nStep 3: Apply Charles’s Law and Gay-Lussac’s Law to find out the relationship\nbetween the circumference and temperature of the gas.The circumference of the\nballoon is directly proportional to the volume of the gas. This is because the\ncircumference of the balloon is the distance around the outside of the balloon,\nand the volume of the gas is the amount of space that the gas takes up.\n\nThe pressure of the gas is directly proportional to the temperature of the gas.\nThis is because the pressure of the gas is the force that the gas exerts on the\nwalls of the balloon, and the temperature of the gas is the measure of the\naverage kinetic energy of the gas molecules.\n\nTherefore, the circumference of the balloon is directly proportional to the\ntemperature of the gas. This means that if the temperature of the gas increases,\nthe circumference of the balloon will also increase.\n\nStep 4: Apply the relationship between the circumference and temperature\nof the gas to find out the relationship between the circumference cubed and\ntemperature of the gas. The circumference cubed is directly proportional to the\ntemperature of the gas. This is because the circumference cubed is the volume\nof the balloon, and the volume of the balloon is directly proportional to the\ntemperature of the gas.\n\nTherefore, the student should expect to find a cubic relationship between C*\nand T. The correct answer is 0) a cubic relationship between C® and T.\n\nTable 23: Error example of STEP-BACK PROMPTING on MMLU high-school Physics in the class of\nContext Loss. In this case, at the end of the Reasoning chain, the model forgot the original question,\nand lose the context to apply the reasoning to the question.\n\n28\n", "vlm_text": "The table consists of three sections labeled \"Question,\" \"Principles,\" and \"Answer.\"\n\n**Question**: \nIt describes an experiment where the circumference of a helium-filled balloon is measured under three conditions (room temperature, after warming, and after freezing). The student is tasked with plotting the circumference cubed \\( C^3 \\) as a function of temperature \\( T \\) and determining which relationship is expected:\n0) Cubic relationship between \\( C^3 \\) and \\( T \\)\n1) Indirect relationship between \\( C^3 \\) and \\( T \\)\n2) Extrapolated temperature where \\( C^3 \\) reaches zero\n3) Maximum \\( C^3 \\) as \\( T \\) increases\n\n**Principles**: \nOutlines principles to be used:\n- Ideal Gas Law: \\( PV = nRT \\)\n- Volume of a sphere: \\( V = \\frac{4}{3} \\pi r^3 \\)\n- Absolute temperature (in Kelvin)\n- Absolute zero (−273.15 °C)\n\n**Answer**: \nDescribes solving the problem using Charles’s Law and Gay-Lussac’s Law. Step 1 involves applying Charles’s Law to find the relationship between the volume and temperature.\nStep 2: Apply Gay-Lussac’s Law to find out the relationship between the pressure and temperature of the gas. Gay-Lussac’s Law states that the pressure of a fixed mass of a gas is directly proportional to the absolute temperature of the gas when volume is kept constant. This means that if the temperature of the gas increases, the pressure of the gas will also increase. \nStep 3: Apply Charles’s Law and Gay-Lussac’s Law to find out the relationship between the circumference and temperature of the gas.The circumference of the balloon is directly proportional to the volume of the gas. This is because the circumference of the balloon is the distance around the outside of the balloon, and the volume of the gas is the amount of space that the gas takes up. \nThe pressure of the gas is directly proportional to the temperature of the gas. This is because the pressure of the gas is the force that the gas exerts on the walls of the balloon, and the temperature of the gas is the measure of the average kinetic energy of the gas molecules. \nTherefore, the circumference of the balloon is directly proportional to the temperature of the gas. This means that if the temperature of the gas increases, the circumference of the balloon will also increase. \nStep 4: Apply the relationship between the circumference and temperature of the gas to find out the relationship between the circumference cubed and temperature of the gas. The circumference cubed is directly proportional to the temperature of the gas. This is because the circumference cubed is the volume of the balloon, and the volume of the balloon is directly proportional to the temperature of the gas. \nTherefore, the student should expect to find a cubic relationship between    $C^{3}$  and T.  The correct answer is 0) a cubic relationship between  $C^{3}$    and T. \nTable 23: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Context Loss . In this case, at the end of the Reasoning chain, the model forgot the original question, and lose the context to apply the reasoning to the question. "}
{"page": 28, "image_path": "doc_images/STEPBACK_28.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\nQuestion Physics students are checking the constant acceleration equations of kinematics\nby measuring the velocity of a tennis ball that is dropped and falls 6 meters\nand then passes through a photogate. The predicted velocity is 20% above the\nvelocity measured by the photogate. Which of the following best describes the\ncause of the large percent difference?\n\n0) The ball changes its shape while falling.\n\n1) The acceleration of gravity varies as the ball is falling.\n2) Air resistance increases the acceleration of the ball.\n3) The acceleration of the balls varies with the velocity.\n\nPrinciples Vertical motion: y = 0.5 * g * t?, where y is the vertical displacement, g is the\nacceleration due to gravity, t is the time.\n\nFree fall: is a special case of motion with constant acceleration, in which the\nacceleration is due to gravity.\n\nAcceleration to Velocity Formula: v = u + a * t, where v is the final speed, u is\nthe initial velocity, a is the acceleration, and t is the time.\n\nAnswer Using the Principles of Vertical motion and Horizontal motion, we can solve\n\nthe problem as following:\n\nStep 1: Apply the Vertical motion equation to find the time it takes for the ball\nto fall 6 meters.\n\ny=0.5*g*t?\n6m=0.5 * 9.8 m/s? * ¢?\nt=1.12s\n\nStep 2: Apply the Horizontal motion equation to find the velocity of the ball\nwhen it passes through the photogate.\n\nxX=v*t\nv=x/t\nv=6m/1.12s\nv =5.36 m/s\n\nStep 3: Compare the predicted velocity with the velocity measured by the\nphotogate. The predicted velocity is 20% above the velocity measured by the\nphotogate, so the predicted velocity is 1.2 * 5.36 m/s = 6.43 m/s.\n\nStep 4: Find the cause of the large percent difference. The predicted velocity is\n6.43 m/s, but the velocity measured by the photogate is 5.36 m/s. The difference\nis 1.07 m/s. This difference is caused by air resistance. Air resistance is a force\nthat opposes the motion of an object through the air. It is caused by the friction\nbetween the object and the air molecules. The greater the surface area of the\nobject, the greater the air resistance. The tennis ball has a large surface area, so\nit experiences a lot of air resistance. This air resistance slows down the tennis\nball and causes the difference between the predicted velocity and the velocity\nmeasured by the photogate.\n\nTherefore, the correct answer is 0) The ball changes its shape while falling.\n\nTable 24: Error example of STEP-BACK PROMPTING on MMLU high-school Physics in the class of\nReasoning Error. In this case, the model was able to correctly identify air resistance is the cause of\nthe velocity difference, but made the error at the final reasoning step of deriving the right answer.\n\n29\n", "vlm_text": "The table contains the following elements:\n\n**Question:**\nPhysics students are checking the constant acceleration equations of kinematics by measuring the velocity of a tennis ball that is dropped and falls 6 meters and then passes through a photogate. The predicted velocity is 20% above the velocity measured by the photogate. Which of the following best describes the cause of the large percent difference?\n0) The ball changes its shape while falling.\n1) The acceleration of gravity varies as the ball is falling.\n2) Air resistance increases the acceleration of the ball.\n3) The acceleration of the balls varies with the velocity.\n\n**Principles:**\n- Vertical motion: \\( y = 0.5 \\times g \\times t^2 \\), where \\( y \\) is the vertical displacement, \\( g \\) is the acceleration due to gravity, \\( t \\) is the time.\n- Free fall: a special case of motion with constant acceleration, where the acceleration is due to gravity.\n- Acceleration to Velocity Formula: \\( v = u + a \\times t \\), where \\( v \\) is the final speed, \\( u \\) is the initial velocity, \\( a \\) is the acceleration, and \\( t \\) is the time.\n\n**Answer:**\nUsing the principles of vertical motion and horizontal motion, the solution is:\n\n- **Step 1:** Apply the vertical motion equation to find the time it takes for the ball to fall 6 meters.\n  - \\( y = 0.5 \\times g \\times t^2 \\)\n  - \\( 6 \\, \\text{m} = 0.5 \\times 9.8 \\, \\text{m/s}^2 \\times t^2 \\)\n  - \\( t = 1.12 \\, \\text{s} \\)\n\n- **Step 2:** Apply the horizontal motion equation to find the velocity of the ball when it passes through the photogate.\n  - \\( x = v \\times t \\)\n  - \\( v = x / t \\)\n  - \\( v = 6 \\, \\text{m} / 1.12 \\, \\text{s} \\)\n  - \\( v = 5.36 \\, \\text{m/s} \\)\n\n- **Step 3:** Compare the predicted velocity with the velocity measured by the photogate. The predicted velocity is 20% above the velocity measured by the photogate, so the predicted velocity is \\( 1.2 \\times 5.36 \\, \\text{m/s} = 6.43 \\, \\text{m/s} \\).\n\n- **Step 4:** Find the cause of the large percent difference. The predicted velocity is 6.43 m/s, but the velocity measured by the photogate is 5.36 m/s. The difference is 1.07 m/s. This difference is\nTable 24: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Reasoning Error . In this case, the model was able to correctly identify air resistance is the cause of the velocity difference, but made the error at the final reasoning step of deriving the right answer. "}
{"page": 29, "image_path": "doc_images/STEPBACK_29.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset\n\nexample\n\nMMLU-Physics\n\nOriginal Question: What happens to the pressure, P, of an ideal gas if\nthe temperature is increased by a factor of 2 and the volume is increased\nby a factor of 8 ?\n\n0) P decreases by a factor of 16.\n\n1) P decreases by a factor of 4.\n\n2) P decreases by a factor of 2.\n\n3) P increases by a factor of 4.\n\nOriginal Answer [Incorrect]: The correct answer is 0. The ideal gas\nlaw is PV = nRT. If the temperature is increased by a factor of 2 and the\nvolume is increased by a factor of 8, then the pressure will decrease by a\nfactor of 16.\nStepback Question: What are the physics principles behind this\nquestion?\nPrinciples:\nIdeal gas law: PV = nRT, where P is the pressure, V is the volume, n is\nthe number of moles, R is the gas constant, and T is the temperature.\nFinal Answer: Using the Principles of Ideal gas law, we can solve the\nproblem as following:\n\nStep 1: Apply Ideal gas law to find out the pressure of an ideal gas. The\nideal gas law states that PV = nRT, where P is the pressure, V is the\nvolume, n is the number of moles, R is the gas constant, and T is the\ntemperature.\n\nStep 2: Apply Ideal gas law to find out the pressure of an ideal gas when\nthe temperature is increased by a factor of 2 and the volume is increased\nby a factor of 8. If the temperature is increased by a factor of 2, then T be-\ncomes 2T. If the volume is increased by a factor of 8, then V becomes 8V.\nSubstituting these values into the ideal gas law, we get: P(8V) = nR(2T)\nDividing both sides by 8V, we get: P= nR(2T)/8V\n\nWe can see that the pressure has decreased by a factor of 4.\n\nTherefore, the correct answer is 1) P decreases by a factor of 4.\n\nTable 25: Illustration of wins of STEP-BACK PROMPTING on the MMLU-Physics dataset.\n\n30\n", "vlm_text": "The table contains information on a dataset example from \"MMLU-Physics.\" It includes:\n\n- **Original Question:** Relating to the behavior of the pressure \\(P\\) of an ideal gas when the temperature and volume are increased by certain factors.\n- **Original Answer [Incorrect]:** States the incorrect answer choice as 0, with an explanation.\n- **Stepback Question:** Asks about the physics principles behind the question.\n- **Principles:** Outlines the ideal gas law \\(PV = nRT\\).\n- **Final Answer:** Provides steps to solve the problem using the ideal gas law, showing that the pressure decreases by a factor of 16 after the correct calculations.\nTherefore, the correct answer is 1) P decreases by a factor of 4. Table 25: Illustration of wins of S TEP -B ACK  P ROMPTING  on the MMLU-Physics dataset. \n"}
{"page": 30, "image_path": "doc_images/STEPBACK_30.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset\n\nexample\n\nMMLU-Physics\n\nOriginal Question: A liquid flows at a constant flow rate through a pipe\nwith circular cross-sections of varying diameters. At one point in the\npipe, the diameter is 2 cm and the flow speed is 18 m/s. What is the flow\nspeed at another point in this pipe, where the diameter is 3 cm?\n\n0) 4 m/s\n\n1) 6 m/s\n\n2) 8 m/s\n\n3) 12 m/s\n\nOriginal Answer [Incorrect]: The answer is 3) 12 m/s A step-by-step\nsolution is below: The flow rate is constant, so the product of the speed\nand the cross-sectional area is constant. The cross-sectional area is\nproportional to the square of the diameter, so the speed is inversely\nproportional to the square of the diameter. The ratio of the speeds is the\ninverse of the ratio of the squares of the diameters, so the speed at the\nsecond point is 18m/s * (2em/3cm)? = 12 m/s.\n\nStepback Question: What are the physics principles behind this\nquestion?\n\nPrinciples:\n\nConservation of Mass: the amount of mass flowing through the pipe at\ntwo different points must be equal, or Al * vl = A2 * v2, where A1 is\nthe area of cross-section one, v1 is the velocity at point 1, A2 is the area\nof cross-section two, v2 is the velocity at point 2.\n\nArea of Circle: A = 7 « r?, where r is the radius of the circle.\n\nFinal Answer: Using the Principles of Continuity equation, we can\nsolve the problem as following:\n\nStep 1: Apply the Continuity equation to find out the flow speed at\nanother point in this pipe. The continuity equation states that the product\nof the area and the velocity is constant at all points in a pipe. In this\nproblem, we are given the following information:\n\nAl = 7 * (2em)? = 4aem?\n\nvl =18 m/s\n\nA2 = 1 * (3cem)? = 9rem?\n\nWe can use the continuity equation to find v2:\nAl * v1 =A2 * v2\n\nArem? * 18m/s = 9mem? * v2\n\nv2 =8 m/s\n\nTherefore, the flow speed at another point in this pipe is 8 m/s.\nThe correct answer is 2) 8 m/s.\n\nTable 26: Illustration of wins of STEP-BACK PROMPTING on the MMLU-Physics dataset.\n\n31\n", "vlm_text": "dataset \nMMLU-Physics \nOriginal Question : A liquid flows at a constant flow rate through a pipe with circular cross-sections of varying diameters. At one point in the pipe, the diameter is   $2\\,\\mathrm{cm}$   and the flow speed is  $18\\;\\mathrm{m}/\\mathrm{s}$  . What is the flow speed at another point in this pipe, where the diameter is   $3\\,\\mathrm{cm}^{\\prime}$  ? 0)  $4\\:\\mathrm{m/s}$  1)  $6\\:\\mathrm{m/s}$  2)   $8\\;\\mathrm{m}/\\mathrm{s}$  3)   $12\\,\\mathrm{m/s}$  \nOriginal Answer [Incorrect] : The answer is 3)   $12\\,\\mathrm{m/s}$   A step-by-step solution is below: The flow rate is constant, so the product of the speed and the cross-sectional area is constant. The cross-sectional area is proportional to the square of the diameter, so the speed is inversely proportional to the square of the diameter. The ratio of the speeds is the inverse of the ratio of the squares of the diameters, so the speed at the second point is    $18m/s*(2\\bar{c m}/3c m)^{2}=12\\:\\mathrm{m/s}$  . \nStepback Question : What are the physics principles behind this question? \nPrinciples \nConservation of Mass: the amount of mass flowing through the pipe at two different points must be equal, or   $\\mathsf{A}1\\mathrm{\\Omega}^{*}\\,\\mathrm{v}1=\\mathrm{A}2\\mathrm{\\Omega}^{*}\\,\\mathrm{v}2$  , where A1 is the area of cross-section one, v1 is the velocity at point 1, A2 is the area of cross-section two, v2 is the velocity at point 2. \nArea of Circle:    $A=\\pi*r^{2}$  , where r is the radius of the circle. \nFinal Answer : Using the Principles of Continuity equation, we can solve the problem as following: \nStep 1: Apply the Continuity equation to find out the flow speed at another point in this pipe. The continuity equation states that the product of the area and the velocity is constant at all points in a pipe. In this problem, we are given the following information: \n\n$$\n\\begin{array}{l}{{A1=\\pi*(2c m)^{2}=4\\pi c m^{2}}}\\\\ {{\\mathrm{v1}=18\\,\\mathrm{m/s}}}\\\\ {{A2=\\pi*(3c m)^{2}=9\\pi c m^{2}}}\\end{array}\n$$\n \nTherefore, the flow speed at another point in this pipe is   $8\\,\\mathrm{\\m/s}$  . The correct answer is 2)  $8\\;\\mathrm{m}/\\mathrm{s}$  . "}
{"page": 31, "image_path": "doc_images/STEPBACK_31.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset\n\nexample\n\nMMLU-Physics\n\nOriginal Question: A 2 j.F capacitor is connected directly to a battery. When\nthe capacitor is fully charged, it stores 600 wC of charge. An experimenter\nreplaces the 2 F capacitor with three 18 jF capacitors in series connected to\nthe same battery. Once the capacitors are fully charged, what charge is stored\non each capacitor?\n\n0) 100 pC\n\n1) 200 pC\n\n2) 600 pC\n\n3) 1800 pC\n\nOriginal Answer [Incorrect]: The answer is 100 jC. The total capacitance of\nthe three 18 j.F capacitors in series is 1 /(1/18+1/18+1/18)=6 uF The\ncharge stored on the three capacitors in series is 6 4F * V = 600 pC. The charge\nstored on each capacitor is 600 uC / 3 = 200 pC.\n\nStepback Question: What are the physics principles behind this question?\nPrinciples:\n\nCapacitors: Q = C *V, where Q is the charge, C is the capacitance and V is the\nvoltage.\n\nCapacitors in series: C = 1 / (1/C1 + 1/C2 + ... + 1/Cn), where C is the\nequivalent capacitance and C1, C2, Cn are the capacitances of each capacitor.\nCapacitor in parallel: C = Cl + C2 +... + Cn, where C is the equivalent\ncapacitance and C1, C2, Cn are the capacitances of each capacitor.\n\nFinal Answer: Using the Principles of Capacitance and Capacitors in series,\nwe can solve the problem as following:\n\nStep 1: Apply Capacitance to find out the voltage of the battery.\n\nWe know that the capacitance of the 2 jF capacitor is 2 wF and the charge\nstored on the capacitor is 600 wC. Using the formula for capacitance, we can\nfind the voltage of the battery:\n\nC=Q/V\n2 uF = 600 wC/V\nV =300V\n\nStep 2: Apply Capacitors in series to find out the equivalent capacitance of the\nthree 18 F capacitors in series.\n\nWe know that the capacitance of each of the three capacitors is 18 uF. Using the\nformula for capacitors in series, we can find the equivalent capacitance of the\nthree capacitors:\n\n1/Ceg=1/C,+1/C24+1/C3\n\n1/Ceg = 1/18 wF+1/18 wF+1/18 pF\n\n1/Ceqg =3/18 pF\n\nCeq = 6 UF\n\nStep 3: Apply Capacitance to find out the charge stored on each capac-\nitor.\n\nWe know that the equivalent capacitance of the three capacitors is 6 F and the\nvoltage of the battery is 300 V. Using the formula for capacitance, we can find\nthe charge stored on each capacitor:\n\nC=Q/V\n6 uF =Q/300V\nQ= 1800 pC\n\nTherefore, the charge stored on each capacitor is 1800 wC. The correct\nanswer is 3) 1800 pC.\n\nTable 27: Illustration of wins of STEP-BACK PROMPTING on the MMLU-Physics dataset.\n\n32\n", "vlm_text": "Original Question : A 2    $\\mu\\mathrm{F}$   capacitor is connected directly to a battery. When the capacitor is fully charged, it stores   $600\\ \\mu\\mathrm{C}$   of charge. An experimenter replaces the  $2\\;\\mu\\mathrm{F}$   capacitor with three   $18\\;\\mu\\mathrm{F}$   capacitors in series connected to the same battery. Once the capacitors are fully charged, what charge is stored on each capacitor? 0)   $100\\;\\mu\\mathbf{C}$  1)   $200\\,\\mu\\mathrm{C}$  2)  $600\\;\\mu\\mathrm{C}$  3)   $1800\\,\\mu\\mathrm{C}$  \nOriginal Answer [Incorrect] :  The answer is  $100\\;\\mu\\mathrm{C}$  . The total capacitance of the three  $18\\ \\mu\\mathrm{F}$   capacitors in series is  $1\\mathrm{~/~}(1\\mathrm{~/~}18+1\\mathrm{~/~}18+1\\mathrm{~/~}18)=6\\mathrm{~}\\mu\\mathrm{F}.$   The charge stored on the three capacitors in series is  $6\\:\\mu\\mathrm{F}^{\\ast}\\mathrm{~V}=600\\:\\mu\\mathrm{C}$  . The charge stored on each capacitor is  $600\\;\\mu\\mathrm{C}⁄3=200\\;\\mu\\mathrm{C}$  . \nStepback Question : What are the physics principles behind this question? Principles : \nCapacitors:   ${\\mathrm{Q}}={\\mathrm{C}}^{*}{\\mathrm{V}},$   where  $\\mathrm{\\DeltaQ}$   is the charge,  $\\mathbf{C}$   is the capacitance and  $\\mathrm{v}$   is the voltage. \nCapacitors in series:   $\\mathbf{C}={1}\\mathbf{\\Omega}/$     $\\mathrm{(1/C1\\,+\\,1/C2\\,+\\,...~+\\,1/C n)}$  , where   $\\mathbf{C}$   is the equivalent capacitance and C1, C2, Cn are the capacitance s of each capacitor. Capacitor in parallel:   $\\mathsf{C}=\\mathsf{C}\\mathrm{1}+\\mathsf{C}\\mathrm{2}+\\ldots\\mathrm{~+~}\\mathsf{C}\\mathrm{n}$  , where   $\\mathbf{C}$   is the equivalent capacitance and C1, C2, Cn are the capacitance s of each capacitor. \nFinal Answer : Using the Principles of Capacitance and Capacitors in series, \n\n\nstored on the capacitor is  $600\\;\\mu\\mathrm{C}$  . Using the formula for capacitance, we can find the voltage of the battery: \n\n$$\n\\begin{array}{l}{\\mathbf{C}=\\mathbf{Q}\\,,\\,\\mathbf{V}}\\\\ {2\\,\\mu\\mathrm{F}=600\\,\\mu\\mathbf{C}\\,,\\,\\mathbf{V}}\\\\ {\\mathbf{V}=300\\,\\mathbf{V}}\\end{array}\n$$\n \nStep 2: Apply Capacitors in series to find out the equivalent capacitance of the three  $18\\;\\mu\\mathrm{F}$   capacitors in series. \nWe know that the capacitance of each of the three capacitors is   $18\\;\\mu\\mathrm{F}.$  . Using the formula for capacitors in series, we can find the equivalent capacitance of the three capacitors: \n\n$$\n\\begin{array}{l}{1\\:/\\:C_{e q}=1\\:/\\:C_{1}+1\\:/\\:C_{2}+1\\:/\\:C_{3}}\\\\ {1\\:/\\:C_{e q}=1\\:/\\:18\\:\\mu\\mathrm{F}+1\\:/\\:18\\:\\mu\\mathrm{F}+1\\:/\\:18\\:\\mu\\mathrm{F}}\\\\ {1\\:/\\:C_{e q}=3\\:/\\:18\\:\\mu\\mathrm{F}}\\\\ {C_{e q}=6\\:\\mu\\mathrm{F}}\\end{array}\n$$\n \nStep 3: Apply Capacitance to find out the charge stored on each capac- itor. \nWe know that the equivalent capacitance of the three capacitors is  $6\\:\\mu\\mathrm{F}$   and the voltage of the battery is  $300\\;\\mathrm{V}.$   Using the formula for capacitance, we can find the charge stored on each capacitor: \n ${\\bf C}={\\bf Q}\\,/\\,{\\bar{\\bf V}}$   $6\\:\\mu\\mathrm{F}=\\mathrm{Q}\\:/\\:300\\:\\mathrm{V}$   $\\mathsf{Q}=1800\\,\\mu\\mathsf{C}$  \nTherefore, the charge stored on each capacitor is   $1800\\ \\mu\\mathbf{C}$  . The correct answer is 3)   $1800\\;\\mu\\mathbf{C}$  . \nTable 27: Illustration of wins of S TEP -B ACK  P ROMPTING  on the MMLU-Physics dataset. "}
{"page": 32, "image_path": "doc_images/STEPBACK_32.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset\n\nexample\n\nMMLU-\nChemistry\n\nOriginal Question: Which of the following indicates that a reaction is\nspontaneous?\n\n0) at equilibrium there are more products than reactants\n\n1) the value of AG® is greater than zero\n\n2) the value of AS° is greater than zero\n\n3) the value of Keq is less than one\n\nOriginal Answer [Incorrect]: 2) the value of AS° is greater than zero.\n\nA reaction is spontaneous if the value of AS° is greater than zero. This is\nbecause a positive AS° indicates that the reaction results in an increase in\nentropy, which is a measure of disorder. A spontaneous reaction is one that\noccurs without the input of energy, and an increase in entropy is a natural\ntendency of the universe.\n\nStepback Question: What are the chemistry principles behind this question?\nPrinciples:\n\nSpontaneous reactions: A spontaneous reaction is a reaction that occurs without\nthe input of energy.\n\nFinal Answer: A reaction is spontaneous if the change in Gibbs free energy is\nnegative (AG < 0). The value of AG® is greater than zero indicates that the\nreaction is not spontaneous.\n\nThe correct answer is 0) at equilibrium there are more products than reactants.\n\nMMLU-\nChemistry\n\nOriginal Question: Potassium-40 is a minor isotope found in naturally oc-\ncurring potassium. It is radioactive and can be detected on simple radiation\ncounters. How many protons, neutrons, and electrons does potassium-40 have\nwhen it is part of K2S04?\n\n0) 21 neutrons, 19 protons, 18 electrons\n\n1) 20 neutrons, 19 protons, 19 electrons\n\n2) 21 neutrons, 19 protons, 19 electrons\n\n3) 19 neutrons, 19 protons, 19 electrons\n\nOriginal Answer [Incorrect]: The correct answer is 2).\n\nPotassium-40 has 19 protons and 21 neutrons. When it is part of K2SO4, it has\n19 electrons.\n\nStepback Question: What are the chemistry principles behind this question?\nPrinciples:\n\nAtomic number: The atomic number of an element is the number of protons in\nthe nucleus of an atom of that element.\n\nFinal Answer: The atomic number of potassium is 19, so all potassium atoms\nhave 19 protons. The mass number of potassium-40 is 40, so it has 40 - 19 =\n21 neutrons. When potassium is part of a compound, it loses one electron to\nbecome a potassium ion. Therefore, potassium-40 has 19 - 1 = 18 electrons\nwhen it is part of K2SO4.\n\nThe correct answer is 0) 21 neutrons, 19 protons, 18 electrons.\n\nTable 28: Illustration of wins of STEP-BACK PROMPTING on the MMLU-Chemistry dataset.\n\n33\n", "vlm_text": "The table includes an example related to chemistry concepts focusing on spontaneous reactions. \n\n- **Original Question**: The question asks which condition indicates a reaction is spontaneous, with four options provided.\n- **Original Answer [Incorrect]**: An incorrect answer is noted, suggesting a reaction is spontaneous if the change in entropy (\\(\\Delta S^\\circ\\)) is greater than zero. This explanation is followed by reasoning that a positive change in entropy implies increased disorder, which is a natural tendency, but it incorrectly associates this solely with spontaneity.\n- **Stepback Question**: A prompt for deeper analysis, asking about the key chemistry principles relevant to the question.\n- **Principles**: It notes that spontaneous reactions are defined as reactions that occur without energy input.\n- **Final Answer**: Corrects the misconception by explaining that a reaction is spontaneous if the change in Gibbs free energy (\\(\\Delta G\\)) is negative (\\(\\Delta G < 0\\)). It clarifies that a positive value of \\(\\Delta G^\\circ\\) indicates the reaction is not spontaneous.\nThe correct answer is 0) at equilibrium there are more products than reactants. \nOriginal Question : Potassium-40 is a minor isotope found in naturally oc- curring potassium. It is radioactive and can be detected on simple radiation counters. How many protons, neutrons, and electrons does potassium-40 have when it is part of K2SO4? 0) 21 neutrons, 19 protons, 18 electrons 1) 20 neutrons, 19 protons, 19 electrons 2) 21 neutrons, 19 protons, 19 electrons 3) 19 neutrons, 19 protons, 19 electrons Original Answer [Incorrect] :  The correct answer is 2). Potassium-40 has 19 protons and 21 neutrons. When it is part of K2SO4, it has 19 electrons. Stepback Question : What are the chemistry principles behind this question? Principles : Atomic number: The atomic number of an element is the number of protons in the nucleus of an atom of that element. Final Answer : The atomic number of potassium is 19, so all potassium atoms have 19 protons. The mass number of potassium-40 is 40, so it has  $40\\textrm{-}19=$  21 neutrons. When potassium is part of a compound, it loses one electron to become a potassium ion. Therefore, potassium-40 has   $19\\textrm{-}1=18$   electrons when it is part of K2SO4. The correct answer is 0) 21 neutrons, 19 protons, 18 electrons. "}
{"page": 33, "image_path": "doc_images/STEPBACK_33.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset example\n\nTimeQA Original Question: Carlos Ascues played for which team from 2013 to\n2014?\nOriginal Answer [Incorrect]: Carlos Ascues played for Benfica from\n2013 to 2014.\nStepback Question: Which teams did Carlos Ascues play for?\nFinal Answer [Correct]: From 2013 to 2014, Carlos Ascues played for\nthe Greek team Panetolikos.\n\nTimeQA Original Question: Seth Nana Twumasi played for which team between\nJan 2011 and Feb 2011?\nOriginal Answer [Incorrect]: Seth Nana Twumasi played for the FC\nHonka team between Jan 2011 and Feb 2011.\nStepback Question: Which teams did Seth Nana Twumasi play for?\nFinal Answer [Correct]: Northampton. He was on a loan transfer from\nPeterborough.\n\nTimeQA Original Question: What position did Carmel Hanna take in May 2002?\n\nOriginal Answer [Incorrect]: According to the article, Carmel Hanna\nwas appointed as Minister of State for Children and the Family in May\n2002. She held this position until 2005.\n\nStepback Question: What positions did Carmel Hanna hold?\n\nFinal Answer [Correct]: From the context, we can see that Carmel\nHanna was named minister of Employment and Learning (2001). We\ncan then infer that she held the position of Minister for Employment and\nLearning in May 2002.\n\nTable 29: Illustration of wins of STEP-BACK PROMPTING on the TimeQA dataset.\n\n34\n", "vlm_text": "The table contains examples from the TimeQA dataset. Each example includes:\n\n- **Original Question:** A question related to a specific fact or event.\n- **Original Answer [Incorrect]:** An incorrect answer provided initially.\n- **Stepback Question:** A follow-up question to reconsider the context.\n- **Final Answer [Correct]:** The correct answer established after clarification.\n\nAdditionally, some text is highlighted in red to indicate incorrect information."}
{"page": 34, "image_path": "doc_images/STEPBACK_34.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset\n\nexample\n\nSituatedQA\n\nOriginal Question: when was the last time miss texas won miss america\nas of November 29, 2010\n\nOriginal Answer [Incorrect]: Laura Leigh Covington was the last Miss\nTexas to win the Miss America competition. This happened in 2000.\nStepback Question: which years did miss texas win miss america\nFinal Answer [Correct]: According to Wikipedia, the last time Miss\nTexas won Miss America was in 1975.\n\nSituatedQA\n\nOriginal Question: when is the last time congress passed a complete\nbudget as of 2021\n\nOriginal Answer [Incorrect]: The last time Congress passed a complete\nbudget as of 2021 was on January 19, 2018.\n\nStepback Question: what are the years that congress passed a complete\nbudget as of 2021\n\nFinal Answer [Correct]: The last time Congress passed a complete bud-\nget as of 2021 was December 27, 2020, the Consolidated Appropriations\nAct, 2021.\n\nSituatedQA\n\nOriginal Question: when was the last time unc did not make the ncaa\ntournament as of 2003\n\nOriginal Answer [Incorrect]: The last time UNC did not make the\nNCAA tournament was 1990.\n\nStepback Question: which years did unc not make the ncaa tournament\nas of 2003\n\nFinal Answer [Correct]: The correct answer is 2002-03. The context\nshows the standings of North Carolina Tar Heels men’s basketball. From\nthe standings, we can see that this team has 19 wins and 16 losses. 19-16\nis not good enough to make the NCAA tournament, which is mentioned\nin the context. From the standings, we can also see that this is the\nstanding for 2002-03 season. So the last time UNC did not make the\nNCAA tournament as of 2003 is 2002-03.\n\nTable 30: Illustration of wins of STEP-BACK PROMPTING on the SituatedQA dataset.\n\n35\n", "vlm_text": "The table contains examples from the \"SituatedQA\" dataset. Each example includes:\n\n1. **Original Question**: The initial question posed.\n2. **Original Answer [Incorrect]**: An incorrect response to the question.\n3. **Stepback Question**: A follow-up question meant to refine the context of the original question.\n4. **Final Answer [Correct]**: The correct and refined answer based on the additional context.\n\nEach example illustrates the process of correcting an initial incorrect answer by revisiting the context through a stepback question, leading to a correct final answer."}
{"page": 35, "image_path": "doc_images/STEPBACK_35.jpg", "ocr_text": "Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\n\ndataset\n\nexample\n\nStrategyQA\n\nOriginal Question: Could you drive a Rowe 550 to the 2008 Summer\nOlympics?\n\nOriginal Answer [Incorrect]: The 2008 Summer Olympics was held in\nBeijing, China. The Rowe 550 is an all-electric car. The Rowe 550 has a\nrange of 70 miles on a single charge and a top speed of about 30 mph.\nThe distance between Beijing and the U.K. is about 4000 miles.\nStepback Question: What kind of vehicle is a Rowe 550?\n\nFinal Answer [Correct]: The Roewe 550 was released in 2008; the\n2008 Summer Olympics were held from August 8-24, 2008. So you\ncould drive a Rowe 550 to the 2008 Summer Olympics.\n\nStrategyQA\n\nOriginal Question: what channel does thursday night football come on\nregular tv as of 2017?\n\nOriginal Answer [Incorrect]: Thursday Night Football is a weekly\nseries of National Football League (NFL) games broadcast on Thursday\nnights. It started in 2006 on NFL Network. Under a new agreement\nbetween the NFL and CBS, CBS will air 50% of the Thursday Night\nFootball games and NFL Network will air the other 50%.\n\nStepback Question: which channel is thursday night football on as of\n2017?\n\nFinal Answer [Correct]: In 2017, Thursday Night Football was aired\non CBS, NBC, and NFL Network.\n\nStrategyQA\n\nOriginal Question: who is the present president of assam sahitya sabha\nas of 2018?\n\nOriginal Answer [Incorrect]: Dr. Nagen Saikia\n\nStepback Question: who lead assam sahitya sabha as of 2018?\n\nFinal Answer [Correct]: The answer is Paramananda Rajbongshi. As\nper a news from 2019, The Asam Sahitya Sabha, which was established\nin 1917, in Sibsagar, Assam, had got Paramananda Rajbongshi as its\npresident. So, as of 2018, the president of assam sahitya sabha is Para-\nmananda Rajbongshi.\n\nTable 31: Illustration of wins of STEP- BACK PROMPTING on the StrategyQA dataset.\n\n36\n", "vlm_text": "The table presents examples from the StrategyQA dataset. Each example includes:\n\n1. **Original Question**: The question initially posed.\n2. **Original Answer [Incorrect]**: An incorrect answer to the original question, with elaboration.\n3. **Stepback Question**: A clarifying question to better understand the context or requirement.\n4. **Final Answer [Correct]**: The correct answer provided after reevaluation.\n\nThe examples cover various topics, such as the feasibility of driving a specific car to the Olympics, televised sports programming, and leadership positions."}
