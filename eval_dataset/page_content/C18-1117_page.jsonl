{"page": 0, "image_path": "doc_images/C18-1117_0.jpg", "ocr_text": "Diachronic word embeddings and semantic shifts: a survey\n\nAndrey Kutuzov Lilja @vrelid Terrence Szymanski® Erik Velldal\nUniversity of Oslo, Norway\n{andreku | liljao | erikve}@ifi.uio.no\n° ANZ, Melbourne, Australia\nterry.szymanski@gmail.com\n\nAbstract\n\nRecent years have witnessed a surge of publications aimed at tracing temporal changes in lexical\nsemantics using distributional methods, particularly prediction-based word embedding models.\nHowever, this vein of research lacks the cohesion, common terminology and shared practices of\nmore established areas of natural language processing. In this paper, we survey the current state\nof academic research related to diachronic word embeddings and semantic shifts detection. We\nstart with discussing the notion of semantic shifts, and then continue with an overview of the\nexisting methods for tracing such time-related shifts with word embedding models. We propose\nseveral axes along which these methods can be compared, and outline the main challenges before\nthis emerging subfield of NLP, as well as prospects and possible applications.\n\n1 Introduction\n\nThe meanings of words continuously change over time, reflecting complicated processes in language and\nsociety. Examples include both changes to the core meaning of words (like the word gay shifting from\nmeaning ‘carefree’ to ‘homosexual’ during the 20th century) and subtle shifts of cultural associations\n(like Iraq or Syria being associated with the concept of ‘war’ after armed conflicts had started in these\ncountries). Studying these types of changes in meaning enables researchers to learn more about human\nlanguage and to extract temporal-dependent data from texts.\n\nThe availability of large corpora and the development of computational semantics have given rise to\na number of research initiatives trying to capture diachronic semantic shifts in a data-driven way. Re-\ncently, word embeddings (Mikolov et al., 2013b) have become a widely used input representation for\nthis task. There are dozens of papers on the topic, mostly published after 2011 (we survey them in\nSection 3 and further below). However, this emerging field is highly heterogenous. There are at least\nthree different research communities interested in it: natural language processing (and computational\nlinguistics), information retrieval (and computer science in general), and political science. This is re-\nflected in the terminology, which is far from being standardized. One can find mentions of ‘temporal\nembeddings,’ ‘diachronic embeddings,’ ‘dynamic embeddings,’ etc., depending on the background of a\nparticular research group. The present survey paper attempts to describe this diversity, introduce some\naxes of comparison and outline main challenges which the practitioners face. Figure 1 shows the timeline\nof events that influenced the research in this area: in the following sections we cover them in detail.\n\nThis survey is restricted in scope to research which traces semantic shifts using distributional word em-\nbedding models (that is, representing lexical meaning with dense vectors produced from co-occurrence\ndata). We only briefly mention other data-driven approaches also employed to analyze temporal-labeled\ncorpora (for example, topic modeling). Also, we do not cover syntactic shifts and other changes in the\nfunctions rather than meaning of words.\n\nThe paper is structured as follows. In Section 2 we introduce the notion of ‘semantic shift’ and pro-\nvide some linguistic background for it. Section 3 aims to compare different approaches to the task of\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License. License details: http: //\ncreativecommons.org/licenses/by/4.0/\n\n1384\n\nProceedings of the 27th International Conference on Computational Linguistics, pages 1384-1397\nSanta Fe, New Mexico, USA, August 20-26, 2018.\n", "vlm_text": "Diachronic word embeddings and semantic shifts: a survey \nAndrey Kutuzov Lilja Øvrelid Terrence Szymanski ♦ Erik Velldal \nUniversity of Oslo, Norway {andreku | liljao | erikve}@ifi.uio.no ♦ ANZ, Melbourne, Australia terry.szymanski@gmail.com \nAbstract \nRecent years have witnessed a surge of publications aimed at tracing temporal changes in lexical semantics using distributional methods, particularly prediction-based word embedding models. However, this vein of research lacks the cohesion, common terminology and shared practices of more established areas of natural language processing. In this paper, we survey the current state of academic research related to diachronic word embeddings and semantic shifts detection. We start with discussing the notion of semantic shifts, and then continue with an overview of the existing methods for tracing such time-related shifts with word embedding models. We propose several axes along which these methods can be compared, and outline the main challenges before this emerging subﬁeld of NLP, as well as prospects and possible applications. \n1 Introduction \nThe meanings of words continuously change over time, reﬂecting complicated processes in language and society. Examples include both changes to the core meaning of words (like the word  gay  shifting from meaning ‘carefree’ to ‘homosexual’ during the 20th century) and subtle shifts of cultural associations (like  Iraq  or  Syria  being associated with the concept of ‘war’ after armed conﬂicts had started in these countries). Studying these types of changes in meaning enables researchers to learn more about human language and to extract temporal-dependent data from texts. \nThe availability of large corpora and the development of computational semantics have given rise to a number of research initiatives trying to capture  diachronic semantic shifts  in a data-driven way. Re- cently,  word embeddings  (Mikolov et al., 2013b) have become a widely used input representation for this task. There are dozens of papers on the topic, mostly published after 2011 (we survey them in Section 3 and further below). However, this emerging ﬁeld is highly heterogenous. There are at least three different research communities interested in it: natural language processing (and computational linguistics), information retrieval (and computer science in general), and political science. This is re- ﬂected in the terminology, which is far from being standardized. One can ﬁnd mentions of ‘temporal embeddings,’ ‘diachronic embeddings,’ ‘dynamic embeddings,’ etc., depending on the background of a particular research group. The present survey paper attempts to describe this diversity, introduce some axes of comparison and outline main challenges which the practitioners face. Figure 1 shows the timeline of events that inﬂuenced the research in this area: in the following sections we cover them in detail. \nThis survey is restricted in scope to research which traces semantic shifts using distributional word em- bedding models (that is, representing lexical meaning with dense vectors produced from co-occurrence data). We only brieﬂy mention other data-driven approaches also employed to analyze temporal-labeled corpora (for example, topic modeling). Also, we do not cover syntactic shifts and other changes in the functions rather than meaning of words. \nThe paper is structured as follows. In Section 2 we introduce the notion of ‘semantic shift’ and pro- vide some linguistic background for it. Section 3 aims to compare different approaches to the task of "}
{"page": 1, "image_path": "doc_images/C18-1117_1.jpg", "ocr_text": "S s s\ns » &\nRJ Ss SS\nSS SS we\nS 3 Sk\nSs es Pt\ns S ws SS Os\ns oP s ee\n> Ry ww os OS\n= Ss N wo Ph OS\n& PP SS LD Bs\ns Re) s SF TF oer Se”\n& & ss os PF FFF SEF\noy\nss es OS, s se Sy PX os\n\no, -€ €-€  Sceccsce\n\nFigure 1: Distributional models in the task of tracing diachronic semantic shifts: research timeline\n\nautomatic detection of semantic shifts: in the choice of diachronic data, evaluation strategies, methodol-\nogy of extracting semantic shifts from data, and the methods to compare word vectors across time spans.\nSections 4 and 5 describe two particularly interesting results of diachronic embeddings research: namely,\nthe statistical laws of semantic change and temporal semantic relations. In Section 6 we outline possible\napplications of systems that trace semantic shifts. Section 7 presents open challenges which we believe\nto be most important for the field, and in Section 8 we summarize and conclude.\n\n2 The concept of semantic shifts\n\nHuman languages change over time, due to a variety of linguistic and non-linguistic factors and at all\nlevels of linguistic analysis. In the field of theoretical (diachronic) linguistics, much attention has been\ndevoted to expressing regularities of linguistic change. For instance, laws of phonological change have\nbeen formulated (e.g., Grimm’s law or the great vowel shift) to account for changes in the linguistic sound\nsystem. When it comes to lexical semantics, linguists have studied the evolution of word meaning over\ntime, describing so-called lexical semantic shifts or semantic change, which Bloomfield (1933) defines\nas “innovations which change the lexical meaning rather than the grammatical function of a form.”\n\nHistorically, much of the theoretical work on semantic shifts has been devoted to documenting and\ncategorizing various types of semantic shifts (Bréal, 1899; Stern, 1931; Bloomfield, 1933). The cat-\negorization found in Bloomfield (1933) is arguably the most used and has inspired a number of more\nrecent studies (Blank and Koch, 1999; Geeraerts, 1997; Traugott and Dasher, 2001). Bloomfield (1933)\noriginally proposed nine classes of semantic shifts, six of which are complimentary pairs along a di-\nmension. For instance, the pair ‘narrowing’ — ‘broadening’ describes the observation that word meaning\noften changes to become either more specific or more general, e.g. Old English mete ‘food’ becomes\nEnglish meat ‘edible flesh,’ or that the more general English word dog is derived from Middle English\ndogge which described a dog of a particular breed. Bloomfield (1933) also describes change along the\nspectrum from positive to negative, describing the speaker’s attitude as one of either degeneration or\nelevation, e.g. from Old English cniht ’boy, servant’ to the more elevated knight.\n\nThe driving forces of semantic shifts are varied, but include linguistic, psychological, sociocultural\nor cultural/encyclopedic causes (Blank and Koch, 1999; Grzega and Schoener, 2007). Linguistic pro-\ncesses that cause semantic shifts generally involve the interaction between words of the vocabulary and\ntheir meanings. This may be illustrated by the process of ellipsis, whereby the meaning of one word is\ntransferred to a word with which it frequently co-occurs, or by the need for discrimination of synonyms\ncaused by lexical borrowings from other languages. Semantic shifts may be also be caused by changes\nin the attitudes of speakers or in the general environment of the speakers. Thus, semantic shifts are natu-\nrally separated into two important classes: linguistic drifts (slow and regular changes in core meaning of\nwords) and cultural shifts (culturally determined changes in associations of a given word). Researchers\nstudying semantic shifts from a computational point of view have shown the existence of this division\nempirically (Hamilton et al., 2016c). In the traditional classification of Stern (1931), the semantic shift\ncategory of substitution describes a change that has a non-linguistic cause, namely that of technologi-\n\n1385\n", "vlm_text": "The image is a timeline chart that illustrates key milestones in the field of distributional models aimed at tracing diachronic semantic shifts from 2010 to 2017. It includes notable developments such as:\n\n- 2010: Introduction of the \"Time tensor with Random Indexing\".\n- 2011: Exploration using the \"Google Ngrams corpus\".\n- 2012: Work on \"Word epoch disambiguation\".\n- 2013: Advancements in \"Prediction-based models\".\n- 2014: Use of \"Word embeddings\" with the example of \"word2vec\".\n- 2015: Development of \"Models alignment\".\n- 2016: Analysis using \"NYT corpus\" and \"COHA corpus\".\n- 2017: Insights into \"Laws of semantic change\", \"Local measures better for cultural shifts\", \"Gigaword corpus\", \"Diachronic relations\", and \"Criticism of semantic change laws\". Also, \"Joint learning across time spans\" is noted in 2017.\n\nThe timeline captures the evolution of methodologies and datasets used in studying how word meanings change over time.\nautomatic detection of semantic shifts: in the choice of diachronic data, evaluation strategies, methodol- ogy of extracting semantic shifts from data, and the methods to compare word vectors across time spans. Sections 4 and 5 describe two particularly interesting results of diachronic embeddings research: namely, the statistical laws of semantic change and temporal semantic relations. In Section 6 we outline possible applications of systems that trace semantic shifts. Section 7 presents open challenges which we believe to be most important for the ﬁeld, and in Section 8 we summarize and conclude. \n2 The concept of semantic shifts \nHuman languages change over time, due to a variety of linguistic and non-linguistic factors and at all levels of linguistic analysis. In the ﬁeld of theoretical (diachronic) linguistics, much attention has been devoted to expressing regularities of linguistic change. For instance, laws of phonological change have been formulated (e.g., Grimm’s law or the great vowel shift) to account for changes in the linguistic sound system. When it comes to lexical semantics, linguists have studied the evolution of word meaning over time, describing so-called lexical  semantic shifts  or  semantic change , which Bloomﬁeld (1933) deﬁnes as “innovations which change the lexical meaning rather than the grammatical function of a form.” \nHistorically, much of the theoretical work on semantic shifts has been devoted to documenting and categorizing various types of semantic shifts (Bréal, 1899; Stern, 1931; Bloomﬁeld, 1933). The cat- egorization found in Bloomﬁeld (1933) is arguably the most used and has inspired a number of more recent studies (Blank and Koch, 1999; Geeraerts, 1997; Traugott and Dasher, 2001). Bloomﬁeld (1933) originally proposed nine classes of semantic shifts, six of which are complimentary pairs along a di- mension. For instance, the pair ‘narrowing’ – ‘broadening’ describes the observation that word meaning often changes to become either more speciﬁc or more general, e.g. Old English  mete  ‘food’ becomes English  meat  ‘edible ﬂesh,’ or that the more general English word  dog  is derived from Middle English dogge  which described a dog of a particular breed. Bloomﬁeld (1933) also describes change along the spectrum from positive to negative, describing the speaker’s attitude as one of either degeneration or elevation, e.g. from Old English  cniht  ’boy, servant’ to the more elevated  knight . \nThe driving forces of semantic shifts are varied, but include linguistic, psychological, sociocultural or cultural/encyclopedic causes (Blank and Koch, 1999; Grzega and Schoener, 2007). Linguistic pro- cesses that cause semantic shifts generally involve the interaction between words of the vocabulary and their meanings. This may be illustrated by the process of ellipsis, whereby the meaning of one word is transferred to a word with which it frequently co-occurs, or by the need for discrimination of synonyms caused by lexical borrowings from other languages. Semantic shifts may be also be caused by changes in the attitudes of speakers or in the general environment of the speakers. Thus, semantic shifts are natu- rally separated into two important classes: linguistic drifts (slow and regular changes in core meaning of words) and cultural shifts (culturally determined changes in associations of a given word). Researchers studying semantic shifts from a computational point of view have shown the existence of this division empirically (Hamilton et al., 2016c). In the traditional classiﬁcation of Stern (1931), the semantic shift category of  substitution  describes a change that has a non-linguistic cause, namely that of technologi- cal progress. This may be exempliﬁed by the word  car  which shifted its meaning from non-motorized vehicles after the introduction of the automobile. "}
{"page": 2, "image_path": "doc_images/C18-1117_2.jpg", "ocr_text": "cal progress. This may be exemplified by the word car which shifted its meaning from non-motorized\nvehicles after the introduction of the automobile.\n\nThe availability of large corpora have enabled the development of new methodologies for the study\nof lexical semantic shifts within general linguistics (Traugott, 2017). A key assumption in much of this\nwork is that changes in a word’s collocational patterns reflect changes in word meaning (Hilpert, 2008),\nthus providing a usage-based account of semantics (Gries, 1999). For instance, Kerremans et al. (2010)\nstudy the very recent neologism detweet, showing the development of two separate usages/meanings\nfor this word (‘to delete from twitter, vs ‘to avoid tweeting’) based on large amounts of web-crawled\ndata. The usage-based view of lexical semantics aligns well with the assumptions underlying the distri-\nbutional semantic approach (Firth, 1957) often employed in NLP . Here, the time spans studied are often\nconsiderably shorter (decades, rather than centuries) and we find that these distributional methods seem\nwell suited for monitoring the gradual process of meaning change. Gulordava and Baroni (2011), for\ninstance, showed that distributional models capture cultural shifts, like the word sleep acquiring more\nnegative connotations related to sleep disorders, when comparing its 1960s contexts to its 1990s contexts.\n\nTo sum up, semantic shifts are often reflected in large corpora through change in the context of the\nword which is undergoing a shift, as measured by co-occurring words. It is thus natural to try to detect\nsemantic shifts automatically, in a ‘data-driven’ way. This vein of research is what we cover in the present\nsurvey. In the following sections, we overview the methods currently used for the automatic detection of\nsemantic shifts and the recent academic achievements related to this problem.\n\n3 Tracing semantic shifts distributionally\n\nConceptually, the task of discovery of semantic shifts from data can be formulated as follows. Given\ncorpora [C), C2, ...C,] containing texts created in time periods [1,2,...n], the task is to locate words\nwith different meaning in different time periods, or to locate the words which changed most. Other\nrelated tasks are possible: discovering general trends in semantic shifts (see Section 4) or tracing the\ndynamics of the relationships between words (see Section 5). In the next subsections, we address several\naxes along which one can categorize the research on detecting semantic shifts with distributional models.\n\n3.1 Sources of diachronic data for training and testing\n\nWhen automatically detecting semantic shifts, the types of generalizations we will be able to infer are\ninfluenced by properties of the textual data being used, such as the source of the datasets and the temporal\ngranularity of the data. In this subsection we discuss the data choices made by researchers (of course,\nnot pretending to cover the whole range of the diachronic corpora used).\n\n3.1.1 Training data\n\nThe time unit (the granularity of the temporal dimension) can be chosen before slicing the text collection\ninto subcorpora. Earlier works dealt mainly with long-term semantic shifts (spanning decades or even\ncenturies), as they are easier to trace. One of the early examples is Sagi et al. (2011) who studied\ndifferences between Early Middle, Late Middle and Early Modern English, using the Helsinki Corpus\n(Rissanen and others, 1993).\n\nThe release of the Google Books Ngrams corpus! played an important role in the development of\nthe field and spurred work on the new discipline of ‘culturomics,’ studying human culture through dig-\nital media (Michel et al., 2011). Mihalcea and Nastase (2012) used this dataset to detect differences\nin word usage and meaning across 50-years time spans, while Gulordava and Baroni (2011) compared\nword meanings in the 1960s and in the 1990s, achieving good correlation with human judgments. Un-\nfortunately, Google Ngrams is inherently limited in that it does not contain full texts. However, for\nmany cases, this corpus was enough, and its usage as the source of diachronic data continued in Mitra\net al. (2014) (employing syntactic ngrams), who detected word sense changes over several different time\nperiods spanning from 3 to 200 years.\n\n‘https: //books.google.com/ngrams\n\n1386\n", "vlm_text": "\nThe availability of large corpora have enabled the development of new methodologies for the study of lexical semantic shifts within general linguistics (Traugott, 2017). A key assumption in much of this work is that changes in a word’s collocational patterns reﬂect changes in word meaning (Hilpert, 2008), thus providing a usage-based account of semantics (Gries, 1999). For instance, Kerremans et al. (2010) study the very recent neologism  detweet , showing the development of two separate usages/meanings for this word (‘to delete from twitter,’ vs ‘to avoid tweeting’) based on large amounts of web-crawled data. The usage-based view of lexical semantics aligns well with the assumptions underlying the distri- butional semantic approach (Firth, 1957) often employed in NLP . Here, the time spans studied are often considerably shorter (decades, rather than centuries) and we ﬁnd that these distributional methods seem well suited for monitoring the gradual process of meaning change. Gulordava and Baroni (2011), for instance, showed that distributional models capture cultural shifts, like the word  sleep  acquiring more negative connotations related to sleep disorders, when comparing its 1960s contexts to its 1990s contexts. \nTo sum up, semantic shifts are often reﬂected in large corpora through change in the context of the word which is undergoing a shift, as measured by co-occurring words. It is thus natural to try to detect semantic shifts automatically, in a ‘data-driven’ way. This vein of research is what we cover in the present survey. In the following sections, we overview the methods currently used for the automatic detection of semantic shifts and the recent academic achievements related to this problem. \n3 Tracing semantic shifts distribution ally \nConceptually, the task of discovery of semantic shifts from data can be formulated as follows. Given corpora    $[C_{1},C_{2},...C_{n}]$   containing texts created in time periods    $[1,2,...n]$  , the task is to locate words with different meaning in different time periods, or to locate the words which changed most. Other related tasks are possible: discovering general trends in semantic shifts (see Section 4) or tracing the dynamics of the relationships between words (see Section 5). In the next subsections, we address several axes along which one can categorize the research on detecting semantic shifts with distributional models. \n3.1 Sources of diachronic data for training and testing \nWhen automatically detecting semantic shifts, the types of generalizations we will be able to infer are inﬂuenced by properties of the textual data being used, such as the source of the datasets and the temporal granularity of the data. In this subsection we discuss the data choices made by researchers (of course, not pretending to cover the whole range of the diachronic corpora used). \n3.1.1 Training data \nThe time unit (the granularity of the temporal dimension) can be chosen before slicing the text collection into subcorpora. Earlier works dealt mainly with long-term semantic shifts (spanning decades or even centuries), as they are easier to trace. One of the early examples is Sagi et al. (2011) who studied differences between Early Middle, Late Middle and Early Modern English, using the Helsinki Corpus (Rissanen and others, 1993). \nThe release of the Google Books Ngrams corpus 1   played an important role in the development of the ﬁeld and spurred work on the new discipline of ‘culturomics,’ studying human culture through dig- ital media (Michel et al., 2011). Mihalcea and Nastase (2012) used this dataset to detect differences in word usage and meaning across 50-years time spans, while Gulordava and Baroni (2011) compared word meanings in the 1960s and in the 1990s, achieving good correlation with human judgments. Un- fortunately, Google Ngrams is inherently limited in that it does not contain full texts. However, for many cases, this corpus was enough, and its usage as the source of diachronic data continued in Mitra et al. (2014) (employing syntactic ngrams), who detected word sense changes over several different time periods spanning from 3 to 200 years. "}
{"page": 3, "image_path": "doc_images/C18-1117_3.jpg", "ocr_text": "In more recent work, time spans tend to decrease in size and become more granular. In general,\ncorpora with smaller time spans are useful for analyzing socio-cultural semantic shifts, while corpora\nwith longer spans are necessary for the study of linguistically motivated semantic shifts. As researchers\nare attempting to trace increasingly subtle cultural semantic shifts (more relevant for practical tasks),\nthe granularity of time spans is decreasing: for example, Kim et al. (2014) and Liao and Cheng (2016)\nanalyzed the yearly changes of words. Note that, instead of using granular ‘bins’, time can also be\nrepresented as a continuous differentiable value (Rosenfeld and Erk, 2018).\n\nIn addition to the Google Ngrams dataset (with granularity of 5 years), Kulkarni et al. (2015) used\nAmazon Movie Reviews (with granularity of 1 year) and Twitter data (with granularity of 1 month).\nTheir results indicated that computational methods for the detection of semantic shifts can be robustly\napplied to time spans less than a decade. Zhang et al. (2015) used another yearly text collection, the\nNew-York Times Annotated Corpus (Sandhaus, 2008), again managing to trace subtle semantic shifts.\nThe same corpus was employed by Szymanski (2017), with 21 separate models, one for each year from\n1987 to 2007, and to some extent by Yao et al. (2018), who crawled the NYT web site to get 27 yearly\nsubcorpora (from 1990 to 2016). The inventory of diachronic corpora used in tracing semantic shifts\nwas expanded by Eger and Mehler (2016), who used the Corpus of Historical American (COHA?), with\ntime slices equal to one decade. Hamilton et al. (2016a) continued the usage of COHA (along with\nthe Google Ngrams corpus). Kutuzov et al. (2017b) started to employ the yearly slices of the English\nGigaword corpus (Parker et al., 2011) in the analysis of cultural semantic drift related to armed conflicts.\n\n3.1.2 Test sets\n\nDiachronic corpora are needed not only as a source of training data for developing semantic shift de-\ntection systems, but also as a source of fest sets to evaluate such systems. In this case, however, the\nsituation is more complicated. Ideally, diachronic approaches should be evaluated on human-annotated\nlists of semantically shifted words (ranked by the degree of the shift). However, such gold standard data\nis difficult to obtain, even for English, let alone for other languages. General linguistics research on\nlanguage change like that of Traugott and Dasher (2001) and others usually contain only a small number\nof hand-picked examples, which is not sufficient to properly evaluate an automatic unsupervised system.\n\nVarious ways of overcoming this problem have been proposed. For example, Mihalcea and Nastase\n(2012) evaluated the ability of a system to detect the time span that specific contexts of a word undergoing\na shift belong to (word epoch disambiguation). A similar problem was offered as SemEval-2015 Task 7:\n‘Diachronic Text Evaluation’ (Popescu and Strapparava, 2015). Another possible evaluation method is\nso-called cross-time alignment, where a system has to find equivalents for certain words in different time\nperiods (for example, ‘Obama’ in 2015 corresponds to ‘Trump’ in 2017). There exist several datasets\ncontaining such temporal equivalents for English (Yao et al., 2018). Yet another evaluation strategy is\nto use the detected diachronic semantic shifts to trace or predict real-world events like armed conflicts\n(Kutuzov et al., 2017b). Unfortunately, all these evaluation methods still require the existence of large\nmanually annotated semantic shift datasets. The work to properly create and curate such datasets is in its\ninfancy.\n\nOne reported approach to avoid this requirement is borrowed from research on word sense disambigua-\ntion and consists of making a synthetic task by merging two real words together and then modifying the\ntraining and test data according to a predefined sense-shifting function. Rosenfeld and Erk (2018) suc-\ncessfully employed this approach to evaluate their system; however, it still operates on synthetic words,\nlimiting the ability of this evaluation scheme to measure the models’ performance with regards to real\nsemantic shift data. Thus, the problem of evaluating semantic shift detection approaches is far from be-\ning solved, and practitioners often rely on self-created test sets, or even simply manually inspecting the\nresults.\n\n3.2 Methodology of extracting semantic shifts from data\n\nAfter settling on a diachronic data set to be used in the system, one has to choose the methods to analyze\nit. Before the broad adoption of word embedding models, it was quite common to use change in raw\n\n*http://corpus.byu.edu/coha/\n\n1387\n", "vlm_text": "In more recent work, time spans tend to decrease in size and become more granular. In general, corpora with smaller time spans are useful for analyzing socio-cultural semantic shifts, while corpora with longer spans are necessary for the study of linguistically motivated semantic shifts. As researchers are attempting to trace increasingly subtle cultural semantic shifts (more relevant for practical tasks), the granularity of time spans is decreasing: for example, Kim et al. (2014) and Liao and Cheng (2016) analyzed the  yearly  changes of words. Note that, instead of using granular ‘bins’, time can also be represented as a continuous differentiable value (Rosenfeld and Erk, 2018). \nIn addition to the Google Ngrams dataset (with granularity of 5 years), Kulkarni et al. (2015) used Amazon Movie Reviews (with granularity of 1 year) and Twitter data (with granularity of 1 month). Their results indicated that computational methods for the detection of semantic shifts can be robustly applied to time spans less than a decade. Zhang et al. (2015) used another yearly text collection, the New-York Times Annotated Corpus (Sandhaus, 2008), again managing to trace subtle semantic shifts. The same corpus was employed by Szymanski (2017), with 21 separate models, one for each year from 1987 to 2007, and to some extent by Yao et al. (2018), who crawled the NYT web site to get 27 yearly subcorpora (from 1990 to 2016). The inventory of diachronic corpora used in tracing semantic shifts was expanded by Eger and Mehler (2016), who used the Corpus of Historical American   $(\\mathrm{{COHA}}^{2})$  ), with time slices equal to one decade. Hamilton et al. (2016a) continued the usage of COHA (along with the Google Ngrams corpus). Kutuzov et al. (2017b) started to employ the yearly slices of the English Gigaword corpus (Parker et al., 2011) in the analysis of cultural semantic drift related to armed conﬂicts. \n3.1.2 Test sets \nDiachronic corpora are needed not only as a source of  training  data for developing semantic shift de- tection systems, but also as a source of  test  sets to evaluate such systems. In this case, however, the situation is more complicated. Ideally, diachronic approaches should be evaluated on human-annotated lists of semantically shifted words (ranked by the degree of the shift). However, such gold standard data is difﬁcult to obtain, even for English, let alone for other languages. General linguistics research on language change like that of Traugott and Dasher (2001) and others usually contain only a small number of hand-picked examples, which is not sufﬁcient to properly evaluate an automatic unsupervised system. \nVarious ways of overcoming this problem have been proposed. For example, Mihalcea and Nastase (2012) evaluated the ability of a system to detect the time span that speciﬁc contexts of a word undergoing a shift belong to ( word epoch disambiguation ). A similar problem was offered as SemEval-2015 Task 7: ‘Diachronic Text Evaluation’ (Popescu and Strapparava, 2015). Another possible evaluation method is so-called cross-time alignment, where a system has to ﬁnd equivalents for certain words in different time periods (for example, ‘Obama’ in 2015 corresponds to ‘Trump’ in 2017). There exist several datasets containing such temporal equivalents for English (Yao et al., 2018). Yet another evaluation strategy is to use the detected diachronic semantic shifts to trace or predict real-world events like armed conﬂicts (Kutuzov et al., 2017b). Unfortunately, all these evaluation methods still require the existence of large manually annotated semantic shift datasets. The work to properly create and curate such datasets is in its infancy. \nOne reported approach to avoid this requirement is borrowed from research on word sense disambigua- tion and consists of making a synthetic task by merging two real words together and then modifying the training and test data according to a predeﬁned sense-shifting function. Rosenfeld and Erk (2018) suc- cessfully employed this approach to evaluate their system; however, it still operates on synthetic words, limiting the ability of this evaluation scheme to measure the models’ performance with regards to real semantic shift data. Thus, the problem of evaluating semantic shift detection approaches is far from be- ing solved, and practitioners often rely on self-created test sets, or even simply manually inspecting the results. \n3.2 Methodology of extracting semantic shifts from data \nAfter settling on a diachronic data set to be used in the system, one has to choose the methods to analyze it. Before the broad adoption of word embedding models, it was quite common to use change in raw word frequencies in order to trace semantic shifts or other kinds of linguistic change; see, among others, Juola (2003), Hilpert and Gries (2009), Michel et al. (2011), Lijfﬁjt et al. (2012), or Choi and Varian (2012) for frequency analysis of words in web search queries. Researchers also studied the increase or decrease in the frequency of a word    $A$   collocating with another word    $B$   over time, and based on this inferred changes in the meaning of  $A$   (Heyer et al., 2009). "}
{"page": 4, "image_path": "doc_images/C18-1117_4.jpg", "ocr_text": "word frequencies in order to trace semantic shifts or other kinds of linguistic change; see, among others,\nJuola (2003), Hilpert and Gries (2009), Michel et al. (2011), Lijffijt et al. (2012), or Choi and Varian\n(2012) for frequency analysis of words in web search queries. Researchers also studied the increase or\ndecrease in the frequency of a word A collocating with another word B over time, and based on this\ninferred changes in the meaning of A (Heyer et al., 2009).\n\nHowever, it is clear that semantic shifts are not always accompanied with changes in word frequency\n(or this connection may be very subtle and non-direct). Thus, if one were able to more directly model\nword meaning, such an approach should be superior to frequency-proxied methods. A number of recent\npublications have showed that distributional word representations (Turney et al., 2010; Baroni et al.,\n2014) provide an efficient way to solve these tasks. They represent meaning with sparse or dense (em-\nbedding) vectors, produced from word co-occurrence counts. Although conceptually the source of the\ndata for these models is still word frequencies, they ‘compress’ this information into continuous lexical\nrepresentations which are both efficient and convenient to work with. Indeed, Kulkarni et al. (2015)\nexplicitly demonstrated that distributional models outperform the frequency-based methods in detecting\nsemantic shifts. They managed to trace semantic shifts more precisely and with greater explanatory\npower. One of the examples from their work is the semantic evolution of the word gay: through time, its\nnearest semantic neighbors changed, manifesting the gradual move away from the sense of ‘cheerful’ to\nthe sense of ‘homosexual.’\n\nIn fact, distributional models were being used in diachronic research long before the paper of Kulkarni\net al. (2015), although there was no rigorous comparison to the frequentist methods. Already in 2009, it\nwas proposed that one can use distributional methods to detect semantic shifts in a quantitative way. The\npioneering work by Jurgens and Stevens (2009) described an insightful conceptualization of a sequence\nof distributional model updates through time: it is effectively a Word:Semantic Vector:Time tensor, in\nthe sense that each word in a distributional model possesses a set of semantic vectors for each time span\nwe are interested in. It paved the way for quantitatively comparing not only words with regard to their\nmeaning, but also different stages in the development of word meaning over time.\n\nJurgens and Stevens (2009) employed the Random Indexing (RI) algorithm (Kanerva et al., 2000) to\ncreate word vectors. Two years later, Gulordava and Baroni (2011) used explicit count-based models,\nconsisting of sparse co-occurrence matrices weighted by Local Mutual Information, while Sagi et al.\n(2011) turned to Latent Semantic Analysis (Deerwester et al., 1990). In Basile et al. (2014), an extension\nto RI dubbed Temporal Random Indexing (TRI) was proposed. However, no quantitative evaluation\nof this approach was offered (only a few hand-picked examples based on the Italian texts from the\nGutenberg Project), and thus it is unclear whether TRI is any better than other distributional models\nfor the task of semantic shift detection.\n\nFurther on, the diversity of the employed methods started to increase. For example, Mitra et al.\n(2014) analyzed clusters of the word similarity graph in the subcorpora corresponding to different time\nperiods. Their distributional model consisted of lexical nodes in the graphs connected with weighted\nedges. The weights corresponded to the number of shared most salient syntactic dependency contexts,\nwhere saliency was determined by co-occurrence counts scaled by Mutual Information (MI). Importantly,\nthey were able to detect not only the mere fact of a semantic shift, but also its type: the birth of a new\nsense, splitting of an old sense into several new ones, or merging of several senses into one. Thus, this\nwork goes into a much less represented class of ‘fine-grained’ approaches to semantic shift detection.\nIt is also important that Mitra et al. (2014) handle natively the issue of polysemous words, putting the\nmuch-neglected problem of word senses in the spotlight.\n\nThe work of Kim et al. (2014) was seminal in the sense that it is arguably the first one employing\nprediction-based word embedding models to trace diachronic semantic shifts. Particularly, they used\nincremental updates (see below) and Continuous Skipgram with negative sampling (SGNS) (Mikolov\net al., 2013a).> Hamilton et al. (2016a) showed the superiority of SGNS over explicit PPMI-based\ndistributional models in semantic shifts analysis, although they noted that low-rank SVD approximations\n(Bullinaria and Levy, 2007) can perform on par with SGNS, especially on smaller datasets. Since then,\n\n3Continuous Bag-of-Words (CBOW) from the same paper is another popular choice for learning semantic vectors.\n\n1388\n", "vlm_text": "\nHowever, it is clear that semantic shifts are not always accompanied with changes in word frequency (or this connection may be very subtle and non-direct). Thus, if one were able to more directly model word meaning, such an approach should be superior to frequency-proxied methods. A number of recent publications have showed that  distributional word representations  (Turney et al., 2010; Baroni et al., 2014) provide an efﬁcient way to solve these tasks. They represent meaning with sparse or dense (em- bedding) vectors, produced from word co-occurrence counts. Although conceptually the source of the data for these models is still word frequencies, they ‘compress’ this information into continuous lexical representations which are both efﬁcient and convenient to work with. Indeed, Kulkarni et al. (2015) explicitly demonstrated that distributional models outperform the frequency-based methods in detecting semantic shifts. They managed to trace semantic shifts more precisely and with greater explanatory power. One of the examples from their work is the semantic evolution of the word  gay : through time, its nearest semantic neighbors changed, manifesting the gradual move away from the sense of ‘cheerful’ to the sense of ‘homosexual.’ \nIn fact, distributional models were being used in diachronic research long before the paper of Kulkarni et al. (2015), although there was no rigorous comparison to the frequentist methods. Already in 2009, it was proposed that one can use distributional methods to detect semantic shifts in a quantitative way. The pioneering work by Jurgens and Stevens (2009) described an insightful conceptualization of a sequence of distributional model updates through time: it is effectively a Word:Semantic Vector:Time tensor, in the sense that each word in a distributional model possesses a set of semantic vectors for each time span we are interested in. It paved the way for quantitatively comparing not only words with regard to their meaning, but also different stages in the development of word meaning over time. \nJurgens and Stevens (2009) employed the  Random Indexing  (RI) algorithm (Kanerva et al., 2000) to create word vectors. Two years later, Gulordava and Baroni (2011) used explicit count-based models, consisting of sparse co-occurrence matrices weighted by Local Mutual Information, while Sagi et al. (2011) turned to Latent Semantic Analysis (Deerwester et al., 1990). In Basile et al. (2014), an extension to RI dubbed  Temporal Random Indexing  (TRI) was proposed. However, no quantitative evaluation of this approach was offered (only a few hand-picked examples based on the Italian texts from the Gutenberg Project ), and thus it is unclear whether TRI is any better than other distributional models for the task of semantic shift detection. \nFurther on, the diversity of the employed methods started to increase. For example, Mitra et al. (2014) analyzed clusters of the word similarity graph in the subcorpora corresponding to different time periods. Their distributional model consisted of lexical nodes in the graphs connected with weighted edges. The weights corresponded to the number of shared most salient syntactic dependency contexts, where saliency was determined by co-occurrence counts scaled by Mutual Information (MI). Importantly, they were able to detect not only the mere fact of a semantic shift, but also its type: the birth of a new sense, splitting of an old sense into several new ones, or merging of several senses into one. Thus, this work goes into a much less represented class of ‘ﬁne-grained’ approaches to semantic shift detection. It is also important that Mitra et al. (2014) handle natively the issue of polysemous words, putting the much-neglected problem of word senses in the spotlight. \nThe work of Kim et al. (2014) was seminal in the sense that it is arguably the ﬁrst one employing prediction-based word embedding models  to trace diachronic semantic shifts. Particularly, they used incremental updates (see below) and Continuous Skipgram with negative sampling (SGNS) (Mikolov et al., 2013a).   Hamilton et al. (2016a) showed the superiority of SGNS over explicit PPMI-based distributional models in semantic shifts analysis, although they noted that low-rank SVD approximations (Bullinaria and Levy, 2007) can perform on par with SGNS, especially on smaller datasets. Since then, the majority of publications in the ﬁeld started using dense word representations: either in the form of SVD-factorized PPMI matrices, or in the form of prediction-based shallow neural models like SGNS. "}
{"page": 5, "image_path": "doc_images/C18-1117_5.jpg", "ocr_text": "the majority of publications in the field started using dense word representations: either in the form of\nSVD-factorized PPMI matrices, or in the form of prediction-based shallow neural models like SGNS 4\n\nThere are some works employing other distributional approaches to semantic shifts detection. For\ninstance, there is a strong vein of research based on dynamic topic modeling (Blei and Lafferty, 2006;\nWang and McCallum, 2006), which learns the evolution of topics over time. In Wijaya and Yeniterzi\n(2011), it helped solve a typical digital humanities task of finding traces of real-world events in the\ntexts. Heyer et al. (2016) employed topic analysis to trace the so-called ‘context volatility’ of words. In\nthe political science, topic models are also sometimes used as proxies to social trends developing over\ntime: for example, Mueller and Rauh (2017) employed LDA to predict timing of civil wars and armed\nconflicts. Frermann and Lapata (2016) drew on these ideas to trace diachronic word senses development.\nBut most scholars nowadays seem to prefer parametric distributional models, particularly prediction-\nbased embedding algorithms like SGNS, CBOW or GloVe (Pennington et al., 2014). Following their\nwidespread adoption in NLP in general, they have become the dominant representations for the analysis\nof diachronic semantic shifts as well.\n\n3.3, Comparing vectors across time\n\nIt is rather straightforward to train separate word embedding models using time-specific corpora con-\ntaining texts from several different time periods. As a consequence, these models are also time-specific.\nHowever, it is not that straightforward to compare word vectors across different models.\nIt usually does not make sense to, for example, directly calculate cosine similarities between embed-\ndings of one and the same word in two different models. The reason is that most modern word embedding\nalgorithms are inherently stochastic and the resulting embedding sets are invariant under rotation. Thus,\neven when trained on the same data, separate learning runs will produce entirely different numerical\nvectors (though with roughly the same pairwise similarities between vectors for particular words). This\nis expressed even stronger for models trained on different corpora. It means that even if word meaning is\ncompletely stable, the direct cosine similarity between its vectors from different time periods can still be\nquite low, simply because the random initializations of the two models were different. To alleviate this,\nKulkarni et al. (2015) suggested that before calculating similarities, one should first align the models to\nfit them in one vector space, using linear transformations preserving general vector space structure. Af-\nter that, cosine similarities across models become meaningful and can be used as indicators of semantic\nshifts. They also proposed constructing the time series of a word embedding over time, which allows\nfor the detection of ‘bursts’ in its meaning with the Mean Shift model (Taylor, 2000). Notably, almost\nsimultaneously the idea of aligning diachronic word embedding models using a distance-preserving pro-\njection technique was proposed by Zhang et al. (2015). Later, Zhang et al. (2016) expanded on this by\nadding the so called ‘local anchors’: that is, they used both linear projections for the whole models and\nsmall sets of nearest neighbors for mapping the query words to their correct temporal counterparts.\nInstead of aligning their diachronic models using linear transformations, Eger and Mehler (2016) com-\npared word meaning using so-called ‘second-order embeddings,’ that is, the vectors of words’ similarities\nto all other words in the shared vocabulary of all models. This approach does not require any transfor-\nmations: basically, one simply analyzes the word’s position compared to other words. At the same time,\nHamilton et al. (2016a) and Hamilton et al. (2016c) showed that these two approaches can be used simul-\ntaneously: they employed both ‘second order embeddings’ and orthogonal Procrustes transformations to\nalign diachronic models.\nRecently, it was shown in Bamler and Mandt (2017) (‘dynamic skip-gram’ model) and Yao et al. (2018)\n(‘dynamic Word2Vec’ model) that it is possible to learn the word embeddings across several time periods\njointly, enforcing alignment across all of them simultaneously, and positioning all the models in the same\nvector space in one step. This develops the idea of model alignment even further and eliminates the need\nto first learn separate embeddings for each time period, and then align subsequent model pairs. Bamler\nand Mandt (2017) additionally describe two variations of their approach: a) for the cases when data slices\narrive sequentially, as in streaming applications, where one can not use future observations, and b) for\n\n4Levy and Goldberg (2014) showed that these two approaches are equivalent from the mathematical point of view.\n\n1389\n", "vlm_text": "\nThere are some works employing other distributional approaches to semantic shifts detection. For instance, there is a strong vein of research based on dynamic topic modeling (Blei and Lafferty, 2006; Wang and McCallum, 2006), which learns the evolution of topics over time. In Wijaya and Yeniterzi (2011), it helped solve a typical digital humanities task of ﬁnding traces of real-world events in the texts. Heyer et al. (2016) employed topic analysis to trace the so-called ‘context volatility’ of words. In the political science, topic models are also sometimes used as proxies to social trends developing over time: for example, Mueller and Rauh (2017) employed LDA to predict timing of civil wars and armed conﬂicts. Frermann and Lapata (2016) drew on these ideas to trace diachronic word senses development. But most scholars nowadays seem to prefer parametric distributional models, particularly prediction- based embedding algorithms like SGNS, CBOW or GloVe (Pennington et al., 2014). Following their widespread adoption in NLP in general, they have become the dominant representations for the analysis of diachronic semantic shifts as well. \n3.3 Comparing vectors across time \nIt is rather straightforward to train separate word embedding models using time-speciﬁc corpora con- taining texts from several different time periods. As a consequence, these models are also time-speciﬁc. However, it is not that straightforward to compare word vectors across different models. \nIt usually does not make sense to, for example, directly calculate cosine similarities between embed- dings of one and the same word in two different models. The reason is that most modern word embedding algorithms are inherently stochastic and the resulting embedding sets are invariant under rotation. Thus, even when trained on the same data, separate learning runs will produce entirely different numerical vectors (though with roughly the same pairwise similarities between vectors for particular words). This is expressed even stronger for models trained on different corpora. It means that even if word meaning is completely stable, the direct cosine similarity between its vectors from different time periods can still be quite low, simply because the random initializations of the two models were different. To alleviate this, Kulkarni et al. (2015) suggested that before calculating similarities, one should ﬁrst  align  the models to ﬁt them in one vector space, using linear transformations preserving general vector space structure. Af- ter that, cosine similarities across models become meaningful and can be used as indicators of semantic shifts. They also proposed constructing the time series of a word embedding over time, which allows for the detection of ‘bursts’ in its meaning with the  Mean Shift  model (Taylor, 2000). Notably, almost simultaneously the idea of aligning diachronic word embedding models using a distance-preserving pro- jection technique was proposed by Zhang et al. (2015). Later, Zhang et al. (2016) expanded on this by adding the so called ‘local anchors’: that is, they used both linear projections for the whole models and small sets of nearest neighbors for mapping the query words to their correct temporal counterparts. \nInstead of aligning their diachronic models using linear transformations, Eger and Mehler (2016) com- pared word meaning using so-called ‘second-order embeddings,’ that is, the vectors of words’ similarities to all other words in the shared vocabulary of all models. This approach does not require any transfor- mations: basically, one simply analyzes the word’s position compared to other words. At the same time, Hamilton et al. (2016a) and Hamilton et al. (2016c) showed that these two approaches can be used simul- taneously: they employed both ‘second order embeddings’ and orthogonal Procrustes transformations to align diachronic models. \nRecently, it was shown in Bamler and Mandt (2017) (‘ dynamic skip-gram ’ model) and Yao et al. (2018) (‘ dynamic Word2Vec ’ model) that it is possible to learn the word embeddings across several time periods jointly, enforcing alignment across all of them simultaneously, and positioning all the models in the same vector space in one step. This develops the idea of model alignment even further and eliminates the need to ﬁrst learn separate embeddings for each time period, and then align subsequent model pairs. Bamler and Mandt (2017) additionally describe two variations of their approach: a) for the cases when data slices arrive sequentially, as in streaming applications, where one can not use future observations, and b) for the cases when data slices are available all at once, allowing for training on the whole sequence from the very beginning. A similar approach is taken by Rosenfeld and Erk (2018) who train a deep neural network on word and time representations. Word vectors in this setup turn into linear transformations applied to a continuous time variable, and thus producing an embedding of word    $w$   at time  $t$  . "}
{"page": 6, "image_path": "doc_images/C18-1117_6.jpg", "ocr_text": "the cases when data slices are available all at once, allowing for training on the whole sequence from\nthe very beginning. A similar approach is taken by Rosenfeld and Erk (2018) who train a deep neural\nnetwork on word and time representations. Word vectors in this setup turn into linear transformations\napplied to a continuous time variable, and thus producing an embedding of word w at time t.\n\nYet another way to make the models comparable is made possible by the fact that prediction-based\nword embedding approaches (as well as RI) allow for incremental updates of the models with new data\nwithout any modifications. This is not the case for the traditional explicit count-based algorithms, which\nusually require a computationally expensive dimensionality reduction step. Kim et al. (2014) proposed\nthe idea of incrementally updated diachronic embedding models: that is, they train a model on the year y;,\nand then the model for the year y;+1 is initialized with the word vectors from y;. This can be considered\nas an alternative to model alignment: instead of aligning models trained from scratch on different time\nperiods, one starts with training a model on the diachronically first period, and then updates this same\nmodel with the data from the successive time periods, saving its state each time. Thus, all the models are\ninherently related to each other, which, again, makes it possible to directly calculate cosine similarities\nbetween the same word in different time period models, or at least makes the models more comparable.\n\nSeveral works have appeared recently which aim to address the technical issues accompanying this\napproach of incremental updating. Among others, Peng et al. (2017) described a novel method of incre-\nmentally learning the hierarchical softmax function for the CROW and Continuous Skipgram algorithms.\nIn this way, one can update word embedding models with new data and new vocabulary much more ef-\nficiently, achieving faster training than when doing it from scratch, while at the same time preserving\ncomparable performance. Continuing this line of research, Kaji and Kobayashi (2017) proposed a con-\nceptually similar incremental extension for negative sampling, which is a method of training examples\nselection, widely used with prediction-based models as a faster replacement for hierarchical softmax.\n\nEven after the models for different time periods are made comparable in this or that way, one still has\nto choose the exact method of comparing word vectors across these models. Hamilton et al. (2016a)\nand Hamilton et al. (2016c) made an important observation that the distinction between linguistic and\ncultural semantic shifts is correlated with the distinction between global and local embedding compari-\nson methods. The former take into account the whole model (for example, ‘second-order embeddings,’\nwhen we compare the word’s similarities to all other words in the lexicon), while the latter focus on the\nword’s immediate neighborhood (for example, when comparing the lists of k nearest neighbors). They\nconcluded that global measures are sensitive to regular processes of linguistic shifts, while local mea-\nsures are better suited to detect slight cultural shifts in word meaning. Thus, the choice of particular\nembedding comparison approach should depend on what type of semantic shifts one seeks to detect.\n\n4 Laws of semantic change\n\nThe use of diachronic word embeddings for studying the dynamics of word meaning has resulted in\nseveral hypothesized ‘laws’ of semantic change. We review some of these law-like generalizations below,\nbefore finally describing a study that questions their validity.\n\nDubossarsky et al. (2015) experimented with K-means clustering applied to SGNS embeddings trained\nfor evenly sized yearly samples for the period 1850-2009. They found that the degree of semantic change\nfor a given word — quantified as the change in self-similarity over time — negatively correlates with its\ndistance to the centroid of its cluster. They proposed that the likelihood for semantic shift correlates with\nthe degree of prototypicality (the ‘law of prototypicality’ in Dubossarsky et al. (2017)).\n\nAnother relevant study is reported by Eger and Mehler (2016), based on two different graph models;\none being a time-series model relating embeddings across time periods to model semantic shifts and the\nother modeling the self-similarity of words across time. Experiments were performed with time-indexed\nhistorical corpora of English, German and Latin, using time-periods corresponding to decades, years\nand centuries, respectively. To enable comparison of embeddings across time, second-order embeddings\nencoding similarities to other words were used, as described in 3.3, limited to the ‘core vocabulary’\n(words occurring at least 100 times in all time periods). Based on linear relationships observed in the\ngraphs, Eger and Mehler (2016) postulate two ‘laws’ of semantic change:\n\n1390\n", "vlm_text": "\nYet another way to make the models comparable is made possible by the fact that prediction-based word embedding approaches (as well as RI) allow for incremental updates of the models with new data without any modiﬁcations. This is not the case for the traditional explicit count-based algorithms, which usually require a computationally expensive dimensionality reduction step. Kim et al. (2014) proposed the idea of  incrementally updated diachronic embedding models : that is, they train a model on the year    $y_{i}$  , and then the model for the year    $y_{i+1}$   is initialized with the word vectors from  $y_{i}$  . This can be considered as an alternative to model alignment: instead of aligning models trained from scratch on different time periods, one starts with training a model on the diachronically ﬁrst period, and then updates this same model with the data from the successive time periods, saving its state each time. Thus, all the models are inherently related to each other, which, again, makes it possible to directly calculate cosine similarities between the same word in different time period models, or at least makes the models more comparable. \nSeveral works have appeared recently which aim to address the technical issues accompanying this approach of incremental updating. Among others, Peng et al. (2017) described a novel method of incre- mentally learning the  hierarchical softmax  function for the CBOW and Continuous Skipgram algorithms. In this way, one can update word embedding models with new data and new vocabulary much more ef- ﬁciently, achieving faster training than when doing it from scratch, while at the same time preserving comparable performance. Continuing this line of research, Kaji and Kobayashi (2017) proposed a con- ceptually similar incremental extension for  negative sampling , which is a method of training examples selection, widely used with prediction-based models as a faster replacement for  hierarchical softmax . \nEven after the models for different time periods are made comparable in this or that way, one still has to choose the exact method of comparing word vectors across these models. Hamilton et al. (2016a) and Hamilton et al. (2016c) made an important observation that the distinction between linguistic and cultural semantic shifts is correlated with the distinction between  global  and  local  embedding compari- son methods. The former take into account the whole model (for example, ‘second-order embeddings,’ when we compare the word’s similarities to all other words in the lexicon), while the latter focus on the word’s immediate neighborhood (for example, when comparing the lists of    $k$   nearest neighbors). They concluded that global measures are sensitive to regular processes of linguistic shifts, while local mea- sures are better suited to detect slight cultural shifts in word meaning. Thus, the choice of particular embedding comparison approach should depend on what type of semantic shifts one seeks to detect. \n4 Laws of semantic change \nThe use of diachronic word embeddings for studying the dynamics of word meaning has resulted in several hypothesized ‘laws’ of semantic change. We review some of these law-like generalizations below, before ﬁnally describing a study that questions their validity. \nDubossarsky et al. (2015) experimented with K-means clustering applied to SGNS embeddings trained for evenly sized yearly samples for the period 1850–2009. They found that the degree of semantic change for a given word – quantiﬁed as the change in self-similarity over time – negatively correlates with its distance to the centroid of its cluster. They proposed that the likelihood for semantic shift correlates with the degree of prototypicality (the  ‘law of prototypicality’  in Dubossarsky et al. (2017)). \nAnother relevant study is reported by Eger and Mehler (2016), based on two different graph models; one being a time-series model relating embeddings across time periods to model semantic shifts and the other modeling the self-similarity of words across time. Experiments were performed with time-indexed historical corpora of English, German and Latin, using time-periods corresponding to decades, years and centuries, respectively. To enable comparison of embeddings across time, second-order embeddings encoding similarities to other words were used, as described in 3.3, limited to the ‘core vocabulary’ (words occurring at least 100 times in all time periods). Based on linear relationships observed in the graphs, Eger and Mehler (2016) postulate two ‘laws’ of semantic change: "}
{"page": 7, "image_path": "doc_images/C18-1117_7.jpg", "ocr_text": "1. word vectors can be expressed as linear combinations of their neighbors in previous time periods;\n\n2. the meaning of words tend to decay linearly in time, in terms of the similarity of a word to itself;\nthis is in line with the ‘law of differentiation’ proposed by Xu and Kemp (2015).\n\nIn another study, Hamilton et al. (2016a) considered historical corpora for English, German, French\nand Chinese, spanning 200 years and using time spans of decades. The goal was to investigate the\nrole of frequency and polysemy with respect to semantic shifts. As in Eger and Mehler (2016), the\nrate of semantic change was quantified by self-similarity across time-points (with words represented by\nProcrustes-aligned SVD embeddings). Through a regression analysis, Hamilton et al. (2016a) investi-\ngated how the change rates correlate with frequency and polysemy, and proposed another two ‘laws’:\n\n1. frequent words change more slowly (‘the law of conformity’);\n2. polysemous words (controlled for frequency) change more quickly (‘the law of innovation’ ).\n\nAzarbonyad et al. (2017) showed that these laws (at least the law of conformity) hold not only for\ndiachronic corpora, but also for other ‘viewpoints’: for example, semantic shifts across models trained on\ntexts produced by different political actors or written in different genres (Kutuzov et al., 2016). However,\nthe temporal dimension allows for a view of the corpora under analysis as a sequence, making the notion\nof ‘semantic shift’? more meaningful.\n\nLater, Dubossarsky et al. (2017) questioned the validity of some of these proposed ‘laws’ of semantic\nchange. In a series of replication and control experiments, they demonstrated that some of the regularities\nobserved in previous studies are largely artifacts of the models used and frequency effects. In particular,\nthey considered 10-year bins comprising equally sized yearly samples from Google Books 5-grams of\nEnglish fiction for the period 1990-1999. For control experiments, they constructed two additional\ndata sets; one with chronologically shuffled data where each bin contains data from all decades evenly\ndistributed, and one synchronous variant containing repeated random samples from the year 1999 alone.\nAny measured semantic shifts within these two alternative data sets would have to be due to random\nsampling noise.\n\nDubossarsky et al. (2017) performed experiments using raw co-occurrence counts, PPMI weighted\ncounts, and SVD transformations (Procrustes aligned), and conclude that the ‘laws’ proposed in previ-\nous studies — that semantic change is correlated with frequency, polysemy (Hamilton et al., 2016a) and\nprototypicality (Dubossarsky et al., 2015) — are not valid as they are also observed in the control condi-\ntions. Dubossarsky et al. (2017) suggested that these spurious effects are instead due to the type of word\nrepresentation used — count vectors — and that semantic shifts must be explained by a more diverse set\nof factors than distributional ones alone. Thus, the discussion on the existence of the ‘laws of semantic\nchange’ manifested by distributional trends is still open.\n\n5 Diachronic semantic relations\n\nWord embedding models are known to successfully capture complex relationships between concepts, as\nmanifested in the well-known word analogies task (Mikolov et al., 2013a), where a model must ‘solve’\nequations of the form ‘A is to B is as C is to what?’ A famous example is the distributional model captur-\ning the fact that the relation between ‘man’ and ‘woman’ is the same as between ‘king’ and ‘queen’ (by\nadding and subtracting the corresponding word vectors). Thus, it is a natural development to investigate\nwhether changes in semantic relationships across time can also be traced by looking at the diachronic\ndevelopment of distributional models.\n\nZhang et al. (2015) considered the temporal correspondences problem, wherein the objective is to\nidentify the word in a target time period which corresponds to a query term in the source time period\n(for example, given the query term iPod in the 2000s, the counterpart term in the 1980s time period is\nWalkman). This is proposed as a means to improve the results of information retrieval from document\ncollections with significant time spans. Szymanski (2017) frames this as the temporal word analogy\nproblem, extending the word analogies concept into the temporal dimension. This work shows that\n\n1391\n", "vlm_text": "2. the meaning of words tend to decay linearly in time, in terms of the similarity of a word to itself; this is in line with the ‘ law of differentiation ’ proposed by Xu and Kemp (2015). \nIn another study, Hamilton et al. (2016a) considered historical corpora for English, German, French and Chinese, spanning 200 years and using time spans of decades. The goal was to investigate the role of frequency and polysemy with respect to semantic shifts. As in Eger and Mehler (2016), the rate of semantic change was quantiﬁed by self-similarity across time-points (with words represented by Procrustes-aligned SVD embeddings). Through a regression analysis, Hamilton et al. (2016a) investi- gated how the change rates correlate with frequency and polysemy, and proposed another two ‘laws’: \n1. frequent words change more slowly (‘ the law of conformity ’); 2. polysemous words (controlled for frequency) change more quickly (‘ the law of innovation ’). \nAzarbonyad et al. (2017) showed that these laws (at least the law of conformity) hold not only for diachronic corpora, but also for other ‘viewpoints’: for example, semantic shifts across models trained on texts produced by different political actors or written in different genres (Kutuzov et al., 2016). However, the temporal dimension allows for a view of the corpora under analysis as a sequence, making the notion of ‘semantic shift’ more meaningful. \nLater, Dubossarsky et al. (2017) questioned the validity of some of these proposed ‘laws’ of semantic change. In a series of replication and control experiments, they demonstrated that some of the regularities observed in previous studies are largely artifacts of the models used and frequency effects. In particular, they considered 10-year bins comprising equally sized yearly samples from Google Books 5-grams of English ﬁction for the period 1990–1999. For control experiments, they constructed two additional data sets; one with chronologically shufﬂed data where each bin contains data from all decades evenly distributed, and one synchronous variant containing repeated random samples from the year 1999 alone. Any measured semantic shifts within these two alternative data sets would have to be due to random sampling noise. \nDubossarsky et al. (2017) performed experiments using raw co-occurrence counts, PPMI weighted counts, and SVD transformations (Procrustes aligned), and conclude that the ‘laws’ proposed in previ- ous studies – that semantic change is correlated with frequency, polysemy (Hamilton et al., 2016a) and prototypicality (Dubossarsky et al., 2015) – are not valid as they are also observed in the control condi- tions. Dubossarsky et al. (2017) suggested that these spurious effects are instead due to the type of word representation used – count vectors – and that semantic shifts must be explained by a more diverse set of factors than distributional ones alone. Thus, the discussion on the existence of the ‘laws of semantic change’ manifested by distributional trends is still open. \n5 Diachronic semantic relations \nWord embedding models are known to successfully capture complex  relationships  between concepts, as manifested in the well-known word analogies task (Mikolov et al., 2013a), where a model must ‘solve’ equations of the form ‘A is to B is as C is to what?’ A famous example is the distributional model captur- ing the fact that the relation between ‘ man ’ and ‘ woman ’ is the same as between ‘ king ’ and ‘ queen ’ (by adding and subtracting the corresponding word vectors). Thus, it is a natural development to investigate whether changes in semantic relationships across time can also be traced by looking at the diachronic development of distributional models. \nZhang et al. (2015) considered the  temporal correspondences problem , wherein the objective is to identify the word in a target time period which corresponds to a query term in the source time period (for example, given the query term  iPod  in the 2000s, the counterpart term in the 1980s time period is Walkman ). This is proposed as a means to improve the results of information retrieval from document collections with signiﬁcant time spans. Szymanski (2017) frames this as the  temporal word analogy problem, extending the word analogies concept into the temporal dimension. This work shows that diachronic word embeddings can successfully model relations like ‘word    $w_{1}$   at time period    $t_{\\alpha}$   is like word    $w_{2}$   at time period  $t_{\\beta}{}^{\\prime}$  . To this end, embedding models trained on different time periods are aligned using linear transformations. Then, the temporal analogies are solved by simply ﬁnding out which word vector in the time period  $t_{\\beta}$   is the closest to the vector of    $w_{1}$   in the time period    $t_{\\alpha}$  . "}
{"page": 8, "image_path": "doc_images/C18-1117_8.jpg", "ocr_text": "diachronic word embeddings can successfully model relations like ‘word wy at time period ty is like\nword w2 at time period ts’. To this end, embedding models trained on different time periods are aligned\nusing linear transformations. Then, the temporal analogies are solved by simply finding out which word\nvector in the time period tg is the closest to the vector of wy in the time period ta.\n\nA variation of this task was studied in Rosin et al. (2017), where the authors learn the relatedness\nof words over time, answering queries like ‘in which time period were the words Obama and president\nmaximally related’. This technique can be used for a more efficient user query expansion in general-\npurpose search engines. Kutuzov et al. (2017a) modeled a different semantic relation: ‘words w; and\nwe at time period t, are in the same semantic relation as words w3 and wa at time period tg’. To trace\nthe temporal dynamics of these relations, they re-applied linear projections learned on sets of w; and w2\npairs from the model for the period ¢,, to the model trained on the subsequent time period t,,,1. This was\nused to solve the task of detecting lasting or emerging armed conflicts and the violent groups involved in\nthese conflicts.\n\n6 Applications\n\nApplications of diachronic word embeddings approaches can generally be grouped into two broad cat-\negories: linguistic studies which investigate the how and why of semantic shifts, and event detection\napproaches which mine text data for actionable purposes.\n\nThe first category generally involves corpora with longer time spans, since linguistic changes happen\nat a relatively slow pace. Some examples falling into this category include tracking semantic drift of\nparticular words (Kulkarni et al., 2015) or of word sentiment (Hamilton et al., 2016b), identifying the\nbreakpoints between epochs (Sagi et al., 2011; Mihalcea and Nastase, 2012), studying the laws of se-\nmantic change at scale (Hamilton et al., 2016c) and finding different words with similar meanings ai\ndifferent points in time (Szymanski, 2017). This has been held up as a good use case of deep learning\nfor research in computational linguistics (Manning, 2015), and there are opportunities for future work\napplying diachronic word embeddings not only in the field of historical linguistics, but also in related\nareas like sociolinguistics and digital humanities.\n\nThe second category involves mining texts for cultural semantic shifts (usually on shorter time spans)\nindicating real-world events. Examples of this category are temporal information retrieval (Rosin e\nal., 2017), predicting civil turmoils (Kutuzov et al., 2017b; Mueller and Rauh, 2017), or tracing the\npopularity of entities using norms of word vectors (Yao et al., 2018). They can potentially be employed\nto improve user experience in production systems or for policy-making in governmental structures.\n\nWe believe that the near future will see a more diverse landscape of applications for diachronic word\nembeddings, especially related to the real-time analysis of large-scale news streams. ‘Between the lines,’\nthese data sources contain a tremendous amount of information about processes in our world, manifested\nin semantic shifts of various sorts. The task of researchers is to reveal this information and make i\nreliable and practically useful.\n\n7 Open challenges\n\nThe study of temporal aspects of semantic shifts using distributional models (including word embed-\ndings) is far from being a solved problem. The field still has a considerable number of open challenges.\nBelow we briefly describe the most demanding ones.\n\ne The existing methods should be expanded to a wider scope of languages. Hamilton et al. (2016a),\nKutuzov and Kuzmenko (2018) and others have started to analyze other languages, but the over-\nwhelming majority of publications still apply only to English corpora. It might be the case that the\nbest methodologies are the same for different languages, but this should be shown empirically.\n\ne There is a clear need to devise algorithms that work on small datasets, as they are very common in\nhistorical linguistics, digital humanities, and similar disciplines.\n\n1392\n", "vlm_text": "\nA variation of this task was studied in Rosin et al. (2017), where the authors learn the relatedness of words over time, answering queries like ‘in which time period were the words  Obama  and  president maximally related’. This technique can be used for a more efﬁcient user query expansion in general- purpose search engines. Kutuzov et al. (2017a) modeled a different semantic relation: ‘words  $w_{1}$   and  $w_{2}$   at time period  $t_{\\alpha}$   are in the same semantic relation as words    $w_{3}$   and    $w_{4}$   at time period  $t_{\\beta}{}^{\\prime}$  . To trace the temporal dynamics of these relations, they re-applied linear projections learned on sets of  $w_{1}$   and    $w_{2}$  pairs from the model for the period  $t_{n}$   to the model trained on the subsequent time period  $t_{n+1}$  . This was used to solve the task of detecting lasting or emerging armed conﬂicts and the violent groups involved in these conﬂicts. \n6 Applications \nApplications of diachronic word embeddings approaches can generally be grouped into two broad cat- egories:  linguistic studies  which investigate the how and why of semantic shifts, and  event detection approaches which mine text data for actionable purposes. \nThe ﬁrst category generally involves corpora with longer time spans, since linguistic changes happen at a relatively slow pace. Some examples falling into this category include tracking semantic drift of particular words (Kulkarni et al., 2015) or of word sentiment (Hamilton et al., 2016b), identifying the breakpoints between epochs (Sagi et al., 2011; Mihalcea and Nastase, 2012), studying the laws of se- mantic change at scale (Hamilton et al., 2016c) and ﬁnding different words with similar meanings at different points in time (Szymanski, 2017). This has been held up as a good use case of deep learning for research in computational linguistics (Manning, 2015), and there are opportunities for future work applying diachronic word embeddings not only in the ﬁeld of historical linguistics, but also in related areas like sociolinguistics and digital humanities. \nThe second category involves mining texts for cultural semantic shifts (usually on shorter time spans) indicating real-world events. Examples of this category are temporal information retrieval (Rosin et al., 2017), predicting civil turmoils (Kutuzov et al., 2017b; Mueller and Rauh, 2017), or tracing the popularity of entities using norms of word vectors (Yao et al., 2018). They can potentially be employed to improve user experience in production systems or for policy-making in governmental structures. \nWe believe that the near future will see a more diverse landscape of applications for diachronic word embeddings, especially related to the real-time analysis of large-scale news streams. ‘Between the lines,’ these data sources contain a tremendous amount of information about processes in our world, manifested in semantic shifts of various sorts. The task of researchers is to reveal this information and make it reliable and practically useful. \n7 Open challenges \nThe study of temporal aspects of semantic shifts using distributional models (including word embed- dings) is far from being a solved problem. The ﬁeld still has a considerable number of open challenges. Below we brieﬂy describe the most demanding ones. \n•  The existing methods should be expanded to a  wider scope of languages . Hamilton et al. (2016a), Kutuzov and Kuzmenko (2018) and others have started to analyze other languages, but the over- whelming majority of publications still apply only to English corpora. It might be the case that the best methodologies are the same for different languages, but this should be shown empirically. "}
{"page": 9, "image_path": "doc_images/C18-1117_9.jpg", "ocr_text": "e Carefully designed and robust gold standard test sets of semantic shifts (of different kinds) should\nbe created. This is a difficult task in itself, but the experience from synchronic word embeddings\nevaluation (Hill et al., 2015) and other NLP areas proves that it is possible.\n\ne There is a need for rigorous formal mathematical models of diachronic embeddings. Arguably, this\nwill follow the vein of research in joint learning across several time spans, started by Bamler and\nMandt (2017) and Yao et al. (2018), but other directions are also open.\n\ne Most current studies stop after stating the simple fact that a semantic shift has occurred. However,\nmore detailed analysis of the nature of the shift is needed. This includes:\n\n1. Sub-classification of types of semantic shifts (broadening, narrowing, etc). This problem was\nto some degree addressed by Mitra et al. (2014), but much more work is certainly required to\nempirically test classification schemes proposed in much of the theoretical work described in\nSection 2.\n\n2. Identifying the source of a shift (for example, linguistic or extra-linguistic causes). This cau-\nsation detection is closely linked to the division between linguistic drifts and cultural shifts, as\nproposed in Hamilton et al. (2016c).\n\n3. Quantifying the weight of senses acquired over time. Many words are polysemous, and the\nrelative importance of senses is flexible (Frermann and Lapata, 2016). The issue of handling\nsenses is central for detecting semantic shifts, but most of the algorithms described in this sur-\nvey are not sense-aware. To address this, methods from sense embeddings research (Bartunov\net al., 2016) might be employed.\n\n4. Identifying groups of words that shift together in correlated ways. Some work in this direction\nwas started in Dubossarsky et al. (2016), who showed that verbs change more than nouns, and\nnouns change more than adjectives. This is also naturally related to proving the (non-)existence\nof the ‘laws of semantic change’ (see Section 4).\n\ne Last but not least, we believe that the community around diachronic word embeddings research\nseverely lacks relevant forums, like topical workshops or shared tasks. Diachronic text evaluation\ntasks like the one at SemEval-2015 (Popescu and Strapparava, 2015) are important but not enough,\nsince they focus on identifying the time period when a text was authored, not the process of shifting\nmeanings of a word. Organizing such events can promote the field and help address many of the\nchallenges described above.\n\n8 Summary\n\nWe have presented an outline of the current research related to computational detection of semantic shifts\nusing diachronic (temporal) word embeddings. We covered the linguistic nature of semantic shifts, the\ntypical sources of diachronic data and the distributional approaches used to model it, from frequentist\nmethods to contemporary prediction-based models. To sum up, Figure | shows the timeline of events\nthat have been influential in the development of research in this area: introducing concepts, usage of\ncorpora and important findings.\n\nThis emerging field is still relatively new, and although recent years has seen a string of significant\ndiscoveries and academic interchange, much of the research still appears slightly fragmented, not least\ndue to the lack of dedicated venues like workshops, special issues, or shared tasks. We hope that this\nsurvey will be useful to those who want to understand how this field has developed, and gain an overview\nof what defines the current state-of-the-art and what challenges lie ahead.\n\nAcknowledgements\n\nWe thank William Hamilton, Haim Dubossarsky and Chris Biemann for their helpful feedback during\nthe preparation of this survey. All possible mistakes remain the sole responsibility of the authors.\n\n1393\n", "vlm_text": "•  Carefully designed and robust  gold standard test sets  of semantic shifts (of different kinds) should be created. This is a difﬁcult task in itself, but the experience from synchronic word embeddings evaluation (Hill et al., 2015) and other NLP areas proves that it is possible. •  There is a need for rigorous  formal mathematical models of diachronic embeddings . Arguably, this will follow the vein of research in joint learning across several time spans, started by Bamler and Mandt (2017) and Yao et al. (2018), but other directions are also open. •  Most current studies stop after stating the simple fact that a semantic shift has occurred. However, more detailed analysis of the nature of the shift is needed. This includes: 1.  Sub-classiﬁcation of types of semantic shifts  (broadening, narrowing, etc). This problem was to some degree addressed by Mitra et al. (2014), but much more work is certainly required to empirically test classiﬁcation schemes proposed in much of the theoretical work described in Section 2. 2.  Identifying the source of a shift  (for example, linguistic or extra-linguistic causes). This cau- sation detection is closely linked to the division between linguistic drifts and cultural shifts, as proposed in Hamilton et al. (2016c). 3.  Quantifying the weight of senses  acquired over time. Many words are polysemous, and the relative importance of senses is ﬂexible (Frermann and Lapata, 2016). The issue of handling senses is central for detecting semantic shifts, but most of the algorithms described in this sur- vey are not sense-aware. To address this, methods from sense embeddings research (Bartunov et al., 2016) might be employed. 4.  Identifying groups of words that shift together  in correlated ways. Some work in this direction was started in Dubossarsky et al. (2016), who showed that verbs change more than nouns, and nouns change more than adjectives. This is also naturally related to proving the (non-)existence of the ‘laws of semantic change’ (see Section 4). •  Last but not least, we believe that the community around diachronic word embeddings research severely lacks relevant forums, like  topical workshops  or  shared tasks . Diachronic text evaluation tasks like the one at  SemEval-2015  (Popescu and Strapparava, 2015) are important but not enough, since they focus on identifying the time period when a text was authored, not the process of shifting meanings of a word. Organizing such events can promote the ﬁeld and help address many of the challenges described above. \n8 Summary \nWe have presented an outline of the current research related to computational detection of semantic shifts using diachronic (temporal) word embeddings. We covered the linguistic nature of semantic shifts, the typical sources of diachronic data and the distributional approaches used to model it, from frequentist methods to contemporary prediction-based models. To sum up, Figure 1 shows the timeline of events that have been inﬂuential in the development of research in this area: introducing concepts, usage of corpora and important ﬁndings. \nThis emerging ﬁeld is still relatively new, and although recent years has seen a string of signiﬁcant discoveries and academic interchange, much of the research still appears slightly fragmented, not least due to the lack of dedicated venues like workshops, special issues, or shared tasks. We hope that this survey will be useful to those who want to understand how this ﬁeld has developed, and gain an overview of what deﬁnes the current state-of-the-art and what challenges lie ahead. \nAcknowledgements \nWe thank William Hamilton, Haim Dubossarsky and Chris Biemann for their helpful feedback during the preparation of this survey. All possible mistakes remain the sole responsibility of the authors. "}
{"page": 10, "image_path": "doc_images/C18-1117_10.jpg", "ocr_text": "References\n\nHosein Azarbonyad, Mostafa Dehghani, Kaspar Beelen, Alexandra Arkut, Maarten Marx, and Jaap Kamps. 2017.\nWords are malleable: Computing semantic shifts in political and media discourse. In Proceedings of the ACM\non Conference on Information and Knowledge Management, pages 1509-1518, Singapore.\n\nRobert Bamler and Stephan Mandt. 2017. Dynamic word embeddings. In Proceedings of the International\nConference on Machine Learning, pages 380-389, Sydney, Australia.\n\nMarco Baroni, Georgiana Dinu, and German Kruszewski. 2014. Don’t count, predict! A systematic comparison\nof context-counting vs. context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the\nAssociation for Computational Linguistics, volume 1, pages 238-247, Baltimore, USA.\n\nSergey Bartunov, Dmitry Kondrashkin, Anton Osokin, and Dmitry Vetrov. 2016. Breaking sticks and ambiguities\nwith adaptive skip-gram. In Proceedings of the 19th International Conference on Artificial Intelligence and\nStatistics, pages 130-138, Cadiz, Spain.\n\nPierpaolo Basile, Annalina Caputo, and Giovanni Semeraro. 2014. Analysing word meaning over time by exploit-\ning temporal random indexing. In Proceedings of the First Italian Conference on Computational Linguistics,\npages 38-42, Turin, Italy.\n\nAndreas Blank and Peter Koch. 1999. Historical semantics and cognition. Walter de Gruyter.\n\nDavid M Blei and John D Lafferty. 2006. Dynamic topic models. In Proceedings of the 23rd International\nConference on Machine learning, pages 113-120, Pittsburgh, USA.\n\nLeonard Bloomfield. 1933. Language. Allen & Unwin.\nMichel Bréal. 1899. Essai de sémantique. Hachette, Paris.\n\nJohn A Bullinaria and Joseph P Levy. 2007. Extracting semantic representations from word co-occurrence statis-\ntics: A computational study. Behavior research methods, 39(3):5 10-526.\n\nHyunyoung Choi and Hal Varian. 2012. Predicting the present with Google trends. Economic Record, 88(s1):2-9.\n\nScott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. 1990. Index-\ning by Latent Semantic Analysis. Journal of the American Society for Information Science, 41(6):39 1-407.\n\nHaim Dubossarsky, Yulia Tsvetkov, Chris Dyer, and Eitan Grossman. 2015. A bottom up approach to category\nmapping and meaning change. In Proceedings of the NetWordS 2015 Word Knowledge and Word Usage, pages\n66-70, Pisa, Italy.\n\nHaim Dubossarsky, Daphna Weinshall, and Eitan Grossman. 2016. Verbs change more than nouns: a bottom-up\ncomputational approach to semantic change. Lingue e linguaggio, 15(1):7-28.\n\nHaim Dubossarsky, Daphna Weinshall, and Eitan Grossman. 2017. Outta control: Laws of semantic change and\ninherent biases in word representation models. In Proceedings of the 2017 Conference on Empirical Methods\nin Natural Language Processing, pages 1147-1156, Copenhagen, Denmark.\n\nSteffen Eger and Alexander Mehler. 2016. On the linearity of semantic change: Investigating meaning variation\nvia dynamic graph models. In Proceedings of the 54th Annual Meeting of the Association for Computational\nLinguistics, pages 52-58, Berlin, Germany.\n\nJohn Firth. 1957. A synopsis of linguistic theory, 1930-1955. Blackwell.\n\nLea Frermann and Mirella Lapata. 2016. A bayesian model of diachronic meaning change. Transactions of the\nAssociation of Computational Linguistics, 4:31-45.\n\nDirk Geeraerts. 1997. Diachronic prototype semantics: A contribution to historical lexicology. Clarendon Press,\nOxford.\n\nStefan Th. Gries. 1999. Particle movement: a cognitive and functional approach. Cognitive Linguistics, 10:105-\n145.\n\nJoachim Grzega and Marion Schoener. 2007. English and general historical lexicology. Eichstétt-Ingolstadt:\nKatholische Universitat.\n\n1394\n", "vlm_text": "References \nHosein Azarbonyad, Mostafa Dehghani, Kaspar Beelen, Alexandra Arkut, Maarten Marx, and Jaap Kamps. 2017. Words are malleable: Computing semantic shifts in political and media discourse. In  Proceedings of the ACM on Conference on Information and Knowledge Management , pages 1509–1518, Singapore. \nRobert Bamler and Stephan Mandt. 2017. Dynamic word embeddings. In  Proceedings of the International Conference on Machine Learning , pages 380–389, Sydney, Australia. \nMarco Baroni, Georgiana Dinu, and Germán Kruszewski. 2014. Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors. In  Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , volume 1, pages 238–247, Baltimore, USA. \nSergey Bartunov, Dmitry Kondrashkin, Anton Osokin, and Dmitry Vetrov. 2016. Breaking sticks and ambiguities with adaptive skip-gram. In  Proceedings of the 19th International Conference on Artiﬁcial Intelligence and Statistics , pages 130–138, Cadiz, Spain. \nPierpaolo Basile, Annalina Caputo, and Giovanni Semeraro. 2014. Analysing word meaning over time by exploit- ing temporal random indexing. In  Proceedings of the First Italian Conference on Computational Linguistics , pages 38–42, Turin, Italy. \nAndreas Blank and Peter Koch. 1999.  Historical semantics and cognition . Walter de Gruyter. \nDavid M Blei and John D Lafferty. 2006. Dynamic topic models. In  Proceedings of the 23rd International Conference on Machine learning , pages 113–120, Pittsburgh, USA. \nLeonard Bloomﬁeld. 1933.  Language . Allen & Unwin. \nMichel Bréal. 1899.  Essai de sémantique . Hachette, Paris. \nJohn A Bullinaria and Joseph P Levy. 2007. Extracting semantic representations from word co-occurrence statis- tics: A computational study.  Behavior research methods , 39(3):510–526. \nHyunyoung Choi and Hal Varian. 2012. Predicting the present with Google trends.  Economic Record , 88(s1):2–9. \nScott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. 1990. Index- ing by Latent Semantic Analysis.  Journal of the American Society for Information Science , 41(6):391–407. \nHaim Dubossarsky, Yulia Tsvetkov, Chris Dyer, and Eitan Grossman. 2015. A bottom up approach to category mapping and meaning change. In  Proceedings of the NetWordS 2015 Word Knowledge and Word Usage , pages 66–70, Pisa, Italy. \nHaim Dubossarsky, Daphna Weinshall, and Eitan Grossman. 2016. Verbs change more than nouns: a bottom-up computational approach to semantic change.  Lingue e linguaggio , 15(1):7–28. \nHaim Dubossarsky, Daphna Weinshall, and Eitan Grossman. 2017. Outta control: Laws of semantic change and inherent biases in word representation models. In  Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 1147–1156, Copenhagen, Denmark. \nSteffen Eger and Alexander Mehler. 2016. On the linearity of semantic change: Investigating meaning variation via dynamic graph models. In  Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics , pages 52–58, Berlin, Germany. \nJohn Firth. 1957.  A synopsis of linguistic theory, 1930-1955 . Blackwell. \nLea Frermann and Mirella Lapata. 2016. A bayesian model of diachronic meaning change.  Transactions of the Association of Computational Linguistics , 4:31–45. \nDirk Geeraerts. 1997.  Diachronic prototype semantics: A contribution to historical lexicology . Clarendon Press, Oxford. \nStefan Th. Gries. 1999. Particle movement: a cognitive and functional approach.  Cognitive Linguistics , 10:105– 145. \nJoachim Grzega and Marion Schoener. 2007. English and general historical lexicology.  Eichstätt-Ingolstadt: Katholische Universität . "}
{"page": 11, "image_path": "doc_images/C18-1117_11.jpg", "ocr_text": "Kristina Gulordava and Marco Baroni. 2011. A distributional similarity approach to the detection of semantic\nchange in the Google Books Ngram corpus. In Proceedings of the GEMS 2011 Workshop on Geometrical\nModels of Natural Language Semantics, pages 67-71, Edinburgh, UK.\n\nL. William Hamilton, Jure Leskovec, and Dan Jurafsky. 2016a. Diachronic word embeddings reveal statistical\nlaws of semantic change. In Proceedings of the 54th Annual Meeting of the Association for Computational\nLinguistics, pages 1489-1501, Berlin, Germany.\n\nWilliam L. Hamilton, Kevin Clark, Jure Leskovec, and Dan Jurafsky. 2016b. Inducing domain-specific sentiment\nlexicons from unlabeled corpora. In Proceedings of the Conference on Empirical Methods in Natural Language\nProcessing, pages 595-605, Austin, Texas.\n\nWilliam L. Hamilton, Jure Leskovec, and Dan Jurafsky. 2016c. Cultural shift or linguistic drift? Comparing\ntwo computational measures of semantic change. In Proceedings of the Conference on Empirical Methods in\nNatural Language Processing, pages 2116-2121, Austin, Texas.\n\nGerhard Heyer, Florian Holz, and Sven Teresniak. 2009. Change of topics over time — tracking topics by their\nchange of meaning. In Proceeding of the International Conference on Knowledge Discovery and Information\nRetrieval, pages 223-228, Madeira, Portugal.\n\nGerhard Heyer, Cathleen Kantner, Andreas Niekler, Max Overbeck, and Gregor Wiedemann. 2016. Modeling\nthe dynamics of domain specific terminology in diachronic corpora. In Proceedings of the 12th International\nconference on Terminology and Knowledge Engineering (TKE 2016).\n\nFelix Hill, Roi Reichart, and Anna Korhonen. 2015. Simlex-999: Evaluating semantic models with (genuine)\nsimilarity estimation. Computational Linguistics, 41(4):665-695.\n\nMartin Hilpert and Stefan Th. Gries. 2009. Assessing frequency changes in multistage diachronic corpora: Appli-\ncations for historical corpus linguistics and the study of language acquisition. Literary and Linguistic Comput-\ning, 24(4):385-401.\n\nM. Hilpert. 2008. Germanic future constructions: A usage-based approach to language change. Benjamins,\nAmsterdam, Netherlands.\n\nPatrick Juola. 2003. The time course of language change. Computers and the Humanities, 37(1):77-96.\nDavid Jurgens and Keith Stevens. 2009. Event detection in blogs using Temporal Random Indexing.\n\nNobuhiro Kaji and Hayato Kobayashi. 2017. Incremental skip-gram model with negative sampling. In Proceed-\nings of the Conference on Empirical Methods in Natural Language Processing, pages 363-371, Copenhagen,\nDenmark.\n\nPentti Kanerva, Jan Kristofersson, and Anders Holst. 2000. Random indexing of text samples for latent semantic\nanalysis. In Proceedings of the 22nd annual conference of the cognitive science society, volume 1036, pages\n103-106, Mahwah, USA.\n\nD. Kerremans, S. Stegmayr, and H.-J. Schmid. 2010. The neocrawler: Identifying and retrieving neologisms\nfrom the internet and monitoring ongoing change. In K. Allan and J. A. Robinson, editors, Current methods in\nhistorical semantics, pages 130-160. De Gruyter Mouton.\n\nYoon Kim, Yi-I Chiu, Kentaro Hanaki, Darshan Hegde, and Slav Petrov. 2014. Temporal analysis of language\nthrough neural language models. In Proceedings of the 52nd Annual Meeting of the Association for Computa-\ntional Linguistics, pages 61-65, Baltimore, USA.\n\nVivek Kulkarni, Rami Al-Rfou, Bryan Perozzi, and Steven Skiena. 2015. Statistically significant detection of\nlinguistic change. In Proceedings of the 24th International Conference on World Wide Web, pages 625-635,\nFlorence, Italy.\n\nAndrey Kutuzov and Elizaveta Kuzmenko. 2018. Two centuries in two thousand words: Neural embedding models\nin detecting diachronic lexical changes. Quantitative Approaches to the Russian Language, pages 95-112.\n\nAndrey Kutuzov, Elizaveta Kuzmenko, and Anna Marakasova. 2016. Exploration of register-dependent lexical\nsemantics using word embeddings. In Proceedings of the Workshop on Language Technology Resources and\nTools for Digital Humanities (LT4DH), pages 26-34, Osaka, Japan.\n\nAndrey Kutuzov, Erik Velldal, and Lilja @vrelid. 2017a. Temporal dynamics of semantic relations in word\nembeddings: an application to predicting armed conflict participants. In Proceedings of the Conference on\nEmpirical Methods in Natural Language Processing, pages 1824-1829, Copenhagen, Denmark.\n\n1395\n", "vlm_text": "Kristina Gulordava and Marco Baroni. 2011. A distributional similarity approach to the detection of semantic change in the Google Books Ngram corpus. In  Proceedings of the GEMS 2011 Workshop on Geometrical Models of Natural Language Semantics, pages 67–71, Edinburgh, UK.L. William Hamilton, Jure Leskovec, and Dan Jurafsky. 2016a. Diachronic word embeddings reveal statistical laws of semantic change. In  Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics , pages 1489–1501, Berlin, Germany. William L. Hamilton, Kevin Clark, Jure Leskovec, and Dan Jurafsky. 2016b. Inducing domain-speciﬁc sentiment lexicons from unlabeled corpora. In  Proceedings of the Conference on Empirical Methods in Natural Language Processing , pages 595–605, Austin, Texas. William L. Hamilton, Jure Leskovec, and Dan Jurafsky. 2016c. Cultural shift or linguistic drift? Comparing two computational measures of semantic change. In  Proceedings of the Conference on Empirical Methods in Natural Language Processing , pages 2116–2121, Austin, Texas. Gerhard Heyer, Florian Holz, and Sven Teresniak. 2009. Change of topics over time – tracking topics by their change of meaning. In  Proceeding of the International Conference on Knowledge Discovery and Information Retrieval , pages 223–228, Madeira, Portugal. Gerhard Heyer, Cathleen Kantner, Andreas Niekler, Max Overbeck, and Gregor Wiedemann. 2016. Modeling the dynamics of domain speciﬁc terminology in diachronic corpora. In  Proceedings of the 12th International conference on Terminology and Knowledge Engineering (TKE 2016) . Felix Hill, Roi Reichart, and Anna Korhonen. 2015. Simlex-999: Evaluating semantic models with (genuine) similarity estimation.  Computational Linguistics , 41(4):665–695. Martin Hilpert and Stefan Th. Gries. 2009. Assessing frequency changes in multistage diachronic corpora: Appli- cations for historical corpus linguistics and the study of language acquisition.  Literary and Linguistic Comput- ing , 24(4):385–401. M. Hilpert. 2008.  Germanic future constructions: A usage-based approach to language change . Benjamins, Amsterdam, Netherlands. Patrick Juola. 2003. The time course of language change.  Computers and the Humanities , 37(1):77–96. David Jurgens and Keith Stevens. 2009. Event detection in blogs using Temporal Random Indexing. Nobuhiro Kaji and Hayato Kobayashi. 2017. Incremental skip-gram model with negative sampling. In  Proceed- ings of the Conference on Empirical Methods in Natural Language Processing , pages 363–371, Copenhagen, Denmark. Pentti Kanerva, Jan Kristofersson, and Anders Holst. 2000. Random indexing of text samples for latent semantic analysis. In  Proceedings of the 22nd annual conference of the cognitive science society , volume 1036, pages 103–106, Mahwah, USA. D. Kerremans, S. Stegmayr, and H.-J. Schmid. 2010. The neocrawler: Identifying and retrieving neologisms from the internet and monitoring ongoing change. In K. Allan and J. A. Robinson, editors,  Current methods in historical semantics , pages 130–160. De Gruyter Mouton. Yoon Kim, Yi-I Chiu, Kentaro Hanaki, Darshan Hegde, and Slav Petrov. 2014. Temporal analysis of language through neural language models. In  Proceedings of the 52nd Annual Meeting of the Association for Computa- tional Linguistics , pages 61–65, Baltimore, USA. Vivek Kulkarni, Rami Al-Rfou, Bryan Perozzi, and Steven Skiena. 2015. Statistically signiﬁcant detection of linguistic change. In  Proceedings of the 24th International Conference on World Wide Web , pages 625–635, Florence, Italy. Andrey Kutuzov and Elizaveta Kuzmenko. 2018. Two centuries in two thousand words: Neural embedding models in detecting diachronic lexical changes.  Quantitative Approaches to the Russian Language , pages 95–112. Andrey Kutuzov, Elizaveta Kuzmenko, and Anna Marakasova. 2016. Exploration of register-dependent lexical semantics using word embeddings. In  Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH) , pages 26–34, Osaka, Japan. Andrey Kutuzov, Erik Velldal, and Lilja Øvrelid. 2017a. Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conﬂict participants. In  Proceedings of the Conference on Empirical Methods in Natural Language Processing , pages 1824–1829, Copenhagen, Denmark. "}
{"page": 12, "image_path": "doc_images/C18-1117_12.jpg", "ocr_text": "Andrey Kutuzov, Erik Velldal, and Lilja @vrelid. 2017b. Tracing armed conflicts with diachronic word embedding\nmodels. In Proceedings of the Events and Stories in the News Workshop at ACL 2017, pages 31-36, Vancouver,\nCanada.\n\nOmer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit matrix factorization. In Proceedings\nof the 27th International Conference on Neural Information Processing Systems, pages 2177-2185, Montreal,\nCanada.\n\nXuanyi Liao and Guang Cheng. 2016. Analysing the semantic change based on word embedding. In Natural\nLanguage Understanding and Intelligent Applications, pages 213-223. Springer International Publishing.\n\nJefrey Lijffijt, Tanja Saily, and Terttu Nevalainen. 2012. CEECing the baseline: Lexical stability and significant\nchange in a historical corpus. In Studies in Variation, Contacts and Change in English, volume 10. Research\nUnit for Variation, Contacts and Change in English (VARIENG).\n\nChristopher D. Manning. 2015. Computational linguistics and deep learning. Computational Linguistics,\n41(4):701-707.\n\nJean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K. Gray, Joseph P. Pickett,\nDale Hoiberg, Dan Clancy, Peter Norvig, Jon Orwant, Steven Pinker, Martin A. Nowak, and Erez Lieberman\nAiden. 2011. Quantitative analysis of culture using millions of digitized books. Science, 331(6014):176-182.\n\nRada Mihalcea and Vivi Nastase. 2012. Word epoch disambiguation: Finding how words change over time. In\nProceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 259-263, Jeju\nIsland, Korea.\n\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient estimation of word representations\nin vector space. arXiv preprint arXiv:1301.3781.\n\nTomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013b. Distributed representations of\nwords and phrases and their compositionality. Advances in Neural Information Processing Systems, 26:3111-\n3119.\n\nSunny Mitra, Ritwik Mitra, Martin Riedl, Chris Biemann, Animesh Mukherjee, and Pawan Goyal. 2014. That’s\nsick dude!: Automatic identification of word sense change across different timescales. In Proceedings of the\n52nd Annual Meeting of the Association for Computational Linguistics, pages 1020-1029, Baltimore, Maryland.\n\nHannes Mueller and Christofer Rauh. 2017. Reading between the lines: Prediction of political violence using\nnewspaper text. American Political Science Review, page 1-18.\n\nRobert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. English Gigaword Fifth Edition\nLDC2011T07. Technical report, Technical Report. Linguistic Data Consortium, Philadelphia.\n\nHao Peng, Jianxin Li, Yangqiu Song, and Yaopeng Liu. 2017. Incrementally learning the hierarchical softmax\nfunction for neural language models. In Proceedings of the 31st AAAI Conference on Artificial Intelligence,\npages 3267-327, San Francisco, California USA.\n\nJeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global vectors for word repre-\nsentation. In Proceedings of the 2014 conference on Empirical Methods in Natural Language Processing, pages\n1532-1543, Doha, Qatar.\n\nOctavian Popescu and Carlo Strapparava. 2015. SemEval 2015, task 7: Diachronic text evaluation. In Proceedings\nof the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 870-878, Denver, Colorado.\n\nMatti Rissanen et al. 1993. The helsinki corpus of english texts. Kytté et. al, pages 73-81.\n\nAlex Rosenfeld and Katrin Erk. 2018. Deep neural models of semantic shift. In Proceedings of the 2018 Con-\nference of the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies, pages 474-484, New Orleans, Louisiana, USA.\n\nGuy D. Rosin, Eytan Adar, and Kira Radinsky. 2017. Learning word relatedness over time. In Proceedings of\nthe 2017 Conference on Empirical Methods in Natural Language Processing, pages 1179-1189, Copenhagen,\n\nDenmark.\n\nEyal Sagi, Stefan Kaufmann, and Brady Clark. 2011. Tracing semantic change with latent semantic analysis.\nCurrent methods in historical semantics, pages 161-183.\n\n1396\n", "vlm_text": "Andrey Kutuzov, Erik Velldal, and Lilja Øvrelid. 2017b. Tracing armed conﬂicts with diachronic word embedding models. In  Proceedings of the Events and Stories in the News Workshop at ACL 2017 , pages 31–36, Vancouver, Canada. Omer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit matrix factorization. In  Proceedings of the 27th International Conference on Neural Information Processing Systems , pages 2177–2185, Montreal, Canada. Xuanyi Liao and Guang Cheng. 2016. Analysing the semantic change based on word embedding. In  Natural Language Understanding and Intelligent Applications , pages 213–223. Springer International Publishing. Jefrey Lijfﬁjt, Tanja Säily, and Terttu Nevalainen. 2012. CEECing the baseline: Lexical stability and signiﬁcant change in a historical corpus. In  Studies in Variation, Contacts and Change in English , volume 10. Research Unit for Variation, Contacts and Change in English (VARIENG). Christopher D. Manning. 2015. Computational linguistics and deep learning. Computational Linguistics , 41(4):701–707.Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, Matthew K. Gray, Joseph P. Pickett, Dale Hoiberg, Dan Clancy, Peter Norvig, Jon Orwant, Steven Pinker, Martin A. Nowak, and Erez Lieberman Aiden. 2011. Quantitative analysis of culture using millions of digitized books.  Science , 331(6014):176–182. Rada Mihalcea and Vivi Nastase. 2012. Word epoch disambiguation: Finding how words change over time. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics , pages 259–263, Jeju Island, Korea. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efﬁcient estimation of word representations in vector space.  arXiv preprint arXiv:1301.3781 . Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013b. Distributed representations of words and phrases and their compositional it y.  Advances in Neural Information Processing Systems , 26:3111– 3119. Sunny Mitra, Ritwik Mitra, Martin Riedl, Chris Biemann, Animesh Mukherjee, and Pawan Goyal. 2014. That’s sick dude!: Automatic identiﬁcation of word sense change across different timescales. In  Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , pages 1020–1029, Baltimore, Maryland. Hannes Mueller and Christofer Rauh. 2017. Reading between the lines: Prediction of political violence using newspaper text.  American Political Science Review , page 1–18. Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. English Gigaword Fifth Edition LDC2011T07. Technical report, Technical Report. Linguistic Data Consortium, Philadelphia. Hao Peng, Jianxin Li, Yangqiu Song, and Yaopeng Liu. 2017. Incrementally learning the hierarchical softmax function for neural language models. In  Proceedings of the 31st AAAI Conference on Artiﬁcial Intelligence , pages 3267–327, San Francisco, California USA. Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global vectors for word repre- sentation. In  Proceedings of the 2014 conference on Empirical Methods in Natural Language Processing , pages 1532–1543, Doha, Qatar. Octavian Popescu and Carlo Strapparava. 2015. SemEval 2015, task 7: Diachronic text evaluation. In  Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015) , pages 870–878, Denver, Colorado. Matti Rissanen et al. 1993. The helsinki corpus of english texts.  Kyttö et. al , pages 73–81. Alex Rosenfeld and Katrin Erk. 2018. Deep neural models of semantic shift. In  Proceedings of the 2018 Con- ference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies , pages 474–484, New Orleans, Louisiana, USA. Guy D. Rosin, Eytan Adar, and Kira Radinsky. 2017. Learning word relatedness over time. In  Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , pages 1179–1189, Copenhagen, Denmark. Eyal Sagi, Stefan Kaufmann, and Brady Clark. 2011. Tracing semantic change with latent semantic analysis. \nCurrent methods in historical semantics , pages 161–183. "}
{"page": 13, "image_path": "doc_images/C18-1117_13.jpg", "ocr_text": "Evan Sandhaus. 2008. The New York Times annotated corpus overview. Linguistic Data Consortium, Philadel-\nphia, 6(12):e26752.\n\nGustaf Stern. 1931. Meaning and change of meaning; with special reference to the English language. Wettergren\n& Kerbers.\n\nTerrence Szymanski. 2017. Temporal word analogies: Identifying lexical replacement with diachronic word\nembeddings. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics,\npages 448-453, Vancouver, Canada.\n\nWayne A Taylor. 2000. Change-point analysis: a powerful new tool for detecting changes.\n\nElizabeth Closs Traugott and Richard B Dasher. 2001. Regularity in semantic change. Cambridge University\nPress.\n\nElizabeth Traugott. 2017. Semantic change. Oxford Research Encyclopedias: Linguistics.\n\nPeter Turney, Patrick Pantel, et al. 2010. From frequency to meaning: Vector space models of semantics. Journal\nof artificial intelligence research, 37(1):141-188.\n\nXuerui Wang and Andrew McCallum. 2006. Topics over time: a non-markov continuous-time model of topical\ntrends. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data\nmining, pages 424—433, Philadelphia, PA, USA.\n\nDerry Tanti Wijaya and Reyyan Yeniterzi. 2011. Understanding semantic change of words over centuries. In\n\nProceedings of the 2011 international workshop on Detecting and Exploiting Cultural diversity on the social\nweb, pages 35-40.\n\nYang Xu and Charles Kemp. 2015. A computational evaluation of two laws of semantic change. In Proceedings\nof the 37th Annual Meeting of the Cognitive Science Society, Austin, TX, USA.\n\nZijun Yao, Yifan Sun, Weicong Ding, Nikhil Rao, and Hui Xiong. 2018. Dynamic word embeddings for evolving\nsemantic discovery. In Proceedings of the Eleventh ACM International Conference on Web Search and Data\nMining, pages 673-681, Marina Del Rey, CA, USA.\n\nYating Zhang, Adam Jatowt, Sourav Bhowmick, and Katsumi Tanaka. 2015. Omnia mutantur, nihil interit:\nConnecting past with present by finding corresponding terms across time. In Proceedings of the 53rd Annual\nMeeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural\nLanguage Processing, pages 645-655, Beijing, China.\n\nYating Zhang, Adam Jatowt, Sourav S. Bhowmick, and Katsumi Tanaka. 2016. The past is not a foreign country:\nDetecting semantically similar terms across time. [EEE Transactions on Knowledge and Data Engineering,\n28(10):2793-2807, October.\n\n1397\n", "vlm_text": "Evan Sandhaus. 2008. The New York Times annotated corpus overview.  Linguistic Data Consortium, Philadel- phia , 6(12):e26752. Gustaf Stern. 1931.  Meaning and change of meaning; with special reference to the English language.  Wettergren & Kerbers. Terrence Szymanski. 2017. Temporal word analogies: Identifying lexical replacement with diachronic word embeddings. In  Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics , pages 448–453, Vancouver, Canada. Wayne A Taylor. 2000. Change-point analysis: a powerful new tool for detecting changes. Elizabeth Closs Traugott and Richard B Dasher. 2001.  Regularity in semantic change . Cambridge University Press.Elizabeth Traugott. 2017. Semantic change.  Oxford Research Encyclopedias: Linguistics . Peter Turney, Patrick Pantel, et al. 2010. From frequency to meaning: Vector space models of semantics.  Journal of artiﬁcial intelligence research , 37(1):141–188. Xuerui Wang and Andrew McCallum. 2006. Topics over time: a non-markov continuous-time model of topical trends. In  Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 424–433, Philadelphia, PA, USA. Derry Tanti Wijaya and Reyyan Yeniterzi. 2011. Understanding semantic change of words over centuries. In Proceedings of the 2011 international workshop on Detecting and Exploiting Cultural diversity on the social web , pages 35–40. Yang Xu and Charles Kemp. 2015. A computational evaluation of two laws of semantic change. In  Proceedings of the 37th Annual Meeting of the Cognitive Science Society , Austin, TX, USA. Zijun Yao, Yifan Sun, Weicong Ding, Nikhil Rao, and Hui Xiong. 2018. Dynamic word embeddings for evolving semantic discovery. In  Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining , pages 673–681, Marina Del Rey, CA, USA. Yating Zhang, Adam Jatowt, Sourav Bhowmick, and Katsumi Tanaka. 2015. Omnia mutantur, nihil interit: Connecting past with present by ﬁnding corresponding terms across time. In  Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing , pages 645–655, Beijing, China. Yating Zhang, Adam Jatowt, Sourav S. Bhowmick, and Katsumi Tanaka. 2016. The past is not a foreign country: Detecting semantically similar terms across time.  IEEE Transactions on Knowledge and Data Engineering , 28(10):2793–2807, October. "}
