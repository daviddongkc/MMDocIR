{"layout": 0, "type": "text", "text": "T AKE A  S TEP  B ACK : E VOKING  R EASONING VIA  A B - STRACTION IN  L ARGE  L ANGUAGE  M ODELS ", "text_level": 1, "page_idx": 0, "bbox": [106, 78, 507, 117], "page_size": [612.0, 792.0]}
{"layout": 1, "type": "text", "text": "Huaixiu Steven Zheng ∗ Swaroop Mishra ∗ Xinyun Chen Heng-Tze Cheng Ed H. Chi Quoc V Le Denny Zhou ", "text_level": 1, "page_idx": 0, "bbox": [114, 134, 449, 158], "page_size": [612.0, 792.0]}
{"layout": 2, "type": "text", "text": "Google DeepMind ", "page_idx": 0, "bbox": [113.9780044555664, 161.77154541015625, 188.40858459472656, 173.77647399902344], "page_size": [612.0, 792.0]}
{"layout": 3, "type": "text", "text": "A BSTRACT ", "text_level": 1, "page_idx": 0, "bbox": [277, 193, 334, 204], "page_size": [612.0, 792.0]}
{"layout": 4, "type": "text", "text": "We present S TEP -B ACK  P ROMPTING , a simple prompting technique that enables LLMs to do abstractions to derive high-level concepts and first principles from instances containing specific details. Using the concepts and principles to guide the reasoning steps, LLMs significantly improve their abilities in following a correct reasoning path towards the solution. We conduct experiments of S TEP -B ACK P ROMPTING  with PaLM-2L models and observe substantial performance gains on a wide range of challenging reasoning-intensive tasks including STEM, Knowl- edge QA, and Multi-Hop Reasoning. For instance, S TEP -B ACK  P ROMPTING improves PaLM-2L performance on MMLU Physics and Chemistry by  $7\\%$   and  $11\\%$  , TimeQA by  $27\\%$  , and MuSiQue by  $7\\%$  . ", "page_idx": 0, "bbox": [142, 218.17156982421875, 471, 328.8064880371094], "page_size": [612.0, 792.0]}
{"layout": 5, "type": "text", "text": "The purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise. — Edsger W. Dijkstra ", "page_idx": 0, "bbox": [107, 344.1595458984375, 505, 367.013916015625], "page_size": [612.0, 792.0]}
{"layout": 6, "type": "text", "text": "1 I N TRO DUCT ION ", "text_level": 1, "page_idx": 0, "bbox": [108, 395, 207, 407], "page_size": [612.0, 792.0]}
{"layout": 7, "type": "text", "text": "The field of natural language processing (NLP) is witnessing a ground-breaking revolution because of the Transformer-based (Vaswani et al., 2017) large language models (LLMs) (Devlin et al., 2018; Raffel et al., 2020; Brown et al., 2020; Anil et al., 2023). Scaling up the model size and pre-training corpus (Hoffmann et al., 2022; Chowdhery et al., 2022) has brought remarkable improvement in model capabilities and sample efficiency with insights from the scaling law (Kaplan et al., 2020; Hoffmann et al., 2022), as well as emergent abilities (Wei et al., 2022a) such as multi-step reasoning (Wei et al., 2022b; Zhou et al., 2022) and instruction following (Mishra et al., 2022b; Wei et al., 2021). ", "page_idx": 0, "bbox": [107, 420.92755126953125, 505, 498.68548583984375], "page_size": [612.0, 792.0]}
{"layout": 8, "type": "image", "page_idx": 0, "img_path": "layout_images/STEPBACK_0.jpg", "bbox": [112, 518, 492, 665], "page_size": [612.0, 792.0], "ocr_text": "1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\nMMLU Physics\n\n= GPT-4 = PaLM-2L = PaLM-2L +CoT # PaLM-2L + Step-Back Prompting\n\nMMLU Chemistry\n\nTimeQA\n\nSituatedQA\n\nMuSiQue\n\nStrategyQA\n", "vlm_text": "The image is a bar chart comparing the performance of different models across various tasks. Here’s what it shows:\n\n1. **Models Compared**:\n   - GPT-4 (blue)\n   - PaLM-2L (red)\n   - PaLM-2L + CoT (yellow)\n   - PaLM-2L + Step-Back Prompting (green)\n\n2. **Tasks Evaluated**:\n   - MMLU Physics\n   - MMLU Chemistry\n   - TimeQA\n   - SituatedQA\n   - MuSiQue\n   - StrategyQA\n\n3. **Performance Scores**:\n   - Each task features bars of different colors representing the models.\n   - The y-axis indicates performance scores, ranging from 0.0 to 1.0.\n   - The highest performance score in each task varies across different models.\n\nThe image visually demonstrates how different prompting techniques and models perform across specific evaluation tasks."}
{"layout": 9, "type": "text", "text": "Figure 1: Strong Performance of S TEP -B ACK  P ROMPTING : our proposed Abstraction-and-Reasoning scheme leads to a substantial improvement in a wide range of challenging tasks in STEM, Knowledge QA and Multi-Hop Reasoning requiring complex (often multi-hop) reasoning. ", "page_idx": 0, "bbox": [107, 677.3065795898438, 505, 711.2294921875], "page_size": [612.0, 792.0]}
{"layout": 10, "type": "text", "text": "Despite the great advancements, complex multi-step reasoning remains challenging for even the state- of-the-art LLMs. Lightman et al. (2023) show that process-supervision with step-by-step verification is a promising remedy to improve the correctness of intermediate reasoning steps. Techniques such as Chain-of-Thought prompting (Wei et al., 2022b) were introduced to produce a coherent series of intermediate reasoning steps to increase the success rate of following the right decoding path. Inspired by the fact that when faced with challenging tasks humans often step back and do abstractions to arrive at high-level concepts and principles to guide the process, we propose S TEP -B ACK  P ROMPTING  to ground reasoning on abstractions to reduce the chance of making errors in the intermediate reasoning steps. ", "page_idx": 1, "bbox": [107, 82.6185302734375, 505, 182.2954559326172], "page_size": [612.0, 792.0]}
{"layout": 11, "type": "image", "page_idx": 1, "img_path": "layout_images/STEPBACK_1.jpg", "bbox": [107, 192, 504, 469], "page_size": [612.0, 792.0], "ocr_text": "‘hain-of-Thought\n...lf the temperature is increased by a\nfactor of 2 and the volume is increased by\n\na factor of 8, we can rewrite the ideal gas\nlaw as: 2P' (8V) = nR(2T), where P*\nrepresents the new pressure.\n\nSimplifying the equation, we get: 16P'V =\n2nRT or P= (2nRT) / (16V)\n\nSince n, R, and V are constants, we can\nwrite this as: P' = (1/8) * (nRT/V)\n\nSince nRT/V is the original pressure P, we\nhave: P’ = (1/8) * P This means the new\npressure P' is 1/8 of the original pressure >€\nP..\n\nIf the temperature is increased by a factor of 2\nand the volume is increased by a factor of 8,\nthen the pressure will decrease by a factor of\n16.\n\nStep-Back Prompting\nStepback Answer\nIdeal gas law: PV = nRT, where P is the pressure, V\n\nis the volume, nis the number of moles, R is the gas\nconstant, and T is the temperature.\n\nWhat are the physics\nprinciples behind this\nquestion?\n\nStep 2: Reasoning\n\nFinal Answer\n‘Apply Ideal gas law to find out the pressure.\n\nStep 1: Abstraction\n\nIf the temperature is increased by a factor of 2, then T\nbecomes 2T. If the volume is increased by a factor of 8,\nthen V becomes 8V.\n\nOriginal Question\nWhat happens to the\npressure, P, of an ideal gas if\nthe temperature is increased\nby a factor of 2 and the\nvolume is increased by a\nfactor of 8 ?\n\nSubstituting these values into the ideal gas law, we get:\nP(8V) = nR(2T)\n\nDividing both sides by 8V, we get:\nP=nR(2T)/8V\n\nWe can see that the pressure has decreased by a factor\nof 4.\n\n... After that, she pursued graduate studies\nat the University of California, Berkeley,\nearning her master's degree in 1950 and her\nPh.D. in 1955.\n\nConsidering this timeline, it is highly likely\nthat Estella Leopold was attending the\nUniversity of California, Berkeley, between\nAugust 1954 and November 1954...\n\nx/\n\nEstella Leopold attended the University of\nWisconsin-Madison between August 1954\nand November 1954\n\nx\n\nStep-Back Prompting\n\nB.S. in Botany, University of Wisconsin, Madison, 1948\n| M.S. in Botany, University of California, Berkeley, 1950\nPh.D. in Botany, Yale University, 1955\n\nWhat was Estella Leopold's\neducation history?\n\nStep 2: Reasoning\n\nFinal Answer\n‘She was enrolled in the Ph.D. program in Botany at Yale\nfrom 1951 to 1955. Therefore, Estella Leopold was most\nlikely attending Yale University between August 1954 ay,\n\nEstella Leopold went to which\n‘school between Aug 1954\nand Nov 1954?\n\nNovember 1954.\n\n", "vlm_text": "The image is a comparison of two problem-solving methods: Chain-of-Thought and Step-Back Prompting.\n\n1. **First Problem: Ideal Gas Law**\n   - **Chain-of-Thought**: The pressure decreases by a factor of 8, leading to an incorrect answer of decrease by a factor of 16.\n   - **Step-Back Prompting**: Breaks down using the ideal gas law (PV = nRT), correctly concludes the pressure decreases by a factor of 4.\n\n2. **Second Problem: Estella Leopold’s Education**\n   - **Chain-of-Thought**: Incorrectly states Estella attended the University of Wisconsin-Madison between August 1954 and November 1954.\n   - **Step-Back Prompting**: Provides Estella’s educational history and correctly concludes she likely attended Yale University during that period.\n\nThe image highlights how Step-Back Prompting offers a more structured and accurate approach to problem-solving compared to the Chain-of-Thought method."}
{"layout": 12, "type": "text", "text": "Figure 2: Illustration of S TEP -B ACK  P ROMPTING  with two steps of Abstraction and Reasoning guided by concepts and principles.  Top : an example of MMLU high-school physics (Hendrycks et al., 2020) where the first principle of Ideal Gas Law is retrieved via abstraction.  Bottom : an example from TimeQA (Chen et al., 2021) where the high-level concept of education history is a result of the abstraction.  Left : PaLM-2L (Anil et al., 2023) fails to answer the original question. Chain-of-Thought prompting (Wei et al., 2022b; Kojima et al., 2022) ran into errors during intermediate reasoning steps (highlighted as red).  Right : PaLM-2L (Anil et al., 2023) successfully answers the question via S TEP -B ACK  P ROMPTING . ", "page_idx": 1, "bbox": [107, 480.8255615234375, 505, 569.5435180664062], "page_size": [612.0, 792.0]}
{"layout": 13, "type": "text", "text": "Among many of the cognitive skills, abstraction (Lachmy et al., 2022) is ubiquitous to humans’ ability to process vast amount of information and derive general rules, and principles. For example, Kepler compressed thousands of measurements into Kepler’s three laws of planetary motion which precisely describe the orbits of planets around the Sun (Russell, 1964). In critical decision making, humans find abstraction to be helpful since it provides a broader view of the environment. This work explores how LLMs can tackle complex tasks involving many low-level details through a two-step process of abstraction-and-reasoning. The first step is to teach LLMs to step back, and derive high-level abstractions such as concepts and first principles from the specific example. The second step is to leverage the reasoning ability to ground the solution on the high-level concepts and first principles. We use few-shot exemplar demonstrations to execute S TEP -B ACK  P ROMPTING  on LLMs. ", "page_idx": 1, "bbox": [107, 583.1715698242188, 505, 693.8065185546875], "page_size": [612.0, 792.0]}
{"layout": 14, "type": "text", "text": "We experiment across a range of tasks involving domain specific reasoning such as Physics and Chem- istry, knowledge-intensive question answering requiring factual knowledge, multi-hop commonsense reasoning. We observe significant performance improvements (up to  $27\\%$  ) in PaLM-2L (Anil et al., 2023) demonstrating the efficacy of S TEP -B ACK  P ROMPTING  in tackling complex tasks which are otherwise challenging due to the amount of details involved to reason through. Figure 1 shows a summary of all the key results presented in this paper. Some the tasks are very challenging: both PaLM-2L and GPT-4 achieve only    $\\sim40\\%$   accuracy on TimeQA and MuSiQue. Chain-of-Thought prompting leads to a minor improvement on a few tasks, while S TEP -B ACK  P ROMPTING  improves the performance of PaLM-2L across the board:  $7\\%$   and    $11\\%$   on MMLU Physics and Chemistry,    $27\\%$  on TimeQA, and  $7\\%$   on MuSiQue. ", "page_idx": 1, "bbox": [107, 698.738525390625, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 15, "type": "text", "text": "", "page_idx": 2, "bbox": [107, 82.6185302734375, 505, 160.3774871826172], "page_size": [612.0, 792.0]}
{"layout": 16, "type": "text", "text": "We conduct a variety of analysis and find that S TEP -B ACK  P ROMPTING  has strong performance improvements (up to  $36\\%$  ) over chain of thought (CoT) prompting (Wei et al., 2022b) and take a deep breathe (TDB) prompting (Yang et al., 2023). We perform a qualitative evaluation where we find that Step-Back fixes a large po  errors of the base model (up to  $\\sim40\\%$  ) while introducing a small portion of new errors (max  ∼  $\\sim12\\%$  ). We also conduct an error analysis and find that majority of the errors made by S TEP -B ACK ROMPTING  is attributed to the intrinsic limitations of reasoning capabilities of LLMs while abstraction skills are relatively easy to teach LLMs, pointing out the direction for future improvements of methods alike S TEP -B ACK  P ROMPTING . ", "page_idx": 2, "bbox": [107, 165.30853271484375, 505, 254.02647399902344], "page_size": [612.0, 792.0]}
{"layout": 17, "type": "text", "text": "2 S TEP -B ACK  P ROMPTING ", "text_level": 1, "page_idx": 2, "bbox": [107, 272, 252, 284], "page_size": [612.0, 792.0]}
{"layout": 18, "type": "text", "text": "S TEP -B ACK  P ROMPTING  is motivated by the observation that many tasks contain a lot of details, and are hard for LLMs to retrieve relevant facts to tackle the task. As shown in the first example (top) in Figure 2, for a Physics question of “ What happens to the pressure, P, of an ideal gas if the temperature is increased by a factor of 2 and the volume is increased by a factor of 8 ? ”, the LLM can deviate from the first principle of Ideal Gas Law when reasoning directly on the question. Similarly, a question of “ Estella Leopold went to which school between Aug 1954 and Nov 1954? ” is very hard to address directly given the detailed time range constraint. In both cases, taking a step back and asking a step-back question helps model to solve the problem effectively. ", "page_idx": 2, "bbox": [107, 298.4445495605469, 505, 387.1614990234375], "page_size": [612.0, 792.0]}
{"layout": 19, "type": "text", "text": "We define a step-back question as a derived question from the original question at a higher-level of abstraction. For instance, instead of directly asking “ which school Estella Leopold went to during a specific period ”, a step-back question (Figure 2 bottom) would ask about the “ education history ”, which is a high-level concept encompasses the original question. Answering the step-back question of “ Estella Leopold’s education history ” in this case will provide all the necessary information to reason about “ which school Estella Leopold went to during a specific period ”. The premise is that more often the step-back question is much easier to address than the original question. Grounding the reasoning on top of such abstractions helps to avoid reasoning errors in the intermediate steps such as the example shown in Figure 2 (left) from Chain-of-Thought. In short, S TEP -B ACK  P ROMPTING consists two simple steps: ", "page_idx": 2, "bbox": [107, 392.09356689453125, 505, 502.7284851074219], "page_size": [612.0, 792.0]}
{"layout": 20, "type": "text", "text": " Abstraction : Instead of addressing the question directly, we first prompt the LLM to ask a generic step-back question about a higher-level concept or principles, and retrieve relevant facts about the high-level concept or principles.  Reasoning : Grounded on the facts regarding high-level concept or principles, the LLM can reason about the solution to the original question. We term this  Abstraction-grounded Reasoning . ", "page_idx": 2, "bbox": [111, 507.408935546875, 505, 566.4425048828125], "page_size": [612.0, 792.0]}
{"layout": 21, "type": "text", "text": "In the following sections, we present an empirical study of S TEP -B ACK  P ROMPTING  on a range of challenging tasks covering STEM, Knowledge QA and Multi-Hop Reasoning involving complex reasoning. ", "page_idx": 2, "bbox": [107, 571.4815673828125, 505, 605.4044799804688], "page_size": [612.0, 792.0]}
{"layout": 22, "type": "text", "text": "3 E X PERI MENTAL  S ETUP ", "text_level": 1, "page_idx": 2, "bbox": [107, 624, 246, 636], "page_size": [612.0, 792.0]}
{"layout": 23, "type": "text", "text": "Here we define the tasks and models we experiment with. We also describe our evaluation metric and the baselines we consider. ", "page_idx": 2, "bbox": [107, 649.8225708007812, 505, 672.7864990234375], "page_size": [612.0, 792.0]}
{"layout": 24, "type": "text", "text": "3.1 T ASKS ", "text_level": 1, "page_idx": 2, "bbox": [107, 688, 161, 699], "page_size": [612.0, 792.0]}
{"layout": 25, "type": "text", "text": "We experiment with the following diverse tasks: (a) STEM, (b) Knowledge QA and (c) Multi-Hop Reasoning. We describe below the datasets we consider (see Appendix B for more details). ", "page_idx": 2, "bbox": [107, 709.6975708007812, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 26, "type": "text", "text": "•  STEM : MMLU (Hendrycks et al., 2020) contains a series of benchmarks across diverse domains to evaluate model’s language understanding. We consider the high school physics and chemistry portions of MMLU because of the deep reasoning involved. •  Knowledge QA : We consider TimeQA (Chen et al., 2021) since it contains complex queries that requires challenging time-sensitive knowledge. We also experiment with SituatedQA (Zhang & Choi, 2021), another challenging open-retrieval QA dataset requiring model to answer questions given temporal or geographical contexts. •  Multi-Hop Reasoning : We experiment with MuSiQue (Trivedi et al., 2022), a hard multihop reasoning dataset created via composable pairs of single-hop questions, and StrategyQA (Geva et al., 2021) with open-domain questions that demands some strategy to solve. ", "page_idx": 3, "bbox": [135, 82.25988006591797, 505, 201.1494598388672], "page_size": [612.0, 792.0]}
{"layout": 27, "type": "text", "text": "3.2 M ODELS ", "text_level": 1, "page_idx": 3, "bbox": [108, 213, 171, 225], "page_size": [612.0, 792.0]}
{"layout": 28, "type": "text", "text": "We use the following state of the art LLMs: PaLM-2L (Anil et al., 2023) and GPT-4 (OpenAI, 2023). We experiment with a variety of baselines with an instruction-tuned PaLM-2L model. ", "page_idx": 3, "bbox": [107, 234.64056396484375, 505, 257.6044921875], "page_size": [612.0, 792.0]}
{"layout": 29, "type": "text", "text": "3.3 E VALUATION ", "text_level": 1, "page_idx": 3, "bbox": [108, 270, 189, 282], "page_size": [612.0, 792.0]}
{"layout": 30, "type": "text", "text": "Conventional evaluation metric such as accuracy, F1 score has limitations specifically for evaluating the generations of state of the art LLMs since these models often generate long form answers which are hard to capture. We instead conduct evaluation using the PaLM2-L model where we few-shot prompt the model to identify equivalence between target answers and the model predictions. Few shot examples, prompts and other details we use for this evaluation are in Appendix C. ", "page_idx": 3, "bbox": [107, 291.09454345703125, 505, 346.93548583984375], "page_size": [612.0, 792.0]}
{"layout": 31, "type": "text", "text": "3.4BASELINE METHODS", "text_level": 1, "page_idx": 3, "bbox": [107, 360, 222, 371], "page_size": [612.0, 792.0]}
{"layout": 32, "type": "text", "text": "•  PaLM-2L, PaLM-2L 1-shot : PaLM-2L is either queried directly with the question or has a single demonstration exemplar of question-answer included in the prompt. •    $\\mathbf{PaLM-}2\\mathbf{L}+\\mathbf{CoT}_{\\mathrm{i}}$  , PaLM-2L  $^+$   CoT 1-shot : PaLM-2L model is queried with zero-shot CoT prompting (Kojima et al., 2022): “ Let’s think step by step ” is appended to the question. For 1-shot, One demonstration example of a question and answer pair is provided in the prompt, where the answer is in the style of CoT (Wei et al., 2022b) with intermediate reasoning steps. •  PaLM-2L  $^+$   TDB : Zero-shot prompting with “ Take a deep breath and work on this problem step-by-step. ” (Yang et al., 2023) prepended to the question. •  PaLM  $\\mathbf{\\nabla}\\!\\cdot\\!\\mathbf{2L}+\\mathbf{RAC}$  : For Sections 5 and 6, we use retrieval-augmented generation (RAG) where the relevant passage retrieved is used as context by the LLM. •  GPT-4 : GPT-4 API is directly queried. ", "page_idx": 3, "bbox": [135, 376.48089599609375, 505, 525.78125], "page_size": [612.0, 792.0]}
{"layout": 33, "type": "text", "text": "We do not use RAG for MMLU, because of the inherent reasoning nature of this benchmark contrary to the other fact-seeking datasets. All inferences are done using greedy decoding. ", "page_idx": 3, "bbox": [107, 535.0035400390625, 505, 557.9674682617188], "page_size": [612.0, 792.0]}
{"layout": 34, "type": "text", "text": "4 STEM ", "text_level": 1, "page_idx": 3, "bbox": [107, 573, 162, 586], "page_size": [612.0, 792.0]}
{"layout": 35, "type": "text", "text": "We evaluate S TEP -B ACK  P ROMPTING  on STEM tasks (Hendrycks et al., 2020) to gauge the efficacy of our method on reasoning in highly-specialized domains. We explain below our experimental setup, result and analysis of applying S TEP -B ACK  P ROMPTING  on the MMLU high-school Physics and Chemistry benchmarks. ", "page_idx": 3, "bbox": [107, 598.4485473632812, 505, 643.3295288085938], "page_size": [612.0, 792.0]}
{"layout": 36, "type": "text", "text": "4.1 S TEP -B ACK  P ROMPTING ", "text_level": 1, "page_idx": 3, "bbox": [107, 657, 237, 668], "page_size": [612.0, 792.0]}
{"layout": 37, "type": "text", "text": "Questions in the MMLU benchmarks require deeper reasoning. Furthermore, they also require understanding and application of formulae which are often physics and chemistry principles and concepts. In this case, we first teach the model to do abstraction in the form of concepts and first principles such as  Newton’s first law of motion ,  Doppler effect , and  Gibbs free energy  etc. The implicit step-back question here is “ what are the physics or chemistry principles and concepts involved in Table 1: Strong performance of S TEP -B ACK  P ROMPTING  on STEM tasks achieving state-of-the-art surpassing GPT-4. CoT: zero-shot Chain of Thought prompting (Kojima et al., 2022), TDB: Take a Deep Breathe prompting (Yang et al., 2023). The Table reports the average accuracy over 5 evaluation runs, with standard deviations in the parentheses. ", "page_idx": 3, "bbox": [107, 676.820556640625, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 38, "type": "text", "text": "", "page_idx": 4, "bbox": [107, 80.32757568359375, 504, 125.20946502685547], "page_size": [612.0, 792.0]}
{"layout": 39, "type": "table", "page_idx": 4, "img_path": "layout_images/STEPBACK_2.jpg", "bbox": [160, 138, 452, 245], "page_size": [612.0, 792.0], "ocr_text": "Method | MMLU Physics | MMLU Chemistry\n\nPaLM-2L 66.4% (0.8%) 70.9% (0.9%)\nPaLM-2L 1-shot 64% (1.6%) 75.6% (0.4%)\nPaLM-2L + CoT 65% (2%) 75.3% (1.5%)\nPaLM-2L + CoT 1-shot 61.5% (1.8%) 76.6% (1%)\n\nPaLM-2L + TDB 65.7% (0.7%) 73.8% (1.1%)\n\nPaLM-2L + Step-Back (ours) | 73.2% (1.9%) 81.8% (1.4%)\n\nGPT-4 70.3% (2.3%) | 79.9% (1.0%)\n\n", "vlm_text": "The table presents performance metrics for different methods on two datasets: MMLU Physics and MMLU Chemistry. The methods include variations of PaLM-2L and GPT-4. Here's a breakdown:\n\n### Methods:\n1. **PaLM-2L**\n2. **PaLM-2L 1-shot**\n3. **PaLM-2L + CoT**\n4. **PaLM-2L + CoT 1-shot**\n5. **PaLM-2L + TDB**\n6. **PaLM-2L + Step-Back (ours)**\n7. **GPT-4**\n\n### Performance:\n- The performance is given in percentages, representing accuracy, with a percentage in parentheses indicating some measure of variance or error (possibly standard deviation).\n\n#### MMLU Physics:\n- **PaLM-2L**: 66.4% (0.8%)\n- **PaLM-2L 1-shot**: 64% (1.6%)\n- **PaLM-2L + CoT**: 65% (2%)\n- **PaLM-2L + CoT 1-shot**: 61.5% (1.8%)\n- **PaLM-2L + TDB**: 65.7% (0.7%)\n- **PaLM-2L + Step-Back (ours)**: 73.2% (1.9%)\n- **GPT-4**: 70.3% (2.3%)\n\n#### MMLU Chemistry:\n- **PaLM-2L**: 70.9% (0.9%)\n- **PaLM-2L 1-shot**: 75.6% (0.4%)\n- **PaLM-2L + CoT**: 75.3% (1.5%)\n- **PaLM-2L + CoT 1-shot**: 76.6% (1%)\n- **PaLM-2L + TDB**: 73.8% (1.1%)\n- **PaLM-2L + Step-Back (ours)**: 81.8% (1.4%)\n- **GPT-4**: 79.9% (1.0%)\n\n#### Observations:\n- **PaLM-2L + Step-Back (ours)** method shows the highest performance on both datasets.\n- **GPT-4** performs well, especially on MMLU Chemistry."}
{"layout": 40, "type": "text", "text": "solving this task? ”. We provide demonstrations to teach the model to recite from its own knowledge relevant principles for solving the task (see Appendix D.1 for few-shot exemplars). ", "page_idx": 4, "bbox": [107, 271.7805480957031, 504, 294.7445068359375], "page_size": [612.0, 792.0]}
{"layout": 41, "type": "text", "text": "4.2 R ESULTS ", "text_level": 1, "page_idx": 4, "bbox": [107, 309, 171, 321], "page_size": [612.0, 792.0]}
{"layout": 42, "type": "text", "text": "Table 1 illustrates model performance across various setup. PaLM-2L baseline performance is  $66.4\\%$   and  $70.9\\%$   on Physics and Chemistry, re- spectively. We find that CoT and TDB zero-shot prompting do not significantly increase model performance which could be due to inherent hardness and deep reasoning associated with these tasks. In addition PaLM-2L 1-shot and PaLM-  $2\\mathrm{L}+\\mathrm{CoT}$  1-shot do not improve against the baseline much, highlighting the challenge of demonstrating the reasoning steps to the model. In contrast, S TEP -B ACK  P ROMPTING  signifi- cantly improves model performance:  $+7\\%$   and  $+11\\%$   compared to PaLM-2L, achieving state- of-the-art performance surpassing GPT-4. ", "page_idx": 4, "bbox": [106, 330.9505615234375, 297, 496.3794860839844], "page_size": [612.0, 792.0]}
{"layout": 43, "type": "image", "page_idx": 4, "img_path": "layout_images/STEPBACK_3.jpg", "img_caption": "Number of Shots ", "bbox": [307, 333, 502, 446], "page_size": [612.0, 792.0], "ocr_text": "Accuracy\n0.75\n0.74\n0.73\n0.72\n071\n0.70\n", "vlm_text": "The image is a line graph titled \"Accuracy.\" The x-axis is labeled with numbers from 1 to 5, which are described in the caption as the \"Number of Shots.\" The y-axis ranges from 0.70 to 0.75. The line connects five data points, showing fluctuations in accuracy across the five shots. The peak accuracy occurs at the third shot, while the lowest is on the fourth shot."}
{"layout": 44, "type": "text", "text": "4.3 A BLATION AND  A NALYSIS ", "text_level": 1, "page_idx": 4, "bbox": [106, 511, 245, 523], "page_size": [612.0, 792.0]}
{"layout": 45, "type": "text", "text": "Few-shot Ablation : First, in Figure 3 we ob- serve that S TEP -B ACK  P ROMPTING  is robust against number of few-shot exemplars of (question, principles) pairs used as demonstrations. Adding more demonstration examples beyond a single example is not helpful any more. This indicates that the task of retrieving the relevant principles and concepts is relatively easy to learn and a single demonstration suffices. ", "page_idx": 4, "bbox": [107, 532.2269287109375, 505, 588.426513671875], "page_size": [612.0, 792.0]}
{"layout": 46, "type": "text", "text": "Error Analysis : Figure 4 (left) shows the error analysis of the predictions of S TEP -B ACK  P ROMPT - ING  compared to the baseline PaLM-2L model for MMLU high-school Physics: S TEP -B ACK P ROMPTING  corrects  $20.5\\%$   errors from the baseline while introducing  $11.9\\%$   errors. ", "page_idx": 4, "bbox": [107, 592.9989013671875, 505, 627.280517578125], "page_size": [612.0, 792.0]}
{"layout": 47, "type": "text", "text": "To further understand where the errors come from in S TEP -B ACK  P ROMPTING , we annotate all the wrong predictions of S TEP -B ACK  P ROMPTING  in the test set, and category them into 5 classes (see Appendix E.1 for examples in each class):\n\n ", "page_idx": 4, "bbox": [107, 632.2115478515625, 505, 666.134521484375], "page_size": [612.0, 792.0]}
{"layout": 48, "type": "text", "text": "•  Principle Error : The error happens at the step of Abstraction, where the first principles generated by models are wrong or incomplete.\n\n •  Factual Error : There is at least one factual error when the model recites its own factual knowledge.\n\n •  Math Error : There is at least one math error in the intermediate steps when math calculations are involved in deriving the final answer. ", "page_idx": 4, "bbox": [107, 670.7929077148438, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 49, "type": "text", "text": "Table 2: Strong performance of S TEP -B ACK  P ROMPTING  on Knowledge QA tasks. CoT: Chain of Thought prompting, TDB: Take a Deep Breathe prompting, RAG: retrieval-augmented generation. S TEP -B ACK  P ROMPTING  results in significant performance improvements.\n\n ", "page_idx": 5, "bbox": [107, 80.32757568359375, 505, 114.25048065185547], "page_size": [612.0, 792.0]}
{"layout": 50, "type": "table", "page_idx": 5, "img_path": "layout_images/STEPBACK_4.jpg", "bbox": [112, 128, 501, 256], "page_size": [612.0, 792.0], "ocr_text": "Method TimeQA | TQA Easy TQA Hard SituatedQA\nPaLM-2L 41.5% 42.6% 40.4% 54.3% (0.3%)\nPaLM-2L 1-shot 40.7% 41.7% 39.1% 51.8% (0.6%)\nPaLM-2L + CoT 40.8% 41.8% 39.8% 56.4% (0.2%)\nPaLM-2L + CoT 1-shot 38.1% 39.3% 36.8% 54% (0.8%)\nPaLM-2L + TDB 40.9% 42.6% 39.1% 54% (0.5%)\nPaLM-2L + RAG 57.4% 67.8% 46.8% 59.3% (0.4%)\nPaLM-2L + Step-Back (ours) 66% 70.4% 61.6% 57.5% (0.3%)\nPaLM-2L + Step-Back + RAG (ours) | 68.7% 75.2% 62.3% 61% (0.4%)\nGPT-4 45.6% 48.9% 42.6% 63.2% (0.4%)\n\n", "vlm_text": "The table shows the performance of different methods on four benchmarks: TimeQA, TQA Easy, TQA Hard, and SituatedQA. Here's a breakdown:\n\n- **Methods**: Various combinations of the PaLM-2L model with different approaches, such as 1-shot learning, CoT (Chain of Thought), TDB, RAG, and Step-Back, compared to GPT-4.\n- **Columns**: Each method's performance is measured in percentages for each benchmark.\n  - **TimeQA**: \n    - Highest: PaLM-2L + Step-Back + RAG (68.7%)\n  - **TQA Easy**: \n    - Highest: PaLM-2L + Step-Back + RAG (75.2%)\n  - **TQA Hard**: \n    - Highest: PaLM-2L + Step-Back (61.6%)\n  - **SituatedQA**: \n    - Highest: GPT-4 (63.2% with a variation of 0.4%)\n\nThe values in parentheses represent variation percentages for SituatedQA."}
{"layout": 51, "type": "text", "text": "•  Context Loss : There is at least one error when the model response loses context from the question, and deviates from addressing the original question.\n\n •  Reasoning Error : We define Reasoning Error as when the model makes error in the intermediate Reasoning steps before arriving at the final answer. ", "page_idx": 5, "bbox": [107, 284.57391357421875, 505, 332.64849853515625], "page_size": [612.0, 792.0]}
{"layout": 52, "type": "text", "text": "All five types of errors are happening during the Reasoning step except  Principle Error  which points to the failure of the Abstraction step. As shown in Figure 4 (right),  Principle Error  in fact comprises only a small fraction of the errors the model makes: more than  $90\\%$   of the errors happen at the Reasoning step. Among the four error types during Reasoning,  Reasoning Error  and  Math Error  are the major loss buckets. This corroborates with the finding in the ablation study above that very few exemplars are needed to teach LLMs the Abstraction skill. Reasoning step is still the bottleneck of how well S TEP -B ACK  P ROMPTING  can perform tasks such as MMLU requiring complex reasoning. For MMLU Physics specifically, the Reasoning and Math skills are critical for solving the problems successfully: even if the first principles are retrieved correctly, deep reasoning and math are involved to derive a correct final answer through a typical multi-step reasoning process. ", "page_idx": 5, "bbox": [107, 337.7745666503906, 505, 448.4104919433594], "page_size": [612.0, 792.0]}
{"layout": 53, "type": "image", "page_idx": 5, "img_path": "layout_images/STEPBACK_5.jpg", "img_caption": "Figure 4: Error Analysis of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics.  Left : example categories in four buckets regarding whether the baseline or Step-Back prediction is right or wrong. Right : five classes of errors Step-Back makes with Reasoning being the dominating class. ", "bbox": [106, 471, 505, 641], "page_size": [612.0, 792.0], "ocr_text": "‘Step-Back Wrong\n11.9%\n\nBoth Wrong\n27.2%\n\nBoth Right\n40.4\n\n0.6\n\n0.4\n\n0.55\n\n", "vlm_text": "The image contains two main parts related to error analysis in high-school physics using Step-Back Prompting on the MMLU dataset:\n\n1. **Left: Pie Chart** - This chart shows the distribution of prediction outcomes in four categories:\n   - Both Right: 40.4%\n   - Baseline Wrong: 20.5%\n   - Step-Back Wrong: 11.9%\n   - Both Wrong: 27.2%\n\n2. **Right: Bar Chart** - This chart highlights five classes of errors made by the Step-Back model:\n   - Factual Error: 0.04\n   - Math Error: 0.25\n   - Context Loss: 0.07\n   - Reasoning Error: 0.55 (dominating class)\n   - Principle Error: 0.09\n\nThe analysis suggests that reasoning errors are most frequent when using Step-Back Prompting."}
{"layout": 54, "type": "text", "text": "5 K NOWLEDGE  QA ", "text_level": 1, "page_idx": 5, "bbox": [107, 671, 217, 684], "page_size": [612.0, 792.0]}
{"layout": 55, "type": "text", "text": "We evaluate S TEP -B ACK  P ROMPTING  on question answering benchmarks requiring intensive factual knowledge. Knowledge QA has been challenging for LLMs. In this section, we first describe the experimental setup, followed by results and analysis on S TEP -B ACK  P ROMPTING . ", "page_idx": 5, "bbox": [107, 698.738525390625, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 56, "type": "text", "text": "5.1 S TEP -B ACK  P ROMPTING ", "text_level": 1, "page_idx": 6, "bbox": [106, 83, 236, 94], "page_size": [612.0, 792.0]}
{"layout": 57, "type": "text", "text": "We evaluate S TEP -B ACK  P ROMPTING  on TimeQA (Chen et al., 2021) and SituatedQA (Zhang & Choi, 2021) in the Knowledge QA category. We first teach the LLMs to do Abstraction. The step-back question “ What was Estella Leopold’s education history ” in Figure 2 is generated by the LLM through few-shot demonstrations (see Appendix D.2 for details). Given the knowledge-intensive nature of these queries, we use retrieval augmentation (RAG) in combination with S TEP -B ACK  P ROMPTING . The step-back question is used to retrieve relevant facts, which works as additional context (see Table 12 for the prompting template) to ground the final reasoning step. ", "page_idx": 6, "bbox": [104, 103.14154052734375, 505, 180.90049743652344], "page_size": [612.0, 792.0]}
{"layout": 58, "type": "text", "text": "5.2 R ESULTS ", "text_level": 1, "page_idx": 6, "bbox": [107, 193, 171, 205], "page_size": [612.0, 792.0]}
{"layout": 59, "type": "text", "text": "We evaluate the models on the test-set of TimeQA. As shown in Table 2, the baseline models of GPT-4 and PaLM-2L achieved    $45.6\\%$   and  $41.5\\%$  , highlighting the difficulty of the task. Applying either CoT or TDB zero-shot (and one-shot) prompting to the baseline model shows no improvement. In contrast, augmenting the baseline model by regular retrieval augmentation (RAG) improves the accuracy to  $57.4\\%$  , highlighting the factual intensive nature of the task. The result of Step-Back  $+\\;\\mathbf{R}\\mathbf{A}\\mathbf{G}$   shows the effectiveness of going back to a high-level concept, which enables much more reliable retrieval augmentation: the accuracy on TimeQA achieves a remarkable  $68.7\\%$  . ", "page_idx": 6, "bbox": [104, 214.03857421875, 505, 291.7965087890625], "page_size": [612.0, 792.0]}
{"layout": 60, "type": "text", "text": "Next, we segment TimeQA into the Easy and Hard difficulty level provided in the original dataset. As expected, all methods perform worse on the Hard segment. While RAG can improve the Easy accuracy from  $42.6\\%$   to  $67.8\\%$  , the improvement is much smaller on the Hard accuracy:  $40.4\\%$   to  $46.8\\%$  . This is where S TEP -B ACK  P ROMPTING  really shines by retrieving facts regarding high-level concepts to ground the final reasoning: Step-Back  $^+$   RAG further improves the Hard accuracy to\n\n  $62.3\\%$  , outperforming  $42.6\\%$   from GPT-4. We hypothesis that facts regarding the high-level concepts\n\n (such as  education history ) is much more accessible than the low-level details. ", "page_idx": 6, "bbox": [104, 296.7285461425781, 505, 374.48651123046875], "page_size": [612.0, 792.0]}
{"layout": 61, "type": "text", "text": "On the SituatedQA benchmark, we observe a moderate quality gain from    $54.3\\%$   to our best method of Step-Back  $^+$   RAG    $61\\%$   with a small gap to GPT-4’s    $63.{\\dot{2}}{\\bar{\\%}}$  . Similar to TimeQA, prompting techniques such as CoT and TDB don’t help significantly for SituatedQA. ", "page_idx": 6, "bbox": [104, 379, 505, 413.34149169921875], "page_size": [612.0, 792.0]}
{"layout": 62, "type": "image", "page_idx": 6, "img_path": "layout_images/STEPBACK_6.jpg", "bbox": [122, 431, 486, 537], "page_size": [612.0, 792.0], "ocr_text": "Accuracy\n\n0.80\n\ne@ All « Easy » Hard\n\n0.75 +—\n0.70 6\n\n0.65\n0.60\n0.55\n\nNumber of Shots\n\n06\n\n04\n\n0.2\n\n0.0\n\n0.02\n\nReasoning Error Scoring Error\n\nRAG\n\n0.01\n\nStepBack\n", "vlm_text": "The image consists of two charts:\n\n1. **Line Chart (Left):**\n   - Displays accuracy against the number of shots.\n   - Three categories are shown: All (blue circles), Easy (red triangles), and Hard (yellow stars).\n   - Accuracy remains relatively stable across 1 to 5 shots.\n   - Easy tasks have higher accuracy compared to All and Hard tasks.\n\n2. **Bar Chart (Right):**\n   - Compares different types of errors or methods labeled as Reasoning Error, Scoring Error, RAG, and StepBack.\n   - The values are: Reasoning Error (0.52), Scoring Error (0.02), RAG (0.45), and StepBack (0.01).\n   - Reasoning Error and RAG have higher values compared to Scoring Error and StepBack."}
{"layout": 63, "type": "text", "text": "Figure 5: Ablation and error analysis of S TEP -B ACK  P ROMPTING  on TimeQA.  Left : ablation against number of few-shot exemplars.  Right : four classes of errors Step-Back makes with Reasoning and RAG being the dominating error sources. ", "page_idx": 6, "bbox": [104, 553.008544921875, 505, 586.9304809570312], "page_size": [612.0, 792.0]}
{"layout": 64, "type": "text", "text": "5.3 A BLATION AND  A NALYSIS ", "text_level": 1, "page_idx": 6, "bbox": [107, 606, 245, 617], "page_size": [612.0, 792.0]}
{"layout": 65, "type": "text", "text": "Few-shot Ablation : We observe in Figure 5 (left) that the performance of S TEP -B ACK  P ROMPTING is robust against the number of exemplars used in demonstration, highlighting again the sample efficiency of learning Abstraction skills for models like PaLM-2L. ", "page_idx": 6, "bbox": [104, 625.9609375, 505, 660.2424926757812], "page_size": [612.0, 792.0]}
{"layout": 66, "type": "text", "text": "Error Analysis:  Figure 5 (right) shows the breakdown of the all the remaining errors made by S TEP -B ACK  P ROMPTING  predictions. Similar to Section 4.3, we categorize the errors:\n\n ", "page_idx": 6, "bbox": [104, 664.81494140625, 505, 688.1375122070312], "page_size": [612.0, 792.0]}
{"layout": 67, "type": "text", "text": "•  StepBack : The step-back question generated is not helpful in solving the task.\n\n •  RAG : RAG fails to retrieval relevant information despite that the step-back question is on target.\n\n •  Scoring Error : The evaluation by the judge model made a mistake. ", "page_idx": 6, "bbox": [104, 692.7109375, 505, 733.2592163085938], "page_size": [612.0, 792.0]}
{"layout": 68, "type": "text", "text": "Table 3: Results of S TEP -B ACK  P ROMPTING  on Multi-Hop Reasoning. CoT: Chain of Thought prompting, TDB: Take a Deep Breathe prompting, RAG: retrieval augmentation generation. Average accuracy is over 5 evaluation runs with the standard deviations included in the parentheses. ", "page_idx": 7, "bbox": [106, 80.32757568359375, 505, 114.25048065185547], "page_size": [612.0, 792.0]}
{"layout": 69, "type": "table", "page_idx": 7, "img_path": "layout_images/STEPBACK_7.jpg", "bbox": [151, 128, 461, 255], "page_size": [612.0, 792.0], "ocr_text": "Method MuSiQue StrategyQA\n\nPaLM-2L 35.5% (3%) | 82.8% (0.7%)\nPaLM-2L 1-shot 29.0% (0.5%) | 76.6% (0.5%)\nPaLM-2L + CoT 38.7% (3.2%) | 83.6% (0.4%)\nPaLM-2L + CoT 1-shot 38.5% (2.2%) | 76.8% (1.4%)\nPaLM-2L + TDB 39.0% (2.3%) | 82.7% (0.9%)\nPaLM-2L + RAG 39.6% (2.8%) | 84.2% (0.5%)\nPaLM-2L + Step-Back (ours) 42.6% (3.1%) | 82.7% (0.4%)\nPaLM-2L + Step-Back + RAG (ours) | 42.8% (2.0%) | 86.4% (1%)\n\nGPT-4\n\n38.5% (0.2%)\n\n78.3% (1.1%)\n\n", "vlm_text": "The table compares different methods and their performance on two datasets, MuSiQue and StrategyQA. The methods evaluated include variations of PaLM-2L with different techniques and GPT-4. \n\nEach method's performance is presented as a percentage with a margin of error in parentheses. The methods evaluated are:\n\n- PaLM-2L\n- PaLM-2L 1-shot\n- PaLM-2L + CoT\n- PaLM-2L + CoT 1-shot\n- PaLM-2L + TDB\n- PaLM-2L + RAG\n- PaLM-2L + Step-Back (ours)\n- PaLM-2L + Step-Back + RAG (ours)\n- GPT-4\n\nThe highest performance for each dataset is bolded:\n\n- **MuSiQue:** PaLM-2L + Step-Back + RAG (ours) at **42.8% (2.0%)**\n- **StrategyQA:** PaLM-2L + Step-Back + RAG (ours) at **86.4% (1%)**"}
{"layout": 70, "type": "text", "text": "•  Reasoning Error : The retrieved context is relevant, but the model still fails to reason through the context to arrive at the right answer. ", "page_idx": 7, "bbox": [106, 287.0079040527344, 505, 310.33050537109375], "page_size": [612.0, 792.0]}
{"layout": 71, "type": "text", "text": "StepBack rarely fails. In contrast, we find more than half of the errors are due to reasoning errors.  $45\\%$   of errors are due to failure in retrieving the right information despite that Abstraction provided by step-back makes it a much easier task. This reflects the difficulty level of the TimeQA task. Additional error analysis of TimeQA is in Appendix A. ", "page_idx": 7, "bbox": [106, 315.57855224609375, 505, 360.46051025390625], "page_size": [612.0, 792.0]}
{"layout": 72, "type": "text", "text": "6 M ULTI -H OP  R EASONING ", "text_level": 1, "page_idx": 7, "bbox": [107, 383, 254, 396], "page_size": [612.0, 792.0]}
{"layout": 73, "type": "text", "text": "We evaluate S TEP -B ACK  P ROMPTING  on challenging Multi-Hop reasoning benchmark MuSiQue (Trivedi et al., 2022) and StrategyQA (Geva et al., 2021). We follow the same protocol as Section 5 to implement S TEP -B ACK  P ROMPTING . ", "page_idx": 7, "bbox": [106, 412.4005432128906, 505, 446.323486328125], "page_size": [612.0, 792.0]}
{"layout": 74, "type": "text", "text": "6.1 R ESULTS ", "text_level": 1, "page_idx": 7, "bbox": [107, 466, 171, 477], "page_size": [612.0, 792.0]}
{"layout": 75, "type": "text", "text": "Table 3 shows performance of various baselines on the dev set of MuSiQue and StrategyQA. Baseline performance of PaLM-2L and GPT4 are low   $(35.5\\%$   and  $38.5\\%$   for PaLM-2L and GPT-4 respectively) in MuSiQue since it is a hard multihop reasoning behchmark. In contrast, StartegyQA has stronger baselines   $(82.8\\%$   and  $78.3\\%$   for PaLM-2L and GPT4 respectively) probably because of the binary fication task. CoT and TDB improve model performance a bit in case of MuSiQue (  $\\sim3\\%$   and 3.5% respectively) which can be attributed to the inherent reasoning nature of this task where these methods are shown to be helpful. In case of StrategyQA, there is no signficant performance gain with COT and TDB which could be due to the high baseline performance in this task, with limited scope for these prompting methods to improve performance. Often, 1-shot performance is significantly lower than their zero-shot methods which could be attributed to the potential example bias (Zhao et al., 2021; Parmar et al., 2023). RAG improves model performance (  $\\sim4\\%$   and  $2\\%$   for MuSiQue and StrategyQA respectively.). S TEP -B ACK  P ROMPTING  with the power of abstraction produces the best performance of all methods:    $42.8\\%$   in MuSiQue and    $86.4\\%$   in StrategyQA, significantly outperforming GPT-4 on both tasks. ", "page_idx": 7, "bbox": [106, 489.8165588378906, 505, 644.2864990234375], "page_size": [612.0, 792.0]}
{"layout": 76, "type": "text", "text": "6.2 A NALYSIS ", "text_level": 1, "page_idx": 7, "bbox": [107, 664, 176, 676], "page_size": [612.0, 792.0]}
{"layout": 77, "type": "text", "text": "Similar to our observation in previous sections, we find that S TEP -B ACK  P ROMPTING  with RAG is able to turn    $15.4\\%$   wrong predictions of base model into correct predictions, while leading to  $6.1\\%$  errors the other way around. Furthermore, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   fixes  $12.7\\%$   errors coming from RAG. The errors introduced to RAG by Step-Back is just    $4.4\\%$  . More detailed analysis is in Appendix A.2. ", "page_idx": 7, "bbox": [106, 687.779541015625, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 78, "type": "text", "text": "7 D ISCUSSION ", "text_level": 1, "page_idx": 8, "bbox": [108, 82, 190, 93], "page_size": [612.0, 792.0]}
{"layout": 79, "type": "text", "text": "Abstraction helps humans to solve complex tasks by removing irrelevant details and distill the high- level concepts and principles to guide the problem-solving process. S TEP -B ACK  P ROMPTING  breaks complex tasks such as knowledge-intensive QA, multi-hop reasoning and science questions into two separate steps of Abstraction and Reasoning. We demonstrate through empirical experiments that Abstraction is an easy skill to teach the LLMs such as PaLM-2L via sample-efficient demonstrations. Grounding on the high-level concepts and principles, LLMs can leverage their intrinsic Reasoning capabilities to derive the solution. This reduces the chance of reasoning failures in the intermediate steps, and is shown to improve the performance on a wide range of complex reasoning tasks. Despite the success, through error analysis, we find that Reasoning is still one of the hardest skills for LLMs to acquire as it is still the dominating failure mode even after the large chunk of task complexity reduction by S TEP -B ACK  P ROMPTING . ", "page_idx": 8, "bbox": [107, 105.67950439453125, 505, 227.2734832763672], "page_size": [612.0, 792.0]}
{"layout": 80, "type": "text", "text": "Nevertheless, Abstraction is neither absolutely necessary nor possible in all scenarios. For instance, the task can be as simple as  who was the president of the United States in 2000? , in which case there is not such a need to step back and ask a high-level question as the answer to such questions is readily available. Parallelly, questions such as  what is the speed of light?  point to the first principles themselves. Doing Abstraction in this case would not make a difference. ", "page_idx": 8, "bbox": [107, 232.20556640625, 505, 288.0455017089844], "page_size": [612.0, 792.0]}
{"layout": 81, "type": "text", "text": "8 R ELATED  W ORK ", "text_level": 1, "page_idx": 8, "bbox": [108, 303, 211, 315], "page_size": [612.0, 792.0]}
{"layout": 82, "type": "text", "text": "S TEP -B ACK  P ROMPTING  is related to the literature of prompting and decomposition. ", "page_idx": 8, "bbox": [107, 327.3925476074219, 449.49700927734375, 339.3974914550781], "page_size": [612.0, 792.0]}
{"layout": 83, "type": "text", "text": "8.1 P ROMPTING ", "text_level": 1, "page_idx": 8, "bbox": [107, 352, 183, 362], "page_size": [612.0, 792.0]}
{"layout": 84, "type": "text", "text": "Few-shot prompting (Brown et al., 2020; Liu et al., 2023; Mishra et al., 2022a; Wei et al., 2022b) has significantly improved model performance across a range of tasks without requiring to update any model parameters. Our work S TEP -B ACK  P ROMPTING  is in the same category as chain of thought prompting (Wei et al., 2022b) and scratchpad (Nye et al., 2021) owing to its simplicity and generic nature, however, is focused on the key idea of abstraction which is inspired from the fact that often taking a step back and looking at broader level help humans in performing complex tasks. Our work is also related to the recitation-augmented language models (Sun et al., 2022), however in contrast to their work, we explicitly perform step-back and abstraction, with optional use of retrieval augmentation depending the nature of the task at hand. ", "page_idx": 8, "bbox": [107, 372.3215637207031, 505, 471.99749755859375], "page_size": [612.0, 792.0]}
{"layout": 85, "type": "text", "text": "8.2 D E COMPOSITION ", "text_level": 1, "page_idx": 8, "bbox": [108, 485, 205, 495], "page_size": [612.0, 792.0]}
{"layout": 86, "type": "text", "text": "Decomposing a task into simpler tasks and solving these tasks to solve the original task have been an effective way (Zhou et al., 2022; Patel et al., 2022; Khot et al., 2022; Press et al., 2022) to improve model performance on complex tasks. Several prompting methods have been successful in improving model performance. Our work S TEP -B ACK  P ROMPTING , in contrast, is on making the question more abstract and high level, which is different from decomposition that is often low level breakdowns of the original question. Furthermore, abstract questions such as  what is the employment history of person   $X?$   are often generic in nature so have a many-to-one mapping since many questions (e.g. which employer did X work for in 1990?  and  which employer did X work for in 2000? ) can have the same abstract questions. This is in contrast to decomposition where there is often a one-to-many mapping since there are multiple decomposed sub-problems necessary to solve a given question. ", "page_idx": 8, "bbox": [107, 504.9205322265625, 505, 615.5565185546875], "page_size": [612.0, 792.0]}
{"layout": 87, "type": "text", "text": "9 C ONCLUSION ", "text_level": 1, "page_idx": 8, "bbox": [108, 632, 195, 642], "page_size": [612.0, 792.0]}
{"layout": 88, "type": "text", "text": "We introduce S TEP -B ACK  P ROMPTING  as a simple and generic method to elicit deep reasoning via abstraction in large language models. Experimentation on LLMs across fact-seeking, commonsense reasoning and domain specific reasoning benchmark shows S TEP -B ACK  P ROMPTING  significantly improve model performance. We hypothesize that abstraction helps models to hallucinate less and reason better, probably reflecting the true nature of the model which are often hidden while responding to the original question without abstraction. We hope our work will inspire more human-inspired approaches to elicit the hidden potential of large language models. ", "page_idx": 8, "bbox": [107, 654.902587890625, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 89, "type": "text", "text": "R EFERENCES ", "text_level": 1, "page_idx": 9, "bbox": [107, 81, 177, 95], "page_size": [612.0, 792.0]}
{"layout": 90, "type": "text", "text": "Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report.  arXiv preprint arXiv:2305.10403 , 2023. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neel a kant an, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.  Advances in neural information processing systems , 33:1877–1901, 2020. Wenhu Chen, Xinyi Wang, and William Yang Wang. A dataset for answering time-sensitive questions. arXiv preprint arXiv:2108.06314 , 2021. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways.  arXiv preprint arXiv:2204.02311 , 2022. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding.  arXiv preprint arXiv:1810.04805 , 2018. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies.  Transactions of the Association for Computational Linguistics , 9:346–361, 2021. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300 , 2020. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buch at s kaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models.  arXiv preprint arXiv:2203.15556 , 2022. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 , 2020. Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks.  arXiv preprint arXiv:2210.02406 , 2022. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners.  Advances in neural information processing systems , 35: 22199–22213, 2022. Royi Lachmy, Valentina Pyatkin, Avshalom Manevich, and Reut Tsarfaty. Draw me a flower: Processing and grounding abstraction in natural language.  Transactions of the Association for Computational Linguistics , 2022. Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step.  arXiv preprint arXiv:2305.20050 , 2023. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.  ACM Computing Surveys , 55(9):1–35, 2023. Swaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, and Hannaneh Hajishirzi. Reframing instructional prompts to gptk’s language. In  Findings of the Association for Computational Linguistics: ACL 2022 , pp. 589–612, 2022a. Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-task generalization via natural language crowd sourcing instructions. In  Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 3470–3487, 2022b. ", "page_idx": 9, "bbox": [108, 100.4705810546875, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 91, "type": "text", "text": "Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Micha lewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratch pads for intermediate computation with language models.  arXiv preprint arXiv:2112.00114 , 2021. ", "page_idx": 10, "bbox": [108, 82.6185302734375, 505, 127.50048065185547], "page_size": [612.0, 792.0]}
{"layout": 92, "type": "text", "text": "OpenAI. Gpt-4 technical report.  arXiv preprint arXiv:2303.08774 , 2023. ", "page_idx": 10, "bbox": [108, 134.424560546875, 399.80316162109375, 146.4294891357422], "page_size": [612.0, 792.0]}
{"layout": 93, "type": "text", "text": "Mihir Parmar, Swaroop Mishra, Mor Geva, and Chitta Baral. Don’t blame the annotator: Bias already starts in the annotation instructions. In  Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics , pp. 1771–1781, 2023. Pruthvi Patel, Swaroop Mishra, Mihir Parmar, and Chitta Baral. Is a question decomposition unit all we need? In  Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing , pp. 4553–4569, 2022. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring and narrowing the compositional it y gap in language models.  arXiv preprint arXiv:2210.03350 , 2022. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer.  The Journal of Machine Learning Research , 21(1):5485–5551, 2020. John L Russell. Kepler’s laws of planetary motion: 1609–1666.  The British journal for the history of science , 2(1):1–24, 1964. Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and Denny Zhou. Recitation-augmented language models.  arXiv preprint arXiv:2210.01296 , 2022. Harsh Trivedi, Niranjan Bala subramania n, Tushar Khot, and Ashish Sabharwal. Musique: Multihop questions via single-hop question composition.  Transactions of the Association for Computational Linguistics , 10:539–554, 2022. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,  Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need.  Advances in neural information processing systems , 30, 2017. Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners.  arXiv preprint arXiv:2109.01652 , 2021. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 , 2022a. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models.  Advances in Neural Information Processing Systems , 35:24824–24837, 2022b. Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers.  arXiv preprint arXiv:2309.03409 , 2023. Michael Zhang and Eunsol Choi. Situatedqa: Incorporating extra-linguistic contexts into qa. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pp. 7371–7387, 2021. Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving few-shot performance of language models. In  International Conference on Machine Learning , pp. 12697–12706. PMLR, 2021. Denny Zhou, Nathanael Sch arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning in large language models.  arXiv preprint arXiv:2205.10625 , 2022. ", "page_idx": 10, "bbox": [108, 153.35357666015625, 505, 726.2554931640625], "page_size": [612.0, 792.0]}
{"layout": 94, "type": "text", "text": "A A DDITIONAL  E RROR  A NALYSIS ", "text_level": 1, "page_idx": 11, "bbox": [107, 82, 291, 94], "page_size": [612.0, 792.0]}
{"layout": 95, "type": "text", "text": "A.1 T IME QA E RROR  A NALYSIS ", "text_level": 1, "page_idx": 11, "bbox": [107, 109, 252, 121], "page_size": [612.0, 792.0]}
{"layout": 96, "type": "text", "text": "We conduct error analysis to understand where S TEP -B ACK  P ROMPTING  fixes the errors the baseline models make. Figure 6 shows that compared to the predictions of baseline PaLM-2L, S TEP -B ACK P ROMPTING  is able to fix  $39.9\\%$   of the predictions where the baseline prediction is wrong, while causing    $5.6\\%$   errors. Furthermore, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   fixes    $21.6\\%$   errors coming from RAG. The    $\\%$  of errors introduced by S TEP -B ACK  P ROMPTING  to RAG is still relatively low   $(6.3\\%)$  . Together, this shows that the S TEP -B ACK  P ROMPTING  is helpful most of the time, signifying the need and effectiveness of doing Abstraction before directly addressing the original question. ", "page_idx": 11, "bbox": [106, 131.861572265625, 505, 209.61949157714844], "page_size": [612.0, 792.0]}
{"layout": 97, "type": "image", "page_idx": 11, "img_path": "layout_images/STEPBACK_8.jpg", "bbox": [115, 231, 496, 336], "page_size": [612.0, 792.0], "ocr_text": "Step-Back + RAG Wrong Step-Back + RAG Wrong\n\nBoth Wrong Both Wrong\nRAG Wrong\n\nBaseline Wrong\n\nBoth Right Both Right\n", "vlm_text": "The image contains two pie charts.\n\nThe chart on the left shows:\n- Baseline Wrong: 39.9%\n- Both Wrong: 26.5%\n- Both Right: 27.9%\n- Step-Back + RAG Wrong: 5.6%\n\nThe chart on the right shows:\n- Both Right: 46.2%\n- Both Wrong: 25.8%\n- RAG Wrong: 21.6%\n- Step-Back + RAG Wrong: 6.3%\n\nEach segment is represented with different colors."}
{"layout": 98, "type": "text", "text": "Figure 6: Error Analysis of Step-Back Prompting on TimeQA.  Left : Step-  $\\mathrm{back}+\\mathrm{RAG}$   vs Baseline predictions.  Right : Step-Back RAG vs RAG predictions. Step-Back  $+\\;\\mathbf{R}\\mathbf{A}\\mathbf{G}$   is able to fix    $39.9\\%$  of the predictions where the baseline prediction is wrong, while causing  $5.6\\%$   errors. Furthermore, Step-Back  $^+$  RAG fixes  $21.6\\%$   errors coming from RAG. The    $\\%$   of errors introduced by S TEP -B ACK P ROMPTING  to RAG is still relatively low   $(6.3\\%)$  . ", "page_idx": 11, "bbox": [106, 352.65655517578125, 505, 408.49749755859375], "page_size": [612.0, 792.0]}
{"layout": 99, "type": "text", "text": "A.2 S TRATEGY QA E RROR  A NALYSIS ", "text_level": 1, "page_idx": 11, "bbox": [107, 444, 274, 455], "page_size": [612.0, 792.0]}
{"layout": 100, "type": "text", "text": "Figure 7 shows the error analysis of StrategyQA on the predictions of Step-Back  $^+$   RAG against the baseline model and the raw retrieval augmentation variant of PaLM-2L. Compared to the baseline, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   is able to turn    $15.4\\%$   wrong predictions into correct predictions, while leading to  $6.1\\%$   errors the other way around. Furthermore, Step-Back  $+\\,\\mathbf{R}\\mathbf{A}\\mathbf{G}$   fixes    $12.7\\%$   errors coming from RAG. The errors introduced to RAG by Step-Back is just    $4.4\\%$  . ", "page_idx": 11, "bbox": [106, 466.6845703125, 505, 522.5255126953125], "page_size": [612.0, 792.0]}
{"layout": 101, "type": "image", "page_idx": 11, "img_path": "layout_images/STEPBACK_9.jpg", "bbox": [109, 551, 505, 657], "page_size": [612.0, 792.0], "ocr_text": "Both Wrong\n\nBoth Wrong\nBaseline Wrong RAG Wrong\n\nStep-Back + RAG Wrong\n\nStep-Back + RAG Wrong\n\nBoth Right Both Right\n\n", "vlm_text": "The image shows two pie charts comparing the accuracy of two systems. \n\n- **Left Pie Chart:**\n  - Both Right: 74.6% (green)\n  - Baseline Wrong: 15.4% (red)\n  - Step-Back + RAG Wrong: 6.1% (yellow)\n  - Both Wrong: 3.9% (blue)\n\n- **Right Pie Chart:**\n  - Both Right: 77.2% (green)\n  - RAG Wrong: 12.7% (red)\n  - Step-Back + RAG Wrong: 4.4% (yellow)\n  - Both Wrong: 5.7% (blue)\n\nThese charts likely represent the performance comparison between different methods or configurations, showing the percentage of correct and incorrect results for each scenario."}
{"layout": 102, "type": "text", "text": "Figure 7: Error Analysis of Step-Back Prompting on StrategyQA.  Left : Step-Back  $^+$  RAG vs Baseline predictions.  Right : Step-Back  $^+$   RAG vs RAG predictions. Step-Back  $+$   RAG is able to turn  $\\bar{1}5.4\\%$   wrong predictions into correct predictions, while leading to  $6.{\\bar{1}}\\%$   errors the other way around. Furthermore, Step-Back  $^+$   RAG fixes  $12.7\\%$   errors coming from RAG. The errors introduced to RAG by Step-Back is just  $4.4\\%$  . ", "page_idx": 11, "bbox": [106, 673.5325317382812, 505, 729.3734741210938], "page_size": [612.0, 792.0]}
{"layout": 103, "type": "table", "page_idx": 12, "img_path": "layout_images/STEPBACK_10.jpg", "table_caption": "Table 4: Stats of the evaluation datasets used in this paper. ", "bbox": [124, 80, 488, 230], "page_size": [612.0, 792.0], "ocr_text": "Domain Dataset Split | Number of Examples\nSTEM MMLU high-school Physics Test 151\nMMLU high-school Chemistry | Test 203\nKnowledge QA TimeQA Test 5226\nTimeQA Easy Test 2613\nTimeQA Hard Test 2613\nSituatedQA Test 2901\nMulti-hop Reasoning MuSiQue Dev 2417\nStrategyQA Dev 229\n\n", "vlm_text": "The table contains the following information:\n\n**Columns:**\n1. **Domain**: Categories of datasets.\n2. **Dataset**: Specific datasets within each domain.\n3. **Split**: Type of data division (Test or Dev).\n4. **Number of Examples**: The count of examples in each dataset.\n\n**Data:**\n\n- **STEM:**\n  - *Dataset*: MMLU high-school Physics, MMLU high-school Chemistry\n  - *Split*: Test\n  - *Number of Examples*: 151, 203 respectively\n\n- **Knowledge QA:**\n  - *Dataset*: TimeQA, TimeQA Easy, TimeQA Hard, SituatedQA\n  - *Split*: Test\n  - *Number of Examples*: 5226, 2613, 2613, 2901 respectively\n\n- **Multi-hop Reasoning:**\n  - *Dataset*: MuSiQue, StrategyQA\n  - *Split*: Dev\n  - *Number of Examples*: 2417, 229 respectively"}
{"layout": 104, "type": "text", "text": "Are the following two answers to the given question equivalent? Do not consider whether the answers are right or wrong, but only whether they are equivalent. Directly state ”Yes” or ”No”. Question : Which title was conferred to Anna Muzychuk in 2007? Answer 1 : Anna Muzychuk was conferred the title of International Master (IM) in 2007. She earned the title by scoring three norms in rapid chess tournaments. Answer 2 : International Master Answer 1 (short) : International Master Answer 2 (short) : International Master Are the two answers equivalent?  Yes Question : What state is Seattle located in? Answer 1 : Seattle is in Washington State. Answer 2 : The answer is George Washington. Answer 1 (short) : Washington State Answer 2 (short) : George Washington Are the two answers equivalent?  No Question :    $<$  Question > Answer 1 :  < Model Output > Answer 2 :  < Target Label > ", "page_idx": 12, "bbox": [163, 248.73358154296875, 448, 469.5550842285156], "page_size": [612.0, 792.0]}
{"layout": 105, "type": "text", "text": "B D ATASET  D ETAILS ", "text_level": 1, "page_idx": 12, "bbox": [107, 512, 224, 524], "page_size": [612.0, 792.0]}
{"layout": 106, "type": "text", "text": "Table 4 shows the split and number of examples used for evaluations in TimeQA, StrategyQA and MMLU high-school Physics. ", "page_idx": 12, "bbox": [107, 536.6265869140625, 505, 559.5905151367188], "page_size": [612.0, 792.0]}
{"layout": 107, "type": "text", "text": "C E VALUATION  D ETAILS ", "text_level": 1, "page_idx": 12, "bbox": [107, 575, 244, 587], "page_size": [612.0, 792.0]}
{"layout": 108, "type": "text", "text": "C.1 F EW - SHOT  E XAMPLES FOR  E VALUATION WITH  P A LM2-L ", "text_level": 1, "page_idx": 12, "bbox": [107, 599, 379, 611], "page_size": [612.0, 792.0]}
{"layout": 109, "type": "text", "text": "Given the model free-form outputs and the target label, we use one positive and one negative outputs as few-shot examples to teach the scoring model how to score the output. Table 5 illustrates the prompt we used for the scoring model. We parse out the “Yes” or “No” answer from the scoring model output as TRUE or FALSE score of the model output. ", "page_idx": 12, "bbox": [107, 620.4425659179688, 505, 665.323486328125], "page_size": [612.0, 792.0]}
{"layout": 110, "type": "text", "text": "C.2 H YPER - PARAMETERS FOR  E VALUATION WITH  P A LM2-L ", "text_level": 1, "page_idx": 12, "bbox": [107, 678, 373, 690], "page_size": [612.0, 792.0]}
{"layout": 111, "type": "text", "text": "We use PaLM-2L as the scoring model for evaluation. We experiment with different sampling temperatures, and find that    $T=1$   gives us a highly-accurate evaluating. For example, we sampled 100  test examples and the model predictions, and manually rated the correctness of the model scoring. ", "page_idx": 12, "bbox": [107, 698.738525390625, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 112, "type": "table", "page_idx": 13, "img_path": "layout_images/STEPBACK_11.jpg", "table_caption": "Table 6: Prompt of extracting the underlying principles involved in MMLU physics and chemistry questions. ", "bbox": [107, 80, 504, 266], "page_size": [612.0, 792.0], "ocr_text": "MMLU Physics/Chemistry First-Principle Prompt\n\nYou are an expert at Physics/Chemistry. You are given\na Physics/Chemistry problem. Your task is to extract the\nPhysics/Chemistry concepts and principles involved in solving\nthe problem. Here are a few examples:\n\nQuestion: <Question Example1>\nPrinciples Involved: <Principles Example1>\n\nQuestion: <Question Example5>\n\nPrinciples Involved: <Principles ExampleS >\nQuestion: <Question>\n\nPrinciples Involved:\n\n", "vlm_text": "This table is a prompt template for a Physics/Chemistry task. It instructs the user to extract the Physics or Chemistry concepts and principles involved in solving given problems. The template provides examples labeled as \"Question Example1\" to \"Question Example5\" with corresponding \"Principles Example1\" to \"Principles Example5.\" After the examples, there is a placeholder for a new question and its involved principles."}
{"layout": 113, "type": "table", "page_idx": 13, "img_path": "layout_images/STEPBACK_12.jpg", "bbox": [159, 285, 454, 473], "page_size": [612.0, 792.0], "ocr_text": "MMLU Physics/Chemistry Final Answer Prompt\n\nYou are an expert at Physics/Chemistry. You are given a\nPhysics/Chemistry problem and a set of principles involved in\nsolving the problem. Solve the problem step by step by following the\nprinciples. Here are a few examples:\n\nQuestion: <Question Example1>\nPrinciples: <Principles Example1>\nAnswer: <Answer Example! >\n\nQuestion: <Question Example5>\nPrinciples: <Principles ExampleS>\nAnswer: <Answer Example5>\nQuestion: <Question>\n\nPrinciples: <Principles>\n\nAnswer:\n\n", "vlm_text": "The table contains a prompt titled \"MMLU Physics/Chemistry Final Answer Prompt.\" It provides instructions for solving Physics/Chemistry problems by following a set of principles. The text is organized in the following format:\n\n- Introduction: You are given a Physics/Chemistry problem and a set of principles for solving it.\n- A prompt to solve the problem step by step using the provided principles.\n- Examples showcasing how to approach the problem:\n  - Example 1 to Example 5 with placeholders for:\n    - Question: `<Question ExampleX>`\n    - Principles: `<Principles ExampleX>`\n    - Answer: `<Answer ExampleX>`\n- A blank template for a new question:\n  - Question: `<Question>`\n  - Principles: `<Principles>`\n  - Answer: \n\nThe table provides a structured way to approach and solve problems in a Physics/Chemistry context."}
{"layout": 114, "type": "text", "text": "Table 7: Prompt of querying the model for final answer with first principles behind the question in MMLU high-school Physics and Chemistry. ", "page_idx": 13, "bbox": [107, 481.1185607910156, 505, 504.0824890136719], "page_size": [612.0, 792.0]}
{"layout": 115, "type": "text", "text": "We found that out of 4 trials, the model scoring agrees with human ratings    $97\\%$  ,  $98\\%$  ,  $99\\%$   and    $99\\%$  of the time. ", "page_idx": 13, "bbox": [107, 532, 505, 555.2025146484375], "page_size": [612.0, 792.0]}
{"layout": 116, "type": "text", "text": "D P ROMPTS AND  F EW SHOT  E XAMPLES ", "text_level": 1, "page_idx": 13, "bbox": [107, 579, 320, 591], "page_size": [612.0, 792.0]}
{"layout": 117, "type": "text", "text": "D.1 STEM ", "page_idx": 13, "bbox": [107, 608.3225708007812, 162.43556213378906, 620.3275146484375], "page_size": [612.0, 792.0]}
{"layout": 118, "type": "text", "text": "For MMLU high-school Physics and Chemistry, we first prompt the model to generate the first principles behind the question. Using the generated first principles, we further prompt the model to generate the final answer through few-shot demonstrations The prompt generating first principles is shown in Table 6 for MMLU high-school Physics and Chemistry. ", "page_idx": 13, "bbox": [107, 631.988525390625, 505, 676.8704833984375], "page_size": [612.0, 792.0]}
{"layout": 119, "type": "text", "text": "After extracting the first principles of solving a particular question, we formulate the prompt in Table 7 to query the model for the final answer. ", "page_idx": 13, "bbox": [107, 681.8015747070312, 505, 704.7655029296875], "page_size": [612.0, 792.0]}
{"layout": 120, "type": "text", "text": "Tables 8-9 show one demonstration exemplar of Question-Principles-Answer triplets for MMLU high-school Physics and Chemistry, respectively. ", "page_idx": 13, "bbox": [107, 709.6975708007812, 505, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 121, "type": "table", "page_idx": 14, "img_path": "layout_images/STEPBACK_13.jpg", "bbox": [110, 214, 504, 574], "page_size": [612.0, 792.0], "ocr_text": "Question\n\nA spherical conductor carries a net charge. How is this charge distributed on\nthe sphere?\n\n0) The charge is evenly distributed on the surface.\n\n1) The charge resides on the surface only; the distribution of charge on the\nsurface depends on what other charged objects are near the sphere.\n\n2) The charge moves continually within the sphere.\n\n3) The charge is distributed uniformly throughout the sphere.\n\nPrinciples\n\nCoulomb’s Law: the force between two charged particles is proportional to the\nproduct of their charges and inversely proportional to the square of the distance\nbetween them, F =k * ql * q2/r, where F is the electric force, k is a constant,\nql and q2 are the charges the particles carry, and r is the distance between them.\n\nAnswer\n\nUsing the Principles of Coulomb’s Law, we can solve the problem as following:\nStep 1: Apply Coulomb’s Law to find out how charges are distributed on the\nsurface.\n\nIn the case of a spherical conductor, the charges on the surface will repel each\nother. The further apart the charges are, the less force they will exert on each\nother. Therefore, the charges will distribute themselves evenly on the surface\nof the sphere, as this is the configuration that minimizes the repulsive force\nbetween them.\n\nStep 2: Apply Coulomb’s Law to find out what happens if there are other\ncharges present.\n\nThe distribution of charge on the surface may also be affected by the presence\nof other charged objects near the sphere. For example, if a negatively charged\nobject is brought near a positively charged sphere, the negative charges on the\nsphere will be repelled and will move to the opposite side of the sphere. This\nwill result in a non-uniform distribution of charge on the surface of the sphere.\n\nTherefore, the correct answer is 1) The charge resides on the surface only; the\ndistribution of charge on the surface depends on what other charged objects are\nnear the sphere.\n", "vlm_text": "The table contains the following information:\n\n- **Question**: How is the charge distributed on a spherical conductor carrying a net charge?\n  - Options:\n    0) Evenly distributed on the surface.\n    1) Surface only; depends on other nearby charged objects.\n    2) Moves continually within the sphere.\n    3) Uniformly distributed throughout the sphere.\n\n- **Principles**: Explanation of Coulomb’s Law, which describes the force between two charged particles as proportional to the product of their charges and inversely proportional to the square of the distance between them.\n\n- **Answer**: \n  - Application of Coulomb’s Law to determine charge distribution.\n  - Step 1: Charges on a spherical conductor repel and distribute evenly on the surface to minimize repulsive force.\n  - Step 2: Presence of other charged objects affects surface charge distribution, leading to non-uniform distribution if influenced by nearby charges.\n  - Correct answer: 1) The charge resides on the surface only, and its distribution depends on nearby charged objects."}
{"layout": 122, "type": "text", "text": "Table 8: Few-shot demonstration exemplar for MMLU high-school Physics. ", "page_idx": 14, "bbox": [154.1909942626953, 580.3265380859375, 457.50225830078125, 592.3314819335938], "page_size": [612.0, 792.0]}
{"layout": 123, "type": "table", "page_idx": 15, "img_path": "layout_images/STEPBACK_14.jpg", "bbox": [108, 229, 505, 563], "page_size": [612.0, 792.0], "ocr_text": "Question\n\nPrinciples\n\nAnswer\n\nA sample of an unknown chloride compound was dissolved in water, and\nthen titrated with excess Pb(NO3)2 to create a precipitate. After drying, it is\ndetermined there are 0.0050 mol of precipitate present. What mass of chloride\nis present in the original sample?\n\n0) 0.177 g\n\n1) 0.355 g\n\n2) 0.522 g\n\n3) 0.710 g\n\nPrecipitation reactions: Precipitation reactions occur when two soluble salts are\nmixed and form an insoluble product, called a precipitate. The precipitate can\nbe separated from the solution by filtration or centrifugation.\n\nMolar mass: The molar mass of a substance is the mass of one mole of that\nsubstance. The molar mass is expressed in grams per mole (g/mol).\n\nLimiting reactant: The limiting reactant is the reactant that is completely con-\nsumed in a chemical reaction. The amount of product formed is determined by\nthe amount of limiting reactant.\n\nAssuming the unknown chloride compound is MCI, where M represents the\nmetal cation, the balanced chemical equation for the precipitation reaction is:\nPb(NO3)2(aq) + 2MCl(aq) —+ PbCla(s) + 2M NO3(aq)\n\nSince Pb(.NO3)z is in excess, MCI is the limiting reactant. The stoichiometry\nof the reaction indicates that 2 moles of MCI produce 1 mole of PbCly\nprecipitate. Therefore, 0.0050 mol of PbCl corresponds to 0.010 mol of MCl.\n\nThe mass of chloride in the original sample can be calculated using the molar\nmass of chloride (35.45 g/mol):\n0.010 mol Cl x 35.45 g/mol = 0.355 g Cl\n\nThe correct answer is 1) 0.355 g.\n", "vlm_text": "The table contains three sections: \n\n1. **Question**: \n   - A sample of an unknown chloride compound is dissolved in water and titrated with excess Pb(NO3)2 to form a precipitate. After drying, 0.0050 mol of precipitate is obtained. The task is to determine the mass of chloride in the original sample, with options: \n     - 0) 0.177 g \n     - 1) 0.355 g \n     - 2) 0.522 g \n     - 3) 0.710 g\n\n2. **Principles**: \n   - Explanation of precipitation reactions, molar mass, and limiting reactants:\n     - Precipitation reactions occur when two soluble salts form an insoluble product (precipitate).\n     - Molar mass is the mass of one mole of a substance.\n     - The limiting reactant is fully consumed in a reaction, determining the product amount.\n\n3. **Answer**: \n   - Assuming the compound is MCl (where M is a metal cation), the reaction is:\n     - Pb(NO3)2(aq) + 2MCl(aq) → PbCl2(s) + 2MNO3(aq)\n   - MCl is the limiting reactant. Based on stoichiometry, 2 moles of MCl produce 1 mole of PbCl2. Thus, 0.0050 mol of PbCl2 corresponds to 0.010 mol of MCl.\n   - Calculating mass using the molar mass of chloride (35.45 g/mol):\n     - 0.010 mol Cl × 35.45 g/mol = 0.355 g Cl\n   - The correct answer is 1) 0.355 g."}
{"layout": 124, "type": "text", "text": "Table 9: Few-shot demonstration exemplar for MMLU high-school Chemistry. ", "page_idx": 15, "bbox": [148.9550018310547, 569.3675537109375, 462.7369079589844, 581.3724975585938], "page_size": [612.0, 792.0]}
{"layout": 125, "type": "table", "page_idx": 16, "img_path": "layout_images/STEPBACK_15.jpg", "table_caption": "Table 10: Prompt of asking step-back question in Knowledge QA tasks. ", "bbox": [157, 81, 455, 245], "page_size": [612.0, 792.0], "ocr_text": "Knowledge QA Step-Back Prompt\n\nYou are an expert at world knowledge. Your task is to step back and\nparaphrase a question to a more generic step-back question, which is\neasier to answer. Here are a few examples:\n\nOriginal Question: <Original Question Example1>\nStepback Question: <Stepback Question Example! >\n\nOriginal Question: <Original Question Example5>\nStepback Question: <Stepback Question Example5>\nOriginal Question: <Original Question>\n\nStepback Question:\n", "vlm_text": "The table is titled \"Knowledge QA Step-Back Prompt.\" It provides instructions for creating more generic, paraphrased questions to make them easier to answer. The table includes placeholders for examples of original questions and their corresponding step-back questions, ultimately illustrating the task of simplifying queries."}
{"layout": 126, "type": "table", "page_idx": 16, "img_path": "layout_images/STEPBACK_16.jpg", "table_footnote": "Table 11: Few-shot demonstration exemplars for asking step-back questions in TimeQA and Situat- edQA. ", "bbox": [105, 256, 513, 578], "page_size": [612.0, 792.0], "ocr_text": "dataset Original Question Step-back Question\n\nTimeQA Which position did Knox Cunningham Which positions have Knox Cunning-\nhold from May 1955 to Apr 1956? ham held in his career?\n\nTimeQA Who was the spouse of Anna Karina Who were the spouses of Anna Karina?\nfrom 1968 to 1974?\n\nTimeQA Which team did Thierry Audel play for Which teams did Thierry Audel play for\nfrom 2007 to 2008? in his career?\n\nTimeQA What was the operator of GCR Class What were the operators of GCR Class\n11E from 1913 to Dec 1922? 11E in history?\n\nTimeQA Which country did Sokolovsko belong Which countries did Sokolovsko belong\nto from 1392 to 1525? to in history?\n\nSituatedQA when was the last time a team from which years did a team from canada\ncanada won the stanley cup as of 2002 __ won the stanley cup as of 2002\n\nSituatedQA when did england last get to the semi __ which years did england get to the semi\nfinal in a world cup as of 2019 final in a world cup as of 2019?\n\nSituatedQA what is the biggest hotel in las vegas nv _ what is the size of the hotels in las vegas\nas of November 28, 1993 nv as of November 28, 1993\n\nSituatedQA who has scored most runs in t20 What are the runs of players in t20\nmatches as of 2017 matches as of 2017\n\nSituatedQA who is the highest paid player in the nba _ what is the salary of the high paid play-\n\nthis season as of 2017\n\ners in the nba this season as of 2017\n\n", "vlm_text": "The table includes three columns labeled \"dataset,\" \"Original Question,\" and \"Step-back Question.\"\n\n1. **dataset**: Indicates the source of the questions, either \"TimeQA\" or \"SituatedQA.\"\n2. **Original Question**: Lists specific questions with time constraints, such as historical facts or statistics as of a certain year.\n3. **Step-back Question**: Reframes the original questions to focus on broader or more general information, often removing specific time constraints."}
{"layout": 127, "type": "text", "text": "D.2 K NOWLEDGE  QA ", "text_level": 1, "page_idx": 16, "bbox": [107, 600, 209, 612], "page_size": [612.0, 792.0]}
{"layout": 128, "type": "text", "text": "We use the following prompting in Table 10 to teach the LLM to ask a step-back question for TimeQA and SituatedQA including up to 5 exemplar demonstrations of pairs of Original Question and Step-back Question. ", "page_idx": 16, "bbox": [107, 621.029541015625, 504, 654.9525146484375], "page_size": [612.0, 792.0]}
{"layout": 129, "type": "text", "text": "Table 11 shows 5 exemplars from the Train split of TimeQA and SituatedQA as demonstrations of asking step-back questions. ", "page_idx": 16, "bbox": [107, 659.884521484375, 504, 682.8485107421875], "page_size": [612.0, 792.0]}
{"layout": 130, "type": "text", "text": "The step-back question is extracted from the model output using the prompt. Using the step-back question, we do retrieval augmentation. Using both the retrieval augmentations from the original question and the step-back question, we formulate the final prompt to query the model for the final answer, as shown in Table 12. ", "page_idx": 16, "bbox": [107, 687.779541015625, 504, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 131, "type": "table", "page_idx": 17, "img_path": "layout_images/STEPBACK_17.jpg", "table_caption": "Table 12: Prompt of querying the model for final answer with additional contexts from original and step-back retrieval augmentations in TimeQA and SituatedQA ", "bbox": [104, 81, 506, 245], "page_size": [612.0, 792.0], "ocr_text": "Knowledge QA Final-Answer Prompt\n\nYou are an expert of world knowledge. I am going to ask you a question.\nYour response should be comprehensive and not contradicted with the\nfollowing context if they are relevant. Otherwise, ignore them if they are\nnot relevant.\n\n<Passage from original retrieval augmentation>\n<Passage from step-back retrieval augmentation>\n\nOriginal Question: <Original Question>\nAnswer:\n", "vlm_text": "The table contains a prompt for a knowledge QA (Question-Answer) task. It outlines instructions for generating a comprehensive response to a question based on provided contextual passages. The structure includes:\n\n1. **Prompt Description**: Instructs the responder to use relevant contextual information without contradiction.\n2. **Placeholders**:\n   - `<Passage from original retrieval augmentation>`: Placeholder for a text passage.\n   - `<Passage from step-back retrieval augmentation>`: Another placeholder for additional context.\n   - `<Original Question>`: Placeholder for the original question asked.\n3. **Answer**: Space for the final answer to be formulated."}
{"layout": 132, "type": "table", "page_idx": 17, "img_path": "layout_images/STEPBACK_18.jpg", "table_caption": "Table 13: Few-shot demonstration exemplars for asking step-back questions in MuSiQue and Strate- gyQA. ", "bbox": [106, 268, 505, 626], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nOriginal Question\n\nStep-back Question\n\nMuSiQue at year saw the creation of the region _ which region is the county of Hert-\nwhere the county of Hertfordshire is fordshire located?\nlocated?\n\nMuSiQue Jan Sindel’s was born in what coun-- what is Jan Sindel’s personal his-\ntry? tory?\n\nMuSiQue When was the abolishment of the which studio distributed The Game?\nstudio that distributed The Game?\n\nMuSiQue What city is the person who broad-__ who broadened the doctrine of phi-\nened the doctrine of philosophy of —losophy of language\nlanguage from?\n\nMuSiQue When was the baseball team win- which baseball team won the world\nning the world series in 2015 base- _ series in 2015 baseball?\nball created?\n\nStrategyQA Could the members of The Police what can the members of The Police\nperform lawful arrests? do?\n\nStrategyQA Would a Monoamine Oxidase candy What are the effects of Monoamine\nbar cheer up a depressed friend? Oxidase?\n\nStrategyQA Would a dog respond to bell before Would a dog respond to bell before\nGrey seal? Grey seal?\n\nStrategyQA Is shrimp scampi definitely free of | what is shrimp scampi made of?\nplastic?\n\nStrategyQA Do the anchors on Rede Globo What languages do the anchors on\n\nspeak Chinese?\n\nRede Globo speak?\n\n", "vlm_text": "The table compares two datasets, MuSiQue and StrategyQA, by presenting pairs of questions from each dataset:\n\n1. The first column lists the dataset name.\n2. The second column contains the original question from each dataset.\n3. The third column shows the \"Step-back Question,\" which rephrases or contextualizes the original question.\n\nEach row represents a question pair from either MuSiQue or StrategyQA."}
{"layout": 133, "type": "text", "text": "D.3 M ULTI -H OP  R EASONING ", "text_level": 1, "page_idx": 17, "bbox": [106, 661, 241, 672], "page_size": [612.0, 792.0]}
{"layout": 134, "type": "text", "text": "For Multi-Hop Reasoning, we use the same prompting template as in Knowledge QA to ask the step-back question, and query for the final answer given the retrieval augmentations. Table 13 shows 5 demonstration exemplars for asking step-back questions from the Train split of MuSiQue and StrategyQA. ", "page_idx": 17, "bbox": [108, 687.779541015625, 503, 732.6614990234375], "page_size": [612.0, 792.0]}
{"layout": 135, "type": "table", "page_idx": 18, "img_path": "layout_images/STEPBACK_19.jpg", "table_footnote": "Table 14: Prompt of querying the baseline model for final answer with few-shot demonstration exemplars. ", "bbox": [107, 79, 504, 211], "page_size": [612.0, 792.0], "ocr_text": "Baseline few-shot Prompt\n\nYou are an expert of world knowledge and physics. Your task is to solve\nthe following question. Here are a few examples:\n\nQuestion: <Question Example>\nAnswer: <Answer Example>\nQuestion: <Question>\nAnswer:\n\n", "vlm_text": "The table contains a baseline few-shot prompt. It states that you are an expert in world knowledge and physics and are tasked with solving a question. It provides an example format for questions and answers:\n\n- Question: <Question Example>\n- Answer: <Answer Example>\n- Question: <Question>\n- Answer: \n\nThis format is used to demonstrate how to respond to a given question."}
{"layout": 136, "type": "text", "text": "D.4 B ASELINE  P ROMPTS ", "text_level": 1, "page_idx": 18, "bbox": [107, 233, 222, 244], "page_size": [612.0, 792.0]}
{"layout": 137, "type": "text", "text": "For zero-shot baseline, we simply take the question itself and query the model for answers. For standard few-shot prompting of the baseline model, we formulate the prompt using the template in Table 14 with one exemplar. Table 15 shows the baseline few-shot exemplar exemplars used in this paper. ", "page_idx": 18, "bbox": [107, 253.71856689453125, 504, 298.6004943847656], "page_size": [612.0, 792.0]}
{"layout": 138, "type": "text", "text": "D.5CHAIN OF THOUGHT (COT)", "text_level": 1, "page_idx": 18, "bbox": [107, 311, 253, 323], "page_size": [612.0, 792.0]}
{"layout": 139, "type": "text", "text": "For zero-shot CoT prompting, we simply append  Let’s think step by step.  to the question to query the model. ", "page_idx": 18, "bbox": [107, 332.1245422363281, 504, 355.0885009765625], "page_size": [612.0, 792.0]}
{"layout": 140, "type": "text", "text": "For few-shot CoT prompting, we use the same template as the Baseline prompting in Sec. D.4 by replacing the few-shot examples using CoT responses, as shown in Tables 16, 17, 18, and 19. ", "page_idx": 18, "bbox": [107, 360.02056884765625, 504, 382.9844970703125], "page_size": [612.0, 792.0]}
{"layout": 141, "type": "text", "text": "D.6 T AKE A  D EEP  B REATHE  (TDB) ", "text_level": 1, "page_idx": 18, "bbox": [107, 396, 268, 408], "page_size": [612.0, 792.0]}
{"layout": 142, "type": "text", "text": "We study the zero-shot Take a Deep Breathe prompting found in Yang et al. (2023): we take  Take a deep breath and work on this problem step-by-step. , and prepend it to the question. ", "page_idx": 18, "bbox": [107, 416.508544921875, 504, 439.4725036621094], "page_size": [612.0, 792.0]}
{"layout": 143, "type": "text", "text": "EEXAMPLES OF ERROR ANALYSIS AND WINS OF STEP-BACK PROMPTING", "page_idx": 18, "bbox": [107, 454.51739501953125, 496.768798828125, 468.92340087890625], "page_size": [612.0, 792.0]}
{"layout": 144, "type": "text", "text": "E.1 MMLU  ERROR ANALYSIS ", "page_idx": 18, "bbox": [107, 480.0205383300781, 241.7161865234375, 492.0254821777344], "page_size": [612.0, 792.0]}
{"layout": 145, "type": "text", "text": "In Tables 20-24, we show one example for each of the 5 error categories we identified through error analysis on S TEP -B ACK  P ROMPTING . ", "page_idx": 18, "bbox": [107, 500.5435485839844, 504, 523.5075073242188], "page_size": [612.0, 792.0]}
{"layout": 146, "type": "text", "text": "E.2EXAMPLE WINS FROM STEP-BACK PROMPTING", "text_level": 1, "page_idx": 18, "bbox": [108, 536, 337, 548], "page_size": [612.0, 792.0]}
{"layout": 147, "type": "text", "text": "Tables 25- 27, 28 29, 30 and 31 illustrate the some successful examples of S TEP -B ACK  P ROMPTING on MMLU-Physics, MMLU-Chemistry, TimeQA, SituatedQA, and StrategyQA respectively. ", "page_idx": 18, "bbox": [107, 557.0315551757812, 504, 579.9954833984375], "page_size": [612.0, 792.0]}
{"layout": 148, "type": "table", "page_idx": 19, "img_path": "layout_images/STEPBACK_20.jpg", "table_caption": "Table 15: Demonstration exemplar for standard prompting. ", "bbox": [105, 92, 513, 715], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nQuestion\n\nAnswer\n\nMMLU\nPhysics\n\nA point charge, QI = +1 mC, is\nfixed at the origin. How much\nwork is required to move another\ncharge, Q2 = +8 uC, from the\npoint (0, 4 meters) to the point\n(3 meters, 0)?\n\n0) 3.5J\n\n1) 6.0J\n\n2) 22.5 J\n\n3)40J\n\nThe work required to move a charge in an\nelectric field is equal to the change in potential\nenergy of the charge. The potential energy of a\ncharge in an electric field is given by: U =k *\nQ1 * Q2/r where: k is the Coulomb constant,\nQI and Q2 are the charges, r is the distance\nbetween the charges. In this case, the initial po-\ntential energy of Q2 is: Ul =k * QI * Q2/4 meters\n\nThe final potential energy of Q2 is: U2=k* QI *\nQ2 /3 meters\n\nThe change in potential energy is: AU = U2- U1\n=k * QI * Q2 * (1/3 meters - 1/4 meters)\n\nPlugging in the values, we get: AU = (9 x 10°. «\nm?/C?) x (1x 1073C) «(8 x 1078) « (1/3m —\nAU=6]J\n\nTherefore, the work required to move Q2 from (0,\n4 meters) to (3 meters, 0) is 6 J. The answer is 1)\n6.0J.\n\nMMLU\nChemistry\n\nA sample of an unknown chlo-\nride compound was dissolved in\nwater, and then titrated with ex-\ncess Pb(NO3)2 to create a pre-\ncipitate. After drying, it is deter-\nmined there are 0.0050 mol of\nprecipitate present. What mass\nof chloride is present in the orig-\ninal sample?\n\n0) 0.177 g\n\n1) 0.355 g\n\n2) 0.522 g\n\n3) 0.710 g\n\n0.0050 moles of lead chloride precipitate contain\n0.010 moles of chloride ions due to the 2:1 mole\nratio between chloride ions and lead chloride.\n\nThe mass of 0.010 moles of chloride ions is 0.355\ng.\n\nTherefore, the mass of chloride present in the orig-\ninal sample is 0.355 g.\n\nTimeQA\n\nWho was the spouse of Anna Ka-\nrina from 1968 to 1974?\n\nAnna Karina’s spouse from 1968 to 1974 was\nFrench actor Pierre Fabre.\n\nSituatedQA\n\nwhat is the biggest hotel in las ve-\ngas nv as of November 28, 1993\n\nThe biggest hotel in Las Vegas, Nevada as of\nNovember 28, 1993 was the Excalibur Hotel &\nCasino.\n\nMuSiQue\n\nWhat year saw the creation of\nthe region where the county of\nHertfordshire is located?\n\n1994\n\nStrategyQA\n\nWould a Monoamine Oxidase\ncandy bar cheer up a depressed\nfriend?\n\nA Monoamine Oxidase (MAO) candy bar would\nnot cheer up a depressed friend. MAO is an en-\nzyme that breaks down neurotransmitters such as\nserotonin, dopamine, and norepinephrine. These\nneurotransmitters are associated with mood, so in-\nhibiting MAO can lead to an increase in their lev-\nels.\n\n", "vlm_text": "The table lists various questions from different datasets, providing their answers:\n\n1. **MMLU: Physics**\n   - **Question:** How much work is required to move a charge?\n   - **Answer:** 6.0 J, with an explanation of potential energy change.\n\n2. **MMLU: Chemistry**\n   - **Question:** What mass of chloride is present in the original sample given a known amount of precipitate?\n   - **Answer:** 0.355 g, explaining the mole ratio and calculations.\n\n3. **TimeQA**\n   - **Question:** Who was Anna Karina's spouse from 1968 to 1974?\n   - **Answer:** Pierre Fabre.\n\n4. **SituatedQA**\n   - **Question:** Biggest hotel in Las Vegas as of November 28, 1993?\n   - **Answer:** Excalibur Hotel & Casino.\n\n5. **MuSiQue**\n   - **Question:** Year of creation for Hertfordshire's region?\n   - **Answer:** 1994.\n\n6. **StrategyQA**\n   - **Question:** Effect of a Monoamine Oxidase candy bar on a depressed friend?\n   - **Answer:** It wouldn't cheer up a depressed friend; explanation about MAO enzyme.\n\n"}
{"layout": 149, "type": "table", "page_idx": 20, "img_path": "layout_images/STEPBACK_21.jpg", "table_caption": "Table 16: Demonstration exemplar for CoT prompting for MMLU Physics. ", "bbox": [105, 224, 513, 582], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nQuestion\n\nAnswer\n\nMMLU\nPhysics\n\nA point charge, Q1 = +1 mC, is\nfixed at the origin. How much\nwork is required to move another\ncharge, Q2 = +8 uC, from the\npoint (0, 4 meters) to the point\n(3 meters, 0)?\n\n0) 3.5J\n\n1) 6.0J\n\n2) 22.5 J\n\n3)40J\n\nSure, let’s think step by step.\n\n1. Calculate the electric potential energy of Q2\nat the initial position. The electric potential\nenergy (U) of a point charge Q2 at a distance\nr from another point charge Q1 is given by the\nfollowing equation: U =k * QI * Q2/r, where k\nis Coulomb’s constant.\n\nTherefore, the electric potential energy of Q2 at\nthe initial position is:\n\nUinitiat = (9 X 10°Nm?/C?) * (1 x 10-3C) « (8 x\n10-°C)/4m = 18\n\n2. Calculate the electric potential energy of Q2 at\nthe final position. The electric potential energy of\nQ2? at the final position is:\n\nUsinar = (9 x 10°Nm?/C?) « (1 x 1073C) * (8 x\n10-°C)/3m = 24]\n\n3. Calculate the work required to move Q2 from\nthe initial position to the final position. The work\n(W) required to move a charge from one position\nto another is equal to the change in electric\npotential energy (AU) between the two positions.\nW = AU = Ugina - Vinitia = 24 J - 18S =6I\n\nTherefore, the answer is 1) 6.0 J.\n\n", "vlm_text": "The table shows a physics problem about calculating the work required to move a charge and the solution to that problem. Here's a summary:\n\n**Dataset:** MMLU Physics\n\n**Question:** \n- A point charge, Q1 = +1 mC, is fixed at the origin. How much work is required to move another charge, Q2 = +8 μC, from the point (0, 4 meters) to the point (3 meters, 0)?\n- Options: 0) 3.5 J, 1) 6.0 J, 2) 22.5 J, 3) 40 J\n\n**Answer:**\n1. Calculate the initial electric potential energy of Q2 using Coulomb's law.\n2. Calculate the final electric potential energy of Q2.\n3. Determine the work done, \\( W \\), as the change in electric potential energy: \\( W = U_{\\text{final}} - U_{\\text{initial}} = 6 \\, \\text{J} \\).\n\n**Conclusion:** The work required is 6.0 J."}
{"layout": 150, "type": "table", "page_idx": 21, "img_path": "layout_images/STEPBACK_22.jpg", "table_caption": "Table 17: Demonstration exemplar for CoT prompting for MMLU Chemistry. ", "bbox": [105, 215, 512, 592], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nQuestion\n\nAnswer\n\nMMLU\nChemistry\n\nA sample of an unknown chlo-\nride compound was dissolved in\nwater, and then titrated with ex-\ncess Pb(NO3)2 to create a pre-\ncipitate. After drying, it is deter-\nmined there are 0.0050 mol of\nprecipitate present. What mass\nof chloride is present in the orig-\ninal sample?\n\n0) 0.177 g\n\n1) 0.355 g\n\n2) 0.522 g\n\n3) 0.710 g\n\nHere’s the step-by-step solution:\n\nIdentify the precipitate: The precipitate formed\nwhen a chloride compound reacts with lead nitrate\n(Pb(NO3)2) is lead chloride (PbC12).\n\nDetermine the mole ratio: The balanced chemical\nequation for the reaction between a chloride\ncompound (represented as MCI, where M is the\nunknown metal) and lead nitrate is: 2MCI +\nFrom the balanced equation, you can see that 2\nmoles of chloride ions (Cl-) react with 1 mole of\nlead nitrate to produce 1 mole of lead chloride\nprecipitate. Additionally, 1 mole of lead chloride\ncontains 2 moles of chloride ions.\n\nCalculate the moles of chloride ions: Since\n0.0050 moles of lead chloride precipitate\nwere formed, there must have been 2 x 0.0050 =\n0.010 moles of chloride ions in the original sample.\n\nCalculate the mass of chloride ions: The molar\nmass of chlorine (Cl) is 35.45 g/mol. Therefore,\nthe mass of 0.010 moles of chloride ions is:\n\nmass = moles x molar mass = 0.010 mol x 35.45\ng/mol = 0.355 g\n\nTherefore, the mass of chloride present in the origi-\nnal sample is 0.355 g. The correct answer is option\n1.\n", "vlm_text": "The table has two columns, \"Question\" and \"Answer,\" related to a chemistry topic. \n\n**Question:**\nA sample of an unknown chloride compound was dissolved in water and titrated with excess Pb(NO3)2, forming a precipitate. It was found that 0.0050 mol of precipitate is present. The challenge is to determine the mass of chloride in the original sample, with options:\n0) 0.177 g\n1) 0.355 g\n2) 0.522 g\n3) 0.710 g\n\n**Answer:**\nA step-by-step solution is given:\n1. Identify the precipitate as lead chloride (PbCl2).\n2. Determine the mole ratio from the balanced equation \\(2MCl + Pb(NO3)2 → 2MNO3 + PbCl2\\), showing 2 moles of Cl- react with 1 mole of Pb(NO3)2.\n3. Calculate moles of chloride ions: 0.0050 mol lead chloride precipitate = 0.010 mol Cl-.\n4. Calculate the mass of chloride ions using the molar mass of Cl (35.45 g/mol): \n   \\(mass = 0.010 \\, \\text{mol} \\times 35.45 \\, \\text{g/mol} = 0.355 \\, \\text{g}\\).\n   \nTherefore, the mass of chloride in the original sample is 0.355 g, option 1."}
{"layout": 151, "type": "table", "page_idx": 22, "img_path": "layout_images/STEPBACK_23.jpg", "table_caption": "Table 18: Demonstration exemplar for CoT prompting for TimeQA and SituatedQA. ", "bbox": [104, 184, 514, 623], "page_size": [612.0, 792.0], "ocr_text": "dataset Question\n\nAnswer\n\nTimeQA Who was the spouse of Anna Ka-\nrina from 1968 to 1974?\n\nStep 1: Identify Anna Karina’s spouses:Jean-Luc\nGodard (1961-1965).\n\nPierre Fabre (1968-1974)\n\nDaniel Duval (1978-1981)\n\nDennis Berry (1982-1994)\n\nStep 2: Determine which spouse was married to\nAnna Karina from 1968 to 1974.\n\nJean-Luc Godard was married to Anna Karina\nfrom 1961 to 1965, so he is not the correct answer.\nPierre Fabre was married to Anna Karina from\n1968 to 1974, so he is the correct answer.\n\nDaniel Duval was married to Anna Karina from\n1978 to 1981, so he is not the correct answer.\nDennis Berry was married to Anna Karina from\n1982 to 1994, so he is not the correct answer.\n\nTherefore, Anna Karina’s spouse from 1968 to\n1974 was Pierre Fabre.\n\nSituatedQA what is the biggest hotel in las ve-\ngas nv as of November 28, 1993\n\nSure, let’s think step by step:\n\nWhat were the largest hotels in Las Vegas in 1993?\nAccording to a 1993 article in the Las Vegas\nReview-Journal, the largest hotels in Las Vegas\nat the time were:\n\nMGM Grand (5,005 rooms) Excalibur (4,008\nrooms) The Mirage (3,049 rooms) Flamingo\nHilton (3,565 rooms) Caesars Palace (2,577 rooms)\nWhich of these hotels was the largest on November\n28, 1993? The MGM Grand opened in December\n1993, so it would not have been the largest hotel\non November 28, 1993. The Excalibur opened in\nJune 1990, so it would have been the largest hotel\non November 28, 1993.\n\nTherefore, the largest hotel in Las Vegas on Novem-\nber 28, 1993 was the Excalibur.\n\n", "vlm_text": "The table contains the following information:\n\n1. **Dataset: TimeQA**\n   - **Question:** Who was the spouse of Anna Karina from 1968 to 1974?\n   - **Answer:** The solution involves identifying Anna Karina's spouses and determining that Pierre Fabre was her spouse from 1968 to 1974.\n\n2. **Dataset: SituatedQA**\n   - **Question:** What is the biggest hotel in Las Vegas, NV as of November 28, 1993?\n   - **Answer:** The answer, deduced from a 1993 article, indicates that the Excalibur was the largest hotel on that date. Various hotel sizes are compared, and it is concluded that Excalibur, which opened in June 1990, was the largest at that time."}
{"layout": 152, "type": "table", "page_idx": 23, "img_path": "layout_images/STEPBACK_24.jpg", "table_caption": "Table 19: Demonstration exemplar for CoT prompting for MuSiQue and StrategyQA. ", "bbox": [104, 235, 514, 573], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nQuestion\n\nAnswer\n\nMuSiQue\n\nWhat year saw the creation of\nthe region where the county of\nHertfordshire is located?\n\nThe county of Hertfordshire is in the East of Eng-\nland’ region. The ’East of England’ region was\ncreated in 1994. So, the answer is 1994.\n\nStrategyQA\n\nWould a Monoamine Oxidase\ncandy bar cheer up a depressed\nfriend?\n\nNo, a Monoamine Oxidase (MAO) candy bar\nwould not cheer up a depressed friend. In fact,\nit could be dangerous for them to consume. Here’s\na step-by-step explanation:\n\n1. MAO is an enzyme that breaks down neuro-\ntransmitters like serotonin, dopamine, and nore-\npinephrine. These neurotransmitters are important\nfor regulating mood, and low levels of them are\nassociated with depression.\n\n2. MAO inhibitors (MAOIs) are a type of medica-\ntion that blocks the action of MAO, which can in-\ncrease levels of these neurotransmitters in the brain.\nMAOIs are sometimes used to treat depression, but\nthey can have serious side effects, including inter-\nactions with certain foods and medications.\n\n3. A MAO candy bar would not contain enough\nMAOI to have a therapeutic effect on depression.\nIn fact, it is unlikely that a candy bar could contain\nany MAO[ at all, as these medications are typically\ntaken in pill form.\n\nIn conclusion, a MAO candy bar would not cheer\nup a depressed friend and could even be dangerous\nfor them to consume.\n\n", "vlm_text": "The table lists two datasets, questions, and answers:\n\n1. **Dataset:** MuSiQue\n   - **Question:** What year saw the creation of the region where the county of Hertfordshire is located?\n   - **Answer:** The county of Hertfordshire is in the 'East of England' region. The 'East of England' region was created in 1994. So, the answer is 1994.\n\n2. **Dataset:** StrategyQA\n   - **Question:** Would a Monoamine Oxidase candy bar cheer up a depressed friend?\n   - **Answer:** No, a Monoamine Oxidase (MAO) candy bar would not cheer up a depressed friend. In fact, it could be dangerous for them to consume. Here’s a step-by-step explanation:\n     1. MAO is an enzyme that breaks down neurotransmitters like serotonin, dopamine, and norepinephrine. These neurotransmitters are important for regulating mood, and low levels of them are associated with depression.\n     2. MAO inhibitors (MAOIs) are a type of medication that blocks the action of MAO, which can increase levels of these neurotransmitters in the brain. MAOIs are sometimes used to treat depression, but they can have serious side effects, including interactions with certain foods and medications.\n     3. A MAO candy bar would not contain enough MAOI to have a therapeutic effect on depression. In fact, it is unlikely that a candy bar could contain any MAOI at all, as these medications are typically taken in pill form.\n   \n   In conclusion, a MAO candy bar would not cheer up a depressed friend and could even be dangerous for them to consume."}
{"layout": 153, "type": "table", "page_idx": 24, "img_path": "layout_images/STEPBACK_25.jpg", "bbox": [107, 234, 505, 535], "page_size": [612.0, 792.0], "ocr_text": "Question\n\nAn alarm whose frequency is 400 Hz is dropped out of a third-floor window. The\nstudent who drops it measures the frequency with a very sensitive oscilloscope.\nThe measured frequency\n\n0) appears higher than 400 Hz and the frequency increase as it falls\n\n1) appears higher than 400 Hz and the frequency decreases as it falls\n\n2) appears lower than 400 Hz and the frequency decreases as it falls\n\n3) appears lower than 400 Hz and the frequency increases as it falls\n\nPrinciples\n\nAnswer\n\nDoppler Effect: the effect produced by the motion of a wave source, observer, or\nboth that causes a change in wave frequency perceived by an observer relative\nto the frequency produced by the source. The Doppler effect is observed with\nall types of waves, including electromagnetic and acoustic waves. It was named\nafter Austrian physicist Christian Doppler.\n\nUsing the Principles of Doppler Effect, we can solve the problem as following:\n\nStep 1: Apply Doppler Effect to find out the measured frequency.\n\nThe Doppler Effect is the change in frequency of a wave as measured by an\nobserver who is moving relative to the source of the wave. In this case, the\nsource of the wave is the alarm, and the observer is the student who drops it.\n\nAs the alarm falls, the distance between the alarm and the student decreases.\nThis means that the frequency of the wave as measured by the student will\nincrease. Therefore, the measured frequency will appear higher than 400 Hz,\nand the frequency will increase as the alarm falls.\n\nTherefore, the correct answer is 0) appears higher than 400 Hz and the frequency\nincrease as it falls.\n", "vlm_text": "The table consists of three sections: \n\n1. **Question**: Describes a scenario involving an alarm with a frequency of 400 Hz being dropped out of a window. The student who drops it measures the frequency and must determine how it appears:\n   - 0) Appears higher than 400 Hz and the frequency increases as it falls\n   - 1) Appears higher than 400 Hz and the frequency decreases as it falls\n   - 2) Appears lower than 400 Hz and the frequency decreases as it falls\n   - 3) Appears lower than 400 Hz and the frequency increases as it falls\n\n2. **Principles**: Explains the Doppler Effect, which notes the change in wave frequency perceived by an observer due to the relative motion between the source of the wave and the observer.\n\n3. **Answer**: Steps through applying the Doppler Effect to solve the problem. As the alarm falls, the distance between the alarm and the student decreases, causing the frequency to increase. Thus, the correct choice is 0) the frequency appears higher than 400 Hz and increases as it falls."}
{"layout": 154, "type": "table", "page_idx": 25, "img_path": "layout_images/STEPBACK_26.jpg", "bbox": [108, 135, 505, 647], "page_size": [612.0, 792.0], "ocr_text": "Question\n\nPrinciples\n\nAnswer\n\nAn astronaut lands on a planet whose mass and radius are each twice that of\nEarth. If the astronaut weighs 800 N on Earth, how much will he weigh on this\nplanet?\n\n0) 200 N\n\n1) 400 N\n\n2) 800 N\n\n3) 1600 N\n\nWeight: W = m * g, where W is the weight, m is the mass and g is the\nacceleration due to gravity\n\nAcceleration due to gravity: g=G * m/r?, where G is the gravitational constant,\nm is the mass of the object and r is the radius of the object\n\nUsing the Principles of Newton’s law of universal gravitation and Weight, we\ncan solve the problem as following:\n\nStep 1: Apply Newton’s law of universal gravitation to find out the acceleration\ndue to gravity on the planet.\n\nThe acceleration due to gravity on a planet is given by the formula:\n\ng=G* m/r?, where g is the acceleration due to gravity, G is the gravitational\nconstant, m is the mass of the planet, and r is the radius of the planet.\n\nIn this problem, we are given the following information:\nm=2* Mearth\nt=2* Tearth\n\nPlugging these values into the formula, we get:\n£=G*2* mearth | (2*Pearth)?\ng=G* Mearth! arth\n\nThis is the same as the acceleration due to gravity on Earth.\n\nStep 2: Apply Weight to find out the weight of the astronaut on the planet.\nThe weight of an object is given by the formula:\n\nW =m * g, where W is the weight, m is the mass of the object, and g is the\nacceleration due to gravity.\n\nIn this problem, we are given the following information:\nm= 800 N/gearth\n& = Gearth\n\nPlugging these values into the formula, we get:\nW = 800 N/ Gearth * Jearth\nW = 800N\n\nTherefore, the astronaut will weigh 800 N on the planet. The correct answer is\n2) 800 N.\n\n", "vlm_text": "The table contains a problem related to physics, specifically Newton's law of universal gravitation and the concept of weight. Here's a breakdown of the contents of the table:\n\n- **Question**: The scenario describes an astronaut landing on a planet where both the mass and radius are twice that of Earth. The astronaut weighs 800 N on Earth, and the question asks for his weight on the new planet. The options provided are 200 N, 400 N, 800 N, and 1600 N, with \"400 N\" marked as an option but with no indication that it's correct.\n\n- **Principles**: The table outlines two key equations:\n  - Weight, \\( W = m \\times g \\), where \\( W \\) is weight, \\( m \\) is mass, and \\( g \\) is acceleration due to gravity.\n  - Acceleration due to gravity, \\( g = G \\times m / r^2 \\), where \\( G \\) is the gravitational constant, \\( m \\) is the planet's mass, and \\( r \\) is the planet's radius.\n\n- **Answer**: The solution is presented in a step-by-step format:\n  - **Step 1**: Calculation of the acceleration due to gravity on the new planet, which is found to be the same as on Earth by substituting the conditions \\( m = 2 \\times m_{earth} \\) and \\( r = 2 \\times r_{earth} \\).\n  - **Step 2**: Verification via the weight equation, confirming that since \\( g \\) on the new planet equals \\( g_{earth} \\), the astronaut's weight remains 800 N.\n  - It concludes that the astronaut will weigh 800 N on the planet, identifying option 2 (800 N) as correct.\n\nOverall, the table systematically applies physics principles to identify the correct weight of the astronaut on the new planet."}
{"layout": 155, "type": "text", "text": "Table 21: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Math Error . As highlighted, the math error leads to directly a wrong answer with a factor of 2 off. ", "page_idx": 25, "bbox": [107, 651.5595703125, 503, 675.1212158203125], "page_size": [612.0, 792.0]}
{"layout": 156, "type": "table", "page_idx": 26, "img_path": "layout_images/STEPBACK_27.jpg", "bbox": [107, 228, 506, 531], "page_size": [612.0, 792.0], "ocr_text": "Question\n\nPrinciples\n\nTwo spheres of net charge +5e and -6e briefly come into contact. Afterward,\nwhich of the following is a possible combination of net charges for the two\nspheres?\n\n0) +3e and -4e\n\n1) +1.Se and -2.5e\n\n2) Both of the above\n\n3) None of the above\n\nLaw of conservation of charge: the total charge in a closed system remains\nconstant.\n\nCoulomb’s Law: the mutual repulsion of like charges demands that the charges\nbe as far apart as possible.\n\nAnswer\n\nUsing the Principles of Conservation of charge, we can solve the problem as\nfollowing:\n\nStep 1: Apply Conservation of charge to find out the possible combination of\nnet charges for the two spheres.\n\nThe total charge of the two spheres before they come into contact is +5e - 6e =\n-le. After they come into contact, the total charge of the two spheres must still\nbe -le.\n\nStep 2: Find out the possible combination of net charges for the two spheres.\nThe possible combination of net charges for the two spheres are:\n\n(1) +3e and -4e\n\n(2) +1.5e and -2.5e\n\nTherefore, the correct answer is 2) Both of the above.\n\n", "vlm_text": "The table contains a question about two spheres with net charges of +5e and -6e coming into contact. It asks for the possible combination of net charges afterward. The options are:\n\n0) +3e and -4e  \n1) +1.5e and -2.5e  \n2) Both of the above  \n3) None of the above  \n\nThe principles discussed are the law of conservation of charge and Coulomb's law regarding the repulsion of like charges.\n\nThe answer is provided as:\n\n1. Using the conservation of charge, the total charge of the two spheres before and after contact must be -1e.\n2. The possible combinations are:\n   - (1) +3e and -4e\n   - (2) +1.5e and -2.5e\n\nTherefore, the correct answer is 2) Both of the above."}
{"layout": 157, "type": "text", "text": "Table 22: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Principle Error . In this case, Coulomb’s Law is not needed for solving this problem. Instead, the Charge Quantization Principle is missing from the retrieved principles, and is in fact needed to rule out option (2) of fractional charges. ", "page_idx": 26, "bbox": [107, 536.4905395507812, 504, 581.3724975585938], "page_size": [612.0, 792.0]}
{"layout": 158, "type": "table", "page_idx": 27, "img_path": "layout_images/STEPBACK_28.jpg", "bbox": [108, 81, 500, 308], "page_size": [612.0, 792.0], "ocr_text": "Question\n\nPrinciples\n\nAnswer\n\nThe circumference of a helium-filled balloon is measured for three different\nconditions: at room temperature, after being in a warm oven for 30 minutes,\nand after being in a freezer for 30 minutes. A student plotting the circumference\ncubed C® as a function of temperature T, should expect to find which of the\nfollowing?\n\n0) a cubic relationship between C® and T\n\n1) an indirect relationship between C? and T\n\n2) an extrapolated temperature T where C? reaches zero\n\n3) a maximum C® as the temperature T increases\n\nIdeal Gas Law: PV = nRT, where P is the pressure, V is the volume, n is\nthe number of moles of gas, R is the ideal gas constant, T is the absolute\ntemperature.\n\nVolume of a sphere: V = 4/3 « 1 « r°, where r is the radius.\n\nAbsolute temperature: Absolute temperature is always written as kelvin.\nAbsolute zero: Absolute zero is the lowest limit of the kelvin scale and is the\nlowest possible temperature (- 273.15 °C).\n\nUsing the Principles of Charles’s Law and Gay-Lussac’s Law, we can solve the\nproblem as following:\n\nStep 1: Apply Charles’s Law to find out the relationship between the volume\nand temnerature of the cas Charles’s T aw ctates that the volime of 9 fixed\n", "vlm_text": "The table consists of three sections labeled \"Question,\" \"Principles,\" and \"Answer.\"\n\n**Question**: \nIt describes an experiment where the circumference of a helium-filled balloon is measured under three conditions (room temperature, after warming, and after freezing). The student is tasked with plotting the circumference cubed \\( C^3 \\) as a function of temperature \\( T \\) and determining which relationship is expected:\n0) Cubic relationship between \\( C^3 \\) and \\( T \\)\n1) Indirect relationship between \\( C^3 \\) and \\( T \\)\n2) Extrapolated temperature where \\( C^3 \\) reaches zero\n3) Maximum \\( C^3 \\) as \\( T \\) increases\n\n**Principles**: \nOutlines principles to be used:\n- Ideal Gas Law: \\( PV = nRT \\)\n- Volume of a sphere: \\( V = \\frac{4}{3} \\pi r^3 \\)\n- Absolute temperature (in Kelvin)\n- Absolute zero (−273.15 °C)\n\n**Answer**: \nDescribes solving the problem using Charles’s Law and Gay-Lussac’s Law. Step 1 involves applying Charles’s Law to find the relationship between the volume and temperature."}
{"layout": 159, "type": "text", "text": "Step 2: Apply Gay-Lussac’s Law to find out the relationship between the pressure and temperature of the gas. Gay-Lussac’s Law states that the pressure of a fixed mass of a gas is directly proportional to the absolute temperature of the gas when volume is kept constant. This means that if the temperature of the gas increases, the pressure of the gas will also increase. ", "page_idx": 27, "bbox": [184, 354.1525573730469, 497, 409.9934997558594], "page_size": [612.0, 792.0]}
{"layout": 160, "type": "text", "text": "Step 3: Apply Charles’s Law and Gay-Lussac’s Law to find out the relationship between the circumference and temperature of the gas.The circumference of the balloon is directly proportional to the volume of the gas. This is because the circumference of the balloon is the distance around the outside of the balloon, and the volume of the gas is the amount of space that the gas takes up. ", "page_idx": 27, "bbox": [184, 419.9055480957031, 497, 475.7464904785156], "page_size": [612.0, 792.0]}
{"layout": 161, "type": "text", "text": "The pressure of the gas is directly proportional to the temperature of the gas. This is because the pressure of the gas is the force that the gas exerts on the walls of the balloon, and the temperature of the gas is the measure of the average kinetic energy of the gas molecules. ", "page_idx": 27, "bbox": [184, 485.6595458984375, 497, 530.5404663085938], "page_size": [612.0, 792.0]}
{"layout": 162, "type": "text", "text": "Therefore, the circumference of the balloon is directly proportional to the temperature of the gas. This means that if the temperature of the gas increases, the circumference of the balloon will also increase. ", "page_idx": 27, "bbox": [184, 540.4535522460938, 497, 574.3765258789062], "page_size": [612.0, 792.0]}
{"layout": 163, "type": "text", "text": "Step 4: Apply the relationship between the circumference and temperature of the gas to find out the relationship between the circumference cubed and temperature of the gas. The circumference cubed is directly proportional to the temperature of the gas. This is because the circumference cubed is the volume of the balloon, and the volume of the balloon is directly proportional to the temperature of the gas. ", "page_idx": 27, "bbox": [184, 584.28955078125, 497, 651.0885009765625], "page_size": [612.0, 792.0]}
{"layout": 164, "type": "text", "text": "Therefore, the student should expect to find a cubic relationship between    $C^{3}$  and T.  The correct answer is 0) a cubic relationship between  $C^{3}$    and T. ", "page_idx": 27, "bbox": [184, 661, 497, 683.9655151367188], "page_size": [612.0, 792.0]}
{"layout": 165, "type": "text", "text": "Table 23: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Context Loss . In this case, at the end of the Reasoning chain, the model forgot the original question, and lose the context to apply the reasoning to the question. ", "page_idx": 27, "bbox": [107, 695.39453125, 505, 729.3175048828125], "page_size": [612.0, 792.0]}
{"layout": 166, "type": "table", "page_idx": 28, "img_path": "layout_images/STEPBACK_29.jpg", "bbox": [105, 133, 504, 634], "page_size": [612.0, 792.0], "ocr_text": "Question\n\nPrinciples\n\nAnswer\n\nPhysics students are checking the constant acceleration equations of kinematics\nby measuring the velocity of a tennis ball that is dropped and falls 6 meters\nand then passes through a photogate. The predicted velocity is 20% above the\nvelocity measured by the photogate. Which of the following best describes the\ncause of the large percent difference?\n\n0) The ball changes its shape while falling.\n\n1) The acceleration of gravity varies as the ball is falling.\n\n2) Air resistance increases the acceleration of the ball.\n\n3) The acceleration of the balls varies with the velocity.\n\nVertical motion: y = 0.5 * g * t?, where y is the vertical displacement, g is the\nacceleration due to gravity, t is the time.\n\nFree fall: is a special case of motion with constant acceleration, in which the\nacceleration is due to gravity.\n\nAcceleration to Velocity Formula: v = u + a * t, where v is the final speed, u is\nthe initial velocity, a is the acceleration, and t is the time.\n\nUsing the Principles of Vertical motion and Horizontal motion, we can solve\nthe problem as following:\n\nStep 1: Apply the Vertical motion equation to find the time it takes for the ball\nto fall 6 meters.\n\ny=0.5*e* 0?\n6m=0.5 * 9.8 m/s? * t?\nt=1.12s\n\nStep 2: Apply the Horizontal motion equation to find the velocity of the ball\nwhen it passes through the photogate.\n\nxX=v*t\nv=x/t\nv=6m/1.12s\nv = 5.36 m/s\n\nStep 3: Compare the predicted velocity with the velocity measured by the\nphotogate. The predicted velocity is 20% above the velocity measured by the\nphotogate, so the predicted velocity is 1.2 * 5.36 m/s = 6.43 m/s.\n\nStep 4: Find the cause of the large percent difference. The predicted velocity is\n6.43 m/s, but the velocity measured by the photogate is 5.36 m/s. The difference\nis 1.07 m/s. This difference is caused by air resistance. Air resistance is a force\nthat opposes the motion of an object through the air. It is caused by the friction\nbetween the object and the air molecules. The greater the surface area of the\nobject, the greater the air resistance. The tennis ball has a large surface area, so\nit experiences a lot of air resistance. This air resistance slows down the tennis\nball and causes the difference between the predicted velocity and the velocity\nmeasured by the photogate.\n\nTherefore, the correct answer is 0) The ball changes its shape while falling.\n\n", "vlm_text": "The table contains the following elements:\n\n**Question:**\nPhysics students are checking the constant acceleration equations of kinematics by measuring the velocity of a tennis ball that is dropped and falls 6 meters and then passes through a photogate. The predicted velocity is 20% above the velocity measured by the photogate. Which of the following best describes the cause of the large percent difference?\n0) The ball changes its shape while falling.\n1) The acceleration of gravity varies as the ball is falling.\n2) Air resistance increases the acceleration of the ball.\n3) The acceleration of the balls varies with the velocity.\n\n**Principles:**\n- Vertical motion: \\( y = 0.5 \\times g \\times t^2 \\), where \\( y \\) is the vertical displacement, \\( g \\) is the acceleration due to gravity, \\( t \\) is the time.\n- Free fall: a special case of motion with constant acceleration, where the acceleration is due to gravity.\n- Acceleration to Velocity Formula: \\( v = u + a \\times t \\), where \\( v \\) is the final speed, \\( u \\) is the initial velocity, \\( a \\) is the acceleration, and \\( t \\) is the time.\n\n**Answer:**\nUsing the principles of vertical motion and horizontal motion, the solution is:\n\n- **Step 1:** Apply the vertical motion equation to find the time it takes for the ball to fall 6 meters.\n  - \\( y = 0.5 \\times g \\times t^2 \\)\n  - \\( 6 \\, \\text{m} = 0.5 \\times 9.8 \\, \\text{m/s}^2 \\times t^2 \\)\n  - \\( t = 1.12 \\, \\text{s} \\)\n\n- **Step 2:** Apply the horizontal motion equation to find the velocity of the ball when it passes through the photogate.\n  - \\( x = v \\times t \\)\n  - \\( v = x / t \\)\n  - \\( v = 6 \\, \\text{m} / 1.12 \\, \\text{s} \\)\n  - \\( v = 5.36 \\, \\text{m/s} \\)\n\n- **Step 3:** Compare the predicted velocity with the velocity measured by the photogate. The predicted velocity is 20% above the velocity measured by the photogate, so the predicted velocity is \\( 1.2 \\times 5.36 \\, \\text{m/s} = 6.43 \\, \\text{m/s} \\).\n\n- **Step 4:** Find the cause of the large percent difference. The predicted velocity is 6.43 m/s, but the velocity measured by the photogate is 5.36 m/s. The difference is 1.07 m/s. This difference is"}
{"layout": 167, "type": "text", "text": "Table 24: Error example of S TEP -B ACK  P ROMPTING  on MMLU high-school Physics in the class of Reasoning Error . In this case, the model was able to correctly identify air resistance is the cause of the velocity difference, but made the error at the final reasoning step of deriving the right answer. ", "page_idx": 28, "bbox": [107, 640.819580078125, 503, 674.7424926757812], "page_size": [612.0, 792.0]}
{"layout": 168, "type": "table", "page_idx": 29, "img_path": "layout_images/STEPBACK_30.jpg", "bbox": [105, 188, 511, 565.75], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nexample\n\nMMLU-Physics\n\nOriginal Question: What happens to the pressure, P, of an ideal gas if\nthe temperature is increased by a factor of 2 and the volume is increased\nby a factor of 8?\n\n0) P decreases by a factor of 16.\n\n1) P decreases by a factor of 4.\n\n2) P decreases by a factor of 2.\n\n3) P increases by a factor of 4.\n\nOriginal Answer [Incorrect]: The correct answer is 0. The ideal gas\nlaw is PV = nRT. If the temperature is increased by a factor of 2 and the\nvolume is increased by a factor of 8, then the pressure will decrease by a\nfactor of 16.\n\nStepback Question: What are the physics principles behind this\nquestion?\n\nPrinciples:\n\nIdeal gas law: PV = nRT, where P is the pressure, V is the volume, n is\nthe number of moles, R is the gas constant, and T is the temperature.\nFinal Answer: Using the Principles of Ideal gas law, we can solve the\nproblem as following:\n\nStep 1: Apply Ideal gas law to find out the pressure of an ideal gas. The\nideal gas law states that PV = nRT, where P is the pressure, V is the\nvolume, n is the number of moles, R is the gas constant, and T is the\ntemperature.\n\nStep 2: Apply Ideal gas law to find out the pressure of an ideal gas when\nthe temperature is increased by a factor of 2 and the volume is increased\nby a factor of 8. If the temperature is increased by a factor of 2, then T be-\ncomes 2T. If the volume is increased by a factor of 8, then V becomes 8V.\nSubstituting these values into the ideal gas law, we get: P(8V) = nR(2T)\nDividing both sides by 8V, we get: P = nR(2T) / 8V\n\nWe can cee that the nressure has decreased by a factor of 4.\n", "vlm_text": "The table contains information on a dataset example from \"MMLU-Physics.\" It includes:\n\n- **Original Question:** Relating to the behavior of the pressure \\(P\\) of an ideal gas when the temperature and volume are increased by certain factors.\n- **Original Answer [Incorrect]:** States the incorrect answer choice as 0, with an explanation.\n- **Stepback Question:** Asks about the physics principles behind the question.\n- **Principles:** Outlines the ideal gas law \\(PV = nRT\\).\n- **Final Answer:** Provides steps to solve the problem using the ideal gas law, showing that the pressure decreases by a factor of 16 after the correct calculations."}
{"layout": 169, "type": "text", "text": "Therefore, the correct answer is 1) P decreases by a factor of 4. Table 25: Illustration of wins of S TEP -B ACK  P ROMPTING  on the MMLU-Physics dataset. ", "page_idx": 29, "bbox": [219.1669921875, 583.20556640625, 470.80242919921875, 595.2105102539062], "page_size": [612.0, 792.0]}
{"layout": 170, "type": "text", "text": "", "page_idx": 29, "bbox": [125.6729965209961, 606.6395263671875, 486.0187072753906, 618.6444702148438], "page_size": [612.0, 792.0]}
{"layout": 171, "type": "text", "text": "dataset ", "text_level": 1, "page_idx": 30, "bbox": [113, 169, 141, 177], "page_size": [612.0, 792.0]}
{"layout": 172, "type": "text", "text": "MMLU-Physics ", "text_level": 1, "page_idx": 30, "bbox": [113, 184, 179, 194], "page_size": [612.0, 792.0]}
{"layout": 173, "type": "text", "text": "Original Question : A liquid flows at a constant flow rate through a pipe with circular cross-sections of varying diameters. At one point in the pipe, the diameter is   $2\\,\\mathrm{cm}$   and the flow speed is  $18\\;\\mathrm{m}/\\mathrm{s}$  . What is the flow speed at another point in this pipe, where the diameter is   $3\\,\\mathrm{cm}^{\\prime}$  ? 0)  $4\\:\\mathrm{m/s}$  1)  $6\\:\\mathrm{m/s}$  2)   $8\\;\\mathrm{m}/\\mathrm{s}$  3)   $12\\,\\mathrm{m/s}$  ", "page_idx": 30, "bbox": [218, 182.84690856933594, 503, 271.92242431640625], "page_size": [612.0, 792.0]}
{"layout": 174, "type": "text", "text": "Original Answer [Incorrect] : The answer is 3)   $12\\,\\mathrm{m/s}$   A step-by-step solution is below: The flow rate is constant, so the product of the speed and the cross-sectional area is constant. The cross-sectional area is proportional to the square of the diameter, so the speed is inversely proportional to the square of the diameter. The ratio of the speeds is the inverse of the ratio of the squares of the diameters, so the speed at the second point is    $18m/s*(2\\bar{c m}/3c m)^{2}=12\\:\\mathrm{m/s}$  . ", "page_idx": 30, "bbox": [219, 270.5179138183594, 504, 349], "page_size": [612.0, 792.0]}
{"layout": 175, "type": "text", "text": "Stepback Question : What are the physics principles behind this question? ", "page_idx": 30, "bbox": [219, 347.22991943359375, 504, 370.552490234375], "page_size": [612.0, 792.0]}
{"layout": 176, "type": "text", "text": "Principles ", "text_level": 1, "page_idx": 30, "bbox": [218, 371, 264, 380], "page_size": [612.0, 792.0]}
{"layout": 177, "type": "text", "text": "Conservation of Mass: the amount of mass flowing through the pipe at two different points must be equal, or   $\\mathsf{A}1\\mathrm{\\Omega}^{*}\\,\\mathrm{v}1=\\mathrm{A}2\\mathrm{\\Omega}^{*}\\,\\mathrm{v}2$  , where A1 is the area of cross-section one, v1 is the velocity at point 1, A2 is the area of cross-section two, v2 is the velocity at point 2. ", "page_idx": 30, "bbox": [219, 380.4655456542969, 504, 425.3475036621094], "page_size": [612.0, 792.0]}
{"layout": 178, "type": "text", "text": "Area of Circle:    $A=\\pi*r^{2}$  , where r is the radius of the circle. ", "page_idx": 30, "bbox": [219, 424, 465.7337341308594, 436.3065185546875], "page_size": [612.0, 792.0]}
{"layout": 179, "type": "text", "text": "Final Answer : Using the Principles of Continuity equation, we can solve the problem as following: ", "page_idx": 30, "bbox": [219, 434.90191650390625, 504, 458.2235107421875], "page_size": [612.0, 792.0]}
{"layout": 180, "type": "text", "text": "Step 1: Apply the Continuity equation to find out the flow speed at another point in this pipe. The continuity equation states that the product of the area and the velocity is constant at all points in a pipe. In this problem, we are given the following information: ", "page_idx": 30, "bbox": [219, 457.17755126953125, 504, 502.05950927734375], "page_size": [612.0, 792.0]}
{"layout": 181, "type": "equation", "text": "\n$$\n\\begin{array}{l}{{A1=\\pi*(2c m)^{2}=4\\pi c m^{2}}}\\\\ {{\\mathrm{v1}=18\\,\\mathrm{m/s}}}\\\\ {{A2=\\pi*(3c m)^{2}=9\\pi c m^{2}}}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 30, "bbox": [217, 499.25, 333, 536], "page_size": [612.0, 792.0]}
{"layout": 182, "type": "text", "text": "Therefore, the flow speed at another point in this pipe is   $8\\,\\mathrm{\\m/s}$  . The correct answer is 2)  $8\\;\\mathrm{m}/\\mathrm{s}$  . ", "page_idx": 30, "bbox": [219, 599.6435546875, 504, 622.6074829101562], "page_size": [612.0, 792.0]}
{"layout": 183, "type": "text", "text": "Original Question : A 2    $\\mu\\mathrm{F}$   capacitor is connected directly to a battery. When the capacitor is fully charged, it stores   $600\\ \\mu\\mathrm{C}$   of charge. An experimenter replaces the  $2\\;\\mu\\mathrm{F}$   capacitor with three   $18\\;\\mu\\mathrm{F}$   capacitors in series connected to the same battery. Once the capacitors are fully charged, what charge is stored on each capacitor? 0)   $100\\;\\mu\\mathbf{C}$  1)   $200\\,\\mu\\mathrm{C}$  2)  $600\\;\\mu\\mathrm{C}$  3)   $1800\\,\\mu\\mathrm{C}$  ", "page_idx": 31, "bbox": [189, 117.09288787841797, 504, 217.12840270996094], "page_size": [612.0, 792.0]}
{"layout": 184, "type": "text", "text": "Original Answer [Incorrect] :  The answer is  $100\\;\\mu\\mathrm{C}$  . The total capacitance of the three  $18\\ \\mu\\mathrm{F}$   capacitors in series is  $1\\mathrm{~/~}(1\\mathrm{~/~}18+1\\mathrm{~/~}18+1\\mathrm{~/~}18)=6\\mathrm{~}\\mu\\mathrm{F}.$   The charge stored on the three capacitors in series is  $6\\:\\mu\\mathrm{F}^{\\ast}\\mathrm{~V}=600\\:\\mu\\mathrm{C}$  . The charge stored on each capacitor is  $600\\;\\mu\\mathrm{C}⁄3=200\\;\\mu\\mathrm{C}$  . ", "page_idx": 31, "bbox": [189, 215.72288513183594, 504, 261], "page_size": [612.0, 792.0]}
{"layout": 185, "type": "text", "text": "Stepback Question : What are the physics principles behind this question? Principles : ", "page_idx": 31, "bbox": [189, 259.55889892578125, 489.16033935546875, 283.4792175292969], "page_size": [612.0, 792.0]}
{"layout": 186, "type": "text", "text": "Capacitors:   ${\\mathrm{Q}}={\\mathrm{C}}^{*}{\\mathrm{V}},$   where  $\\mathrm{\\DeltaQ}$   is the charge,  $\\mathbf{C}$   is the capacitance and  $\\mathrm{v}$   is the voltage. ", "page_idx": 31, "bbox": [189, 281.8355407714844, 504, 304.79949951171875], "page_size": [612.0, 792.0]}
{"layout": 187, "type": "text", "text": "Capacitors in series:   $\\mathbf{C}={1}\\mathbf{\\Omega}/$     $\\mathrm{(1/C1\\,+\\,1/C2\\,+\\,...~+\\,1/C n)}$  , where   $\\mathbf{C}$   is the equivalent capacitance and C1, C2, Cn are the capacitance s of each capacitor. Capacitor in parallel:   $\\mathsf{C}=\\mathsf{C}\\mathrm{1}+\\mathsf{C}\\mathrm{2}+\\ldots\\mathrm{~+~}\\mathsf{C}\\mathrm{n}$  , where   $\\mathbf{C}$   is the equivalent capacitance and C1, C2, Cn are the capacitance s of each capacitor. ", "page_idx": 31, "bbox": [189, 303.7535705566406, 504, 348.6344909667969], "page_size": [612.0, 792.0]}
{"layout": 188, "type": "text", "text": "Final Answer : Using the Principles of Capacitance and Capacitors in series, ", "page_idx": 31, "bbox": [189, 347.22991943359375, 504, 360.1912536621094], "page_size": [612.0, 792.0]}
{"layout": 189, "type": "text", "text": "", "page_idx": 31, "bbox": [190, 366.25, 450, 375.75], "page_size": [612.0, 792.0]}
{"layout": 190, "type": "text", "text": "", "page_idx": 31, "bbox": [190, 376.25, 503, 385.75], "page_size": [612.0, 792.0]}
{"layout": 191, "type": "text", "text": "stored on the capacitor is  $600\\;\\mu\\mathrm{C}$  . Using the formula for capacitance, we can find the voltage of the battery: ", "page_idx": 31, "bbox": [189, 391.424560546875, 504, 414.38848876953125], "page_size": [612.0, 792.0]}
{"layout": 192, "type": "equation", "text": "\n$$\n\\begin{array}{l}{\\mathbf{C}=\\mathbf{Q}\\,,\\,\\mathbf{V}}\\\\ {2\\,\\mu\\mathrm{F}=600\\,\\mu\\mathbf{C}\\,,\\,\\mathbf{V}}\\\\ {\\mathbf{V}=300\\,\\mathbf{V}}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 31, "bbox": [187, 412.25, 267, 448], "page_size": [612.0, 792.0]}
{"layout": 193, "type": "text", "text": "Step 2: Apply Capacitors in series to find out the equivalent capacitance of the three  $18\\;\\mu\\mathrm{F}$   capacitors in series. ", "page_idx": 31, "bbox": [189, 457.17755126953125, 504, 480.1415100097656], "page_size": [612.0, 792.0]}
{"layout": 194, "type": "text", "text": "We know that the capacitance of each of the three capacitors is   $18\\;\\mu\\mathrm{F}.$  . Using the formula for capacitors in series, we can find the equivalent capacitance of the three capacitors: ", "page_idx": 31, "bbox": [189, 479, 504, 513.0184936523438], "page_size": [612.0, 792.0]}
{"layout": 195, "type": "equation", "text": "\n$$\n\\begin{array}{l}{1\\:/\\:C_{e q}=1\\:/\\:C_{1}+1\\:/\\:C_{2}+1\\:/\\:C_{3}}\\\\ {1\\:/\\:C_{e q}=1\\:/\\:18\\:\\mu\\mathrm{F}+1\\:/\\:18\\:\\mu\\mathrm{F}+1\\:/\\:18\\:\\mu\\mathrm{F}}\\\\ {1\\:/\\:C_{e q}=3\\:/\\:18\\:\\mu\\mathrm{F}}\\\\ {C_{e q}=6\\:\\mu\\mathrm{F}}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 31, "bbox": [187, 511.25, 362, 559], "page_size": [612.0, 792.0]}
{"layout": 196, "type": "text", "text": "Step 3: Apply Capacitance to find out the charge stored on each capac- itor. ", "page_idx": 31, "bbox": [189, 566.7665405273438, 504, 589.7305297851562], "page_size": [612.0, 792.0]}
{"layout": 197, "type": "text", "text": "We know that the equivalent capacitance of the three capacitors is  $6\\:\\mu\\mathrm{F}$   and the voltage of the battery is  $300\\;\\mathrm{V}.$   Using the formula for capacitance, we can find the charge stored on each capacitor: ", "page_idx": 31, "bbox": [189, 588.6845703125, 504, 622.6074829101562], "page_size": [612.0, 792.0]}
{"layout": 198, "type": "text", "text": " ${\\bf C}={\\bf Q}\\,/\\,{\\bar{\\bf V}}$   $6\\:\\mu\\mathrm{F}=\\mathrm{Q}\\:/\\:300\\:\\mathrm{V}$   $\\mathsf{Q}=1800\\,\\mu\\mathsf{C}$  ", "page_idx": 31, "bbox": [189, 621, 262, 655], "page_size": [612.0, 792.0]}
{"layout": 199, "type": "text", "text": "Therefore, the charge stored on each capacitor is   $1800\\ \\mu\\mathbf{C}$  . The correct answer is 3)   $1800\\;\\mu\\mathbf{C}$  . ", "page_idx": 31, "bbox": [189, 665, 504, 688.3604736328125], "page_size": [612.0, 792.0]}
{"layout": 200, "type": "text", "text": "Table 27: Illustration of wins of S TEP -B ACK  P ROMPTING  on the MMLU-Physics dataset. ", "page_idx": 31, "bbox": [125.6729965209961, 699.79052734375, 486.0187072753906, 711.7954711914062], "page_size": [612.0, 792.0]}
{"layout": 201, "type": "table", "page_idx": 32, "img_path": "layout_images/STEPBACK_31.jpg", "bbox": [138, 155, 506, 389], "page_size": [612.0, 792.0], "ocr_text": "example\n\nistry\n\nOriginal Question: Which of the following indicates that a reaction is\nspontaneous?\n\n0) at equilibrium there are more products than reactants\n\n1) the value of AG® is greater than zero\n\n2) the value of AS° is greater than zero\n\n3) the value of Keq is less than one\n\nOriginal Answer [Incorrect]: 2) the value of AS° is greater than zero.\n\nA reaction is spontaneous if the value of AS° is greater than zero. This is\nbecause a positive AS° indicates that the reaction results in an increase in\nentropy, which is a measure of disorder. A spontaneous reaction is one that\noccurs without the input of energy, and an increase in entropy is a natural\ntendency of the universe.\n\nStepback Question: What are the chemistry principles behind this question?\nPrinciples:\n\nSpontaneous reactions: A spontaneous reaction is a reaction that occurs without\nthe input of energy.\n\nFinal Answer: A reaction is spontaneous if the change in Gibbs free energy is\nnegative (AG < 0). The value of AG® is greater than zero indicates that the\nreaction is not spontaneous.\n", "vlm_text": "The table includes an example related to chemistry concepts focusing on spontaneous reactions. \n\n- **Original Question**: The question asks which condition indicates a reaction is spontaneous, with four options provided.\n- **Original Answer [Incorrect]**: An incorrect answer is noted, suggesting a reaction is spontaneous if the change in entropy (\\(\\Delta S^\\circ\\)) is greater than zero. This explanation is followed by reasoning that a positive change in entropy implies increased disorder, which is a natural tendency, but it incorrectly associates this solely with spontaneity.\n- **Stepback Question**: A prompt for deeper analysis, asking about the key chemistry principles relevant to the question.\n- **Principles**: It notes that spontaneous reactions are defined as reactions that occur without energy input.\n- **Final Answer**: Corrects the misconception by explaining that a reaction is spontaneous if the change in Gibbs free energy (\\(\\Delta G\\)) is negative (\\(\\Delta G < 0\\)). It clarifies that a positive value of \\(\\Delta G^\\circ\\) indicates the reaction is not spontaneous."}
{"layout": 202, "type": "text", "text": "The correct answer is 0) at equilibrium there are more products than reactants. ", "page_idx": 32, "bbox": [190, 388.9235534667969, 504, 400.9284973144531], "page_size": [612.0, 792.0]}
{"layout": 203, "type": "text", "text": "Original Question : Potassium-40 is a minor isotope found in naturally oc- curring potassium. It is radioactive and can be detected on simple radiation counters. How many protons, neutrons, and electrons does potassium-40 have when it is part of K2SO4? 0) 21 neutrons, 19 protons, 18 electrons 1) 20 neutrons, 19 protons, 19 electrons 2) 21 neutrons, 19 protons, 19 electrons 3) 19 neutrons, 19 protons, 19 electrons Original Answer [Incorrect] :  The correct answer is 2). Potassium-40 has 19 protons and 21 neutrons. When it is part of K2SO4, it has 19 electrons. Stepback Question : What are the chemistry principles behind this question? Principles : Atomic number: The atomic number of an element is the number of protons in the nucleus of an atom of that element. Final Answer : The atomic number of potassium is 19, so all potassium atoms have 19 protons. The mass number of potassium-40 is 40, so it has  $40\\textrm{-}19=$  21 neutrons. When potassium is part of a compound, it loses one electron to become a potassium ion. Therefore, potassium-40 has   $19\\textrm{-}1=18$   electrons when it is part of K2SO4. The correct answer is 0) 21 neutrons, 19 protons, 18 electrons. ", "page_idx": 32, "bbox": [190, 404.5259094238281, 504, 636.0675048828125], "page_size": [612.0, 792.0]}
{"layout": 204, "type": "table", "page_idx": 33, "img_path": "layout_images/STEPBACK_32.jpg", "table_footnote": "Table 29: Illustration of wins of S TEP -B ACK  P ROMPTING  on the TimeQA dataset. ", "bbox": [107, 251, 510, 558], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nexample\n\nTimeQA\n\nOriginal Question: Carlos Ascues played for which team from 2013 to\n2014?\n\nOriginal Answer [Incorrect]: Carlos Ascues played for Benfica from\n2013 to 2014.\n\nStepback Question: Which teams did Carlos Ascues play for?\n\nFinal Answer [Correct]: From 2013 to 2014, Carlos Ascues played for\nthe Greek team Panetolikos.\n\nTimeQA\n\nOriginal Question: Seth Nana Twumasi played for which team between\nJan 2011 and Feb 2011?\n\nOriginal Answer [Incorrect]: Seth Nana Twumasi played for the FC\nHonka team between Jan 2011 and Feb 2011.\n\nStepback Question: Which teams did Seth Nana Twumasi play for?\nFinal Answer [Correct]: Northampton. He was on a loan transfer from\nPeterborough.\n\nTimeQA\n\nOriginal Question: What position did Carmel Hanna take in May 2002?\nOriginal Answer [Incorrect]: According to the article, Carmel Hanna\nwas appointed as Minister of State for Children and the Family in May\n2002. She held this position until 2005.\n\nStepback Question: What positions did Carmel Hanna hold?\n\nFinal Answer [Correct]: From the context, we can see that Carmel\nHanna was named minister of Employment and Learning (2001). We\ncan then infer that she held the position of Minister for Employment and\nLearning in May 2002.\n\n", "vlm_text": "The table contains examples from the TimeQA dataset. Each example includes:\n\n- **Original Question:** A question related to a specific fact or event.\n- **Original Answer [Incorrect]:** An incorrect answer provided initially.\n- **Stepback Question:** A follow-up question to reconsider the context.\n- **Final Answer [Correct]:** The correct answer established after clarification.\n\nAdditionally, some text is highlighted in red to indicate incorrect information."}
{"layout": 205, "type": "table", "page_idx": 34, "img_path": "layout_images/STEPBACK_33.jpg", "table_footnote": "Table 30: Illustration of wins of S TEP -B ACK  P ROMPTING  on the SituatedQA dataset. ", "bbox": [105, 218, 510, 591], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nexample\n\nSituatedQA\n\nOriginal Question: when was the last time miss texas won miss america\nas of November 29, 2010\n\nOriginal Answer [Incorrect]: Laura Leigh Covington was the last Miss\nTexas to win the Miss America competition. This happened in 2000.\nStepback Question: which years did miss texas win miss america\nFinal Answer [Correct]: According to Wikipedia, the last time Miss\nTexas won Miss America was in 1975.\n\nSituatedQA\n\nOriginal Question: when is the last time congress passed a complete\nbudget as of 2021\n\nOriginal Answer [Incorrect]: The last time Congress passed a complete\nbudget as of 2021 was on January 19, 2018.\n\nStepback Question: what are the years that congress passed a complete\nbudget as of 2021\n\nFinal Answer [Correct]: The last time Congress passed a complete bud-\nget as of 2021 was December 27, 2020, the Consolidated Appropriations\nAct, 2021.\n\nSituatedQA\n\nOriginal Question: when was the last time unc did not make the ncaa\ntournament as of 2003\n\nOriginal Answer [Incorrect]: The last time UNC did not make the\nNCAA tournament was 1990.\n\nStepback Question: which years did unc not make the ncaa tournament\nas of 2003\n\nFinal Answer [Correct]: The correct answer is 2002-03. The context\nshows the standings of North Carolina Tar Heels men’s basketball. From\nthe standings, we can see that this team has 19 wins and 16 losses. 19-16\nis not good enough to make the NCAA tournament, which is mentioned\nin the context. From the standings, we can also see that this is the\nstanding for 2002-03 season. So the last time UNC did not make the\nNCAA tournament as of 2003 is 2002-03.\n\n", "vlm_text": "The table contains examples from the \"SituatedQA\" dataset. Each example includes:\n\n1. **Original Question**: The initial question posed.\n2. **Original Answer [Incorrect]**: An incorrect response to the question.\n3. **Stepback Question**: A follow-up question meant to refine the context of the original question.\n4. **Final Answer [Correct]**: The correct and refined answer based on the additional context.\n\nEach example illustrates the process of correcting an initial incorrect answer by revisiting the context through a stepback question, leading to a correct final answer."}
{"layout": 206, "type": "table", "page_idx": 35, "img_path": "layout_images/STEPBACK_34.jpg", "table_caption": "Table 31: Illustration of wins of S TEP -B ACK  P ROMPTING  on the StrategyQA dataset. ", "bbox": [105, 211, 511, 596], "page_size": [612.0, 792.0], "ocr_text": "dataset\n\nexample\n\nStrategyQA\n\nOriginal Question: Could you drive a Rowe 550 to the 2008 Summer\nOlympics?\n\nOriginal Answer [Incorrect]: The 2008 Summer Olympics was held in\nBeijing, China. The Rowe 550 is an all-electric car. The Rowe 550 has a\nrange of 70 miles on a single charge and a top speed of about 30 mph.\nThe distance between Beijing and the U.K. is about 4000 miles.\nStepback Question: What kind of vehicle is a Rowe 550?\n\nFinal Answer [Correct]: The Roewe 550 was released in 2008; the\n2008 Summer Olympics were held from August 8-24, 2008. So you\ncould drive a Rowe 550 to the 2008 Summer Olympics.\n\nStrategyQA\n\nOriginal Question: what channel does thursday night football come on\nregular tv as of 2017?\n\nOriginal Answer [Incorrect]: Thursday Night Football is a weekly\nseries of National Football League (NFL) games broadcast on Thursday\nnights. It started in 2006 on NFL Network. Under a new agreement\nbetween the NFL and CBS, CBS will air 50% of the Thursday Night\nFootball games and NFL Network will air the other 50%.\n\nStepback Question: which channel is thursday night football on as of\n2017?\n\nFinal Answer [Correct]: In 2017, Thursday Night Football was aired\non CBS, NBC, and NFL Network.\n\nStrategyQA\n\nOriginal Question: who is the present president of assam sahitya sabha\nas of 2018?\n\nOriginal Answer [Incorrect]: Dr. Nagen Saikia\n\nStepback Question: who lead assam sahitya sabha as of 2018?\n\nFinal Answer [Correct]: The answer is Paramananda Rajbongshi. As\nper a news from 2019, The Asam Sahitya Sabha, which was established\nin 1917, in Sibsagar, Assam, had got Paramananda Rajbongshi as its\npresident. So, as of 2018, the president of assam sahitya sabha is Para-\nmananda Rajbongshi.\n", "vlm_text": "The table presents examples from the StrategyQA dataset. Each example includes:\n\n1. **Original Question**: The question initially posed.\n2. **Original Answer [Incorrect]**: An incorrect answer to the original question, with elaboration.\n3. **Stepback Question**: A clarifying question to better understand the context or requirement.\n4. **Final Answer [Correct]**: The correct answer provided after reevaluation.\n\nThe examples cover various topics, such as the feasibility of driving a specific car to the Olympics, televised sports programming, and leadership positions."}
