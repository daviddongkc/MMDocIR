{"layout": 0, "type": "text", "text": "GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media ", "text_level": 1, "page_idx": 0, "bbox": [133, 67, 465, 101], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 1, "type": "text", "text": "Yi-Ju Lu Department of Statistics National Cheng Kung University Tainan, Taiwan l852888@gmail.com ", "page_idx": 0, "bbox": [121.80799865722656, 119.2330322265625, 279.544921875, 189.3344268798828], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 2, "type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0, "bbox": [158, 223, 205, 236], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 3, "type": "text", "text": "This paper solves the fake news detection prob- lem under a more realistic scenario on so- cial media. Given the source short-text tweet and the corresponding sequence of retweet users without text comments, we aim at pre- dicting whether the source tweet is fake or not, and generating explanation by highlight- ing the evidences on suspicious retweeters and the words they concern. We develop a novel neural network-based model, Graph-aware Co- Attention Networks (GCAN), to achieve the goal. Extensive experiments conducted on real tweet datasets exhibit that GCAN can signiﬁ- cantly outperform state-of-the-art methods by  $16\\%$   in accuracy on average. In addition, the case studies also show that GCAN can produce reasonable explanations. ", "page_idx": 0, "bbox": [87, 246.37762451171875, 274, 449.66552734375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 4, "type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0, "bbox": [72, 460, 155, 473], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 5, "type": "text", "text": "Social media is indispensable in people’s daily life, where users can express themselves, access news, and interact with each other. Information can fur- ther spread through the social network. Opinions and sentiments on source stories can be reﬂected by user participation and interaction. The conve- nient and low-cost essence of social networking brings collective intelligence, but at the same time leads to a negative by-product, the propagation of misinformation such as  fake news . ", "page_idx": 0, "bbox": [71, 481.864990234375, 292, 616.9534301757812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 6, "type": "text", "text": "Fake news is a kind of news story possess- ing intentionally false information on social me- dia ( Rashkin et al. ,  2017 ;  Allcott and Gentzkow , 2017 ). The widespread of fake news can mislead the public, and produce unjust political, economic, or psychological proﬁt for some parties ( Horne and Adali ,  2017 ;  Allcott and Gentzkow ,  2017 ). Data mining and machine learning techniques were uti- lized to detect fake news ( Shu et al. ,  2017 ;  Cha et al. ,  2020 ). Typical approaches rely on the con- tent of new articles to extract textual features, such ", "page_idx": 0, "bbox": [71, 617.3939819335938, 292, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 7, "type": "text", "text": "Cheng-Te Li Institute of Data Science National Cheng Kung University Tainan, Taiwan chengte@mail.ncku.edu.tw", "page_idx": 0, "bbox": [312.2850341796875, 119.2330322265625, 484.4400634765625, 189.3344268798828], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 8, "type": "text", "text": "as n-gram and bag of words, and apply supervised learning (e.g., random forest and support vector ma- chine) for binary classiﬁcation ( Shu et al. ,  2017 ). NLP researchers also learn advanced linguistic fea- tures, such as factive/assertive verbs and subjec- tivity ( Popat ,  2017 ) and writing styles and consis- tency ( Potthast et al. ,  2018 ). Multi-modal context information is also investigated, such as user pro- ﬁles ( Yang et al. ,  2012 ;  Liu and Wu ,  2018 ) and retweet propagation ( Ruchansky et al. ,  2017 ;  Shu et al. ,  2019a ). ", "page_idx": 0, "bbox": [306, 223.4199981689453, 527, 372.0574645996094], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 9, "type": "text", "text": "Nevertheless, there are still critical challenges in detecting fake news online. First, existing content- based approaches ( Castillo et al. ,  2011 ;  Potthast et al. ,  2018 ;  Shu et al. ,  2019a ) require documents to be  long  text, e.g., news articles, so that the rep- resentation of words and sentences can be better learned. However, tweets on social media are usu- ally  short  text ( Yan et al. ,  2015 ), which produces severe data sparsity problem. Second, some state- of-the-art models ( Ruchansky et al. ,  2017 ;  Liu and Wu ,  2018 ;  Shu et al. ,  2019a ) require a rich collec- tion of  user comments  for every news story, to learn the opinions of retweeters, which usually provide strong evidences in identifying fake news. How- ever, most users on social media tend to simply reshare the source story without leaving any com- ments ( Kwak et al. ,  2010 ). Third, some studies ( Ma et al. ,  2018 ) consider that the pathways of informa- tion cascade (i.e., retweets) in the social network are useful for classifying misinformation, and thus learn the representations of the tree-based propa- gation structures. However, it is costly to obtain the diffusion structure of retweets at most times due to privacy concerns ( Li et al. ,  2018 ). Many users choose to hide or delete the records of social interactions. Fourth, if the service providers or the government agencies desire to inspect who are the suspicious users who support the fake news, and which topics do they concern in producing fake news ( Reis et al. ,  2019 ), existing models cannot provide explanations. Although dEFEND ( Shu et al. ,  2019a ) can generate reasonable explanation, it requires both long text of source articles and text of user comments. ", "page_idx": 0, "bbox": [306, 373.50799560546875, 527, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 10, "type": "text", "text": "", "page_idx": 1, "bbox": [71, 63.68701934814453, 292, 131.02944946289062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 11, "type": "text", "text": "This paper deals with fake news detection un- der a more realistic scenario on social media. We predict whether a source tweet story is fake, given only its  short text  content and its  retweet sequence of users , along with  user proﬁles . That said, we detect fake news under three settings: (a) short-text source tweet, (b) no text of user comments, and (c) no network structures of social network and diffu- sion network. Moreover, we require the fake news detection model to be capable of  explainability , i.e., highlighting the evidence when determining a story is fake. The model is expected to point out the suspicious retweeters who support the spreading of fake news, and highlight the words they especially pay attention to from the source tweet. ", "page_idx": 1, "bbox": [71, 132.81300354003906, 292, 335.6474609375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 12, "type": "text", "text": "To achieve the goal, we propose a novel model, G raph-aware  C o- A ttention  N etwork ( GCAN )   1 . We ﬁrst extract user features from their proﬁles and social interactions, and learn word embed- dings from the source short text. Then we use convolutional and recurrent neural networks to learn the  representation of retweet propagation based on user features. A graph is constructed to model the potential interactions between users, and the graph convolution network is used to learn the  graph-aware representation of user interac- tions . We develop a  dual co-attention mechanism to learn the correlation between the source tweet and retweet propagation, and the co-inﬂuence be- tween the source tweet and user interaction. The binary prediction is generated based on the learned embeddings. ", "page_idx": 1, "bbox": [71, 337.4309997558594, 292, 567.3644409179688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 13, "type": "text", "text": "We summarize the contributions as follows. (1) We study a novel and more realistic scenario of fake news detection on social media. (2) For accu- rate detection, we develop a new model, GCAN, to better learn the representations of user interac- tions, retweet propagation, and their correlation with source short text. (3) Our dual co-attention mechanism can produce reasonable explanations. (4) Extensive experiments on real datasets demon- strate the promising performance of GCAN, com- paring to state-of-the-art models. The GCAN ex- plainability is also exhibited in case studies. ", "page_idx": 1, "bbox": [71, 569.1480102539062, 292, 731.33447265625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 14, "type": "text", "text": "We organize this paper as follows. Section  2 reviews the relevant approaches to fake news detec- tion in social media. We describe the problem state- ment in Section  3 . Then in Section  4 , the details of our proposed GCAN model will be elaborated. Section  5  demonstrates the evaluation settings and results. We conclude this work in Section  6 . ", "page_idx": 1, "bbox": [306, 63.68701934814453, 527, 158.12844848632812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 15, "type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1, "bbox": [307, 171, 397, 184], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 16, "type": "text", "text": "Content-based  approaches rely on the text content to detect the truthfulness of news articles, which usually refer to long text. A variety of text char- acteristics are investigated for supervised learn- ing, including TF-IDF and topic features ( Castillo et al. ,  2011 ), language styles (e.g., part of speech, factive/assertive verbs, and subjectivity) ( Popat , 2017 ), writing styles and consistency ( Potthast et al. ,  2018 ), and social emotions ( Guo et al. ,  2019 ). Zhao et al.  ( 2015 ) ﬁnd the enquiry phrases from user responses are useful, and  Ma et al.  ( 2016 ) use recurrent neural networks to learn better represen- tations of user responses. ", "page_idx": 1, "bbox": [306, 195.03526306152344, 527, 371.1634826660156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 17, "type": "text", "text": "User-based  approaches model the traits of users who retweet the source story.  Yang et al.  ( 2012 ) ex- tract account-based features, such as “is veriﬁed”, gender, hometown, and number of followers.  Shu et al.  ( 2019b ) unveil user proﬁles between fake and real news are signiﬁcantly different. CRNN ( Liu and Wu ,  2018 ) devise a joint recurrent and convo- lutional network model (CRNN) to better represent retweeter’s proﬁles. Session-based heterogeneous graph embedding ( Jiang et al. ,  2018 ) is proposed to learn the traits of users so that they can be identiﬁed in shared accounts. However, since such a method relies on session information, it cannot be directly applied for fake news detection. ", "page_idx": 1, "bbox": [306, 372.145263671875, 527, 561.8224487304688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 18, "type": "text", "text": "Structure-based  approaches leverage the propa- gation structure in the social network to detect fake news.  Sampson et al.  ( 2016 ) leverage the implicit information, i.e., hashtags and URLs, to connect conversations whose users do not have social links, and ﬁnd such implicit info can improve the perfor- mance of rumor classiﬁcation.  Ma et al.  ( 2017 ) cre- ate a kernel-based method that captures high-order patterns differentiating different types of rumors. Ma et al.  ( 2018 ) develop a tree-structured recursive neural networks to learn the embedding of rumor propagation structure. Although multi-relational graph embedding methods ( Feng et al. ,  2019 ;  Wang and Li ,  2019 ) are able to effectively learn how dif- ferent types of entities (related to source news ar- Table 1: Comparison of related studies. Column nota- tions: news story texts (NS), response comments (RC), user characteristics (UC), propagation structure (PS), social network (SN), and model explainability (ME). For the NS column, “S” and “L” indicates short and long text, respectively. ", "page_idx": 1, "bbox": [306, 562.8042602539062, 527, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 19, "type": "text", "text": "", "page_idx": 2, "bbox": [70, 61.9715576171875, 292, 133.75254821777344], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 20, "type": "table", "page_idx": 2, "img_path": "layout_images/2020.acl-main.48_0.jpg", "bbox": [69, 141, 293, 222], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "NS RC UC PS SN ME\nMaet al. (2016) v(S) Vv\nMaet al. (2018) v(S) v veoev\nLiu and Wu (2018) v(S) vv\nRuchansky et al. (2017) V(S) v v\nShu et al. (2019a) VL) Vv v v\nOur work v(S) Vv Vv v\n\n", "vlm_text": "The table compares different studies or works based on several criteria labeled as NS, RC, UC, PS, SN, and ME. Here's a breakdown of the table:\n\n- **NS:** All studies, including \"Our work,\" have a checkmark. Some also specify \"(S)\" next to the checkmark.\n- **RC:** All studies have \"(S)\" next to the checkmark, except Shu et al. (2019a), which has \"(L).\"\n- **UC, PS, SN, ME:** These columns show varying checkmarks and blanks across the studies.\n  - *UC:* Some studies, including \"Our work,\" are marked.\n  - *PS, SN, ME:* Only \"Our work\" is marked in all these categories.\n\nThe specific meanings of NS, RC, UC, PS, SN, and ME aren't provided in the table."}
{"layout": 21, "type": "text", "text": "ticles) interact with each other in a heterogeneous information network for classiﬁcation tasks, they cannot be applied for the inductive setting, i.e., de- tecting the truthfulness of new-coming tweets. ", "page_idx": 2, "bbox": [70, 242.9049835205078, 292, 296.6984558105469], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 22, "type": "text", "text": "Hybrid-based  approaches consider and fuse multi-modal context information regarding the source tweets. CSI ( Ruchansky et al. ,  2017 ) learns the sequential retweet features by incorporating response text and user proﬁles, and generates sus- picious scores of users based on their social inter- actions.  Wang et al.  ( 2018 ) develop an event adver- sarial neural network to learn transferable features by removing the event-speciﬁc features, along with convolutional neural networks to extract textual and visual features. dEFEND ( Shu et al. ,  2019a ) jointly learns the sequential effect of response com- ments and the correlation between news content and comments, and use an attention mechanism to provide explainability. ", "page_idx": 2, "bbox": [70, 297.2922668457031, 292, 500.51947021484375], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 23, "type": "text", "text": "We compare our work and the most relevant stud- ies in Table  1 . The uniqueness of our work lies in: targeting at short text, requiring no user response comments, and allow model explainability. ", "page_idx": 2, "bbox": [70, 501.5060119628906, 292, 555.2984619140625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 24, "type": "text", "text": "3 Problem Statement ", "text_level": 1, "page_idx": 2, "bbox": [71, 567, 189, 581], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 25, "type": "text", "text": "Let    $\\Psi\\,=\\,\\bigl\\{s_{1},s_{2}...s_{|\\Psi|}\\bigr\\}$   be a set of tweet stories, and    $U\\,=\\,\\{u_{1},u_{2}...u_{|U|}\\}$   be a set of users. Each  $s_{i}\\,\\in\\,\\Psi$   is a short-text d the source tweet ), given by  $s_{i}\\;=\\;\\{q_{1}^{i},q_{2}^{i},...,q_{l_{i}}^{i}\\}$   in- dicating    $l_{i}$   words in story    $s_{i}$  .  $u_{j}\\ \\in\\ U$   is associated with a user vec r  $\\mathbf{x}_{j}\\in\\mathbb{R}^{d}$   ∈   represent- ing the user feature with  d  dimensions. When a news story  $s_{i}$   is posted, some users will share  $s_{i}$   and generate a sequence of retweet records, which is termed a  propagation path . Given a news story    $s_{i}$  , we denote its propagation path as  $R_{i}\\,=\\,\\{...,(u_{j},\\mathbf{x}_{j},t_{j}),...\\}$  , where    $(u_{j},\\mathbf{x}_{j},t_{j})$   de- picts    $j$  -th user    $u_{j}$   (with their feature vector    $\\mathbf{x}_{j}$  ) ", "page_idx": 2, "bbox": [70, 590, 292, 767.6674194335938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 26, "type": "image", "page_idx": 2, "img_path": "layout_images/2020.acl-main.48_1.jpg", "img_caption": "Figure 1: The architecture of our GCAN model. ", "bbox": [307, 61, 527, 272], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "§: prediction\n\nf: concatenate\nSource-Interaction\nCo-Attention\n\nSource-Propagation\nCo-Attention\n\n§,: product\n\n2! product\n\nsoftmax\n\nPooling\n\nGraph-aware Source Tweet CNN-based Propagation GRU-based Propagation\nRepresentation Encoding Representation Representation\n\ns4£3%2- 3\n\n", "vlm_text": "The image is a diagram illustrating the architecture of the GCAN (Graph-based Convolutional Attention Network) model. This model is designed for analyzing and processing information propagation in social networks, such as retweet orders. The architecture comprises several components:\n\n1. **Graph-aware Representation:** This part utilizes Graph Convolutional Networks (GCN) to generate graph-aware representations, denoted as \\( g^1, g^2, \\ldots, g^n \\), and is associated with different nodes in a network, like users or tweets.\n\n2. **Source Tweet Encoding:** This section uses Gated Recurrent Units (GRU) to encode source tweets into sequences represented as \\( s^1, s^2, \\ldots, s^m \\).\n\n3. **CNN-based Propagation Representation:** Here, Convolutional Neural Networks (CNN) are employed to model the propagation representation, resulting in features \\( c^1, c^2, \\ldots, c^t \\).\n\n4. **GRU-based Propagation Representation:** GRUs are also applied to capture a different aspect of propagation representation, leading to \\( h^1, h^2, \\ldots, h^n \\).\n\n5. **Co-Attention Mechanisms:** The model incorporates two co-attention mechanisms:\n   - Source-Interaction Co-Attention\n   - Source-Propagation Co-Attention\n\n6. **Pooling and Concatenation:** The features from the different components are pooled and concatenated into a unified feature vector, \\( f \\).\n\n7. **Fully Connected Layer and Prediction:** The concatenated features undergo processing in a fully connected layer, resulting in the final prediction, denoted as \\( \\hat{y} \\).\n\nThe image shows a flow from inputs, through various encoding and representation layers, towards generating a prediction based on interactions and propagation in a modeled network setup."}
{"layout": 27, "type": "text", "text": "who retweets story    $s_{i}$  , and    $j\\;=\\;1,2,...,K$   (i.e.,  $K=|R_{i}|)$  . We denote the set of users who retweet story    $s_{i}$   as    $U_{i}$  . In    $R_{i}$  , we denote the user who orig- inally shares    $s_{i}$   as    $u_{1}$   at time    $t_{1}$  . For    $j>1$  , user  $u_{j}$   retweets    $s_{i}$   at  $t_{j}$     $(t_{j}>t_{1})$  . Each story    $s_{i}$   is asso- ciated with a binary la  $y_{i}\\in\\{0,1\\}$   to repre nt its truthfulness, where  $y_{i}=0$   indicates story  $s_{i}$   is true, and    $y_{i}=1$   means    $s_{i}$   is fake. ", "page_idx": 2, "bbox": [306, 294.9539794921875, 527, 404.5804748535156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 28, "type": "text", "text": "Given a source tweet    $s_{i}$  , along with the corre- sponding propagation path  $R_{i}$   containing users    $u_{j}$  who retweet    $s_{i}$   as well as their feature vectors    $\\mathbf{x}_{j}$  , our goal is to predict the truthfulness    $y_{i}$   of story    $s_{i}$  , i.e., binary classiﬁcation. In addition, we require our mo l to highlight f rs    $u_{j}\\ \\in\\ U_{i}$   who retweet  $s_{i}$   and few words  $q_{k}^{i}\\in s_{i}$    ∈  that can interpret why    $s_{i}$   is identiﬁed as a true or fake one. ", "page_idx": 2, "bbox": [306, 404.3240051269531, 527, 513.950439453125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 29, "type": "text", "text": "4 The Proposed GCAN Model ", "text_level": 1, "page_idx": 2, "bbox": [306, 526, 471, 540], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 30, "type": "text", "text": "We develop a novel model, Graph-aware Co- Attention Networks (GCAN), to predict fake news based on the source tweet and its propagation-based users. GCAN consists of ﬁve components. The ﬁrst is  user characteristics extraction : creating features to quantify how a user participates in online so- cial networking. The second is  new story encoding : generating the representation of words in the source tweet. The third is  user propagation representation : modeling and representing how the source tweet propagates by users using their extracted character- istics. The fourth is  dual co-attention mechanisms : capturing the correlation between the source tweet and users’ interactions/propagation. The last is making prediction : generating the detection out- come by concatenating all learned representations. ", "page_idx": 2, "bbox": [306, 549.6480102539062, 527, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 31, "type": "text", "text": "4.1 User Characteristics Extraction ", "text_level": 1, "page_idx": 3, "bbox": [70, 64, 245, 76], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 32, "type": "text", "text": "To depict how users participate in social network- ing, we employ their metadata and proﬁles to de- ﬁne the feature vector    $\\mathbf{x}_{j}$   of every user    $u_{j}$  . The extracted features are listed as follows: (1) num- ber of words in a user’s self-description, (2) num- ber of words in    $u_{j}$  ’s screen name, (3) number of users who follows  $u_{j}$  , (4) number of users that  $u_{j}$  is following, (5) number of created stories for    $u_{j}$  , (6) time elapsed after    $u_{j}$  ’s ﬁrst story, (7) whether the  $u_{j}$   account is veriﬁed or not, (8) whether    $u_{j}$  allows the geo-spatial positioning, (9) time differ- ence between the source tweet’s post time and  $u_{j}$  ’s retweet time, and (10) the length of retweet path between  $u_{j}$   and the source tweet (1 if    $u_{j}$   retweets the source tweet). Eventually, every user feature vector  $\\mathbf{x}_{j}\\in\\mathbb{R}^{v}$    is generated, where    $v$   is the number of features. ", "page_idx": 3, "bbox": [70, 81.27002716064453, 291, 311.2034606933594], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 33, "type": "text", "text": "4.2 Source Tweet Encoding ", "text_level": 1, "page_idx": 3, "bbox": [71, 321, 206, 333], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 34, "type": "text", "text": "The given source tweet is represented by a word- level encoder. The input is the one-hot vector of each word in story    $s_{i}$  . Since the length of every source story is different, we perform zero padding here by setting a maximum length    $m$  Let    $\\mathbf{E}\\,=\\,[e_{1},e_{2},...,e_{m}]\\,\\in\\,\\mathbb{R}^{m}$    be the input vec- tor of source story, in which    $e_{m}$   is the one-hot encoding of the    $m$  -th word. We create a fully- connected layer to generate word embeddings,  $\\mathbf{V}=[\\mathbf{v}_{1},\\mathbf{v}_{2},...,\\mathbf{v}_{m}]\\in\\mathbb{R}^{d\\times m}$  , where    $d$   is the di- mensionality of word embeddings. The derivation of    $\\mathbf{V}$   is given by: ", "page_idx": 3, "bbox": [70, 338.2120056152344, 291, 500.3984680175781], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 35, "type": "equation", "text": "\n$$\n{\\bf V}=\\operatorname{tanh}({\\bf W}_{w}{\\bf E}+{\\bf b}_{w})\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [125, 510, 236, 526], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 36, "type": "text", "text": "where    ${\\bf W}_{w}$   is the matrix of learnable weights, and  ${\\bf b}_{c}$   is the bias term. Then, we utilize Gating Recur- rent Units (GRU) ( Chung et al. ,  2014 ) to learn the words sequence representation from    $\\mathbf{V}$  . The source tweet representation learning can be depicted by:  ${\\bf s}_{t}\\,=\\,G R U({\\bf v}_{t})$  ,    $t\\,\\in\\,\\{1,...,m\\}$  , where    $m$   is the GRU dimensionality. We denote the source tweet representation as    $\\mathbf{S}=[\\mathbf{s}^{1},\\mathbf{s}^{2},...,\\mathbf{s}^{m}]\\in\\mathbb{R}^{d\\times m}$  . ", "page_idx": 3, "bbox": [70, 536.5919799804688, 291, 645], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 37, "type": "text", "text": "4.3 User Propagation Representation ", "text_level": 1, "page_idx": 3, "bbox": [71, 655, 252, 667], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 38, "type": "text", "text": "The propagation of source tweet    $s_{i}$   is triggered by a sequence of users as time proceeds. We aim at exploiting the extracted user feature vectors    $\\mathbf{x}_{j}$  , along with the user sequence spreading  $s_{i}$  , to learn user propagation representation. The underlying idea is that the user characteristics in real news propagations are different from those of fake ones. ", "page_idx": 3, "bbox": [70, 671.5910034179688, 291, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 39, "type": "text", "text": "We make use of Gating Recurrent Units (GRU) and Convolutional Neural Network (CNN) to learn propagation representations. ", "page_idx": 3, "bbox": [306, 63.68701934814453, 527, 103.93148803710938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 40, "type": "text", "text": "Here the input is the sequence of feature vec- tors of users retweeting    $s_{i}$  , denoted by    $P F(s_{i})=$   $\\langle\\mathbf{x}_{1},\\mathbf{x}_{2},...,\\mathbf{x}_{t},...,\\mathbf{x}_{n}\\rangle$  , where    $n$   is the ﬁxed length of observed retweets. If the number of users shar- ing  $s_{i}$   is higher than    $n$  , we take the ﬁrst  $n$   users. If the number is lower than    $n$  , we resample users in  $P F(s_{i})$   until its length equals to    $n$  . ", "page_idx": 3, "bbox": [306, 104.47498321533203, 527, 199], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 41, "type": "text", "text": "GRU-based Representation. Given the se- quence of feature vectors    $P F(s_{i})=\\langle...,\\mathbf{x}_{t},...,\\rangle$  , we utilize GRU to learn the propagation represen- tation. Each GRU state has two inputs, the current feature vector    $\\mathbf{x}_{t}$   and the previous state’s output vector  $\\mathbf{h}_{t-1}$  , and one output vector    $\\mathbf{h}_{t}$  . The GRU- based representation learning can be depicted by:  $\\mathbf{h}_{t}=G R U(\\mathbf{x}_{t})$  ,    $t\\in\\{1,...,n\\}$  , where  $n$   is the di- mensionality of GRU. We generate the ﬁnal GRU- based user propagation embedding    $\\mathbf{h}\\in\\mathbb{R}^{d}$    by av- erage pooling, given by  $\\begin{array}{r}{\\mathbf{h}=\\frac{1}{n}\\sum_{t=1}^{\\bar{n}}\\mathbf{h}_{t}}\\end{array}$  . ", "page_idx": 3, "bbox": [306, 199.0673065185547, 527, 349], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 42, "type": "text", "text": "CNN-based Representation. We take ad- vantage of 1-D convolution neural network to learn the sequential correlation of user features in    $P F(s_{i})$  . We consider    $\\lambda$   consecutive users at one time to model their sequential correlation, i.e.,    $\\langle\\mathbf{x}_{t},...,\\mathbf{x}_{t+\\lambda-1}\\rangle$  . Hence the ﬁlter is set as  $\\mathbf{W}_{f}\\in\\mathbb{R}^{\\lambda\\times v}$  the output representation vec- tor  $\\mathbf{C}\\in\\mathbb{R}^{d\\times(t+\\lambda-1)}$    is given by ", "page_idx": 3, "bbox": [306, 348.2492370605469, 527, 456.6314697265625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 43, "type": "equation", "text": "\n$$\n\\mathbf{C}=\\mathrm{ReLU}(\\mathbf{W}_{f}\\cdot\\mathbf{X}_{t:t+\\lambda-1}+b_{f})\n$$\n ", "text_format": "latex", "page_idx": 3, "bbox": [339, 467, 493, 483], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 44, "type": "text", "text": "where    ${\\bf W}_{f}$   is the matrix of learnable parameters,  $R e L U$   is the activation function,  $\\mathbf{X}_{t:t+\\lambda-1}$   depicts sub-matrices whose ﬁrst row’s index is from    $t=1$  to  $t=n-\\lambda+1$  , and    $b_{f}$   is the bias term. ", "page_idx": 3, "bbox": [306, 493, 527, 548.9154663085938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 45, "type": "text", "text": "4.4 Graph-aware Propagation Representation ", "text_level": 1, "page_idx": 3, "bbox": [306, 558, 456, 582], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 46, "type": "text", "text": "We aim at creating a graph to model the poten- tial interaction among users who retweet source story  $s_{i}$  . The idea is that some correlation between users with particular characteristics can reveal the possibility that the source tweet is fake. To ful- ﬁll such an idea, a graph    ${\\mathcal{G}}^{i}\\;=\\;(U_{i},{\\mathcal{E}}_{i})$   is con- structed for the set of users who share source story  $s_{i}$   (i.e.,  $U_{i})$  ), where    $\\mathscr{E}_{i}$   is the corresponding edge set. Since the true interactions between users are un- known, we consider    $\\mathcal{G}^{i}$    is a fully-connected graph, i.e.,    $\\forall e_{\\alpha\\beta}\\in\\mathcal{E}_{i}$  ,    $u_{\\alpha}\\in U_{i},u_{\\beta}\\in U_{i}$  , and    $u_{\\alpha}\\neq u_{\\beta}$  ,  $\\textstyle|{\\mathcal{E}}_{i}|\\;=\\;{\\frac{n\\times(n-1)}{2}}$  . To incorporate user features in the graph, each edge    $e_{\\alpha\\beta}\\in\\mathcal{E}_{i}$   is associated with a weight  $\\omega_{\\alpha\\beta}$  , and the weight is derived based on cosine similarity between user feature vectors  $\\mathbf{x}_{\\alpha}$  and    $\\mathbf{x}_{\\beta}$  , given by    $\\begin{array}{r}{\\omega_{\\alpha\\beta}=\\frac{\\mathbf{x}_{\\alpha}\\cdot\\mathbf{x}_{\\beta}}{\\left\\|\\mathbf{x}_{\\alpha}\\right\\|\\left\\|\\mathbf{x}_{\\beta}\\right\\|}}\\end{array}$  . We use matrix ∥ ∥  $\\mathbf{A}=\\left[\\omega_{\\alpha\\beta}\\right]\\in\\mathbb{R}^{n\\times n}$    to represent weig s between any pair of nodes  $u_{\\alpha}$   and    $u_{\\beta}$   in graph  G  $\\mathcal{G}^{i}$  . ", "page_idx": 3, "bbox": [306, 588.1690063476562, 527, 767.6674194335938], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 47, "type": "text", "text": "", "page_idx": 4, "bbox": [71, 63.68701934814453, 291, 143.49476623535156], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 48, "type": "text", "text": "A graph convolution network (GCN) layer ( Kipf and Welling ,  2017 ) is created based on the con- structed graph    $\\mathcal{G}^{i}$    for source tweet    $s_{i}$  . A GCN is a multi-layer neural network that performs on graph data and generates embedding vectors of nodes according to their neighborhoods. GCN can cap- ture information from a node’s direct and indirect neighbors through stacking layer-wise convolution. Given the matrix  A  for graph    $\\mathcal{G}^{i}$  , and  $\\mathbf{X}$  depicting the matrix of feature vectors for use  $\\mathcal{G}^{i}$   $g$  -dimensional node feature matrix  $\\mathbf{H}^{(l+1)}\\in\\mathbb{R}^{n\\times g}$    ∈ can be derived by ", "page_idx": 4, "bbox": [71, 137.3789825439453, 291, 299.5664367675781], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 49, "type": "equation", "text": "\n$$\n\\mathbf{H}^{(l+1)}=\\rho(\\mathbf{\\tilde{A}}\\mathbf{H}^{(l)}\\mathbf{W}_{l}),\n$$\n ", "text_format": "latex", "page_idx": 4, "bbox": [125, 310, 235, 327], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 50, "type": "text", "text": "where  $l$   is the layer number,    $\\tilde{\\mathbf{A}}=\\mathbf{D}^{-\\frac{1}{2}}\\mathbf{A}\\mathbf{D}^{-\\frac{1}{2}}$   is the normalized symmetric weight matrix   $(\\mathbf{D}_{i i}=$   $\\textstyle\\sum_{j}\\mathbf{A}_{i j})$  ), and    $\\mathbf{W}_{l}\\in\\mathbb{R}^{d\\times g}$   is the matrix o  learn- able parameters at the  l -th GCN layer.  ρ  is an activation function, i.e., a ReLU    $\\rho(x)=\\operatorname*{max}(0,x)$  Here    $\\mathbf{H}^{(0)}$    is set to be    $\\mathbf{X}$  . We choose to stack two GCN layers in derive the learned graph-aware rep- resentation, denoted as  $\\mathbf{G}\\in\\mathbb{R}^{g\\times n}$  . ", "page_idx": 4, "bbox": [71, 339, 291, 450.3434753417969], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 51, "type": "text", "text": "4.5 Dual Co-attention Mechanism ", "text_level": 1, "page_idx": 4, "bbox": [71, 463, 237, 475], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 52, "type": "text", "text": "We think the evidence of fake news can be un- veiled through investigating which parts of the source story are concerned by which kinds of retweet users, and fake clues can be reﬂected by how retweet users interact with each other. There- fore, we develop a  dual co-attention mechanism to model the mutual inﬂuence between the source tweet (i.e.,    $\\mathbf{S}\\;=\\;[\\mathbf{s}^{1},\\mathbf{s}^{2},...,\\mathbf{s}^{m}])$   and user propa- gation embeddings (i.e.,    $\\mathbf{C}=[\\mathbf{c}^{1},\\mathbf{c}^{2},...,\\mathbf{c}^{n-\\lambda+1}]$  from Section  4.3 ), and between the source tweet and graph-aware interaction embeddings (i.e.,    $\\mathbf{G}=$   $[\\mathbf{g}^{1},\\mathbf{g}^{2},...,\\mathbf{g}^{n}]$   from Section  4.4 ). Equipped with co-attention learning, our model is capable of the explainability by looking into the attention weights between retweet users in the propagation and words in the source tweet. In other words, by extend- ing the co-attention formulation ( Lu et al. ,  2016 ), the proposed dual co-attention mechanism aims to attend to the source-tweet words and graph- aware interaction users simultaneously (source- interaction co-attention), and also attend to the source-tweet words and propagated users simul- taneously (source-propagation co-attention). ", "page_idx": 4, "bbox": [71, 481.9020080566406, 291, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 53, "type": "text", "text": "", "page_idx": 4, "bbox": [307, 63.68701934814453, 527, 90.38247680664062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 54, "type": "text", "text": "Source-Interaction   $\\mathbf{Co}$  -attention. We ﬁrst compute a proximity matrix    $\\mathbf{F}\\in\\mathbb{R}^{m\\times n}$    as:    $\\mathbf{F}=$  ta  $\\mathrm{nh}(\\mathbf{S}^{\\top}\\mathbf{W}_{s g}\\mathbf{G})$  , where    $\\mathbf{W}_{s g}$   is a  $d\\times g$   matrix of learnable parameters. By treating the proximity matrix as a feature, we can learn to predict source and interaction attention maps, given by ", "page_idx": 4, "bbox": [307, 90.39329528808594, 527, 171.67745971679688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 55, "type": "equation", "text": "\n$$\n\\begin{array}{r l}&{\\mathbf{H}^{s}=\\operatorname{tanh}(\\mathbf{W}_{s}\\mathbf{S}+(\\mathbf{W}_{g}\\mathbf{G})\\mathbf{F}^{\\top})}\\\\ &{\\mathbf{H}^{g}=\\operatorname{tanh}(\\mathbf{W}_{g}\\mathbf{G}+(\\mathbf{W}_{s}\\mathbf{S})\\mathbf{F})}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 4, "bbox": [340, 178, 491, 214], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 56, "type": "text", "text": "where    $\\mathbf{W}_{s}\\in\\mathbf{R}^{k\\times d}$  ,    $\\mathbf{W}_{g}\\in\\mathbf{R}^{k\\times g}$    are matri s of learnable parameters. The proximity matrix  F  can be thought to transforming user-interaction atten- tion space to source story word attention space, and vice versa for its transpose    $\\mathbf{F}^{\\top}$  . Then we can generate the attention weights of source words and interaction users through the softmax function: ", "page_idx": 4, "bbox": [307, 220.16297912597656, 527, 318.5624694824219], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 57, "type": "equation", "text": "\n$$\n\\begin{array}{r l}&{\\mathbf{a}^{s}=\\operatorname{softmax}(\\mathbf{w}_{h s}^{\\top}\\mathbf{H}^{s})}\\\\ &{\\mathbf{a}^{g}=\\operatorname{softmax}(\\mathbf{w}_{h g}^{\\top}\\mathbf{H}^{g})}\\end{array}\n$$\n ", "text_format": "latex", "page_idx": 4, "bbox": [362, 325, 469, 364], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 58, "type": "text", "text": "where    $\\mathbf{a}^{s}\\,\\in\\,\\mathbb{R}^{1\\times m}$    and    $\\mathbf{a}^{g}\\,\\in\\,\\mathbb{R}^{1\\times n}$    are the vec- tors of attention probabilities for each word in the source story and each user in the interaction graph, respectively.    $\\mathbf{w}_{h s},\\mathbf{w}_{h g}\\,\\in\\,\\mathbb{R}^{1\\times k}$    are learn- able weights. Eventually we can generate the atten- tion vectors of source story words and interaction users through weighted sum using the derived at- tention weights, given by ", "page_idx": 4, "bbox": [307, 368.4609680175781, 527, 480.40948486328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 59, "type": "equation", "text": "\n$$\n\\hat{\\mathbf{s}}_{1}=\\sum_{i=1}^{m}\\mathbf{a}_{i}^{s}\\mathbf{s}^{i}\\;,\\quad\\hat{\\mathbf{g}}=\\sum_{j=1}^{n}\\mathbf{a}_{j}^{g}\\mathbf{g}^{j}\n$$\n ", "text_format": "latex", "page_idx": 4, "bbox": [344, 488, 488, 525], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 60, "type": "text", "text": "where  $\\hat{\\mathbf{s}}_{1}\\in\\mathbb{R}^{1\\times d}$   ∈   and  $\\hat{\\mathbf{g}}\\in\\mathbb{R}^{1\\times g}$   ∈   are the learned co- attention feature vectors that depict how words in the source tweet are attended by users who interact with one another. ", "page_idx": 4, "bbox": [307, 532.1399536132812, 527, 589.8914794921875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 61, "type": "text", "text": "Source-Propagation Co-attention. The pro- cess to generate the co-attention feature vectors,  $\\hat{\\bf s}_{2}\\,\\in\\,\\mathbb{R}^{1\\times d}$   ∈   and    $\\hat{\\textbf{c}}\\in\\mathbb{R}^{1\\times d}$   ∈ , for the source story and user propagation, respectively, is the same as source-interaction co-attention, i.e., creating an- other proximity matrix to transform them into each other’s space. We skip the repeated details due to the page limit. ", "page_idx": 4, "bbox": [307, 589.9022827148438, 527, 698.2854614257812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 62, "type": "text", "text": "Note that the GRU-based user representations are not used to learn the interactions with the source tweet. The reason is that how user proﬁles in the retweet sequence look like is also important, as sug- gested by CRNN ( Liu and Wu ,  2018 ), and should ", "page_idx": 4, "bbox": [307, 698.6890258789062, 527, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 63, "type": "table", "page_idx": 5, "img_path": "layout_images/2020.acl-main.48_2.jpg", "table_caption": "Table 2: Statistics of two Twitter datasets. ", "bbox": [71, 63, 297, 182], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Twitter15 Twitter16\n# source tweets 742 412\n# true 372 205\n# fake 370 207\n# users 190,868 115,036\navg. retweets per story 292.19 308.70\navg. words per source 13.25 12.81\n\n", "vlm_text": "The table presents a comparison of datasets labeled Twitter15 and Twitter16, likely related to studies of tweet veracity. It includes the following data for each dataset:\n\n1. **# source tweets**: \n   - Twitter15: 742\n   - Twitter16: 412\n\n2. **# true** (number of true stories/tweets):\n   - Twitter15: 372\n   - Twitter16: 205\n\n3. **# fake** (number of fake stories/tweets):\n   - Twitter15: 370\n   - Twitter16: 207\n\n4. **# users** (number of users involved):\n   - Twitter15: 190,868\n   - Twitter16: 115,036\n\n5. **avg. retweets per story** (average number of retweets per story):\n   - Twitter15: 292.19\n   - Twitter16: 308.70\n\n6. **avg. words per source** (average number of words per source tweet):\n   - Twitter15: 13.25\n   - Twitter16: 12.81\n\nThis data might be used in the context of analyzing tweet authenticity, user engagement, or tweet characteristics across different datasets."}
{"layout": 64, "type": "text", "text": "be emphasized separately. Nevertheless, the CNN- based user representations (i.e., features that depict the sequence of user proﬁles) has been used in the co-attention mechanism to learn their interactions with source tweet. ", "page_idx": 5, "bbox": [71, 198.64002990722656, 292, 265.9824523925781], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 65, "type": "text", "text": "4.6 Make Prediction ", "text_level": 1, "page_idx": 5, "bbox": [72, 275, 174, 287], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 66, "type": "text", "text": "We aim at predicting fake news using the source- interaction co-attention feature vectors    $\\hat{\\bf s}_{1}$   and    $\\hat{\\bf g}$  , the source-propagation feature vectors    $\\hat{\\bf s}_{2}$   and  ˆ , and the sequential propagation feature vector    $\\mathbf{h}$  Let    $\\mathbf{f}\\,=\\,[\\hat{\\bf s}_{1},\\hat{\\bf g},\\hat{\\bf s}_{2},\\hat{\\bf c},\\mathbf{h}]$   which is then fed into a multi-layer feedforward neural network that ﬁnally predicts the label. We generate the binary predic- tion vector  $\\hat{\\mathbf{y}}=\\left[\\hat{y}_{0},\\hat{y}_{1}\\right]$  , where  $\\hat{y}_{0}$   and  $\\hat{y}_{1}$   indicate the predicted probabilities of label being  0  and  1 , respectively. It can be derived through ", "page_idx": 5, "bbox": [71, 291.97698974609375, 292, 427.0654602050781], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 67, "type": "equation", "text": "\n$$\n\\hat{\\mathbf{y}}=\\mathrm{softmax}(\\mathbf{ReLU}(\\mathbf{f}\\mathbf{W}_{f}+\\mathbf{b}_{f})),\n$$\n ", "text_format": "latex", "page_idx": 5, "bbox": [103, 433, 257, 448], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 68, "type": "text", "text": "where    ${\\bf W}_{f}$   is the matrix of learnable parameters, and  ${\\bf b}_{f}$   is the bias term. The loss function is devised to minimize the cross-entropy value: ", "page_idx": 5, "bbox": [71, 454.1449890136719, 292, 494.38946533203125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 69, "type": "equation", "text": "\n$$\n\\mathcal{L}(\\Theta)=-y\\log(\\hat{y}_{1})-(1-y)\\log(1-\\hat{y}_{0})\n$$\n ", "text_format": "latex", "page_idx": 5, "bbox": [78, 500, 270, 515], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 70, "type": "text", "text": "where    $\\Theta$   denotes all learnable parameters in the entire neural network. We choose the Adam opti- mizer to learn  $\\Theta$   as it can determine the learning rate abortively. ", "page_idx": 5, "bbox": [71, 521.4700317382812, 292, 575.262451171875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 71, "type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5, "bbox": [71, 585, 155, 598], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 72, "type": "text", "text": "We conduct experiments to answer three questions: (1) whether our GCAN model is able to achieve satisfactory performance of fake news detection, compared to state-of-the-art methods? (2) how does each component of GCAN contribute to the performance? (3) can GCAN generate a convincing explanation that highlights why a tweet is fake? ", "page_idx": 5, "bbox": [71, 605.3519897460938, 292, 699.79248046875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 73, "type": "text", "text": "5.1 Datasets and Evaluation Settings ", "text_level": 1, "page_idx": 5, "bbox": [71, 709, 250, 721], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 74, "type": "text", "text": "Data.  Two well-known datasets compiled by  Ma et al.  ( 2017 ), Twitter15 and Twitter16, are uti- lized. Each dataset contains a collection of source tweets, along with their corresponding sequences of retweet users. We choose only “true” and “fake” labels as the ground truth. Since the original data does not contain user proﬁles, we use user IDs to crawl user information via Twitter API. ", "page_idx": 5, "bbox": [71, 725.394287109375, 292, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 75, "type": "text", "text": "", "page_idx": 5, "bbox": [307, 63.68701934814453, 527, 131.02944946289062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 76, "type": "text", "text": "Competing Methods.  We compare our GCAN with the state-of-the-art methods and some base- lines, as listed below. (1)  DTC  ( Castillo et al. , 2011 ): a decision tree-based model combining user proﬁles and the source tweet. (2)  SVM-TS  ( Ma et al. ,  2015 ): a linear support vector machine classi- ﬁer that utilizes the source tweet and the sequence of retweet users’ proﬁles. (3)  mGRU  ( Ma et al. , 2016 ): a modiﬁed gated recurrent unit model for rumor detection, which learns temporal patterns from retweet user proﬁle, along with the source’s features. (4)  RFC  ( Kwon et al. ,  2017 ): an ex- tended random forest model combining features from retweet user proﬁles and the source tweet. (5) CSI  ( Ruchansky et al. ,  2017 ): a state-of-the-art fake news detection model incorporating articles, and the group behavior of users who propagate fake news by using LSTM and calculating the user scores. (6)  tCNN  ( Yang et al. ,  2018 ): a modi- ﬁed convolution neural network that learns the lo- cal variations of user proﬁle sequence, combining with the source tweet features. (7)  CRNN  ( Liu and Wu ,  2018 ): a state-of-the-art joint CNN and RNN model that learns local and global varia- tions of retweet user proﬁles, together with the resource tweet. (8)  dEFEND  ( Shu et al. ,  2019a ): a state-of-the-art co-attention-based fake news detec- tion model that learns the correlation between the source article’s sentences and user proﬁles. ", "page_idx": 5, "bbox": [307, 134.95323181152344, 527, 527.8694458007812], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 77, "type": "text", "text": "Model Conﬁguration.  Our model is termed “ GCAN ”. To examine the effectiveness of our graph-aware representation, we create another ver- sion “ GCAN-G ”, denoting our model without the graph convolution part. For both our models and competing methods, we set the number of train- ing epochs to be 50. The hyperparameter setting of GCAN is: number of retweet users  $=40$  , word embedding  $\\mathrm{dim}=32$  , GRU output   $\\mathrm{dim}=32$  , 1-D CNN output ﬁlter size  $=3$  , 1-D CNN output dim  $=$  32, and GCN output   $\\mathrm{dim}=32$  . The hyperparame- ters of competing methods are set by following the settings mentioned in respective studies. ", "page_idx": 5, "bbox": [307, 531.7932739257812, 527, 707.9214477539062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 78, "type": "text", "text": "Metrics & Settings.  The evaluation metrics in- clude Accuracy, Precision, Recall, and F1. We randomly choose   $70\\%$   data for training and   $30\\%$  for testing. The conducted train-test is repeated 20 ", "page_idx": 5, "bbox": [307, 711.8452758789062, 527, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 79, "type": "table", "page_idx": 6, "img_path": "layout_images/2020.acl-main.48_3.jpg", "table_caption": "Table 3: Main results. The best model and the best competitor are highlighted by  bold  and underline, respectively. ", "table_footnote": "times, and the average values are reported. ", "bbox": [70, 61, 525, 292.75], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Twitter15 Twitter16\n\nMethod Fl Rec Pre Acc Fl Rec Pre Acc\n\nDTC 0.4948 0.4806 0.4963 0.4949 | 0.5616 0.5369 0.5753 0.5612\nSVM-TS 0.5190 0.5186 0.5195 0.5195 | 0.6915 0.6910 0.6928 0.6932\nmGRU 0.5104 0.5148 0.5145 0.5547 | 0.5563 0.5618 0.5603 0.6612\nRFC 0.4642 0.5302 0.5718 0.5385 | 0.6275 0.6587 0.7315 0.6620\ntCNN 0.5140 0.5206 0.5199 0.5881 | 0.6200 0.6262 0.6248 0.7374\nCRNN 0.5249 0.5305 0.5296 0.5919 | 0.6367 0.6433 0.6419 0.7576\nCSI 0.7174 0.6867 0.6991 0.6987 | 0.6304 0.6309 0.6321 0.6612\ndEFEND 0.6541 0.6611 0.6584 0.7383 | 0.6311 0.6384 0.6365 0.7016\nGCAN-G 0.7938 0.7990 0.7959 0.8636 | 0.6754 0.6802 0.6785 0.7939\nGCAN 0.8250 0.8295 0.8257 0.8767 | 0.7593 0.7632 0.7594 0.9084\nImprovement | 15.0% 20.8% 18.1% 18.7% | 19.3% 15.9% 3.8% 19.9%\n\n", "vlm_text": "The table compares performance metrics of different methods on two Twitter datasets, Twitter15 and Twitter16. The metrics include F1 score (F1), Recall (Rec), Precision (Pre), and Accuracy (Acc). Each method is evaluated using these metrics on both datasets. \n\nHere's a breakdown:\n\n### Twitter15\n- **Methods Evaluated**: DTC, SVM-TS, mGRU, RFC, tCNN, CRNN, CSI, dEFEND, GCAN-G, GCAN\n- **Performance Metrics**:\n  - **DTC**: F1=0.4948, Rec=0.4806, Pre=0.4963, Acc=0.4949\n  - **GCAN** achieved the highest values across most metrics (F1=0.8250, Rec=0.8295, Pre=0.8257, Acc=0.8767)\n- **Improvement**:\n  - F1 Increased by 15.0%\n  - Rec Increased by 20.8%\n  - Pre Increased by 18.1%\n  - Acc Increased by 18.7%\n\n### Twitter16\n- **Methods Evaluated**: Same as Twitter15\n- **Performance Metrics**:\n  - **DTC**: F1=0.5616, Rec=0.5369, Pre=0.5753, Acc=0.5612\n  - **GCAN** again demonstrated the highest values (F1=0.7593, Rec=0.7632, Pre=0.7594, Acc=0.9084)\n- **Improvement**:\n  - F1 Increased by 19.3%\n  - Rec Increased by 15.9%\n  - Pre Increased by 3.8%\n  - Acc Increased by 19.9%\n\nThe table indicates that the GCAN method exhibits superior performance over other methods across both datasets, with noticeable improvements in all metrics."}
{"layout": 80, "type": "text", "text": "5.2 Experimental Results ", "text_level": 1, "page_idx": 6, "bbox": [71, 312, 198, 324], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 81, "type": "text", "text": "Main Results.  The main results are shown in Ta- ble  3 . We can clearly ﬁnd that the proposed GCAN signiﬁcantly outperforms the best competing meth- ods over all metrics across two datasets, improving the performance by around   $17\\%$   and   $15\\%$   on aver- age in Twitter15 and Twitter16, respectively. Even without the proposed graph-aware representation, GCAN-G can improve the best competing method by   $14\\%$   and  $3\\%$   on average in Twitter15 and Twit- ter16, respectively. Such promising results prove the effectiveness of GCAN for fake news detec- tion. The results also imply three insights. First, GCAN is better than GCAN-G by   $3.5\\%$   and   $13\\%$  improvement in Twitter15 and Twitter16, respec- tively. This exhibits the usefulness of graph-aware representation. Second, the dual co-attention mech- anism in GCAN is quite powerful, as it clearly out- performs the best non-co-attention state-of-the-art model CSI. Third, while both GCAN-G and dE- FEND are co-attention-based, additional sequential features learned from the retweet user sequence in GCAN-G can signiﬁcantly boost the performance. ", "page_idx": 6, "bbox": [71, 331.08221435546875, 292, 629.1534423828125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 82, "type": "text", "text": "Early Detection.  We further report the perfor- mance (in only Accuracy due to page limit) by varying the number of observed retweet users per source story (from  10  to  50 ), as exhibited in Fig- ure  2  and Figure  3 . It can be apparently found that our GCAN consistently and signiﬁcantly outper- forms the competitors. Even with only ten retweet- ers, GCAN can still achieve   $90\\%$   accuracy. Such results tell GCAN is able to generate accurate early detection of the spreading fake news, which is cru- ", "page_idx": 6, "bbox": [71, 630.55029296875, 292, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 83, "type": "image", "page_idx": 6, "img_path": "layout_images/2020.acl-main.48_4.jpg", "img_caption": "Figure 2: Accuracy by # retweet users in Twitter15. ", "bbox": [311, 293.25, 519, 450], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "1.0\n\n0.9\n\nAccuracy\n° bd\nq ES\n\n0.6\n\n0.5\n\nTwitter15\n\n—@ GCAN —+ dEFEND ->— CRNN\n> GCAN-G —+ CSI\n\n10 20 30 40 50\nNumber of users\n\n", "vlm_text": "The image is a line graph showing the accuracy of different models as a function of the number of retweet users on the Twitter15 dataset. The x-axis represents the number of users, ranging from 10 to 50. The y-axis represents accuracy, ranging from 0.5 to 1.0. The graph compares five different models:\n\n1. GCAN (indicated by blue circles).\n2. GCAN-G (indicated by orange arrows).\n3. dEFEND (indicated by green leftward arrows).\n4. CSI (indicated by red plus signs).\n5. CRNN (indicated by purple triangles pointed to the right).\n\nEach line corresponds to a model and shows how the accuracy changes as the number of users increases. The GCAN model consistently shows the highest accuracy, while the CRNN model shows the lowest accuracy across different user numbers. dEFEND starts with moderately high accuracy but decreases as the number of users increases. CSI initially performs worse than dEFEND but becomes comparable as the number of users increases. GCAN-G shows stability similar to GCAN, maintaining high accuracy."}
{"layout": 84, "type": "image", "page_idx": 6, "img_path": "layout_images/2020.acl-main.48_5.jpg", "img_caption": "Figure 3: Accuracy by # retweet users in Twitter16. ", "bbox": [312, 471, 519, 632], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "1.0\n\n0.9\n\nAccuracy\nSo bd\na ES\n\n0.6\n\n0.5\n\nTwitter16\n\n—@ GCAN —¢+ dEFEND -»— CRNN\n\n10\n\n20 30 40 50\nNumber of users\n\n", "vlm_text": "The image is a line graph depicting the accuracy of different models as a function of the number of retweet users in Twitter16. The x-axis represents the number of users, ranging from 10 to 50, and the y-axis represents accuracy, ranging from 0.5 to 1.0.\n\nThe graph includes five lines, each representing a different model:\n\n1. **GCAN (blue line)** - This model shows high accuracy, remaining consistently above 0.9 across all user counts.\n\n2. **GCAN-G (orange line)** - This model shows an increasing accuracy trend, starting just below 0.7 and rising to nearly 0.8 as the number of users increases.\n\n3. **dEFEND (green line)** - This model starts around 0.75, declines slightly, recovers, and ends near its starting accuracy level.\n\n4. **CSI (red line)** - This model starts with accuracy close to 0.7 but gradually decreases below 0.7 as the number of users increases.\n\n5. **CRNN (purple line)** - This model begins slightly above 0.6 and shows a gradual decline to approximately 0.6 as the number of users increases.\n\nThe graph indicates that GCAN maintains the highest accuracy among the models tested, regardless of the number of users."}
{"layout": 85, "type": "text", "text": "cial when defending misinformation. ", "page_idx": 6, "bbox": [307, 656.593017578125, 468.4687194824219, 669.7384643554688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 86, "type": "text", "text": "Ablation Analysis. We report how each of GCAN component contributes by removing each one from the entire model. Below “ALL” de- notes using all components of GCAN. By remov- ing dual co-attention, GRU-based representation, graph-aware representation, and CNN-based rep- resentation, we have sub-models “-A”, “-R”, “-G”, ", "page_idx": 6, "bbox": [307, 671.1983032226562, 527, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 87, "type": "image", "page_idx": 7, "img_path": "layout_images/2020.acl-main.48_6.jpg", "img_caption": "Figure 4: GCAN ablation analysis in Accuracy. ", "bbox": [72, 63, 289, 217], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Accuracy\n° o S ER\n~N co wo Oo\n\n9\na\n\n0.\n\nuu\n\n0.4\n\n-S-A @-A @-R @-G @-C BALL\n\nTwitter15\n\nTwitter16\n", "vlm_text": "The image is a bar graph displaying the results of a GCAN ablation analysis focused on accuracy. It compares the performance across various configurations tested on two datasets, Twitter15 and Twitter16. The x-axis represents these two datasets, while the y-axis denotes Accuracy, ranging from 0.4 to 1.0.\n\nThe bars represent different configurations, each denoted by a specific color and label:\n- Grey (-S-A)\n- Green (-A)\n- Purple (-R)\n- Yellow (-G)\n- Blue (-C)\n- Pink (ALL)\n\nFor each dataset, the accuracy values of each configuration are plotted as bars of corresponding colors. \"ALL\" consistently shows the highest accuracy for both datasets, while other configurations indicate varying levels of accuracy, with some (like -G and -C) performing better than others (-S-A and -A)."}
{"layout": 88, "type": "image", "page_idx": 7, "img_path": "layout_images/2020.acl-main.48_7.jpg", "bbox": [80, 234, 283, 328], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "kansas ky\ncity\n\nbreaki\ncenter\n\nstrict\n\nng\n\nksdknews rt\nconfirmed\n\nrecord\n\nirrelevant\n\ncriminal\nferguson\n\nTrue news\n", "vlm_text": "This image contains two word clouds. The word cloud on the left is labeled \"Fake news\" and includes words like \"city,\" \"breaking,\" \"kansas,\" \"strict,\" \"center,\" \"ku,\" \"ks,\" and \"ksu,\" with varying font sizes that likely indicate frequency or significance of these words in fake news sources. The word cloud on the right is labeled \"True news\" and features words such as \"confirmed,\" \"irrelevant,\" \"criminal,\" \"ferguson,\" \"ksdknews,\" \"rt,\" and \"record.\" Again, the font size varies to show the prominence of these words in true news sources."}
{"layout": 89, "type": "text", "text": "and “-C”, respectively. Sub-model “-S-A” denotes the one without both source tweet embeddings and dual co-attention. The results are presented in Fig- ure  4 . We can ﬁnd every component indeed plays a signiﬁcant contribution, especially for dual co- attention (“-A”) and the representation learning of user propagation and interactions (“-R” and “- G”). Since the source tweet provides fundamental clues, the accuracy drops signiﬁcantly without it (“-S-A”). ", "page_idx": 7, "bbox": [71, 387.76300048828125, 292, 522.8514404296875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 90, "type": "text", "text": "5.3 GCAN Explainability ", "text_level": 1, "page_idx": 7, "bbox": [70, 532, 198, 545], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 91, "type": "text", "text": "The co-attention weights derived from Section  4.5 attended on source tweet words and retweet users (source-propagation co-attention) allow our GCAN to be capable of explainability. By exhibiting where attention weights distribute, evidential words and users in predicting fake news can be revealed. Note that we do not consider source-interaction co- attention for explainability because user interaction features learned from the constructed graph cannot be intuitively interpretable. ", "page_idx": 7, "bbox": [71, 549.635009765625, 292, 684.7234497070312], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 92, "type": "text", "text": "Explainability on Source Words.  To demon- strate the explainability, we select two source tweets in the test data. One is  fake  (“ breaking: ks patient at risk for ebola: in strict isolation at ku med center in kansas city #kwch12 ”), and the other is  real  (“ conﬁrmed: this is irrelevant. rt @ks- ", "page_idx": 7, "bbox": [71, 684.747314453125, 292, 766.68603515625], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 93, "type": "image", "page_idx": 7, "img_path": "layout_images/2020.acl-main.48_8.jpg", "img_caption": "Figure 6: Visualization of attention weights for user propagations of 3 fake (upper F1-F3) and 3 true source tweets. From left to right is retweet order. Dark colors refer to higher attention weights. ", "bbox": [305, 61, 528, 215], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Rewteet Order\n", "vlm_text": "The image is a visualization of attention weights for user propagations of tweets. It compares three fake tweets (labeled F1, F2, F3) to three true tweets (labeled T1, T2, T3). The x-axis represents the retweet order, while the color intensity indicates the attention weight, with darker colors signifying higher attention weights. The fake tweets are represented in shades of red, while the true tweets are in shades of blue. The visualization aims to show how attention typically varies in the propagation process for fake versus true tweets."}
{"layout": 94, "type": "image", "page_idx": 7, "img_path": "layout_images/2020.acl-main.48_9.jpg", "bbox": [306, 227, 526, 445], "page_size": [595.2760009765625, 841.8900146484375], "ocr_text": "Retweet Propagatio\n\nuid | verified creation descpt.\ntime length | source\n\n14 0 7\n\n15 11\n\n16 0 8 1\nBZ ie} 17 1\n33 13\n\n34 1 20\n\n) highlighted\n\nby attention\nweights on\nfake news\n\nhighlighted\n\\ by attention\nweights on\n\nreal news\n", "vlm_text": "The image contains a visual representation related to the classification of a tweet as fake or real news. It displays a tweet, \"Breaking: huge explosion of an #oil pipeline belonging to @saudi_aramco near sudair, #saudiarabia,\" which is classified as fake news. The key phrases \"Breaking\" and \"pipeline\" are highlighted.\n\nBelow the tweet, there is a table labeled \"Retweet Propagation\" with columns: \"uid\" (user ID), \"verified\", \"creation time\", \"descpt. length\" (description length), and \"path to source.\"\n\nThe table is split into two parts:\n1. The first part (peach background) contains information related to fake news, with IDs 14, 15, and 16, and is highlighted with corresponding attention weights.\n2. The second part (green background) is related to real news, with IDs 32, 33, and 34.\n\nAttention weights indicate how certain attributes contribute to the classification of tweets as fake or real news."}
{"layout": 95, "type": "text", "text": "dknews: conﬁrmed: #mike-brown had no criminal record. #ferguson ”). We highlight evidential words with higher co-attention weights in font sizes of word clouds, as exhibited in Figure  5 . GCAN pre- dicts the former to be fake with stronger attention on words “breaking” and “strict”, and detects the latter as real since it contains “conﬁrmed” and “ir- relevant.” Such results may correspond to the com- mon knowledge ( Rashkin et al. ,  2017 ;  Horne and Adali ,  2017 ) that fake news tends to use dramatic and obscure words while real news is attended by conﬁrmed and fact checking-related words. ", "page_idx": 7, "bbox": [306, 536.010009765625, 527, 698.1964111328125], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 96, "type": "text", "text": "Explainability on Retweet Propagation.  We aim to exploit the retweet order in propagations to unfold the behavior difference between fake and real news. We randomly pick three fake (F1-F3) and three true (T1-T3) source stories, and plot their weights from source-propagation co-attention (Sec- tion  4.5 ), as exhibited in Figure  6 , in which the horizontal direction from left to right denotes the order of retweet. The results show that to determine whether a story is fake, one should ﬁrst examine the characteristics of users who  early  retweet the source story. The evidences of fake news in terms of user characteristics may be evenly distributed in the propagation. ", "page_idx": 7, "bbox": [306, 698.2963256835938, 527, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 97, "type": "text", "text": "", "page_idx": 8, "bbox": [70, 63.68701934814453, 292, 185.22647094726562], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 98, "type": "text", "text": "Explainability on Retweeter Characteristics. The source-propagation co-attention of our GCAN model can further provide an explanation to unveil the traits of suspicious users and the words they focus on. A case study is presented in Figure  7 . We can ﬁnd that the traits of suspicious users in retweet propagation can be: accounts are not ver- iﬁed, shorter account creation time, shorter user description length, and shorter graph path length to the user who posts the source tweet. In addition, what they highly attend are words “breaking” and “pipeline.” We think such kind of explanation can beneﬁt interpret the detection of fake news so as to understand their potential stances. ", "page_idx": 8, "bbox": [70, 185.5222625732422, 292, 375.2004699707031], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 99, "type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 8, "bbox": [71, 387, 147, 399], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 100, "type": "text", "text": "In this study, we propose a novel fake news de- tection method, Graph-aware Co-Attention Net- works (GCAN). GCAN is able to predict whether a short-text tweet is fake, given the sequence of its retweeters. The problem scenario is more realistic and challenging than existing studies. Evaluation results show the powerful effectiveness and the rea- sonable explainability of GCAN. Besides, GCAN can also provide early detection of fake news with satisfying performance. We believe GCAN can be used for not only fake news detection, but also other short-text classiﬁcation tasks on social media, such as sentiment detection, hate speech detection, and tweet popularity prediction. We will explore model generalization in the future work. Besides, while fake news usually targets at some events, we will also extend GCAN to study how to remove event- speciﬁc features to further boost the performance and explainability. ", "page_idx": 8, "bbox": [70, 408.4289855957031, 292, 665.46044921875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 101, "type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 8, "bbox": [72, 678, 166, 689], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 102, "type": "text", "text": "This work is supported by Ministry of Science and Technology (MOST) of Taiwan under grants 109-2636-E-006-017 (MOST Young Scholar Fel- lowship) and 108-2218-E-006-036, and also by Academia Sinica under grant AS-TP-107-M05. ", "page_idx": 8, "bbox": [70, 698.6890258789062, 292, 766.0314331054688], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 103, "type": "text", "text": "References ", "text_level": 1, "page_idx": 8, "bbox": [307, 64, 363, 76], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 104, "type": "text", "text": "Hunt Allcott and Matthew Gentzkow. 2017. Social me- dia and fake news in the 2016 election.  The Journal of Economic Perspectives , 31:211–235. Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credibility on twitter. In Proceedings of the 20th International Conference on World Wide Web, WWW ’11, pages 675–684.Meeyoung Cha, Wei Gao, and Cheng-Te Li. 2020. De- tecting fake news in social media: An asia-paciﬁc perspective.  Commun. ACM , 63(4):68–71. Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence model- ing. Ming-Han Feng, Chin-Chi Hsu, Cheng-Te Li, Mi- Yen Yeh, and Shou-De Lin. 2019. Marine: Multi- relational network embeddings with relational prox- imity and node attributes. In  The World Wide Web Conference , WWW ’19, pages 470–479. Chuan Guo, Juan Cao, Xueyao Zhang, Kai Shu, and Miao Yu. 2019. Exploiting emotions for fake news detection on social media.  CoRR , abs/1903.01728. Benjamin Horne and Sibel Adali. 2017. This just in: Fake news packs a lot in title, uses simpler, repetitive content in text body, more similar to satire than real news. In  Proceedings of AAAI International Confer- ence on Web and Social Media , pages 759–766. Jyun-Yu Jiang, Cheng-Te Li, Yian Chen, and Wei Wang. 2018. Identifying users behind shared ac- counts in online streaming services. In  The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval , SIGIR ’18, pages 65–74. Thomas N. Kipf and Max Welling. 2017. Semi- Supervised Classiﬁcation with Graph Convolutional Networks. In  Proceedings of the 5th International Conference on Learning Representations , ICLR ’17. Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is twitter, a social network or a news media? In  Proceedings of the 19th In- ternational Conference on World Wide Web , WWW ’10, pages 591–600. Sejeong Kwon, Meeyoung Cha, and Kyomin Jung. 2017. Rumor detection over varying time windows. PLOS ONE , 12(1):1–19. Cheng-Te Li, Yu-Jen Lin, and Mi-Yen Yeh. 2018. Fore- casting participants of information diffusion on so- cial networks with its applications.  Information Sci- ences , 422:432 – 446. Yang Liu and Yi-Fang Wu. 2018. Early detection of fake news on social media through propagation path classiﬁcation with recurrent and convolutional net- works. In  AAAI Conference on Artiﬁcial Intelli- gence , pages 254–261. ", "page_idx": 8, "bbox": [307, 81.63458251953125, 527, 765.7651977539062], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 105, "type": "text", "text": "Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016. Hierarchical question-image co-attention for visual question answering. In  Proceedings of the 30th International Conference on Neural Informa- tion Processing Systems , NIPS’16, pages 289–297. Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J. Jansen, Kam Fai Wong, and Meeyoung Cha. 2016. Detecting rumors from microblogs with recurrent neural networks.  IJCAI International Joint Conference on Artiﬁcial Intelligence , pages 3818– 3824. Jing Ma, Wei Gao, Zhongyu Wei, Yueming Lu, and Kam-Fai Wong. 2015. Detect rumors using time se- ries of social context information on microblogging websites. In  Proceedings of the 24th ACM Inter- national on Conference on Information and Knowl- edge Management , CIKM ’15, pages 1751–1754. Jing Ma, Wei Gao, and Kam Fai Wong. 2017. Detect rumors in microblog posts using propagation struc- ture via kernel learning. In  ACL 2017 - 55th Annual Meeting of the Association for Computational Lin- guistics, Proceedings of the Conference , pages 708– 717. Jing Ma, Wei Gao, and Kam-Fai Wong. 2018. Ru- mor detection on twitter with tree-structured recur- sive neural networks. In  Proceedings of the 56th An- nual Meeting of the Association for Computational Linguistics , pages 1980–1989. Kashyap Popat. 2017. Assessing the credibility of claims on the web. In  Proceedings of the 26th Inter- national Conference on World Wide Web Compan- ion , WWW ’17 Companion, pages 735–739. Martin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendorff, and Benno Stein. 2018. A stylo- metric inquiry into hyperpartisan and fake news. In Proceedings of the 56th Annual Meeting of the As- sociation for Computational Linguistics , ACL ’18, pages 231–240. Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana Volkova, and Yejin Choi. 2017. Truth of varying shades: Analyzing language in fake news and polit- ical fact-checking. In  Proceedings of the 2017 Con- ference on Empirical Methods in Natural Language Processing , pages 2931–2937. Julio C. S. Reis, Andr´ e Correia, Fabr´ ıcio Murai, Adri- ano Veloso, and Fabr´ ıcio Benevenuto. 2019. Ex- plainable machine learning for fake news detection. In  Proceedings of the 10th ACM Conference on Web Science , WebSci ’19, pages 17–26. Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017. Csi: A hybrid deep model for fake news detection. In  Proceedings of the 2017 ACM on Conference on Information and Knowledge Management , CIKM ’17, pages 797–806. ", "page_idx": 9, "bbox": [71, 64.56158447265625, 292, 765.76513671875], "page_size": [595.2760009765625, 841.8900146484375]}
{"layout": 106, "type": "text", "text": "Justin Sampson, Fred Morstatter, Liang Wu, and Huan Liu. 2016. Leveraging the implicit structure within social media for emergent rumor detection. In  Pro- ceedings of the 25th ACM International on Confer- ence on Information and Knowledge Management , CIKM ’16, pages 2377–2382. Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and Huan Liu. 2019a. defend: Explainable fake news detection. In  Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , KDD ’19, pages 395– 405. Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news detection on social me- dia: A data mining perspective. SIGKDD Explor. Newsl. , 19(1):22–36. Kai Shu, Xinyi Zhou, Suhang Wang, Reza Zafarani, and Huan Liu. 2019b. The role of user proﬁle for fake news detection.  CoRR , abs/1904.13355. Pei-Chi Wang and Cheng-Te Li. 2019. Spotting ter- rorists by learning behavior-aware heterogeneous network embedding. In  Proceedings of the 28th ACM International Conference on Information and Knowledge Management , CIKM ’19, pages 2097– 2100. Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu Su, and Jing Gao. 2018. Eann: Event adversarial neural networks for multi-modal fake news detection. In  Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &#38; Data Mining , KDD ’18, pages 849–857. Rui Yan, Ian E.H. Yen, Cheng-Te Li, Shiqi Zhao, and Xiaohua Hu. 2015. Tackling the achilles heel of so- cial networks: Inﬂuence propagation based language model smoothing. In  Proceedings of the 24th In- ternational Conference on World Wide Web , WWW ’15, pages 1318–1328. Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012. Automatic detection of rumor on sina weibo. In  Pro- ceedings of the ACM SIGKDD Workshop on Mining Data Semantics , MDS ’12. Yang Yang, Lei Zheng, Jiawei Zhang, Qingcai Cui, Zhoujun Li, and Philip S. Yu. 2018. Ti-cnn: Con- volutional neural networks for fake news detection. Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. En- quiring minds: Early detection of rumors in social media from enquiry posts. In  Proceedings of the 24th International Conference on World Wide Web , WWW ’15, pages 1395–1405. ", "page_idx": 9, "bbox": [307, 64.56121826171875, 527, 694.2495727539062], "page_size": [595.2760009765625, 841.8900146484375]}
