{"page": 0, "image_path": "doc_images/P18-1046_0.jpg", "ocr_text": "DSGAN: Generative Adversarial Training for Distant Supervision\nRelation Extraction\n\nPengda Qin‘, Weiran Xu‘, William Yang Wang’\n*Beijing University of Posts and Telecommunications, China\nUniversity of California, Santa Barbara, USA\n{qinpengda, xuweiran}@bupt.edu.cn\n{william}@cs.ucsb.edu\n\nAbstract\n\nDistant supervision can effectively label\ndata for relation extraction, but suffers\nfrom the noise labeling problem. Recent\nworks mainly perform soft bag-level noise\nreduction strategies to find the relatively\nbetter samples in a sentence bag, which is\nsuboptimal compared with making a hard\ndecision of false positive samples in sen-\ntence level. In this paper, we introduce\nan adversarial learning framework, which\nwe named DSGAN, to learn a sentence-\nlevel true-positive generator. Inspired by\nGenerative Adversarial Networks, we re-\ngard the positive samples generated by the\ngenerator as the negative samples to train\nthe discriminator. The optimal generator is\nobtained until the discrimination ability of\nthe discriminator has the greatest decline.\nWe adopt the generator to filter distant su-\npervision training dataset and redistribute\nthe false positive instances into the nega-\ntive set, in which way to provide a cleaned\ndataset for relation classification. The ex-\nperimental results show that the proposed\nstrategy significantly improves the perfor-\nmance of distant supervision relation ex-\ntraction comparing to state-of-the-art sys-\ntems.\n\n1 Introduction\n\nRelation extraction is a crucial task in the field\nof natural language processing (NLP). It has a\nwide range of applications including information\nretrieval, question answering, and knowledge base\ncompletion. The goal of relation extraction sys-\ntem is to predict relation between entity pair in\na sentence (Zelenko et al., 2003; Bunescu and\nMooney, 2005; GuoDong et al., 2005). For exam-\n\n496\n\nDS data space\n\nDS true positive data\nDS false positive data\nDS negative data\n\nThe decision boundary\nof DS data\n\nThe desired decision\nboundary\n\nFigure 1: Illustration of the distant supervision\ntraining data distribution for one relation type.\n\nple, given a sentence “The [owl], held the mouse\nin its [claw],.”, a relation classifier should figure\nout the relation Component-Whole between en-\nity owl and claw.\n\nWith the infinite amount of facts in real world,\nit is extremely expensive, and almost impossible\n‘or human annotators to annotate training dataset\n0 meet the needs of all walks of life. This prob-\nlem has received increasingly attention. Few-\nshot learning and Zero-shot Learning (Xian et al.,\n2017) try to predict the unseen classes with few\nlabeled data or even without labeled data. Dif-\nerently, distant supervision (Mintz et al., 2009;\nHoffmann et al., 2011; Surdeanu et al., 2012) is\n0 efficiently generate relational data from plain\next for unseen relations with distant supervision\n(DS). However, it naturally brings with some de-\nects: the resulted distantly-supervised training\nsamples are often very noisy (shown in Figure 1),\nwhich is the main problem of impeding the per-\normance (Roth et al., 2013). Most of the cur-\nrent state-of-the-art methods (Zeng et al., 2015;\nLin et al., 2016) make the denoising operation in\nhe sentence bag of entity pair, and integrate this\nprocess into the distant supervision relation ex-\n\nProceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 496-505\nMelbourne, Australia, July 15 - 20, 2018. ©2018 Association for Computational Linguistics\n", "vlm_text": "DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction \nPengda  $\\mathbf{Q}\\mathbf{in}^{\\sharp}$  , Weiran  $\\mathbf{X}\\mathbf{u}^{\\sharp}$  , William Yang Wang ♭ ♯ Beijing University of Posts and Telecommunications, China ♭ University of California, Santa Barbara, USA { qinpengda, xuweiran } @bupt.edu.cn { william } @cs.ucsb.edu \nAbstract \nDistant supervision can effectively label data for relation extraction, but suffers from the noise labeling problem. Recent works mainly perform soft bag-level noise reduction strategies to ﬁnd the relatively better samples in a sentence bag, which is suboptimal compared with making a hard decision of false positive samples in sen- tence level. In this paper, we introduce an adversarial learning framework, which we named DSGAN, to learn a sentence- level true-positive generator. Inspired by Generative Adversarial Networks, we re- gard the positive samples generated by the generator as the negative samples to train the discriminator. The optimal generator is obtained until the discrimination ability of the discriminator has the greatest decline. We adopt the generator to ﬁlter distant su- pervision training dataset and redistribute the false positive instances into the nega- tive set, in which way to provide a cleaned dataset for relation classiﬁcation. The ex- perimental results show that the proposed strategy signiﬁcantly improves the perfor- mance of distant supervision relation ex- traction comparing to state-of-the-art sys- tems. \n1 Introduction \nRelation extraction is a crucial task in the ﬁeld of natural language processing (NLP). It has a wide range of applications including information retrieval, question answering, and knowledge base completion. The goal of relation extraction sys- tem is to predict relation between entity pair in a sentence ( Zelenko et al. ,  2003 ;  Bunescu and Mooney ,  2005 ;  GuoDong et al. ,  2005 ). For exam- \nThe image is a diagram depicting a data space, labeled \"DS data space.\" It includes three types of data points represented by different symbols:\n\n1. Purple circles marked as \"DS true positive data.\"\n2. Orange triangles marked as \"DS false positive data.\"\n3. Red crosses marked as \"DS negative data.\"\n\nThere are also two decision boundaries shown:\n\n1. An orange dashed line representing \"The decision boundary of DS data.\"\n2. A black dash-dot line representing \"The desired decision boundary.\"\n\nThe diagram likely illustrates a classification problem where different types of data points are separated by decision boundaries. The desired decision boundary likely represents an ideal separation between the data types, while the actual decision boundary shows the current algorithm's classification.\nFigure 1: Illustration of the distant supervision training data distribution for one relation type. \nple, given a sentence “The    $[o w l]_{e1}$   held the mouse in its    $[c l a w]_{e2}.\\footnote{T h i s i s t h e s i s t h e s i g h i s f o r m a i n t h e h i s t i m s i s i s a n d e n s i t i c a s t e n s i n t e r m s e n t e r m(f o r m a n c e.a n c e,t h e$  , a relation classiﬁer should ﬁgure out the relation  Component-Whole  between en- tity  owl  and  claw . \nWith the inﬁnite amount of facts in real world, it is extremely expensive, and almost impossible for human annotators to annotate training dataset to meet the needs of all walks of life. This prob- lem has received increasingly attention. Few- shot learning and Zero-shot Learning ( Xian et al. , 2017 ) try to predict the unseen classes with few labeled data or even without labeled data. Dif- ferently, distant supervision ( Mintz et al. ,  2009 ; Hoffmann et al. ,  2011 ;  Surdeanu et al. ,  2012 ) is to efﬁciently generate relational data from plain text for unseen relations with distant supervision (DS). However, it naturally brings with some de- fects: the resulted distantly-supervised training samples are often very noisy (shown in Figure  1 ), which is the main problem of impeding the per- formance ( Roth et al. ,  2013 ). Most of the cur- rent state-of-the-art methods ( Zeng et al. ,  2015 ; Lin et al. ,  2016 ) make the denoising operation in the sentence bag of entity pair, and integrate this process into the distant supervision relation ex- traction. Indeed, these methods can ﬁlter a sub- stantial number of noise samples; However, they overlook the case that all sentences of an entity pair are false positive, which is also the common phenomenon in distant supervision datasets. Un- der this consideration, an independent and accu- rate  sentence-level  noise reduction strategy is the better choice. "}
{"page": 1, "image_path": "doc_images/P18-1046_1.jpg", "ocr_text": "traction. Indeed, these methods can filter a sub-\nstantial number of noise samples; However, they\noverlook the case that all sentences of an entity\npair are false positive, which is also the common\nphenomenon in distant supervision datasets. Un-\nder this consideration, an independent and accu-\nrate sentence-level noise reduction strategy is the\nbetter choice.\n\nIn this paper, we design an adversarial learning\nprocess (Goodfellow et al., 2014; Radford et al.,\n2015) to obtain a sentence-level generator that can\nrecognize the true positive samples from the noisy\ndistant supervision dataset without any supervised\ninformation. In Figure 1, the existence of false\npositive samples makes the DS decision boundary\nsuboptimal, therefore hinders the performance of\nrelation extraction. However, in terms of quan-\ntity, the true positive samples still occupy most\nof the proportion; this is the prerequisite of our\nmethod. Given the discriminator that possesses\nthe decision boundary of DS dataset (the brown\ndecision boundary in Figure 1), the generator tries\nto generate true positive samples from DS posi-\ntive dataset; Then, we assign the generated sam-\nples with negative label and the rest samples with\npositive label to challenge the discriminator. Un-\nder this adversarial setting, if the generated sam-\nple set includes more true positive samples and\nmore false positive samples are left in the rest set,\nthe classification ability of the discriminator will\ndrop faster. Empirically, we show that our method\nhas brought consistent performance gains in vari-\nous deep-neural-network-based models, achieving\nstrong performances on the widely used New York\nTimes dataset (Riedel et al., 2010). Our contribu-\ntions are three-fold:\n\ne We are the first to consider adversarial learn-\ning to denoise the distant supervision relation\nextraction dataset.\n\ne Our method is sentence-level and model-\nagnostic, so it can be used as a plug-and-play\ntechnique for any relation extractors.\n\ne We show that our method can generate a\ncleaned dataset without any supervised infor-\nmation, in which way to boost the perfor-\nmance of recently proposed neural relation\nextractors.\n\nIn Section 2, we outline some related works on\ndistant supervision relation extraction. Next, we\n\n497\n\ndescribe our adversarial learning strategy in Sec-\ntion 3. In Section 4, we show the stability analyses\nof DSGAN and the empirical evaluation results.\nAnd finally, we conclude in Section 5.\n\n2 Related Work\n\nTo address the above-mentioned data sparsity is-\nsue, Mintz et al. (2009) first align unlabeled\next corpus with Freebase by distant supervision.\nHowever, distant supervision inevitably suffers\nfrom the wrong labeling problem. Instead of ex-\nplicitly removing noisy instances, the early works\nintend to suppress the noise. Riedel et al. (2010)\nadopt multi-instance single-label learning in rela-\nion extraction; Hoffmann et al. (2011) and Sur-\ndeanu et al. (2012) model distant supervision re-\nlation extraction as a multi-instance multi-label\nproblem.\n\nRecently, some deep-learning-based mod-\nels (Zeng et al., 2014; Shen and Huang, 2016)\nhave been proposed to solve relation extraction.\nNaturally, some works try to alleviate the wrong\nlabeling problem with deep learning technique,\nand their denoising process is integrated into rela-\nion extraction. Zeng et al. (2015) select one most\nplausible sentence to represent the relation be-\nween entity pairs, which inevitably misses some\nvaluable information. Lin et al. (2016) calculate\na series of soft attention weights for all sentences\nof one entity pair and the incorrect sentences can\nbe down-weighted; Base on the same idea, Ji et al.\n(2017) bring the useful entity information into the\ncalculation of the attention weights. However,\ncompared to these soft attention weight assign-\nment strategies, recognizing the true positive\nsamples from distant supervision dataset before\nrelation extraction is a better choice. Takamatsu\net al. (2012) build a noise-filtering strategy based\non the linguistic features extracted from many\nNLP tools, including NER and dependency tree,\nwhich inevitably suffers the error propagation\nproblem; while we just utilize word embedding\nas the input information. In this work, we learn\na true-positive identifier (the generator) which is\nindependent of the relation prediction of entity\npairs, so it can be directly applied on top of any\nexisting relation extraction classifiers. Then, we\nredistribute the false positive samples into the\nnegative set, in which way to make full use of the\ndistantly labeled resources.\n\n", "vlm_text": "\nIn this paper, we design an adversarial learning process ( Goodfellow et al. ,  2014 ;  Radford et al. , 2015 ) to obtain a sentence-level generator that can recognize the true positive samples from the noisy distant supervision dataset without any supervised information. In Figure  1 , the existence of false positive samples makes the DS decision boundary suboptimal, therefore hinders the performance of relation extraction. However, in terms of quan- tity, the true positive samples still occupy most of the proportion; this is the prerequisite of our method. Given the discriminator that possesses the decision boundary of DS dataset (the brown decision boundary in Figure  1 ), the generator tries to generate true positive samples from DS posi- tive dataset; Then, we assign the generated sam- ples with negative label and the rest samples with positive label to challenge the discriminator. Un- der this adversarial setting, if the generated sam- ple set includes more true positive samples and more false positive samples are left in the rest set, the classiﬁcation ability of the discriminator will drop faster. Empirically, we show that our method has brought consistent performance gains in vari- ous deep-neural-network-based models, achieving strong performances on the widely used New York Times dataset ( Riedel et al. ,  2010 ). Our contribu- tions are three-fold: \n•  We are the ﬁrst to consider adversarial learn- ing to denoise the distant supervision relation extraction dataset. \n•  Our method is sentence-level and model- agnostic, so it can be used as a plug-and-play technique for any relation extractors. \n•  We show that our method can generate a cleaned dataset without any supervised infor- mation, in which way to boost the perfor- mance of recently proposed neural relation extractors. \nIn Section  2 , we outline some related works on distant supervision relation extraction. Next, we describe our adversarial learning strategy in Sec- tion  3 . In Section  4 , we show the stability analyses of DSGAN and the empirical evaluation results. And ﬁnally, we conclude in Section  5 . \n\n2 Related Work \nTo address the above-mentioned data sparsity is- sue,  Mintz et al.  ( 2009 ) ﬁrst align unlabeled text corpus with Freebase by distant supervision. However, distant supervision inevitably suffers from the wrong labeling problem. Instead of ex- plicitly removing noisy instances, the early works intend to suppress the noise.  Riedel et al.  ( 2010 ) adopt multi-instance single-label learning in rela- tion extraction;  Hoffmann et al.  ( 2011 ) and  Sur- deanu et al.  ( 2012 ) model distant supervision re- lation extraction as a multi-instance multi-label problem. \nRecently, some deep-learning-based mod- els ( Zeng et al. ,  2014 ;  Shen and Huang ,  2016 ) have been proposed to solve relation extraction. Naturally, some works try to alleviate the wrong labeling problem with deep learning technique, and their denoising process is integrated into rela- tion extraction.  Zeng et al.  ( 2015 ) select one most plausible sentence to represent the relation be- tween entity pairs, which inevitably misses some valuable information. Lin et al.  ( 2016 ) calculate a series of soft attention weights for all sentences of one entity pair and the incorrect sentences can be down-weighted; Base on the same idea,  Ji et al. ( 2017 ) bring the useful entity information into the calculation of the attention weights. However, compared to these soft attention weight assign- ment strategies, recognizing the true positive samples from distant supervision dataset before relation extraction is a better choice.  Takamatsu et al.  ( 2012 ) build a noise-ﬁltering strategy based on the linguistic features extracted from many NLP tools, including NER and dependency tree, which inevitably suffers the error propagation problem; while we just utilize word embedding as the input information. In this work, we learn a true-positive identiﬁer (the generator) which is independent of the relation prediction of entity pairs, so it can be directly applied on top of any existing relation extraction classiﬁers. Then, we redistribute the false positive samples into the negative set, in which way to make full use of the distantly labeled resources. "}
{"page": 2, "image_path": "doc_images/P18-1046_2.jpg", "ocr_text": "3 Adversarial Learning for Distant\nSupervision\n\nIn this section, we introduce an adversarial learn-\ning pipeline to obtain a robust generator which can\nautomatically discover the true positive samples\nfrom the noisy distantly-supervised dataset with-\nout any supervised information. The overview of\nour adversarial learning process is shown in Fig-\nure 2. Given a set of distantly-labeled sentences,\nthe generator tries to generate true positive sam-\nples from it; But, these generated samples are re-\ngarded as negative samples to train the discrimina-\ntor. Thus, when finishing scanning the DS positive\ndataset one time, the more true positive samples\nthat the generator discovers, the sharper drop of\nperformance the discriminator obtains. After ad-\nversarial training, we hope to obtain a robust gen-\nerator that is capable of forcing discriminator into\nmaximumly losing its classification ability.\n\nIn the following section, we describe the adver-\nsarial training pipeline between the generator and\nthe discriminator, including the pre-training strat-\negy, objective functions and gradient calculation.\nBecause the generator involves a discrete sampling\nstep, we introduce a policy gradient method to cal-\nculate gradients for the generator.\n\n3.1 Pre-Training Strategy\n\nBoth the generator and the discriminator require\nthe pre-training process, which is the common set-\nting for GANs (Cai and Wang, 2017; Wang et al.,\n2017). With the better initial parameters, the ad-\nversarial learning is prone to convergence. As pre-\nsented in Figure 2, the discriminator is pre-trained\nwith DS positive dataset P (label 1) and DS nega-\ntive set N (label 0). After our adversarial learn-\ning process, we desire a strong generator that can,\nto the maximum extent, collapse the discrimina-\ntor. Therefore, the more robust generator can be\nobtained via competing with the more robust dis-\ncriminator. So we pre-train the discriminator un-\ntil the accuracy reaches 90% or more. The pre-\ntraining of generator is similar to the discrimi-\nnator; however, for the negative dataset, we use\nanother completely different dataset N@, which\nmakes sure the robustness of the experiment. Spe-\ncially, we let the generator overfits the DS posi-\ntive dataset P. The reason of this setting is that\nwe hope the generator wrongly give high proba-\nbilities to all of the noisy DS positive samples at\nthe beginning of the training process. Then, along\n\n498\n\nwith our adversarial learning, the generator learns\nto gradually decrease the probabilities of the false\npositive samples.\n\n3.2. Generative Adversarial Training for\nDistant Supervision Relation Extraction\n\nThe generator and the discriminator of DSGAN\nare both modeled by simple CNN, because CNN\nperforms well in understanding sentence (Zeng\net al., 2014), and it has less parameters than RNN-\nbased networks. For relation extraction, the input\ninformation consists of the sentences and entity\npairs; thus, as the common setting (Zeng et al.,\n2014; Nguyen and Grishman, 2015), we use both\nword embedding and position embedding to con-\nvert input instances into continuous real-valued\nvectors.\n\nWhat we desire the generator to do is to ac-\ncurately recognize true positive samples. Unlike\nthe generator applied in computer vision field (Im\net al., 2016) that generates new image from the\ninput noise, our generator just needs to discover\ntrue positive samples from the noisy DS posi-\ntive dataset. Thus, it is to realize the “sampling\nfrom a probability distribution” process of the dis-\ncrete GANs (Figure 2). For a input sentence sj,\nwe define the probability of being true positive\nsample by generator as pq(s;). Similarly, for\ndiscriminator, the probability of being true pos-\nitive sample is represented as pp(s;). We de-\nfine that one epoch means that one time scan-\nning of the entire DS positive dataset. In or-\nder to obtain more feedbacks and make the train-\ning process more efficient, we split the DS posi-\nive dataset P = {81, 59,...,8;,...} into N bags\nB = {B', B?,...B%}, and the network parame-\ners Og, 0p are updated when finishing processing\none bag B;!. Based on the notion of adversarial\nlearning, we define the objectives of the generator\nand the discriminator as follow, and they are al-\nernatively trained towards their respective objec-\nives.\n\nGenerator Suppose that the generator produces\na set of probability distribution {pq(sj)}j=1...\\B;|\n‘or a sentence bag B;. Based on these probabili-\nies, a set of sentence are sampled and we denote\nhis set as T’.\n\nT = {sj}, 8) ~ pa(s;),j =1,2,..,|Bil\n\n'The bag here has the different definition from the sen-\ntence bag of an entity pair mentioned in the Section 1.\n", "vlm_text": "3 Adversarial Learning for Distant Supervision \nIn this section, we introduce an adversarial learn- ing pipeline to obtain a robust generator which can automatically discover the true positive samples from the noisy distantly-supervised dataset with- out any supervised information. The overview of our adversarial learning process is shown in Fig- ure  2 . Given a set of distantly-labeled sentences, the generator tries to generate true positive sam- ples from it; But, these generated samples are re- garded as negative samples to train the discrimina- tor. Thus, when ﬁnishing scanning the DS positive dataset one time, the more true positive samples that the generator discovers, the sharper drop of performance the discriminator obtains. After ad- versarial training, we hope to obtain a robust gen- erator that is capable of forcing discriminator into maximumly losing its classiﬁcation ability. \nIn the following section, we describe the adver- sarial training pipeline between the generator and the discriminator, including the pre-training strat- egy, objective functions and gradient calculation. Because the generator involves a discrete sampling step, we introduce a policy gradient method to cal- culate gradients for the generator. \n3.1 Pre-Training Strategy \nBoth the generator and the discriminator require the pre-training process, which is the common set- ting for GANs ( Cai and Wang ,  2017 ;  Wang et al. , 2017 ). With the better initial parameters, the ad- versarial learning is prone to convergence. As pre- sented in Figure  2 , the discriminator is pre-trained with DS positive dataset  $P$   (label 1) and DS nega- tive set    $N^{D}$    (label 0). After our adversarial learn- ing process, we desire a strong generator that can, to the maximum extent, collapse the discrimina- tor. Therefore, the more robust generator can be obtained via competing with the more robust dis- criminator. So we pre-train the discriminator un- til the accuracy reaches   $90\\%$   or more. The pre- training of generator is similar to the discrimi- nator; however, for the negative dataset, we use another completely different dataset    $N^{G}$  , which makes sure the robustness of the experiment. Spe- cially, we let the generator overﬁts the DS posi- tive dataset    $P$  . The reason of this setting is that we hope the generator wrongly give high proba- bilities to all of the noisy DS positive samples at the beginning of the training process. Then, along with our adversarial learning, the generator learns to gradually decrease the probabilities of the false positive samples. \n\n3.2 Generative Adversarial Training for Distant Supervision Relation Extraction \nThe generator and the discriminator of DSGAN are both modeled by simple CNN, because CNN performs well in understanding sentence ( Zeng et al. ,  2014 ), and it has less parameters than RNN- based networks. For relation extraction, the input information consists of the sentences and entity pairs; thus, as the common setting ( Zeng et al. , 2014 ;  Nguyen and Grishman ,  2015 ), we use both word embedding and position embedding to con- vert input instances into continuous real-valued vectors. \nWhat we desire the generator to do is to ac- curately recognize true positive samples. Unlike the generator applied in computer vision ﬁeld ( Im et al. ,  2016 ) that generates new image from the input noise, our generator just needs to discover true positive samples from the noisy DS posi- tive dataset. Thus, it is to realize the “sampling from a probability distribution” process of the dis- crete GANs (Figure  2 ). For a input sentence    $s_{j}$  , we deﬁne the probability of being true positive sample by generator as    $p_{G}(s_{j})$  . Similarly, for discriminator, the probability of being true pos- itive sample is represented as    $p_{D}(s_{j})$  . We de- ﬁne that one epoch means that one time scan- ning of the entire DS positive dataset. In or- der to obtain more feedbacks and make the train- ing process more efﬁcient, we split the DS posi- tive dataset    $P\\;=\\;\\{s_{1},s_{2},...,s_{j},...\\}$   into    $N$   bags  $B\\,=\\,\\{B^{1},B^{2},...B^{N}\\}$  , and the network parame- ters  $\\theta_{G},\\theta_{D}$   are updated when ﬁnishing processing one bag    $B_{i}{}^{1}$  . Based on the notion of adversarial learning, we deﬁne the objectives of the generator and the discriminator as follow, and they are al- ternatively trained towards their respective objec- tives. \nGenerator Suppose that the generator produces a set of probability distribution    $\\{p_{G}(s_{j})\\}_{j=1\\dots|B_{i}|}$  for a sentence bag    $B_{i}$  . Based on these probabili- ties, a set of sentence are sampled and we denote this set as  $T$  . \n\n$$\nT=\\{s_{j}\\},s_{j}\\sim p_{G}(s_{j}),j=1,2,...,|B_{i}|\n$$\n \n1 The  bag  here has the different deﬁnition from the sen- tence  bag  of an entity pair mentioned in the Section  1 . "}
{"page": 3, "image_path": "doc_images/P18-1046_3.jpg", "ocr_text": "| DS Positive |\nDataset\n\nGenerator\n\n‘a4\nS24 = P2 = 0.02\nBagy_1 S30 = p; = 0.83\n4p, = 0.26\nEpoch i Ba Ps = 0.9\nBea: G Ps\nBagi+1\nno\n\n=057'—__\nadie Low-confidence | uy\n__\nsamples\n\nSampling Discriminator |\n\nlabel = 1\n\nlabel = 1\n\nHigh-confidence gy,\nsamples D\n\nlabel = 0\n\nFigure 2: An overview of the DSGAN training pipeline. The generator (denoted by G) calculates the\nprobability distribution over a bag of DS positive samples, and then samples according to this probability\ndistribution. The high-confidence samples generated by G are regarded as true positive samples. The dis-\ncriminator (denoted by D) receives these high-confidence samples but regards them as negative samples;\nconversely, the low-confidence samples are still treated as positive samples. For the generated samples,\nG maximizes the probability of being true positive; on the contrary, D minimizes this probability.\n\nThis generated dataset T’ consists of the high-\nconfidence sentences, and is regard as true posi-\ntive samples by the current generator; however, it\nwill be treated as the negative samples to train the\ndiscriminator. In order to challenge the discrimi-\nnator, the objective of the generator can be formu-\nlated as maximizing the following probabilities of\nthe generated dataset T:\n\nLo = 9~ log pp(s;) (2)\n\n8j€T\n\nBecause Lg involves a discrete sampling step,\nso it cannot be directly optimized by gradient-\nbased algorithm. We adopt a common approach:\nthe policy-gradient-based reinforcement learning.\nThe following section will give the detailed intro-\nduction of the setting of reinforcement learning.\nThe parameters of the generator are continually\nupdated until reaching the convergence condition.\n\nDiscriminator After the generator has gener-\nated the sample subset T , the discriminator treats\nthem as the negative samples; conversely, the rest\npart F = B;—T is treated as positive samples. So,\nthe objective of the discriminator can be formu-\nlated as minimizing the following cross-entropy\nloss function:\n\n499\n\nLp =—( YD logpn(s;)\nsj€(Bi-T) (3)\n+ S23 log(1 — pp(s;)))\n\nsj€T\n\nThe update of discriminator is identical to the\ncommon binary classification problem. Naturally,\nit can be simply optimized by any gradient-based\nalgorithm.\n\nWhat needs to be explained is that, unlike\nthe common setting of discriminator in previ-\nous works, our discriminator loads the same pre-\ntrained parameter set at the beginning of each\nepoch as shown in Figure 2. There are two rea-\nsons. First, at the end of our adversarial training,\nwhat we need is a robust generator rather than a\ndiscriminator. Second, our generator is to sample\ndata rather than generate new data from scratch;\nTherefore, the discriminator is relatively easy to be\ncollapsed. So we design this new adversarial strat-\negy: the robustest generator is yielded when the\ndiscriminator has the largest drop of performance\nin one epoch. In order to create the equal con-\ndition, the bag set B for each epoch is identical,\nincluding the sequence and the sentences in each\n", "vlm_text": "The image is a flowchart illustrating a machine learning process involving a generator and a discriminator. Here's a breakdown of the components:\n\n1. **DS Positive Dataset**: This is the input section where samples are drawn from.\n\n2. **Generator (G)**: \n   - Takes a set of samples (\\(s_1, s_2, \\ldots, s_n\\)) and produces probabilities (\\(p_1, p_2, \\ldots, p_n\\)).\n   - These probabilities determine the confidence of each sample.\n\n3. **Sampling**:\n   - Samples are categorized based on confidence: low-confidence samples (label = 1) and high-confidence samples (label = 0).\n\n4. **Discriminator (D)**:\n   - Receives the sampled sets to discriminate the samples.\n   - Has a pre-training phase where it is loaded with parameters from a positive and negative dataset.\n\n5. **Reward**:\n   - There is feedback (reward) loop influencing the generator, likely for improving predictions or decisions in subsequent iterations.\n\nThe image represents a typical Generative Adversarial Network (GAN) setup or a semi-supervised learning system, where data is classified and confidence assessed iteratively through epochs.\nFigure 2: An overview of the DSGAN training pipeline. The generator (denoted by  G ) calculates the probability distribution over a bag of DS positive samples, and then samples according to this probability distribution. The high-conﬁdence samples generated by G are regarded as true positive samples. The dis- criminator (denoted by  $\\mathbf{D}$  ) receives these high-conﬁdence samples but regards them as negative samples; conversely, the low-conﬁdence samples are still treated as positive samples. For the generated samples, G maximizes  the probability of being true positive; on the contrary,  D minimizes  this probability. \nThis generated dataset    $T$   consists of the high- conﬁdence sentences, and is regard as true posi- tive samples by the current generator; however, it will be treated as the negative samples to train the discriminator. In order to challenge the discrimi- nator, the objective of the generator can be formu- lated as  maximizing  the following probabilities of the generated dataset    $T$  : \n\n$$\nL_{G}=\\sum_{s_{j}\\in T}\\log p_{D}(s_{j})\n$$\n \nBecause    $L_{G}$   involves a discrete sampling step, so it cannot be directly optimized by gradient- based algorithm. We adopt a common approach: the policy-gradient-based reinforcement learning. The following section will give the detailed intro- duction of the setting of reinforcement learning. The parameters of the generator are continually updated until reaching the convergence condition. \nDiscriminator After the generator has gener- ated the sample subset    $T$   , the discriminator treats them as the negative samples; conversely, the rest part  $F=B_{i}\\!-\\!T$  is treated as positive samples. So, the objective of the discriminator can be formu- lated as  minimizing  the following cross-entropy loss function: \n\n$$\n\\begin{array}{r l}{\\lefteqn{L_{D}=-\\big(\\sum_{s_{j}\\in(B_{i}-T)}\\log p_{D}(s_{j})}}\\\\ &{\\quad\\quad\\quad+\\sum_{s_{j}\\in T}\\log(1-p_{D}(s_{j}))\\big)}\\end{array}\n$$\n \nThe update of discriminator is identical to the common binary classiﬁcation problem. Naturally, it can be simply optimized by any gradient-based algorithm. \nWhat needs to be explained is that, unlike the common setting of discriminator in previ- ous works, our discriminator  loads the same pre- trained parameter set at the beginning of each epoch  as shown in Figure  2 . There are two rea- sons. First, at the end of our adversarial training, what we need is a robust generator rather than a discriminator. Second, our generator is to sample data rather than generate new data from scratch; Therefore, the discriminator is relatively easy to be collapsed. So we design this new adversarial strat- egy: the robustest generator is yielded when the discriminator has the largest drop of performance in one epoch. In order to create the equal con- dition, the bag set    $B$   for each epoch is identical, including the sequence and the sentences in each Data:  DS positive set    $P$  , DS negative set    $N^{G}$    for generator G, DS negative set    $N^{D}$    for discriminator D Input:  Pre-trained   $\\mathbf{G}$   with parameters    $\\theta_{G}$   on dataset   $(P,\\,N^{G})$  ; Pre-trained   $\\mathrm{D}$   with parameters    $\\theta_{D}$   on dataset  $(P,N^{D})$  "}
{"page": 4, "image_path": "doc_images/P18-1046_4.jpg", "ocr_text": "Algorithm 1 The DSGAN algorithm.\n\nData: DS positive set P, DS negative set N@ for generator G, DS negative set N? for discriminator D\nInput: Pre-trained G with parameters 6g on dataset (P, N G). Pre-trained D with parameters #p on\n\ndataset (P, N?)\n\nOutput: Adversarially trained generator G\n\n1\n2:\n3\n4\n5:\n6:\n7\n8\n\n: Load parameters 0g for G\n\n: repeat\n\nLoad parameters @p for D\nGe +0,Gp +0\n\nfor B; € P,i =1to N do\n\nB,-T\n\n9p — OD _ apGp\nCalculate the reward r\nGate ral Yo reg log pa(s;)\n0g + 0¢+acGa\nend for\n\n: until ACCp no longer drops\n: Save 0g\n\n: Split P into the bag sequence P = {B!, B?,..., B’,...,\n\nBY}\n\nCompute the probability pg(s;) for each sentence s; in B;\nObtain the generated part T by sampling according to {pq(s;)} ja1..|BI\n\nand the rest set F =\n\nGp — pen 327 log(1 — pp(s;)) + Von 1\" log pp(s;)}\n\nCompute the accuracy ACC p on N? with the current 0p\n\nbag Bj.\n\nOptimizing Generator The objective of the\ngenerator is similar to the objective of the one-step\nreinforcement learning problem: Maximizing the\nexpectation of a given function of samples from a\nparametrized probability distribution. Therefore,\nwe use a policy gradient strategy to update the\ngenerator. Corresponding to the terminology of\nreinforcement learning, sj is the state and Pq(s;)\n\nis\nof\nan\n\nthe policy. In order to better reflect the quality\nthe generator, we define the reward r from two\ngles:\n\ne As the common setting in adversarial learn-\ning, for the generated sample set, we hope\nthe confidence of being positive samples by\nthe discriminator becomes higher. Therefore,\nthe first component of our reward is formu-\nlated as below:\n\n1\n\"=i Ye pols;))-h A)\n\nsj€T\n\nthe function of b; is to reduce variance during\nreinforcement learning.\n\ne The second component is from the average\n\n500\n\nprediction probability of N?,\n\n. 1\np= JN?] S- pp(sj)\n\nsjENP\n\n(5)\n\nN° participates the pre-training process of\nthe discriminator, but not the adversarial\ntraining process. When the classification ca-\npacity of discriminator declines, the accuracy\nof being predicted as negative sample on N?\ngradually drops; thus, p increases. In other\nwords, the generator becomes better. There-\nfore, for epoch k, after processing the bag B;,\nreward rg is calculated as below,\n\nr2 = (Bp; — be) 6)\nwhere bg =max{p;\"},m=1...,k-1\n\nba has the same function as b,.\n\nThe gradient of Lg can be formulated as below:\n\nVopla = S-\n\nsj€Bi\n\nEs ~pa(s;)\"V0q log pa(s;)\n\n1\n= in S- rV oq log pa(s;)\nsj€T\n\n(7)\n", "vlm_text": "\nOutput:  Adversarially trained generator G \n1:  Load parameters    $\\theta_{G}$   for  $\\mathbf{G}$  2:  Split    $P$   into the bag sequence    $P=\\{B^{1},B^{2},...,B^{i},...,B^{N}\\}$  \n3:  repeat \n4: Load parameters  $\\theta_{D}$   for D 5:  $G_{G}\\gets0,G_{D}\\gets0$  6: for    $B_{i}\\in P,i=1$   to  $N$   do 7: Compute the probability  $p_{G}(s_{j})$   for each sentence  $s_{j}$   in    $B_{i}$  8: Obtain the generated part    $T$   by sampling according to    $\\{p_{G}(s_{j})\\}_{j=1\\dots|B|}$   and the rest set  $F=$  B i  −  $\\begin{array}{r l}&{T}\\\\ &{\\quad G_{D}\\gets-\\frac{1}{|P|}\\{\\bigtriangledown\\theta_{D}\\sum^{T}\\log(1-p_{D}(s_{j}))+\\bigtriangledown\\theta_{D}\\sum^{F}\\log p_{D}(s_{j})\\}}\\\\ &{\\quad\\theta_{D}\\gets\\theta_{D}-\\alpha_{D}G_{D}}\\\\ &{\\quad\\mathrm{CalcLife\\,the\\,reward}\\,r}\\\\ &{\\quad G_{G}\\gets\\frac{1}{|T|}\\sum^{T}r\\bigtriangledown\\theta_{G}\\log p_{G}(s_{j})}\\\\ &{\\quad\\theta_{G}\\gets\\theta_{G}+\\alpha_{G}G_{G}}\\end{array}$  9: 12: 13: 14: end for \n15: Compute the accuracy    $A C C_{D}$   on    $N^{D}$    with the current    $\\theta_{D}$  \n16:  until    $A C C_{D}$   no longer drops \n17:  Save    $\\theta_{G}$  \nbag  $B_{i}$  . \nOptimizing Generator The objective of the generator is similar to the objective of the one-step reinforcement learning problem: Maximizing the expectation of a given function of samples from a parametrized probability distribution. Therefore, we use a policy gradient strategy to update the generator. Corresponding to the terminology of reinforcement learning,    $s_{j}$   is the  state  and    $P_{G}(s_{j})$  is the  policy . In order to better reﬂect the quality of the generator, we deﬁne the reward  $r$   from two angles: \n•  As the common setting in adversarial learn- ing, for the generated sample set, we hope the conﬁdence of being positive samples by the discriminator becomes higher. Therefore, the ﬁrst component of our reward is formu- lated as below: \n\n$$\nr_{1}=\\frac{1}{|T|}\\sum_{s_{j}\\in T}p_{D}(s_{j})-b_{1}\n$$\n \nthe function of  $b_{1}$   is to reduce variance during reinforcement learning. \n•  The second component is from the average \nprediction probability of    $N^{D}$  , \n\n$$\n\\tilde{p}=\\frac{1}{|N^{D}|}\\sum_{s_{j}\\in N^{D}}p_{D}(s_{j})\n$$\n \n $N^{D}$    participates the pre-training process of the discriminator, but not the adversarial training process. When the classiﬁcation ca- pacity of discriminator declines, the accuracy of being predicted as negative sample on    $N^{D}$  gradually drops; thus,  $\\tilde{p}$   increases. In other words, the generator becomes better. There- fore, for epoch    $k$  , after processing the bag    $B_{i}$  , reward    $r_{2}$   is calculated as below, \n\n$$\n\\begin{array}{r}{r_{2}=\\eta(\\tilde{p}_{i}^{k}-b_{2})\\qquad\\qquad\\qquad}\\\\ {b_{2}\\!=\\!\\operatorname*{max}\\{\\tilde{p}_{i}^{m}\\},m\\!=\\!1...,k\\!-\\!1}\\end{array}\n$$\n \n $b_{2}$   has the same function as    $b_{1}$  . The gradient of    $L_{G}$   can be formulated as below: \n\n\n$$\n\\begin{array}{l}{\\displaystyle\\bigtriangledown\\theta_{D}L_{G}=\\sum_{s_{j}\\in B_{i}}\\mathbb{E}_{s_{j}\\sim p_{G}(s_{j})}r\\bigtriangledown_{\\theta_{G}}\\log p_{G}\\big(s_{j}\\big)}\\\\ {\\displaystyle}\\\\ {\\displaystyle=\\frac{1}{|T|}\\sum_{s_{j}\\in T}r\\bigtriangledown_{\\theta_{G}}\\log p_{G}\\big(s_{j}\\big)}\\end{array}\n$$\n "}
{"page": 5, "image_path": "doc_images/P18-1046_5.jpg", "ocr_text": "3.3. Cleaning Noisy Dataset with Generator\n\nAfter our adversarial learning process, we obtain\none generator for one relation type; These genera-\ntors possess the capability of generating true pos-\nitive samples for the corresponding relation type.\nThus, we can adopt the generator to filter the noise\nsamples from distant supervision dataset. Simply\nand clearly, we utilize the generator as a binary\nclassifier. In order to reach the maximum utiliza-\ntion of data, we develop a strategy: for an en-\ntity pair with a set of annotated sentences, if all\nof these sentences are determined as false nega-\ntive by our generator, this entity pair will be redis-\ntributed into the negative set. Under this strategy,\nthe scale of distant supervision training set keeps\nunchanged.\n\n4 Experiments\n\nThis paper proposes an adversarial learning strat-\negy to detect true positive samples from the noisy\ndistant supervision dataset. Due to the absence\nof supervised information, we define a genera-\ntor to heuristically learn to recognize true posi-\ntive samples through competing with a discrim-\ninator. Therefore, our experiments are intended\nto demonstrate that our DSGAN method possess\nthis capability. To this end, we first briefly intro-\nduce the dataset and the evaluation metrics. Em-\npirically, the adversarial learning process, to some\nextent, has instability; Therefore, we next illus-\ntrate the convergence of our adversarial training\nprocess. Finally, we demonstrate the efficiency\nof our generator from two angles: the quality of\nthe generated samples and the performance on the\nwidely-used distant supervision relation extraction\ntask.\n\n4.1 Evaluation and Implementation Details\n\nThe Reidel dataset? (Riedel et al., 2010) is a\ncommonly-used distant supervision relation ex-\ntraction dataset. Freebase is a huge knowledge\nbase including billions of triples: the entity pair\nand the specific relationship between them. Given\nthese triples, the sentences of each entity pair are\nselected from the New York Times corpus(NYT).\nEntity mentions of NYT corpus are recognized by\nthe Stanford named entity recognizer (Finkel et al.,\n2005). There are 52 actual relationships and a spe-\ncial relation NA which indicates there is no rela-\ntion between head and tail entities. Entity pairs of\n\n*http://iesl.cs.umass.edu/riedel/ecml/\n\n501\n\nHyperparameter Value\nCNN Window c,,, kernel size cz 3, 100\nWord embedding de, |V| 50, 114042\n\nPosition embedding d,, 5\nLearning rate of G, D le-5, le-4\n\nTable 1: Hyperparameter settings of the generator\nand the discriminator.\n\nNA are defined as the entity pairs that appear in\nthe same sentence but are not related according to\nFreebase.\n\nDue to the absence of the corresponding labeled\ndataset, there is not a ground-truth test dataset to\nevaluate the performance of distant supervision re-\nlation extraction system. Under this circumstance,\nhe previous work adopt the held-out evaluation\no evaluate their systems, which can provide an\napproximate measure of precision without requir-\ning costly human evaluation. It builds a test set\nwhere entity pairs are also extracted from Free-\nbase. Similarly, relation facts that discovered from\nest articles are automatically compared with those\nin Freebase. CNN is widely used in relation clas-\nsification (Santos et al., 2015; Qin et al., 2017),\nhus the generator and the discriminator are both\nmodeled as a simple CNN with the window size\nCw and the kernel size c,. Word embedding is di-\nrectly from the released word embedding matrix\nby Lin et al. (2016)°. Position embedding has the\nsame setting with the previous works: the maxi-\nmum distance of -30 and 30. Some detailed hy-\nperparameter settings are displayed in Table 1.\n\n4.2. Training Process of DSGAN\n\nBecause adversarial learning is widely regarded\nas an effective but unstable technique, here\nwe illustrate some property changes during the\ntraining process, in which way to indicate the\nlearning trend of our proposed approach. We\nuse 3 relation types as the examples: /busi-\nness/person/company, /people/person/place_lived\nand = /location/neighborhood/Meighborhood_of.\nBecause they are from three major classes (bussi-\nness, people, location) of Reidel dataset and they\nall have enough distant-supervised instances.\nThe first row in Figure 3 shows the classification\nability change of the discriminator during training.\nThe accuracy is calculated from the negative set\nNP. At the beginning of adversarial learning, the\n\n3https://github.com/thunlp/NRE\n", "vlm_text": "3.3 Cleaning Noisy Dataset with Generator \nAfter our adversarial learning process, we obtain one generator for one relation type; These genera- tors possess the capability of generating true pos- itive samples for the corresponding relation type. Thus, we can adopt the generator to ﬁlter the noise samples from distant supervision dataset. Simply and clearly, we utilize the generator as a binary classiﬁer. In order to reach the maximum utiliza- tion of data, we develop a strategy: for an en- tity pair with a set of annotated sentences, if all of these sentences are determined as false nega- tive by our generator, this entity pair will be redis- tributed into the negative set. Under this strategy, the scale of distant supervision training set keeps unchanged. \n4 Experiments \nThis paper proposes an adversarial learning strat- egy to detect true positive samples from the noisy distant supervision dataset. Due to the absence of supervised information, we deﬁne a genera- tor to heuristically learn to recognize true posi- tive samples through competing with a discrim- inator. Therefore, our experiments are intended to demonstrate that our DSGAN method possess this capability. To this end, we ﬁrst brieﬂy intro- duce the dataset and the evaluation metrics. Em- pirically, the adversarial learning process, to some extent, has instability; Therefore, we next illus- trate the convergence of our adversarial training process. Finally, we demonstrate the efﬁciency of our generator from two angles: the quality of the generated samples and the performance on the widely-used distant supervision relation extraction task. \n4.1 Evaluation and Implementation Details \nThe Reidel dataset 2   ( Riedel et al. ,  2010 ) is a commonly-used distant supervision relation ex- traction dataset. Freebase is a huge knowledge base including billions of triples: the entity pair and the speciﬁc relationship between them. Given these triples, the sentences of each entity pair are selected from the New York Times corpus(NYT). Entity mentions of NYT corpus are recognized by the Stanford named entity recognizer ( Finkel et al. , 2005 ). There are 52 actual relationships and a spe- cial relation    $N A$   which indicates there is no rela- tion between head and tail entities. Entity pairs of \nThe table lists various hyperparameters and their values:\n\n1. **CNN Window \\(c_w\\), kernel size \\(c_k\\)**: 3, 100\n2. **Word embedding \\(d_e\\), \\(|V|\\)**: 50, 114042\n3. **Position embedding \\(d_p\\)**: 5\n4. **Learning rate of G, D**: 1e-5, 1e-4\n $N A$   are deﬁned as the entity pairs that appear in the same sentence but are not related according to Freebase. \nDue to the absence of the corresponding labeled dataset, there is not a ground-truth test dataset to evaluate the performance of distant supervision re- lation extraction system. Under this circumstance, the previous work adopt the held-out evaluation to evaluate their systems, which can provide an approximate measure of precision without requir- ing costly human evaluation. It builds a test set where entity pairs are also extracted from Free- base. Similarly, relation facts that discovered from test articles are automatically compared with those in Freebase. CNN is widely used in relation clas- siﬁcation ( Santos et al. ,  2015 ;  Qin et al. ,  2017 ), thus the generator and the discriminator are both modeled as a simple CNN with the window size  $c_{w}$   and the kernel size    $c_{k}$  . Word embedding is di- rectly from the released word embedding matrix by  Lin et al.    $(2016)^{3}$  . Position embedding has the same setting with the previous works: the maxi- mum distance of  $-30$   and 30. Some detailed hy- perparameter settings are displayed in Table  1 . \n4.2 Training Process of DSGAN \nBecause adversarial learning is widely regarded as an effective but unstable technique, here we illustrate some property changes during the training process, in which way to indicate the learning trend of our proposed approach. We use 3 relation types as the examples: /busi- ness/person/company ,  /people/person/place lived and /location/neighborhood/neighborhood of . Because they are from three major classes ( bussi- ness ,  people ,  location ) of Reidel dataset and they all have enough distant-supervised instances. The ﬁrst row in Figure  3  shows the classiﬁcation ability change of the discriminator during training. The accuracy is calculated from the negative set  $N^{D}$  . At the beginning of adversarial learning, the "}
{"page": 6, "image_path": "doc_images/P18-1046_6.jpg", "ocr_text": "/ousiness/person/company Ipeople/person/place_lived Nocationineighborhood/neighborhood_of\n\nAccuracy\nAccuracy\n\nBag Sequence\n\nBag Sequence\n\nBag Sequence\n\nIbusiness/person/company Ipeople/person/place_lived\n\nNocation/neighborhood/neighborhood_of\n\nre eet\nBoss\nBors\niy\n“= Random “Random ” “~ Random\n-> Pre-training * Pre-training ov |= Pre-training\n-= DSGAN “= DSGAN 078 |= DSGAN\n\nEpoch\n\nEpoch\n\nEpoch\n\nFigure 3: The convergence of the DSGAN training process for 3 relation types and the performance of\ntheir corresponding generators. The figures in the first row present the performance change on N? in\nsome specific epochs during processing the B = {B!, B?,...B}. Each curve stands for one epoch;\nThe color of curves become darker as long as the epoch goes on. Because the discriminator reloads\nthe pre-trained parameters at the beginning of each epoch, all curves start from the same point for each\nrelation type; Along with the adversarial training, the generator gradually collapses the discriminator.\nThe figures in the second row reflect the performance of generators from the view of the difficulty level\nof training with the positive datasets that are generated by different strategies. Based on the noisy DS\npositive dataset P, DSGAN represents that the cleaned positive dataset is generated by our DSGAN\ngenerator; Random means that the positive set is randomly selected from P; Pre-training denotes thai\nthe dataset is selected according to the prediction probability of the pre-trained generator. These three\nnew positive datasets are in the same size.\n\ndiscriminator performs well on N?; moreover, the noisy dataset; this critical point is yielded\n\nN? is not used during adversarial training.\nTherefore, the accuracy on N DP is the criterion\nto reflect the performance of the discriminator.\nIn the early epochs, the generated samples from\nthe generator increases the accuracy, because it\nhas not possessed the ability of challenging the\ndiscriminator; however, as the training epoch\nincreases, this accuracy gradually decreases,\nwhich means the discriminator becomes weaker.\nIt is because the generator gradually learn to\ngenerate more accurate true positive samples in\neach bag. After the proposed adversarial learning\nprocess, the generator is strong enough to collapse\nthe discriminator. Figure 4 gives more intuitive\ndisplay of the trend of accuracy. Note that there\nis a critical point of the decline of accuracy for\neach presented relation types. It is because that\nthe chance we give the generator to challenge\nthe discriminator is just one time scanning of\n\nwhen the generator has already been robus\nenough. Thus, we stop the training process when\nthe model reaches this critical point. To sum\nup, the capability of our generator can steadily\nincreases, which indicates that DSGAN is a robus\nadversarial learning strategy.\n\n4.3 Quality of Generator\n\nDue to the absence of supervised information, we\nvalidate the quality of the generator from another\nangle. Combining with Figure 1, for one rela-\ntion type, the true positive samples must have\nidently higher relevance (the cluster of purple\ncles). Therefore, a positive set with more true\npositive samples is easier to be trained; In other\nwords, the convergence speed is faster and the fit-\nting degree on training set is higher. Based on\nthis , we present the comparison tests in the sec-\nond row of Figure 3. We build three positive\n\nev-\ncir-\n\n502\n", "vlm_text": "This image consists of six line graphs organized into two rows and three columns. \n\nThe top row of graphs shows \"Accuracy\" on the y-axis, plotted against \"Bag Sequence\" on the x-axis. The categories for each graph are labeled above each chart as \"/business/person/company,\" \"/people/person/place_lived,\" and \"/location/neighborhood/neighborhood_of.\" In each of these graphs, accuracy trends are plotted for different methods, represented by lines of varied shades of blue and a black line. Generally, the graphs show a downward trend in accuracy as the bag sequence increases.\n\nThe bottom row of graphs shows the \"F1 Score\" on the y-axis, plotted against \"Epoch\" on the x-axis, for the same categories as the top row. In these graphs, the methods are indicated by different symbols and colors: black triangles for \"Random,\" blue circles for \"Pre-training,\" and red squares for \"DSGAN.\" These graphs generally show an upward trend in F1 Score as epochs increase, with DSGAN consistently achieving the highest F1 scores.\n\nOverall, these graphs appear to represent the performance of different learning strategies across various categories, evaluating them in terms of accuracy and F1 score over increasing bag sequences and epochs, respectively.\nFigure 3: The convergence of the DSGAN training process for 3 relation types and the performance of their corresponding generators. The ﬁgures in the ﬁrst row present the performance change on    $N^{D}$    in some speciﬁc epochs during processing the    $B\\,=\\,\\{B^{1},B^{2},\\bar{...}B^{N}\\}$  . Each curve stands for one epoch; The color of curves become darker as long as the epoch goes on. Because the discriminator reloads the pre-trained parameters at the beginning of each epoch, all curves start from the same point for each relation type; Along with the adversarial training, the generator gradually collapses the discriminator. The ﬁgures in the second row reﬂect the performance of generators from the view of the difﬁculty level of training with the positive datasets that are generated by different strategies. Based on the noisy DS positive dataset    $P$  ,  DSGAN  represents that the cleaned positive dataset is generated by our DSGAN generator;  Random  means that the positive set is randomly selected from    $P$  ;  Pre-training  denotes that the dataset is selected according to the prediction probability of the pre-trained generator. These three new positive datasets are in the same size. \ndiscriminator performs well on    $N^{D}$  ; moreover,  $N^{D}$    is not used during adversarial training. Therefore, the accuracy on    $N^{D}$    is the criterion to reﬂect the performance of the discriminator. In the early epochs, the generated samples from the generator increases the accuracy, because it has not possessed the ability of challenging the discriminator; however, as the training epoch increases, this accuracy gradually decreases, which means the discriminator becomes weaker. It is because the generator gradually learn to generate more accurate true positive samples in each bag. After the proposed adversarial learning process, the generator is strong enough to collapse the discriminator. Figure  4  gives more intuitive display of the trend of accuracy. Note that there is a critical point of the decline of accuracy for each presented relation types. It is because that the chance we give the generator to challenge the discriminator is just one time scanning of the noisy dataset; this critical point is yielded when the generator has already been robust enough. Thus, we stop the training process when the model reaches this critical point. To sum up, the capability of our generator can steadily increases, which indicates that DSGAN is a robust adversarial learning strategy. \n\n4.3 Quality of Generator \nDue to the absence of supervised information, we validate the quality of the generator from another angle. Combining with Figure  1 , for one rela- tion type, the true positive samples must have ev- idently higher relevance (the cluster of purple cir- cles). Therefore, a positive set with more true positive samples is easier to be trained; In other words, the convergence speed is faster and the ﬁt- ting degree on training set is higher. Based on this , we present the comparison tests in the sec- ond row of Figure  3 . We build three positive "}
{"page": 7, "image_path": "doc_images/P18-1046_7.jpg", "ocr_text": "~#- /business/person/company\n“= /people/person/place_lived\n-* /location/neighborhood/neighborhood_of\n\n15 2s 35 4s\n\nEpoch\n\n58\n\nFigure 4: The performance change of the discrim-\ninator on N? during the training process. Each\npoint in the curves records the prediction accuracy\non N? when finishing each epoch. We stop the\ntraining process when this accuracy no longer de-\ncreases.\n\ndatasets from the noisy distant supervision dataset\nP: the randomly-selected positive set, the positive\nset base on the pre-trained generator and the pos-\nitive set base on the DSGAN generator. For the\npre-trained generator, the positive set is selected\naccording to the probability of being positive from\nhigh to low. These three sets have the same size\nand are accompanied by the same negative set.\nObviously, the positive set from the DSGAN gen-\nerator yields the best performance, which indicates\nthat our adversarial learning process is able to pro-\nduce a robust true-positive generator. In addition,\nthe pre-trained generator also has a good perfor-\nmance; however, compared with the DSGAN gen-\nerator, it cannot provide the boundary between the\nfalse positives and the true positives.\n\n4.4 Performance on Distant Supervision\nRelation Extraction\n\nBased on the proposed adversarial learning pro-\ncess, we obtain a generator that can recognize the\ntrue positive samples from the noisy distant super-\nvision dataset. Naturally, the improvement of dis-\ntant supervision relation extraction can provide a\nintuitive evaluation of our generator. We adopt the\nstrategy mentioned in Section 3.3 to relocate the\ndataset. After obtaining this redistributed dataset,\nwe apply it to train the recent state-of-the-art mod-\nels and observe whether it brings further improve-\nment for these systems. Zeng et al. (2015) and Lin\net al. (2016) are both the robust models to solve\nwrong labeling problem of distant supervision re-\nlation extraction. According to the comparison\ndisplayed in Figure 5 and Figure 6, all four mod-\n\n503\n\n—8— CNN+ONE\n\n© CNN+ONE+DSGAN\n—2—CNN+ATT\n~*~ CNN+ATT+DSGAN\n\nPrecision\n\n02\nRecall\n\n025\n\nFigure 5: Aggregate PR curves of CNN based\nmodel.\n\n—4— PCNN+ONE\n\n—o—PCNN+ONE+DSGAN.\n© PCNN+ATT\n\n+ PCNN+ATT+DSGAN\n\nPrecision\n\nRecall\n\nFigure 6: Aggregate PR curves of PCNN based\nmodel.\n\nels (CNN+ONE, CNN+ATT, PCNN+ONE and\nPCNN+ATT) achieve further improvement.\n\nEven though Zeng et al. (2015) and Lin et al.\n(2016) are designed to alleviate the influence of\nfalse positive samples, both of them merely focus\non the noise filtering in the sentence bag of en-\nity pairs. Zeng et al. (2015) combine at-least-one\nmulti-instance learning with deep neural network\n0 extract only one active sentence to represent the\narget entity pair; Lin et al. (2016) assign soft at-\nention weights to the representations of all sen-\nences of one entity pair, then employ the weighted\nsum of these representations to predict the rela-\nion between the target entity pair. However, from\nour manual inspection of Riedel dataset (Riedel\net al., 2010), we found another false positive case\nhat all the sentences of a specific entity pair are\nwrong; but the aforementioned methods overlook\n\n", "vlm_text": "The image is a line graph displaying the performance change of a discriminator on $N^{D}$ during the training process over multiple epochs. The x-axis represents the number of epochs (ranging from 5 to 85), while the y-axis indicates the accuracy (ranging from 0.5 to 1.05). There are three curves on the graph, each representing a different category:\n\n1. **Blue curve with triangular markers**: Represents the category \"/business/person/company.\" The accuracy starts near 1, decreases over time, and seems to stabilize around 0.85.\n\n2. **Red curve with square markers**: Represents the category \"/people/person/place_lived.\" The accuracy also starts near 1, decreases more steeply compared to the blue curve, and appears to stabilize slightly below 0.75.\n\n3. **Black curve with circular markers**: Represents the category \"/location/neighborhood/neighborhood_of.\" This curve starts at accuracy 1 and remains consistently high, slightly decreasing over time, but largely maintaining an accuracy above 0.95.\n\nThe training process was stopped when the discriminator's accuracy on $N^{D}$ no longer decreased significantly. Each point on the curves marks the prediction accuracy for each epoch.\n\n\ndatasets from the noisy distant supervision dataset  $P$  : the randomly-selected positive set, the positive set base on the pre-trained generator and the pos- itive set base on the DSGAN generator. For the pre-trained generator, the positive set is selected according to the probability of being positive from high to low. These three sets have the same size and are accompanied by the same negative set. Obviously, the positive set from the DSGAN gen- erator yields the best performance, which indicates that our adversarial learning process is able to pro- duce a robust true-positive generator. In addition, the pre-trained generator also has a good perfor- mance; however, compared with the DSGAN gen- erator, it cannot provide the boundary between the false positives and the true positives. \n4.4 Performance on Distant Supervision Relation Extraction \nBased on the proposed adversarial learning pro- cess, we obtain a generator that can recognize the true positive samples from the noisy distant super- vision dataset. Naturally, the improvement of dis- tant supervision relation extraction can provide a intuitive evaluation of our generator. We adopt the strategy mentioned in Section  3.3  to relocate the dataset. After obtaining this redistributed dataset, we apply it to train the recent state-of-the-art mod- els and observe whether it brings further improve- ment for these systems.  Zeng et al.  ( 2015 ) and  Lin et al.  ( 2016 ) are both the robust models to solve wrong labeling problem of distant supervision re- lation extraction. According to the comparison displayed in Figure  5  and Figure  6 , all four mod- \nThe image is a Precision-Recall (PR) curve graph that represents the performance of different models, labeled as CNN-based models, in terms of precision and recall. The graph compares four different configurations of a CNN-based model:\n\n1. **CNN+ONE** - Represented with blue triangles.\n2. **CNN+ONE+DSGAN** - Represented with red circles.\n3. **CNN+ATT** - Represented with black squares.\n4. **CNN+ATT+DSGAN** - Represented with magenta diamonds.\n\nThe x-axis shows the recall values ranging from 0 to 0.4, while the y-axis shows the precision values ranging from 0.3 to 1.0. Each curve illustrates the trade-off between precision and recall for the respective model configuration. The legend at the top right corner indicates which symbol corresponds to each model. The curves visually depict how well each model configuration balances precision and recall, which are crucial metrics in classification problems, especially in contexts where false positives and false negatives have different impacts.\nThe image is a graph displaying aggregate Precision-Recall (PR) curves for models based on PCNN (Piecewise Convolutional Neural Network). The curves compare four different approaches:\n\n1. PCNN + ONE (blue line with triangles)\n2. PCNN + ONE + DSGAN (red line with circles)\n3. PCNN + ATT (black line with squares)\n4. PCNN + ATT + DSGAN (magenta line with stars)\n\nThe x-axis represents Recall, while the y-axis represents Precision. The graph shows how each model's performance varies as recall changes. The PCNN + ATT + DSGAN configuration generally appears to maintain higher precision at various recall levels compared to the others.\nels   $(C N N+O N E$  ,    $C N N{+}A T T$  ,    $P C N N+O N E$   and  $P C N N{+}A T T)$  ) achieve further improvement. \nEven though  Zeng et al.  ( 2015 ) and  Lin et al. ( 2016 ) are designed to alleviate the inﬂuence of false positive samples, both of them merely focus on the noise ﬁltering in the sentence bag of en- tity pairs.  Zeng et al.  ( 2015 ) combine at-least-one multi-instance learning with deep neural network to extract only one active sentence to represent the target entity pair;  Lin et al.  ( 2016 ) assign soft at- tention weights to the representations of all sen- tences of one entity pair, then employ the weighted sum of these representations to predict the rela- tion between the target entity pair. However, from our manual inspection of Riedel dataset ( Riedel et al. ,  2010 ), we found another false positive case that all the sentences of a speciﬁc entity pair are wrong; but the aforementioned methods overlook "}
{"page": 8, "image_path": "doc_images/P18-1046_8.jpg", "ocr_text": "Model - +DSGAN p-value\nCNN+ONE 0.177 0.189 4.37e-04\nCNN+ATT 0.219 0.226 8.36e-03\nPCNN+ONE _ 0.206 0.221 2.89e-06\nPCNN+ATT 0.253 0.264 2.34e-03\nTable 2: Comparison of AUC values between\n\nprevious studies and our DSGAN method. The p-\nvalue stands for the result of t-test evaluation.\n\nthis case, while the proposed method can solve this\nproblem. Our DSGAN pipeline is independent of\nthe relation prediction of entity pairs, so we can\nadopt our generator as the true-positive indicator\nto filter the noisy distant supervision dataset be-\nfore relation extraction, which explains the origin\nof these further improvements in Figure 5 and Fig-\nure 6. In order to give more intuitive compari-\nson, in Table 2, we present the AUC value of each\nPR curve, which reflects the area size under these\ncurves. The larger value of AUC reflects the better\nperformance. Also, as can be seen from the result\nof t-test evaluation, all the p-values are less than\n5e-02, so the improvements are obvious.\n\n5 Conclusion\n\nDistant supervision has become a standard method\nin relation extraction. However, while it brings\nthe convenience, it also introduces noise in dis-\ntantly labeled sentences. In this work, we propose\nthe first generative adversarial training method\nfor robust distant supervision relation extraction.\nMore specifically, our framework has two com-\nponents: a generator that generates true positives,\nand a discriminator that tries to classify positive\nand negative data samples. With adversarial train-\ning, our goal is to gradually decrease the perfor-\nmance of the discriminator, while the generator\nimproves the performance for predicting true pos-\nitives when reaching equilibrium. Our approach\nis model-agnostic, and thus can be applied to any\ndistant supervision model. Empirically, we show\nthat our method can significantly improve the per-\nformances of many competitive baselines on the\nwidely used New York Time dataset.\n\nAcknowledge\n\nThis work was supported by National Natural Sci-\nence Foundation of China (61702047), Beijing\nNatural Science Foundation (4174098), the Fun-\ndamental Research Funds for the Central Univer-\n\n504\n\nsities (2017RCO2) and National Natural Science\nFoundation of China (61703234)\n\nReferences\n\nRazvan Bunescu and Raymond J Mooney. 2005. Sub-\nsequence kernels for relation extraction. In NIPS,\npages 171-178.\n\nLiwei Cai and William Yang Wang. 2017. Kbgan: Ad-\nversarial learning for knowledge graph embeddings.\narXiv preprint arXiv:1711.04071.\n\nJenny Rose Finkel, Trond Grenager, and Christopher\nManning. 2005. Incorporating non-local informa-\ntion into information extraction systems by gibbs\nsampling. In Proceedings of the 43rd annual meet-\ning on association for computational linguistics,\npages 363-370. Association for Computational Lin-\nguistics.\n\nIan Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,\nBing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. 2014. Generative ad-\nversarial nets. In Advances in neural information\nprocessing systems, pages 2672-2680.\n\nZhou GuoDong, Su Jian, Zhang Jie, and Zhang Min.\n2005. Exploring various knowledge in relation ex-\ntraction. In Proceedings of the 43rd annual meeting\non association for computational linguistics, pages\n427-434. Association for Computational Linguis-\ntics.\n\nRaphael Hoffmann, Congle Zhang, Xiao Ling, Luke\nZettlemoyer, and Daniel S Weld. 2011. Knowledge-\nbased weak supervision for information extraction\nof overlapping relations. In Proceedings of the 49th\nAnnual Meeting of the Association for Computa-\ntional Linguistics: Human Language Technologies-\nVolume 1, pages 541-550. Association for Compu-\ntational Linguistics.\n\nDaniel Jiwoong Im, Chris Dongjoo Kim, Hui Jiang,\nand Roland Memisevic. 2016. Generating images\nwith recurrent adversarial networks. arXiv preprint\narXiv: 1602.05110.\n\nGuoliang Ji, Kang Liu, Shizhu He, Jun Zhao, et al.\n2017. Distant supervision for relation extraction\nwith sentence-level attention and entity descriptions.\nIn AAAI, pages 3060-3066.\n\nYankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan,\nand Maosong Sun. 2016. Neural relation extraction\nwith selective attention over instances. In ACL (1).\n\nMike Mintz, Steven Bills, Rion Snow, and Dan Juraf-\nsky. 2009. Distant supervision for relation extrac-\ntion without labeled data. In Proceedings of the\nJoint Conference of the 47th Annual Meeting of the\nACL and the 4th International Joint Conference on\nNatural Language Processing of the AFNLP: Vol-\nume 2-Volume 2, pages 1003-1011. Association for\nComputational Linguistics.\n", "vlm_text": "The table presents a comparison of model performance with and without the addition of DSGAN across different models. Specifically, it includes:\n\n1. **Model Column:**\n   - CNN+ONE\n   - CNN+ATT\n   - PCNN+ONE\n   - PCNN+ATT\n\n2. **Performance without DSGAN (- Column):**\n   - CNN+ONE: 0.177\n   - CNN+ATT: 0.219\n   - PCNN+ONE: 0.206\n   - PCNN+ATT: 0.253\n\n3. **Performance with DSGAN (+DSGAN Column):**\n   - CNN+ONE: 0.189\n   - CNN+ATT: 0.226\n   - PCNN+ONE: 0.221\n   - PCNN+ATT: 0.264\n\n4. **P-value Column:**\n   - CNN+ONE: 4.37e-04\n   - CNN+ATT: 8.36e-03\n   - PCNN+ONE: 2.89e-06\n   - PCNN+ATT: 2.34e-03\n\nThe +DSGAN column values are bolded, indicating the enhancement in performance metrics when DSGAN is applied. The p-values suggest the statistical significance of the changes in performance between the methods without DSGAN and those with DSGAN for each model configuration.\nthis case, while the proposed method can solve this problem. Our DSGAN pipeline is independent of the relation prediction of entity pairs, so we can adopt our generator as the true-positive indicator to ﬁlter the noisy distant supervision dataset be- fore relation extraction, which explains the origin of these further improvements in Figure  5  and Fig- ure  6 . In order to give more intuitive compari- son, in Table  2 , we present the AUC value of each PR curve, which reﬂects the area size under these curves. The larger value of AUC reﬂects the better performance. Also, as can be seen from the result of t-test evaluation, all the p-values are less than 5e-02, so the improvements are obvious. \n5 Conclusion \nDistant supervision has become a standard method in relation extraction. However, while it brings the convenience, it also introduces noise in dis- tantly labeled sentences. In this work, we propose the ﬁrst generative adversarial training method for robust distant supervision relation extraction. More speciﬁcally, our framework has two com- ponents: a generator that generates true positives, and a discriminator that tries to classify positive and negative data samples. With adversarial train- ing, our goal is to gradually decrease the perfor- mance of the discriminator, while the generator improves the performance for predicting true pos- itives when reaching equilibrium. Our approach is model-agnostic, and thus can be applied to any distant supervision model. Empirically, we show that our method can signiﬁcantly improve the per- formances of many competitive baselines on the widely used New York Time dataset. \nAcknowledge \nThis work was supported by National Natural Sci- ence Foundation of China (61702047), Beijing Natural Science Foundation (4174098), the Fun- damental Research Funds for the Central Univer- sities (2017RC02) and National Natural Science Foundation of China (61703234) \n\nReferences \nRazvan Bunescu and Raymond J Mooney. 2005. Sub- sequence kernels for relation extraction. In  NIPS , pages 171–178. \nLiwei Cai and William Yang Wang. 2017. Kbgan: Ad- versarial learning for knowledge graph embeddings. arXiv preprint arXiv:1711.04071 . \nJenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local informa- tion into information extraction systems by gibbs sampling. In  Proceedings of the 43rd annual meet- ing on association for computational linguistics , pages 363–370. Association for Computational Lin- guistics. \nIan Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative ad- versarial nets. In  Advances in neural information processing systems , pages 2672–2680. \nZhou GuoDong, Su Jian, Zhang Jie, and Zhang Min. 2005. Exploring various knowledge in relation ex- traction. In  Proceedings of the 43rd annual meeting on association for computational linguistics , pages 427–434. Association for Computational Linguis- tics. \nRaphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledge- based weak supervision for information extraction of overlapping relations. In  Proceedings of the 49th Annual Meeting of the Association for Computa- tional Linguistics: Human Language Technologies- Volume 1 , pages 541–550. Association for Compu- tational Linguistics. \nDaniel Jiwoong Im, Chris Dongjoo Kim, Hui Jiang, and Roland Memisevic. 2016. Generating images with recurrent adversarial networks.  arXiv preprint arXiv:1602.05110 . \nGuoliang Ji, Kang Liu, Shizhu He, Jun Zhao, et al. 2017. Distant supervision for relation extraction with sentence-level attention and entity descriptions. In  AAAI , pages 3060–3066. \nYankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, and Maosong Sun. 2016. Neural relation extraction with selective attention over instances. In  ACL (1) . \nMike Mintz, Steven Bills, Rion Snow, and Dan Juraf-sky. 2009. Distant supervision for relation extrac- tion without labeled data. In  Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Vol- ume 2-Volume 2 , pages 1003–1011. Association for Computational Linguistics. "}
{"page": 9, "image_path": "doc_images/P18-1046_9.jpg", "ocr_text": "Thien Huu Nguyen and Ralph Grishman. 2015. Event\ndetection and domain adaptation with convolutional\nneural networks. In ACL (2), pages 365-371.\n\nPengda Qin, Weiran Xu, and Jun Guo. 2017. De-\nsigning an adaptive attention mechanism for relation\nclassification. In Neural Networks (IJCNN), 2017\nInternational Joint Conference on, pages 4356—\n4362. IEEE.\n\nAlec Radford, Luke Metz, and Soumith Chintala.\n2015. Unsupervised representation learning with\ndeep convolutional generative adversarial networks.\narXiv preprint arXiv: 1511.06434.\n\nSebastian Riedel, Limin Yao, and Andrew McCal-\nlum. 2010. Modeling relations and their mentions\nwithout labeled text. In Machine Learning and\nKnowledge Discovery in Databases, pages 148-163.\nSpringer.\n\nBenjamin Roth, Tassilo Barth, Michael Wiegand, and\nDietrich Klakow. 2013. A survey of noise reduction\nmethods for distant supervision. In Proceedings of\nthe 2013 workshop on Automated knowledge base\nconstruction, pages 73-78. ACM.\n\nCicero Nogueira dos Santos, Bing Xiang, and Bowen\nZhou. 2015. Classifying relations by ranking with\nconvolutional neural networks. arXiv _ preprint\narXiv:1504.06580.\n\nYatian Shen and Xuanjing Huang. 2016. Attention-\nbased convolutional neural network for semantic re-\nlation extraction. In Proceedings of COLING 2016,\nthe 26th International Conference on Computational\nLinguistics: Technical Papers.\n\nMihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,\nand Christopher D Manning. 2012. Multi-instance\nmulti-label learning for relation extraction. In Pro-\nceedings of the 2012 Joint Conference on Empirical\nMethods in Natural Language Processing and Com-\nputational Natural Language Learning, pages 455—\n465. Association for Computational Linguistics.\n\nShingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.\n2012. Reducing wrong labels in distant supervi-\nsion for relation extraction. In Proceedings of the\n50th Annual Meeting of the Association for Compu-\ntational Linguistics: Long Papers-Volume 1, pages\n721-729. Association for Computational Linguis-\ntics.\n\nJun Wang, Lantao Yu, Weinan Zhang, Yu Gong,\nYinghui Xu, Benyou Wang, Peng Zhang, and Dell\nZhang. 2017. Irgan: A minimax game for uni-\nfying generative and discriminative information re-\ntrieval models. In Proceedings of the 40th Interna-\ntional ACM SIGIR conference on Research and De-\nvelopment in Information Retrieval, pages 515-524.\nACM.\n\nYongqin Xian, Bernt Schiele, and Zeynep Akata. 2017.\nZero-shot learning-the good, the bad and the ugly.\narXiv preprint arXiv: 1703.04394.\n\n505\n\nDmitry Zelenko, Chinatsu Aone, and Anthony\nRichardella. 2003. Kernel methods for relation ex-\ntraction. Journal of machine learning research,\n3(Feb): 1083-1106.\n\nDaojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao.\n2015. Distant supervision for relation extraction via\npiecewise convolutional neural networks. In Pro-\nceedings of the 2015 Conference on Empirical Meth-\nods in Natural Language Processing (EMNLP), Lis-\nbon, Portugal, pages 17-21.\n\nDaojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,\nJun Zhao, et al. 2014. Relation classification via\nconvolutional deep neural network. In COLING,\npages 2335-2344.\n", "vlm_text": "Thien Huu Nguyen and Ralph Grishman. 2015. Event detection and domain adaptation with convolutional neural networks. In  ACL (2) , pages 365–371. Pengda Qin, Weiran Xu, and Jun Guo. 2017. De- signing an adaptive attention mechanism for relation classiﬁcation. In  Neural Networks (IJCNN), 2017 International Joint Conference on , pages 4356– 4362. IEEE. Alec Radford, Luke Metz, and Soumith Chintala. 2015. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 . Sebastian Riedel, Limin Yao, and Andrew McCal- lum. 2010. Modeling relations and their mentions without labeled text. In  Machine Learning and Knowledge Discovery in Databases , pages 148–163. Springer. Benjamin Roth, Tassilo Barth, Michael Wiegand, and Dietrich Klakow. 2013. A survey of noise reduction methods for distant supervision. In  Proceedings of the 2013 workshop on Automated knowledge base construction , pages 73–78. ACM. Cicero Nogueira dos Santos, Bing Xiang, and Bowen Zhou. 2015. Classifying relations by ranking with convolutional neural networks. arXiv preprint arXiv:1504.06580 . Yatian Shen and Xuanjing Huang. 2016. Attention- based convolutional neural network for semantic re- lation extraction. In  Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers . Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multi-label learning for relation extraction. In  Pro- ceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Com- putational Natural Language Learning , pages 455– 465. Association for Computational Linguistics. Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. 2012. Reducing wrong labels in distant supervi- sion for relation extraction. In  Proceedings of the 50th Annual Meeting of the Association for Compu- tational Linguistics: Long Papers-Volume 1 , pages 721–729. Association for Computational Linguis- tics. Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, and Dell Zhang. 2017. Irgan: A minimax game for uni- fying generative and discriminative information re- trieval models. In  Proceedings of the 40th Interna- tional ACM SIGIR conference on Research and De- velopment in Information Retrieval , pages 515–524. ACM. Yongqin Xian, Bernt Schiele, and Zeynep Akata. 2017. Zero-shot learning-the good, the bad and the ugly. arXiv preprint arXiv:1703.04394 . \nDmitry Zelenko, Chinatsu Aone, and Anthony Richardella. 2003. Kernel methods for relation ex- traction. Journal of machine learning research , 3(Feb):1083–1106. Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao. 2015. Distant supervision for relation extraction via piecewise convolutional neural networks. In  Pro- ceedings of the 2015 Conference on Empirical Meth- ods in Natural Language Processing (EMNLP), Lis- bon, Portugal , pages 17–21. Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, Jun Zhao, et al. 2014. Relation classiﬁcation via convolutional deep neural network. In  COLING , pages 2335–2344. "}
